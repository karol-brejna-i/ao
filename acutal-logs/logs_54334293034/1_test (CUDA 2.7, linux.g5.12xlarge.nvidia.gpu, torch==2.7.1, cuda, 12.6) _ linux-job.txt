2026-01-14T08:15:21.4801533Z Current runner version: '2.331.0'
2026-01-14T08:15:21.4807973Z Runner name: 'i-0aed5ecec1ba167a3'
2026-01-14T08:15:21.4808729Z Runner group name: 'default'
2026-01-14T08:15:21.4809567Z Machine name: 'ip-10-0-71-162'
2026-01-14T08:15:21.4812487Z ##[group]GITHUB_TOKEN Permissions
2026-01-14T08:15:21.4814855Z Contents: read
2026-01-14T08:15:21.4815385Z Metadata: read
2026-01-14T08:15:21.4815901Z Packages: read
2026-01-14T08:15:21.4816403Z ##[endgroup]
2026-01-14T08:15:21.4818268Z Secret source: None
2026-01-14T08:15:21.4818891Z Prepare workflow directory
2026-01-14T08:15:21.5366761Z Prepare all required actions
2026-01-14T08:15:21.5403316Z Getting action download info
2026-01-14T08:15:21.8611634Z Download action repository 'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' (SHA:11bd71901bbe5b1630ceea73d27597364c9af683)
2026-01-14T08:15:22.1591570Z Download action repository 'pytorch/pytorch@main' (SHA:b321605fc7207c672be72497ceeb20cbb6367319)
2026-01-14T08:15:37.7063131Z Download action repository 'actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093' (SHA:d3f86a106a0bac45b974a628896c90dbdf5c8093)
2026-01-14T08:15:38.0785512Z Download action repository 'pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1' (SHA:a2c1430e2bddadbad9f49a6f9b879f062c6b19b1)
2026-01-14T08:15:38.2159321Z Download action repository 'actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02' (SHA:ea165f8d65b6e75b540449e92b4886f43607fa02)
2026-01-14T08:15:38.7080925Z Getting action download info
2026-01-14T08:15:38.8496469Z Getting action download info
2026-01-14T08:15:38.9965829Z Download action repository 'aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722' (SHA:ececac1a45f3b08a01d2dd070d28d111c5fe6722)
2026-01-14T08:15:39.2567938Z Download action repository 'aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076' (SHA:062b18b96a7aff071d4dc91bc00c4c1a7945b076)
2026-01-14T08:15:39.5038336Z Uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@refs/heads/main (479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:39.5042337Z ##[group] Inputs
2026-01-14T08:15:39.5044113Z   script: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:39.5046365Z   timeout: 180
2026-01-14T08:15:39.5046628Z   runner: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:39.5046946Z   upload-artifact: 
2026-01-14T08:15:39.5047481Z   upload-artifact-to-s3: false
2026-01-14T08:15:39.5047765Z   download-artifact: 
2026-01-14T08:15:39.5048003Z   repository: 
2026-01-14T08:15:39.5048246Z   fetch-depth: 1
2026-01-14T08:15:39.5048468Z   submodules: recursive
2026-01-14T08:15:39.5048712Z   ref: 
2026-01-14T08:15:39.5048957Z   test-infra-repository: pytorch/test-infra
2026-01-14T08:15:39.5049301Z   test-infra-ref: 
2026-01-14T08:15:39.5049555Z   use-custom-docker-registry: true
2026-01-14T08:15:39.5049888Z   docker-image: pytorch/almalinux-builder
2026-01-14T08:15:39.5050281Z   docker-build-dir: .ci/docker
2026-01-14T08:15:39.5050563Z   gpu-arch-type: cuda
2026-01-14T08:15:39.5050813Z   gpu-arch-version: 12.6
2026-01-14T08:15:39.5051080Z   job-name: linux-job
2026-01-14T08:15:39.5051348Z   continue-on-error: false
2026-01-14T08:15:39.5051637Z   binary-matrix: 
2026-01-14T08:15:39.5051881Z   run-with-docker: true
2026-01-14T08:15:39.5052123Z   secrets-env: 
2026-01-14T08:15:39.5052352Z   no-sudo: false
2026-01-14T08:15:39.5052577Z ##[endgroup]
2026-01-14T08:15:39.5053036Z Complete job name: test (CUDA 2.7, linux.g5.12xlarge.nvidia.gpu, torch==2.7.1, cuda, 12.6) / linux-job
2026-01-14T08:15:39.6204933Z A job started hook has been configured by the self-hosted runner administrator
2026-01-14T08:15:39.6317896Z ##[group]Run '/home/ec2-user/runner-scripts/before_job.sh'
2026-01-14T08:15:39.6329564Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:39.6330229Z ##[endgroup]
2026-01-14T08:15:41.1442486Z Runner Type: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:41.1442986Z Instance Type: g5.12xlarge
2026-01-14T08:15:41.1443242Z AMI Name: unknown
2026-01-14T08:15:41.1490823Z AMI ID: ami-068c0051b15cdb816
2026-01-14T08:15:46.8912315Z ##[group]Run set -euxo pipefail
2026-01-14T08:15:46.8912693Z [36;1mset -euxo pipefail[0m
2026-01-14T08:15:46.8913011Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:15:46.8913413Z [36;1m  echo "::group::Cleanup with-sudo debug output"[0m
2026-01-14T08:15:46.8913831Z [36;1m  sudo rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:46.8914150Z [36;1melse[0m
2026-01-14T08:15:46.8914420Z [36;1m  echo "::group::Cleanup no-sudo debug output"[0m
2026-01-14T08:15:46.8914794Z [36;1m  rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:46.8915090Z [36;1mfi[0m
2026-01-14T08:15:46.8915292Z [36;1m[0m
2026-01-14T08:15:46.8915562Z [36;1mmkdir -p "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:46.8915920Z [36;1mecho "::endgroup::"[0m
2026-01-14T08:15:46.8931153Z shell: /usr/bin/bash -e {0}
2026-01-14T08:15:46.8931429Z env:
2026-01-14T08:15:46.8931683Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:46.8932047Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:46.8932339Z   PR_NUMBER: 3500
2026-01-14T08:15:46.8934046Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:46.8935816Z   NO_SUDO: false
2026-01-14T08:15:46.8936048Z ##[endgroup]
2026-01-14T08:15:46.8975172Z + [[ false == \f\a\l\s\e ]]
2026-01-14T08:15:46.8984864Z + echo '::group::Cleanup with-sudo debug output'
2026-01-14T08:15:46.8985333Z + sudo rm -rfv /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:46.8991089Z ##[group]Cleanup with-sudo debug output
2026-01-14T08:15:47.0090777Z removed directory '/home/ec2-user/actions-runner/_work/ao/ao'
2026-01-14T08:15:47.0114809Z + mkdir -p /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:47.0131438Z + echo ::endgroup::
2026-01-14T08:15:47.0131935Z ##[endgroup]
2026-01-14T08:15:47.0260686Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:15:47.0261142Z with:
2026-01-14T08:15:47.0261366Z   repository: pytorch/test-infra
2026-01-14T08:15:47.0261665Z   path: test-infra
2026-01-14T08:15:47.0261894Z   submodules: recursive
2026-01-14T08:15:47.0262269Z   token: ***
2026-01-14T08:15:47.0262485Z   ssh-strict: true
2026-01-14T08:15:47.0262699Z   ssh-user: git
2026-01-14T08:15:47.0262954Z   persist-credentials: true
2026-01-14T08:15:47.0263237Z   clean: true
2026-01-14T08:15:47.0263478Z   sparse-checkout-cone-mode: true
2026-01-14T08:15:47.0263780Z   fetch-depth: 1
2026-01-14T08:15:47.0264004Z   fetch-tags: false
2026-01-14T08:15:47.0264231Z   show-progress: true
2026-01-14T08:15:47.0264465Z   lfs: false
2026-01-14T08:15:47.0264680Z   set-safe-directory: true
2026-01-14T08:15:47.0264935Z env:
2026-01-14T08:15:47.0265186Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:47.0265543Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:47.0265818Z   PR_NUMBER: 3500
2026-01-14T08:15:47.0267513Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:47.0269267Z ##[endgroup]
2026-01-14T08:15:47.1657368Z Syncing repository: pytorch/test-infra
2026-01-14T08:15:47.1658321Z ##[group]Getting Git version info
2026-01-14T08:15:47.1658785Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/test-infra'
2026-01-14T08:15:47.1659431Z [command]/usr/bin/git version
2026-01-14T08:15:47.1662141Z git version 2.50.1
2026-01-14T08:15:47.1688714Z ##[endgroup]
2026-01-14T08:15:47.1704051Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/be085be7-8183-4413-8b65-c53656739d62' before making global git config changes
2026-01-14T08:15:47.1705136Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:15:47.1720502Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:47.1761440Z ##[group]Initializing the repository
2026-01-14T08:15:47.1766035Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:47.2042832Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:15:47.2043501Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:15:47.2044111Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:15:47.2044541Z hint:
2026-01-14T08:15:47.2044841Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:15:47.2045208Z hint:
2026-01-14T08:15:47.2045566Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:15:47.2046163Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:15:47.2046651Z hint:
2026-01-14T08:15:47.2046891Z hint: 	git branch -m <name>
2026-01-14T08:15:47.2047149Z hint:
2026-01-14T08:15:47.2047621Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:15:47.2053195Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.git/
2026-01-14T08:15:47.2065790Z [command]/usr/bin/git remote add origin https://github.com/pytorch/test-infra
2026-01-14T08:15:47.2114278Z ##[endgroup]
2026-01-14T08:15:47.2114729Z ##[group]Disabling automatic garbage collection
2026-01-14T08:15:47.2118925Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:15:47.2169874Z ##[endgroup]
2026-01-14T08:15:47.2170742Z ##[group]Setting up auth
2026-01-14T08:15:47.2176000Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:15:47.2215339Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:15:47.2654500Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:15:47.2689635Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:15:47.3116016Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:47.3165113Z ##[endgroup]
2026-01-14T08:15:47.3165784Z ##[group]Determining the default branch
2026-01-14T08:15:47.3168546Z Retrieving the default branch name
2026-01-14T08:15:47.6133791Z Default branch 'main'
2026-01-14T08:15:47.6134593Z ##[endgroup]
2026-01-14T08:15:47.6135010Z ##[group]Fetching the repository
2026-01-14T08:15:47.6140324Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
2026-01-14T08:15:47.9755421Z From https://github.com/pytorch/test-infra
2026-01-14T08:15:47.9788245Z  * [new branch]      main       -> origin/main
2026-01-14T08:15:47.9789179Z ##[endgroup]
2026-01-14T08:15:47.9789580Z ##[group]Determining the checkout info
2026-01-14T08:15:47.9790546Z ##[endgroup]
2026-01-14T08:15:47.9794937Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:15:47.9845158Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:15:47.9880041Z ##[group]Checking out the ref
2026-01-14T08:15:47.9882540Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-14T08:15:48.1845019Z Switched to a new branch 'main'
2026-01-14T08:15:48.1847399Z branch 'main' set up to track 'origin/main'.
2026-01-14T08:15:48.1861544Z ##[endgroup]
2026-01-14T08:15:48.1862208Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:15:48.1867232Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:48.1918043Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:15:48.1955668Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:15:48.1993538Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:15:48.2027305Z ##[endgroup]
2026-01-14T08:15:48.2028143Z ##[group]Fetching submodules
2026-01-14T08:15:48.2031074Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:15:48.2444542Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:15:48.2863409Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:15:48.3267599Z ##[endgroup]
2026-01-14T08:15:48.3268081Z ##[group]Persisting credentials for submodules
2026-01-14T08:15:48.3273213Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:15:48.3690190Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:15:48.4096889Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:15:48.4500949Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:15:48.4906740Z ##[endgroup]
2026-01-14T08:15:48.4960646Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:15:48.4993807Z 479ee761cd164688ad6fe63fbc0f27d255b35fe1
2026-01-14T08:15:48.5223786Z Prepare all required actions
2026-01-14T08:15:48.5224242Z Getting action download info
2026-01-14T08:15:48.6525291Z Download action repository 'pytorch/test-infra@main' (SHA:479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:50.7836869Z Getting action download info
2026-01-14T08:15:50.9037629Z Download action repository 'nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482' (SHA:3e91a01664abd3c5cd539100d10d33b9c5b68482)
2026-01-14T08:15:51.1287233Z ##[group]Run ./test-infra/.github/actions/setup-linux
2026-01-14T08:15:51.1287619Z env:
2026-01-14T08:15:51.1287887Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:51.1288247Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:51.1288508Z   PR_NUMBER: 3500
2026-01-14T08:15:51.1290303Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:51.1292027Z ##[endgroup]
2026-01-14T08:15:51.1378314Z ##[group]Run set -euo pipefail
2026-01-14T08:15:51.1378663Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:51.1378970Z [36;1mfunction get_ec2_metadata() {[0m
2026-01-14T08:15:51.1379359Z [36;1m  # Pulled from instance metadata endpoint for EC2[0m
2026-01-14T08:15:51.1380032Z [36;1m  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html[0m
2026-01-14T08:15:51.1380824Z [36;1m  category=$1[0m
2026-01-14T08:15:51.1381779Z [36;1m  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"[0m
2026-01-14T08:15:51.1382783Z [36;1m}[0m
2026-01-14T08:15:51.1383053Z [36;1mecho "ami-id: $(get_ec2_metadata ami-id)"[0m
2026-01-14T08:15:51.1383502Z [36;1mecho "instance-id: $(get_ec2_metadata instance-id)"[0m
2026-01-14T08:15:51.1384006Z [36;1mecho "instance-type: $(get_ec2_metadata instance-type)"[0m
2026-01-14T08:15:51.1384433Z [36;1mecho "system info $(uname -a)"[0m
2026-01-14T08:15:51.1393935Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:51.1394309Z env:
2026-01-14T08:15:51.1394582Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:51.1394946Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:51.1395228Z   PR_NUMBER: 3500
2026-01-14T08:15:51.1396910Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:51.1398666Z ##[endgroup]
2026-01-14T08:15:51.1569197Z ami-id: ami-068c0051b15cdb816
2026-01-14T08:15:51.1695708Z instance-id: i-0aed5ecec1ba167a3
2026-01-14T08:15:51.1824195Z instance-type: g5.12xlarge
2026-01-14T08:15:51.1839361Z system info Linux ip-10-0-71-162.ec2.internal 6.1.158-180.294.amzn2023.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Dec  1 05:36:50 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
2026-01-14T08:15:51.1883948Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:51.1885012Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:51.1894688Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:51.1895067Z env:
2026-01-14T08:15:51.1895336Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:51.1895691Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:51.1896192Z   PR_NUMBER: 3500
2026-01-14T08:15:51.1897857Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:51.1899588Z ##[endgroup]
2026-01-14T08:15:51.1990935Z ##[group]Run if ! docker version >/dev/null 2>/dev/null; then
2026-01-14T08:15:51.1991429Z [36;1mif ! docker version >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:51.1991864Z [36;1m  if systemctl is-active --quiet docker; then[0m
2026-01-14T08:15:51.1992266Z [36;1m      echo "Docker daemon is running...";[0m
2026-01-14T08:15:51.1992607Z [36;1m  else[0m
2026-01-14T08:15:51.1992961Z [36;1m      echo "Starting docker daemon..." && sudo systemctl start docker;[0m
2026-01-14T08:15:51.1993407Z [36;1m  fi[0m
2026-01-14T08:15:51.1993627Z [36;1mfi[0m
2026-01-14T08:15:51.2002238Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:51.2002607Z env:
2026-01-14T08:15:51.2002861Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:51.2003220Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:51.2003467Z   PR_NUMBER: 3500
2026-01-14T08:15:51.2005131Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:51.2007048Z ##[endgroup]
2026-01-14T08:15:51.2563925Z ##[group]Run AWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")
2026-01-14T08:15:51.2564681Z [36;1mAWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")[0m
2026-01-14T08:15:51.2565230Z [36;1mretry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }[0m
2026-01-14T08:15:51.2565879Z [36;1mretry aws ecr get-login-password --region "$AWS_DEFAULT_REGION" | docker login --username AWS \[0m
2026-01-14T08:15:51.2566654Z [36;1m    --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"[0m
2026-01-14T08:15:51.2577183Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:51.2577567Z env:
2026-01-14T08:15:51.2577840Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:51.2578209Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:51.2578469Z   PR_NUMBER: 3500
2026-01-14T08:15:51.2580148Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:51.2581892Z   AWS_RETRY_MODE: standard
2026-01-14T08:15:51.2582154Z   AWS_MAX_ATTEMPTS: 5
2026-01-14T08:15:51.2582414Z   AWS_DEFAULT_REGION: us-east-1
2026-01-14T08:15:51.2582678Z ##[endgroup]
2026-01-14T08:15:52.3435779Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:15:52.3436991Z Configure a credential helper to remove this warning. See
2026-01-14T08:15:52.3438020Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:15:52.3438770Z 
2026-01-14T08:15:52.3439375Z Login Succeeded
2026-01-14T08:15:52.3536321Z ##[group]Run env | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"
2026-01-14T08:15:52.3536937Z [36;1menv | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:52.3537535Z [36;1menv | grep '^CI' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:52.3538277Z [36;1menv | grep '^RUNNER' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:52.3547726Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:52.3548091Z env:
2026-01-14T08:15:52.3548348Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.3548699Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.3548947Z   PR_NUMBER: 3500
2026-01-14T08:15:52.3550611Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.3552345Z ##[endgroup]
2026-01-14T08:15:52.3685222Z ##[group]Run RUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"
2026-01-14T08:15:52.3685711Z [36;1mRUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"[0m
2026-01-14T08:15:52.3686129Z [36;1msudo rm -rf "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:52.3686488Z [36;1mmkdir -p "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:52.3686937Z [36;1mecho "RUNNER_ARTIFACT_DIR=${RUNNER_ARTIFACT_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:52.3687377Z [36;1m[0m
2026-01-14T08:15:52.3687675Z [36;1mRUNNER_TEST_RESULTS_DIR="${RUNNER_TEMP}/test-results"[0m
2026-01-14T08:15:52.3688117Z [36;1msudo rm -rf "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:52.3688488Z [36;1mmkdir -p "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:52.3689189Z [36;1mecho "RUNNER_TEST_RESULTS_DIR=${RUNNER_TEST_RESULTS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:52.3689655Z [36;1m[0m
2026-01-14T08:15:52.3689887Z [36;1mRUNNER_DOCS_DIR="${RUNNER_TEMP}/docs"[0m
2026-01-14T08:15:52.3690322Z [36;1msudo rm -rf "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:52.3690651Z [36;1mmkdir -p "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:52.3691077Z [36;1mecho "RUNNER_DOCS_DIR=${RUNNER_DOCS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:52.3700462Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:52.3700835Z env:
2026-01-14T08:15:52.3701093Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.3701454Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.3701707Z   PR_NUMBER: 3500
2026-01-14T08:15:52.3703370Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.3705161Z ##[endgroup]
2026-01-14T08:15:52.8737044Z ##[group]Run needs=0
2026-01-14T08:15:52.8737308Z [36;1mneeds=0[0m
2026-01-14T08:15:52.8737691Z [36;1mif lspci -v | grep -e 'controller.*NVIDIA' >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:52.8738167Z [36;1m  needs=1[0m
2026-01-14T08:15:52.8738394Z [36;1mfi[0m
2026-01-14T08:15:52.8738636Z [36;1mecho "does=${needs}" >> $GITHUB_OUTPUT[0m
2026-01-14T08:15:52.8747862Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:52.8748221Z env:
2026-01-14T08:15:52.8748470Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.8748821Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.8749066Z   PR_NUMBER: 3500
2026-01-14T08:15:52.8750735Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.8752620Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:52.8753413Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:52.8753979Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:52.8754372Z ##[endgroup]
2026-01-14T08:15:52.9184867Z ##[group]Run pytorch/test-infra/.github/actions/setup-nvidia@main
2026-01-14T08:15:52.9185361Z with:
2026-01-14T08:15:52.9185814Z   driver-version: 580.65.06
2026-01-14T08:15:52.9186145Z env:
2026-01-14T08:15:52.9186482Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.9186948Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.9187323Z   PR_NUMBER: 3500
2026-01-14T08:15:52.9189070Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.9191034Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:52.9191770Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:52.9192395Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:52.9192917Z ##[endgroup]
2026-01-14T08:15:52.9226655Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:52.9228035Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:52.9237499Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:52.9238050Z env:
2026-01-14T08:15:52.9238394Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.9238807Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.9239241Z   PR_NUMBER: 3500
2026-01-14T08:15:52.9240962Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.9242922Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:52.9243687Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:52.9244299Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:52.9244790Z ##[endgroup]
2026-01-14T08:15:52.9349274Z ##[group]Run set -euo pipefail
2026-01-14T08:15:52.9349629Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:52.9349885Z [36;1m[0m
2026-01-14T08:15:52.9350112Z [36;1mhas_gpu=false[0m
2026-01-14T08:15:52.9350361Z [36;1mdevices=""[0m
2026-01-14T08:15:52.9350614Z [36;1m[0m
2026-01-14T08:15:52.9350889Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:15:52.9351371Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:52.9351775Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:52.9352084Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:52.9352410Z [36;1m  fi[0m
2026-01-14T08:15:52.9352627Z [36;1mfi[0m
2026-01-14T08:15:52.9352843Z [36;1m[0m
2026-01-14T08:15:52.9353067Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:15:52.9353490Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:52.9353886Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:52.9354187Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:52.9354514Z [36;1m  fi[0m
2026-01-14T08:15:52.9354762Z [36;1mfi[0m
2026-01-14T08:15:52.9354972Z [36;1m[0m
2026-01-14T08:15:52.9355296Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:15:52.9356039Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:52.9356474Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:52.9356776Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:52.9357090Z [36;1m  fi[0m
2026-01-14T08:15:52.9357328Z [36;1mfi[0m
2026-01-14T08:15:52.9357536Z [36;1m[0m
2026-01-14T08:15:52.9357831Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:52.9358394Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:52.9367400Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:52.9367777Z env:
2026-01-14T08:15:52.9368033Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:52.9368402Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:52.9368655Z   PR_NUMBER: 3500
2026-01-14T08:15:52.9370473Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:52.9372361Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:52.9372995Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:52.9373734Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:52.9374140Z ##[endgroup]
2026-01-14T08:15:56.5656698Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:15:56.5657097Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:15:56.5657484Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:56.5658023Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:56.5658525Z [36;1melse[0m
2026-01-14T08:15:56.5658805Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:56.5659150Z [36;1mfi[0m
2026-01-14T08:15:56.5669489Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:56.5669863Z env:
2026-01-14T08:15:56.5670112Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:56.5670476Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:56.5670735Z   PR_NUMBER: 3500
2026-01-14T08:15:56.5672403Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:56.5674314Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:56.5675461Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:56.5676035Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:56.5676429Z   HAS_NVIDIA: true
2026-01-14T08:15:56.5676638Z ##[endgroup]
2026-01-14T08:15:56.5774458Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:15:56.5775229Z with:
2026-01-14T08:15:56.5775439Z   timeout_minutes: 10
2026-01-14T08:15:56.5775678Z   max_attempts: 3
2026-01-14T08:15:56.5809073Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:15:56.5842569Z   retry_wait_seconds: 10
2026-01-14T08:15:56.5842836Z   polling_interval_seconds: 1
2026-01-14T08:15:56.5843115Z   warning_on_retry: true
2026-01-14T08:15:56.5843467Z   continue_on_error: false
2026-01-14T08:15:56.5843722Z env:
2026-01-14T08:15:56.5843975Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:56.5844338Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:56.5844596Z   PR_NUMBER: 3500
2026-01-14T08:15:56.5846311Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:56.5848172Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:56.5848783Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:56.5849351Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:56.5849766Z   HAS_NVIDIA_GPU: true
2026-01-14T08:15:56.5850121Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:15:56.5850496Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:15:56.5850749Z ##[endgroup]
2026-01-14T08:15:56.6732654Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:15:56.6733375Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:15:56.6736706Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:15:57.0012387Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:15:57.0013065Z No packages marked for removal.
2026-01-14T08:15:57.0089223Z Dependencies resolved.
2026-01-14T08:15:57.0099672Z Nothing to do.
2026-01-14T08:15:57.0100050Z Complete!
2026-01-14T08:15:57.0444085Z + install_nvidia_driver_common
2026-01-14T08:15:57.0447980Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:15:57.0448283Z + lspci
2026-01-14T08:15:57.0449639Z Before installing NVIDIA driver
2026-01-14T08:15:57.0570393Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:15:57.0570940Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:15:57.0571556Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:15:57.0572132Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:15:57.0572648Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:15:57.0573482Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:15:57.0574020Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:57.0574481Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:57.0575085Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:57.0575539Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:57.0576055Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:15:57.0576492Z + lsmod
2026-01-14T08:15:57.0631006Z Module                  Size  Used by
2026-01-14T08:15:57.0631337Z nvidia_uvm           1925120  0
2026-01-14T08:15:57.0631607Z nvidia              14286848  1 nvidia_uvm
2026-01-14T08:15:57.0631909Z drm                   602112  1 nvidia
2026-01-14T08:15:57.0632220Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:15:57.0632539Z backlight              24576  1 drm
2026-01-14T08:15:57.0632831Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:15:57.0633123Z mgc                    86016  1
2026-01-14T08:15:57.0633373Z lustre               1085440  4
2026-01-14T08:15:57.0633636Z mdc                   294912  2 lustre
2026-01-14T08:15:57.0633914Z fid                    36864  1 mdc
2026-01-14T08:15:57.0634191Z lov                   356352  5 mdc,lustre
2026-01-14T08:15:57.0634518Z osc                   479232  5 mdc
2026-01-14T08:15:57.0634782Z lmv                   225280  2 lustre
2026-01-14T08:15:57.0635243Z fld                    49152  2 lov,lmv
2026-01-14T08:15:57.0635521Z ksocklnd              188416  1
2026-01-14T08:15:57.0635875Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:57.0636376Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:57.0636893Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:15:57.0637526Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:15:57.0638043Z xt_conntrack           16384  1
2026-01-14T08:15:57.0638567Z nft_chain_nat          16384  3
2026-01-14T08:15:57.0638888Z xt_MASQUERADE          20480  1
2026-01-14T08:15:57.0639326Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:15:57.0639779Z nf_conntrack_netlink    57344  0
2026-01-14T08:15:57.0640308Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:15:57.0640868Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:15:57.0654079Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:15:57.0654438Z xfrm_user              57344  1
2026-01-14T08:15:57.0654735Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:15:57.0655043Z xt_addrtype            16384  2
2026-01-14T08:15:57.0655311Z nft_compat             20480  4
2026-01-14T08:15:57.0655638Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:15:57.0656102Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:15:57.0656510Z br_netfilter           36864  0
2026-01-14T08:15:57.0656799Z bridge                323584  1 br_netfilter
2026-01-14T08:15:57.0657103Z stp                    16384  1 bridge
2026-01-14T08:15:57.0657401Z llc                    16384  2 bridge,stp
2026-01-14T08:15:57.0657688Z overlay               167936  0
2026-01-14T08:15:57.0657949Z tls                   139264  0
2026-01-14T08:15:57.0658207Z nls_ascii              16384  1
2026-01-14T08:15:57.0658462Z nls_cp437              20480  1
2026-01-14T08:15:57.0658718Z vfat                   24576  1
2026-01-14T08:15:57.0658967Z fat                    86016  1 vfat
2026-01-14T08:15:57.0659246Z sunrpc                700416  2 lnet
2026-01-14T08:15:57.0659530Z ghash_clmulni_intel    16384  0
2026-01-14T08:15:57.0659794Z i8042                  45056  0
2026-01-14T08:15:57.0660046Z serio                  28672  3 i8042
2026-01-14T08:15:57.0660323Z ena                   196608  0
2026-01-14T08:15:57.0660739Z button                 24576  0
2026-01-14T08:15:57.0661008Z sch_fq_codel           20480  33
2026-01-14T08:15:57.0661277Z fuse                  184320  1
2026-01-14T08:15:57.0661522Z loop                   36864  0
2026-01-14T08:15:57.0661776Z dm_mod                188416  0
2026-01-14T08:15:57.0662023Z configfs               57344  1
2026-01-14T08:15:57.0662283Z dmi_sysfs              20480  0
2026-01-14T08:15:57.0662535Z crc32_pclmul           16384  0
2026-01-14T08:15:57.0662794Z crc32c_intel           24576  0
2026-01-14T08:15:57.0663055Z efivarfs               24576  1
2026-01-14T08:15:57.0663307Z + modinfo nvidia
2026-01-14T08:15:57.0663743Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:15:57.0664223Z import_ns:      DMA_BUF
2026-01-14T08:15:57.0664473Z alias:          char-major-195-*
2026-01-14T08:15:57.0664739Z version:        580.82.07
2026-01-14T08:15:57.0664983Z supported:      external
2026-01-14T08:15:57.0665240Z license:        Dual MIT/GPL
2026-01-14T08:15:57.0665528Z firmware:       nvidia/580.82.07/gsp_tu10x.bin
2026-01-14T08:15:57.0665880Z firmware:       nvidia/580.82.07/gsp_ga10x.bin
2026-01-14T08:15:57.0666209Z srcversion:     BA7240A71DCF7DC6FE88C1D
2026-01-14T08:15:57.0666553Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:15:57.0666916Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:15:57.0667280Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:15:57.0667638Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:15:57.0668097Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:15:57.0668455Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:15:57.0668800Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:15:57.0669127Z depends:        i2c-core,drm
2026-01-14T08:15:57.0669381Z retpoline:      Y
2026-01-14T08:15:57.0669600Z name:           nvidia
2026-01-14T08:15:57.0669983Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:15:57.0670566Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:15:57.0671044Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:15:57.0671498Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:15:57.0671824Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:15:57.0672129Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:15:57.0672459Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:15:57.0672774Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:15:57.0673092Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:15:57.0673467Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:15:57.0673888Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:15:57.0674232Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:15:57.0674548Z parm:           NVreg_EnableMSI:int
2026-01-14T08:15:57.0675128Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:15:57.0675515Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:15:57.0675942Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:15:57.0676344Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:15:57.0676791Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:57.0677235Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:15:57.0677684Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:57.0678127Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:15:57.0678484Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:15:57.0678877Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:15:57.0679268Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:15:57.0679631Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:15:57.0679959Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:15:57.0680442Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:15:57.0680781Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:15:57.0681108Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:15:57.0681492Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:15:57.0681886Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:15:57.0682252Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:15:57.0682638Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:15:57.0682982Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:15:57.0683350Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:15:57.0683713Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:15:57.0684074Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:15:57.0684423Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:15:57.0684770Z parm:           NVreg_RmMsg:charp
2026-01-14T08:15:57.0685067Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:15:57.0685402Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:15:57.0685740Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:15:57.0686062Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:15:57.0686407Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:15:57.0686774Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:15:57.0687149Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:15:57.0687482Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:15:57.0687975Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:15:57.0688341Z parm:           rm_firmware_active:charp
2026-01-14T08:15:57.0688635Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:15:57.0688879Z ++ command -v nvidia-smi
2026-01-14T08:15:57.0689133Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:15:57.0689397Z + set +e
2026-01-14T08:15:57.0689713Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:16:00.5046415Z + INSTALLED_DRIVER_VERSION=580.82.07
2026-01-14T08:16:00.5046779Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:00.5047387Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:00.5047629Z + '[' 580.82.07 '!=' 580.65.06 ']'
2026-01-14T08:16:00.5048159Z + echo 'NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing'
2026-01-14T08:16:00.5048743Z + sudo killall nvidia-persistenced
2026-01-14T08:16:00.5049251Z NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing
2026-01-14T08:16:00.6403743Z nvidia-persistenced: no process found
2026-01-14T08:16:00.6428605Z + true
2026-01-14T08:16:00.6429186Z + set -e
2026-01-14T08:16:00.6429501Z + '[' 0 -eq 0 ']'
2026-01-14T08:16:00.6429763Z + '[' amzn2023 '!=' ubuntu20.04 ']'
2026-01-14T08:16:00.6430110Z + sudo yum groupinstall -y 'Development Tools'
2026-01-14T08:16:01.1365142Z Last metadata expiration check: 0:01:06 ago on Wed Jan 14 08:14:55 2026.
2026-01-14T08:16:01.1755461Z No match for group package "system-rpm-config"
2026-01-14T08:16:01.1773769Z No match for group package "rcs"
2026-01-14T08:16:01.1796905Z No match for group package "pkgconfig"
2026-01-14T08:16:01.2402359Z Dependencies resolved.
2026-01-14T08:16:01.2762119Z ================================================================================
2026-01-14T08:16:01.2762625Z  Package           Architecture     Version             Repository         Size
2026-01-14T08:16:01.2763098Z ================================================================================
2026-01-14T08:16:01.2763441Z Installing Groups:
2026-01-14T08:16:01.2763787Z  Development Tools                                                             
2026-01-14T08:16:01.2764101Z 
2026-01-14T08:16:01.2764192Z Transaction Summary
2026-01-14T08:16:01.2764464Z ================================================================================
2026-01-14T08:16:01.2764721Z 
2026-01-14T08:16:01.4964581Z ================================================================================
2026-01-14T08:16:01.4964949Z WARNING:
2026-01-14T08:16:01.4965417Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:16:01.4965683Z 
2026-01-14T08:16:01.4965776Z   Available Versions:
2026-01-14T08:16:01.4965931Z 
2026-01-14T08:16:01.4966026Z   Version 2023.10.20260105:
2026-01-14T08:16:01.4966355Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:16:01.4966635Z 
2026-01-14T08:16:01.4966765Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:16:01.4966993Z 
2026-01-14T08:16:01.4967078Z     Release notes:
2026-01-14T08:16:01.4967521Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:16:01.4967941Z 
2026-01-14T08:16:01.4968068Z ================================================================================
2026-01-14T08:16:01.4974184Z Complete!
2026-01-14T08:16:01.5412865Z ++ uname -r
2026-01-14T08:16:01.5427364Z + sudo yum install -y 'kernel-devel-uname-r == 6.1.158-180.294.amzn2023.x86_64'
2026-01-14T08:16:02.0843067Z Last metadata expiration check: 0:01:07 ago on Wed Jan 14 08:14:55 2026.
2026-01-14T08:16:02.1102382Z Using '==' operator in reldeps can result in an undefined behavior. It is deprecated and the support will be dropped in future versions. Use '=' operator instead.
2026-01-14T08:16:02.1220111Z Package kernel-devel-1:6.1.158-180.294.amzn2023.x86_64 is already installed.
2026-01-14T08:16:02.1847245Z Dependencies resolved.
2026-01-14T08:16:02.2206953Z Nothing to do.
2026-01-14T08:16:02.2207278Z Complete!
2026-01-14T08:16:02.2620954Z + sudo modprobe backlight
2026-01-14T08:16:02.4577018Z + sudo curl -fsL -o /tmp/nvidia_driver https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-580.65.06.run
2026-01-14T08:16:06.5962057Z + set +e
2026-01-14T08:16:06.5962383Z + sudo /bin/bash /tmp/nvidia_driver -s --no-drm
2026-01-14T08:16:07.9449421Z Verifying archive integrity... OK
2026-01-14T08:16:10.7822423Z Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 580.65.06....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2026-01-14T08:16:11.4576877Z 
2026-01-14T08:16:11.4577723Z WARNING: The nvidia-drm module will not be installed. As a result, DRM-KMS will not function with this installation of the NVIDIA driver.
2026-01-14T08:16:11.4578360Z 
2026-01-14T08:16:34.8879064Z 
2026-01-14T08:16:34.8880682Z WARNING: nvidia-installer was forced to guess the X library path '/usr/lib64' and X module path '/usr/lib64/xorg/modules'; these paths were not queryable from the system.  If X fails to find the NVIDIA X driver module, please install the `pkg-config` utility and the X.Org SDK/development package for your distribution and reinstall the driver.
2026-01-14T08:16:34.8882200Z 
2026-01-14T08:16:34.8900888Z 
2026-01-14T08:16:34.8902677Z WARNING: This NVIDIA driver package includes Vulkan components, but no Vulkan ICD loader was detected on this system. The NVIDIA Vulkan ICD will not function without the loader. Most distributions package the Vulkan loader; try installing the "vulkan-loader", "vulkan-icd-loader", or "libvulkan1" package.
2026-01-14T08:16:34.8904019Z 
2026-01-14T08:16:47.6192942Z + NVIDIA_INSTALLATION_STATUS=0
2026-01-14T08:16:47.6193262Z + RESET_GPU=0
2026-01-14T08:16:47.6193476Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:47.6198943Z ++ command -v nvidia-smi
2026-01-14T08:16:47.6201749Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:16:47.6207791Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:16:51.4549546Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:16:51.4549893Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:51.4550136Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:51.4550349Z + '[' 0 -eq 1 ']'
2026-01-14T08:16:51.4550576Z + sudo rm -fv /tmp/nvidia_driver
2026-01-14T08:16:51.6389709Z removed '/tmp/nvidia_driver'
2026-01-14T08:16:51.6416858Z + set -e
2026-01-14T08:16:51.6419949Z + post_install_nvidia_driver_common
2026-01-14T08:16:51.6428325Z + sudo modprobe nvidia
2026-01-14T08:16:51.9190989Z + echo 'After installing NVIDIA driver'
2026-01-14T08:16:51.9191347Z + lspci
2026-01-14T08:16:51.9191578Z After installing NVIDIA driver
2026-01-14T08:16:51.9306074Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:16:51.9306632Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:16:51.9307264Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:16:51.9307833Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:16:51.9308689Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:16:51.9309271Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:16:51.9309803Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:51.9310277Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:51.9310738Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:51.9311203Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:51.9311709Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:16:51.9312154Z + lsmod
2026-01-14T08:16:51.9355908Z Module                  Size  Used by
2026-01-14T08:16:51.9356228Z nvidia_uvm           1921024  0
2026-01-14T08:16:51.9356505Z nvidia              14274560  1 nvidia_uvm
2026-01-14T08:16:51.9356795Z drm                   602112  1 nvidia
2026-01-14T08:16:51.9357113Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:16:51.9357426Z backlight              24576  1 drm
2026-01-14T08:16:51.9357719Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:16:51.9358003Z mgc                    86016  1
2026-01-14T08:16:51.9358255Z lustre               1085440  4
2026-01-14T08:16:51.9358519Z mdc                   294912  2 lustre
2026-01-14T08:16:51.9358789Z fid                    36864  1 mdc
2026-01-14T08:16:51.9359072Z lov                   356352  5 mdc,lustre
2026-01-14T08:16:51.9359353Z osc                   479232  5 mdc
2026-01-14T08:16:51.9359622Z lmv                   225280  2 lustre
2026-01-14T08:16:51.9359894Z fld                    49152  2 lov,lmv
2026-01-14T08:16:51.9360173Z ksocklnd              188416  1
2026-01-14T08:16:51.9360541Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:51.9361039Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:51.9361569Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:16:51.9362191Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:16:51.9362946Z xt_conntrack           16384  1
2026-01-14T08:16:51.9363215Z nft_chain_nat          16384  3
2026-01-14T08:16:51.9363480Z xt_MASQUERADE          20480  1
2026-01-14T08:16:51.9363789Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:16:51.9364339Z nf_conntrack_netlink    57344  0
2026-01-14T08:16:51.9364772Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:16:51.9365246Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:16:51.9365574Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:16:51.9365871Z xfrm_user              57344  1
2026-01-14T08:16:51.9366144Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:16:51.9366436Z xt_addrtype            16384  2
2026-01-14T08:16:51.9366709Z nft_compat             20480  4
2026-01-14T08:16:51.9367019Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:16:51.9367470Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:16:51.9367880Z br_netfilter           36864  0
2026-01-14T08:16:51.9368161Z bridge                323584  1 br_netfilter
2026-01-14T08:16:51.9368470Z stp                    16384  1 bridge
2026-01-14T08:16:51.9368763Z llc                    16384  2 bridge,stp
2026-01-14T08:16:51.9369059Z overlay               167936  0
2026-01-14T08:16:51.9369309Z tls                   139264  0
2026-01-14T08:16:51.9369560Z nls_ascii              16384  1
2026-01-14T08:16:51.9369808Z nls_cp437              20480  1
2026-01-14T08:16:51.9370119Z vfat                   24576  1
2026-01-14T08:16:51.9370371Z fat                    86016  1 vfat
2026-01-14T08:16:51.9370639Z sunrpc                700416  2 lnet
2026-01-14T08:16:51.9370919Z ghash_clmulni_intel    16384  0
2026-01-14T08:16:51.9371299Z i8042                  45056  0
2026-01-14T08:16:51.9371552Z serio                  28672  3 i8042
2026-01-14T08:16:51.9371820Z ena                   196608  0
2026-01-14T08:16:51.9372076Z button                 24576  0
2026-01-14T08:16:51.9372373Z sch_fq_codel           20480  33
2026-01-14T08:16:51.9372638Z fuse                  184320  1
2026-01-14T08:16:51.9372880Z loop                   36864  0
2026-01-14T08:16:51.9373130Z dm_mod                188416  0
2026-01-14T08:16:51.9373393Z configfs               57344  1
2026-01-14T08:16:51.9373641Z dmi_sysfs              20480  0
2026-01-14T08:16:51.9373897Z crc32_pclmul           16384  0
2026-01-14T08:16:51.9374149Z crc32c_intel           24576  0
2026-01-14T08:16:51.9374404Z efivarfs               24576  1
2026-01-14T08:16:51.9375026Z + modinfo nvidia
2026-01-14T08:16:51.9380068Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:16:51.9380555Z import_ns:      DMA_BUF
2026-01-14T08:16:51.9380844Z alias:          char-major-195-*
2026-01-14T08:16:51.9381119Z version:        580.65.06
2026-01-14T08:16:51.9381360Z supported:      external
2026-01-14T08:16:51.9381608Z license:        Dual MIT/GPL
2026-01-14T08:16:51.9381891Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:16:51.9382243Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:16:51.9382577Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:16:51.9382926Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:16:51.9383305Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:16:51.9383665Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:16:51.9384030Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:16:51.9384375Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:16:51.9384726Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:16:51.9385072Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:16:51.9385403Z depends:        i2c-core,drm
2026-01-14T08:16:51.9385662Z retpoline:      Y
2026-01-14T08:16:51.9385880Z name:           nvidia
2026-01-14T08:16:51.9386259Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:16:51.9386773Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:16:51.9387262Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:16:51.9387706Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:16:51.9388185Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:16:51.9388494Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:16:51.9388820Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:16:51.9389128Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:16:51.9389442Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:16:51.9389827Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:16:51.9390235Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:16:51.9390587Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:16:51.9390891Z parm:           NVreg_EnableMSI:int
2026-01-14T08:16:51.9391203Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:16:51.9391575Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:16:51.9391998Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:16:51.9392397Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:16:51.9392844Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:51.9393284Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:16:51.9393721Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:51.9394161Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:16:51.9394507Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:16:51.9394892Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:16:51.9395278Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:16:51.9398689Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:16:51.9399022Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:16:51.9399368Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:16:51.9399697Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:16:51.9400020Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:16:51.9400386Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:16:51.9400797Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:16:51.9401173Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:16:51.9401552Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:16:51.9401900Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:16:51.9402295Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:16:51.9402920Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:16:51.9403288Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:16:51.9403638Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:16:51.9403996Z parm:           NVreg_RmMsg:charp
2026-01-14T08:16:51.9404286Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:16:51.9404628Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:16:51.9404961Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:16:51.9405468Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:16:51.9405805Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:16:51.9406191Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:16:51.9406564Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:16:51.9406902Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:16:51.9407269Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:16:51.9407629Z parm:           rm_firmware_active:charp
2026-01-14T08:16:51.9407921Z + set +e
2026-01-14T08:16:51.9408104Z + nvidia-smi
2026-01-14T08:16:54.2724037Z Wed Jan 14 08:16:54 2026       
2026-01-14T08:16:54.2724545Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:54.2725168Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:16:54.2725740Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:54.2726320Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:16:54.2727301Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:16:54.2727827Z |                                         |                        |               MIG M. |
2026-01-14T08:16:54.2728241Z |=========================================+========================+======================|
2026-01-14T08:16:54.3060583Z |   0  NVIDIA A10G                    Off |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:16:54.3061117Z |  0%   26C    P0             58W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:54.3061603Z |                                         |                        |                  N/A |
2026-01-14T08:16:54.3062082Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:54.3062601Z |   1  NVIDIA A10G                    Off |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:16:54.3063123Z |  0%   26C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:54.3063567Z |                                         |                        |                  N/A |
2026-01-14T08:16:54.3064052Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:54.3064584Z |   2  NVIDIA A10G                    Off |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:16:54.3065085Z |  0%   25C    P0             58W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:16:54.3065754Z |                                         |                        |                  N/A |
2026-01-14T08:16:54.3066223Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:54.3066745Z |   3  NVIDIA A10G                    Off |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:16:54.3067255Z |  0%   25C    P0             59W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:54.3067718Z |                                         |                        |                  N/A |
2026-01-14T08:16:54.3068181Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:54.3068520Z 
2026-01-14T08:16:54.3068733Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:54.3069244Z | Processes:                                                                              |
2026-01-14T08:16:54.3069766Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:16:54.3070263Z |        ID   ID                                                               Usage      |
2026-01-14T08:16:54.3071013Z |=========================================================================================|
2026-01-14T08:16:54.3088853Z |  No running processes found                                                             |
2026-01-14T08:16:55.9931305Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:55.9942331Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:16:58.3091928Z NVIDIA A10G
2026-01-14T08:16:59.4072184Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:59.4072541Z + '[' 0 -eq 0 ']'
2026-01-14T08:16:59.4073105Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:16:59.4073519Z + set -e
2026-01-14T08:16:59.4085305Z INFO: Ignoring allowed status 0
2026-01-14T08:16:59.4085773Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:16:59.4090137Z + sudo yum install -y yum-utils
2026-01-14T08:16:59.8688384Z Last metadata expiration check: 0:02:04 ago on Wed Jan 14 08:14:55 2026.
2026-01-14T08:16:59.8975564Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:16:59.9611376Z Dependencies resolved.
2026-01-14T08:16:59.9971771Z Nothing to do.
2026-01-14T08:16:59.9972002Z Complete!
2026-01-14T08:17:00.0413993Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:17:00.0414891Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:00.0415874Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:00.3563981Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:17:00.4024889Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:17:00.9567988Z nvidia-container-toolkit                         17 kB/s | 833  B     00:00    
2026-01-14T08:17:01.0512887Z Dependencies resolved.
2026-01-14T08:17:01.0884998Z ================================================================================
2026-01-14T08:17:01.0885660Z  Package                       Arch   Version    Repository                Size
2026-01-14T08:17:01.0886116Z ================================================================================
2026-01-14T08:17:01.0886483Z Downgrading:
2026-01-14T08:17:01.0886867Z  libnvidia-container-tools     x86_64 1.17.8-1   nvidia-container-toolkit  40 k
2026-01-14T08:17:01.0887494Z  libnvidia-container1          x86_64 1.17.8-1   nvidia-container-toolkit 1.0 M
2026-01-14T08:17:01.0888116Z  nvidia-container-toolkit      x86_64 1.17.8-1   nvidia-container-toolkit 1.2 M
2026-01-14T08:17:01.0888756Z  nvidia-container-toolkit-base x86_64 1.17.8-1   nvidia-container-toolkit 5.8 M
2026-01-14T08:17:01.0889465Z 
2026-01-14T08:17:01.0889564Z Transaction Summary
2026-01-14T08:17:01.0889825Z ================================================================================
2026-01-14T08:17:01.0890242Z Downgrade  4 Packages
2026-01-14T08:17:01.0890398Z 
2026-01-14T08:17:01.0890504Z Total download size: 8.0 M
2026-01-14T08:17:01.0890778Z Downloading Packages:
2026-01-14T08:17:01.1137891Z (1/4): libnvidia-container-tools-1.17.8-1.x86_6 1.7 MB/s |  40 kB     00:00    
2026-01-14T08:17:01.1228598Z (2/4): libnvidia-container1-1.17.8-1.x86_64.rpm  30 MB/s | 1.0 MB     00:00    
2026-01-14T08:17:01.1349911Z (3/4): nvidia-container-toolkit-1.17.8-1.x86_64  28 MB/s | 1.2 MB     00:00    
2026-01-14T08:17:01.1743319Z (4/4): nvidia-container-toolkit-base-1.17.8-1.x  96 MB/s | 5.8 MB     00:00    
2026-01-14T08:17:01.1751871Z --------------------------------------------------------------------------------
2026-01-14T08:17:01.1754597Z Total                                            93 MB/s | 8.0 MB     00:00     
2026-01-14T08:17:01.1757182Z Running transaction check
2026-01-14T08:17:01.1887934Z Transaction check succeeded.
2026-01-14T08:17:01.1888221Z Running transaction test
2026-01-14T08:17:01.2391505Z Transaction test succeeded.
2026-01-14T08:17:01.2394491Z Running transaction
2026-01-14T08:17:01.8319600Z   Preparing        :                                                        1/1 
2026-01-14T08:17:01.9212104Z   Downgrading      : nvidia-container-toolkit-base-1.17.8-1.x86_64          1/8 
2026-01-14T08:17:01.9258746Z   Downgrading      : libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:17:01.9562147Z   Running scriptlet: libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:17:02.0647837Z   Downgrading      : libnvidia-container-tools-1.17.8-1.x86_64              3/8 
2026-01-14T08:17:02.0688050Z   Downgrading      : nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:17:02.0907838Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:17:02.0994858Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:02.0995467Z   Cleanup          : nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:02.1125127Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:17:02.1206043Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:02.1206913Z   Cleanup          : libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:02.1336312Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:17:02.1426053Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:02.1426666Z   Cleanup          : libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:02.1565681Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:17:02.1648932Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:02.1649666Z   Cleanup          : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:02.1780817Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:02.2413420Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               8/8 
2026-01-14T08:17:05.1650853Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:17:05.1651544Z   Verifying        : libnvidia-container-tools-1.17.8-1.x86_64              1/8 
2026-01-14T08:17:05.1652148Z   Verifying        : libnvidia-container-tools-1.18.1-1.x86_64              2/8 
2026-01-14T08:17:05.1652730Z   Verifying        : libnvidia-container1-1.17.8-1.x86_64                   3/8 
2026-01-14T08:17:05.1653312Z   Verifying        : libnvidia-container1-1.18.1-1.x86_64                   4/8 
2026-01-14T08:17:05.1653887Z   Verifying        : nvidia-container-toolkit-1.17.8-1.x86_64               5/8 
2026-01-14T08:17:05.1654801Z   Verifying        : nvidia-container-toolkit-1.18.1-1.x86_64               6/8 
2026-01-14T08:17:05.1655380Z   Verifying        : nvidia-container-toolkit-base-1.17.8-1.x86_64          7/8 
2026-01-14T08:17:05.3207892Z   Verifying        : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8================================================================================
2026-01-14T08:17:05.3208570Z WARNING:
2026-01-14T08:17:05.3208820Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:17:05.3209079Z 
2026-01-14T08:17:05.3209172Z   Available Versions:
2026-01-14T08:17:05.3209323Z 
2026-01-14T08:17:05.3209423Z   Version 2023.10.20260105:
2026-01-14T08:17:05.3209748Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:17:05.3210068Z 
2026-01-14T08:17:05.3210201Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:17:05.3210431Z 
2026-01-14T08:17:05.3210517Z     Release notes:
2026-01-14T08:17:05.3210963Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:17:05.3211385Z 
2026-01-14T08:17:05.3211511Z ================================================================================
2026-01-14T08:17:05.3939086Z  
2026-01-14T08:17:05.3939566Z 
2026-01-14T08:17:05.3939871Z Downgraded:
2026-01-14T08:17:05.3940595Z   libnvidia-container-tools-1.17.8-1.x86_64                                     
2026-01-14T08:17:05.3941823Z   libnvidia-container1-1.17.8-1.x86_64                                          
2026-01-14T08:17:05.3943004Z   nvidia-container-toolkit-1.17.8-1.x86_64                                      
2026-01-14T08:17:05.3944249Z   nvidia-container-toolkit-base-1.17.8-1.x86_64                                 
2026-01-14T08:17:05.3945012Z 
2026-01-14T08:17:05.3945185Z Complete!
2026-01-14T08:17:05.4469177Z + sudo systemctl restart docker
2026-01-14T08:17:13.6510303Z Wed Jan 14 08:17:13 2026       
2026-01-14T08:17:13.6511173Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:13.6512326Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:13.6513454Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:13.6514604Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:13.6516350Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:13.6517380Z |                                         |                        |               MIG M. |
2026-01-14T08:17:13.6518178Z |=========================================+========================+======================|
2026-01-14T08:17:13.6860582Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:13.6861117Z |  0%   26C    P0             58W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:13.6861593Z |                                         |                        |                  N/A |
2026-01-14T08:17:13.6862077Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:13.6862597Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:13.6863117Z |  0%   26C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:13.6863565Z |                                         |                        |                  N/A |
2026-01-14T08:17:13.6864037Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:13.6864561Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:13.6865063Z |  0%   25C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:13.6865727Z |                                         |                        |                  N/A |
2026-01-14T08:17:13.6866191Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:13.6866722Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:13.6867235Z |  0%   25C    P0             54W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:17:13.6867682Z |                                         |                        |                  N/A |
2026-01-14T08:17:13.6868149Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:13.6868511Z 
2026-01-14T08:17:13.6868811Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:13.6869325Z | Processes:                                                                              |
2026-01-14T08:17:13.6869843Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:13.6870334Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:13.6870760Z |=========================================================================================|
2026-01-14T08:17:13.6889258Z |  No running processes found                                                             |
2026-01-14T08:17:13.6889823Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:14.3280231Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:17:14.5566190Z 3.13: Pulling from docker/library/python
2026-01-14T08:17:14.6472942Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:17:14.6473372Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:17:14.6473941Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:17:14.6474329Z 26d823e3848f: Pulling fs layer
2026-01-14T08:17:14.6474878Z ca4b54413202: Pulling fs layer
2026-01-14T08:17:14.6475267Z b6513238a015: Pulling fs layer
2026-01-14T08:17:14.6475538Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:17:14.6475793Z ca4b54413202: Waiting
2026-01-14T08:17:14.6476011Z 26d823e3848f: Waiting
2026-01-14T08:17:14.6476235Z b6513238a015: Waiting
2026-01-14T08:17:14.6476449Z 9b57076d00d4: Waiting
2026-01-14T08:17:14.7827856Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:17:14.7828711Z 82e18c5e1c15: Download complete
2026-01-14T08:17:14.8411163Z 2ca1bfae7ba8: Verifying Checksum
2026-01-14T08:17:14.8411859Z 2ca1bfae7ba8: Download complete
2026-01-14T08:17:14.8811536Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:17:14.8811953Z be442a7e0d6f: Download complete
2026-01-14T08:17:14.9135300Z ca4b54413202: Verifying Checksum
2026-01-14T08:17:14.9135674Z ca4b54413202: Download complete
2026-01-14T08:17:14.9604120Z 9b57076d00d4: Verifying Checksum
2026-01-14T08:17:14.9604519Z 9b57076d00d4: Download complete
2026-01-14T08:17:14.9883507Z b6513238a015: Verifying Checksum
2026-01-14T08:17:14.9883910Z b6513238a015: Download complete
2026-01-14T08:17:15.4361963Z 26d823e3848f: Verifying Checksum
2026-01-14T08:17:15.4362284Z 26d823e3848f: Download complete
2026-01-14T08:17:16.6587361Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:17:17.3905608Z 82e18c5e1c15: Pull complete
2026-01-14T08:17:19.9500035Z be442a7e0d6f: Pull complete
2026-01-14T08:17:27.2743350Z 26d823e3848f: Pull complete
2026-01-14T08:17:27.5646435Z ca4b54413202: Pull complete
2026-01-14T08:17:28.3504537Z b6513238a015: Pull complete
2026-01-14T08:17:28.3741805Z 9b57076d00d4: Pull complete
2026-01-14T08:17:28.3881582Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:28.3923859Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:34.0456931Z Wed Jan 14 08:17:34 2026       
2026-01-14T08:17:34.0457382Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:34.0457959Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:34.0458856Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:34.0459432Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:34.0460050Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:34.0460577Z |                                         |                        |               MIG M. |
2026-01-14T08:17:34.0460978Z |=========================================+========================+======================|
2026-01-14T08:17:34.1092212Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:34.1092768Z |  0%   22C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:34.1093241Z |                                         |                        |                  N/A |
2026-01-14T08:17:34.1093743Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:34.1094266Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:34.1094775Z |  0%   23C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:34.1095220Z |                                         |                        |                  N/A |
2026-01-14T08:17:34.1095702Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:34.1096226Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:34.1096720Z |  0%   21C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:34.1097173Z |                                         |                        |                  N/A |
2026-01-14T08:17:34.1097642Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:34.1098173Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:34.1098678Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:34.1099125Z |                                         |                        |                  N/A |
2026-01-14T08:17:34.1099851Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:34.1120759Z 
2026-01-14T08:17:34.1121138Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:34.1121665Z | Processes:                                                                              |
2026-01-14T08:17:34.1122188Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:34.1122672Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:34.1123102Z |=========================================================================================|
2026-01-14T08:17:34.1159602Z |  No running processes found                                                             |
2026-01-14T08:17:34.1160157Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:36.7220725Z Command completed after 1 attempt(s).
2026-01-14T08:17:36.7332617Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:17:36.7333200Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:17:36.7333645Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:17:36.7333974Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:17:36.7334322Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:17:36.7334654Z [36;1mdocker system prune -af[0m
2026-01-14T08:17:36.7348835Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:36.7349387Z env:
2026-01-14T08:17:36.7349638Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:36.7350000Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:36.7350248Z   PR_NUMBER: 3500
2026-01-14T08:17:36.7351918Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:36.7353788Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:36.7354378Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:36.7354941Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:36.7355326Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:36.7355644Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:36.7356055Z ##[endgroup]
2026-01-14T08:17:36.7701826Z "docker stop" requires at least 1 argument.
2026-01-14T08:17:36.7702329Z See 'docker stop --help'.
2026-01-14T08:17:36.7702570Z 
2026-01-14T08:17:36.7702785Z Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]
2026-01-14T08:17:36.7703134Z 
2026-01-14T08:17:36.7703272Z Stop one or more running containers
2026-01-14T08:17:37.9726721Z Deleted Images:
2026-01-14T08:17:37.9727033Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:37.9727742Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:37.9728578Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T08:17:37.9729227Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T08:17:37.9729856Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T08:17:37.9730586Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T08:17:37.9731213Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T08:17:37.9731850Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T08:17:37.9732504Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T08:17:37.9733395Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T08:17:37.9733794Z 
2026-01-14T08:17:38.0680755Z Total reclaimed space: 1.109GB
2026-01-14T08:17:38.0788105Z ##[group]Run ./test-infra/.github/actions/setup-ssh
2026-01-14T08:17:38.0788488Z with:
2026-01-14T08:17:38.0789189Z   github-secret: ***
2026-01-14T08:17:38.0789943Z   instructions: All testing is done inside the container, to start an interactive session run:
   docker exec -it $(docker container ps --format '{{.ID}}') bash

2026-01-14T08:17:38.0790781Z   activate-with-label: false
2026-01-14T08:17:38.0791061Z   label: with-ssh
2026-01-14T08:17:38.0791318Z   remove-existing-keys: true
2026-01-14T08:17:38.0791595Z   fail-silently: true
2026-01-14T08:17:38.0791838Z env:
2026-01-14T08:17:38.0792100Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:38.0792477Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:38.0792732Z   PR_NUMBER: 3500
2026-01-14T08:17:38.0794441Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:38.0796333Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:38.0796936Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:38.0797696Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:38.0798096Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:38.0798417Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:38.0798791Z ##[endgroup]
2026-01-14T08:17:38.1991503Z Please see https://github.com/pytorch/pytorch/wiki/Debugging-using-with-ssh-for-Github-Actions for more info.
2026-01-14T08:17:38.8607840Z Grabbing public ssh keys from https://github.com/zxd1997066.keys
2026-01-14T08:17:38.9708413Z ~/.ssh/authorized_keys file found on node, removing ~/.ssh and starting fresh
2026-01-14T08:17:38.9723041Z Public keys pulled and installed to /home/ec2-user/.ssh/authorized_keys
2026-01-14T08:17:38.9766141Z Login using: ssh ec2-user@ec2-100-48-72-45.compute-1.amazonaws.com
2026-01-14T08:17:38.9766708Z All testing is done inside the container, to start an interactive session run:
2026-01-14T08:17:38.9767266Z    docker exec -it $(docker container ps --format '{{.ID}}') bash
2026-01-14T08:17:38.9924621Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:17:38.9925065Z with:
2026-01-14T08:17:38.9925279Z   repository: pytorch/ao
2026-01-14T08:17:38.9925547Z   ref: refs/pull/3500/merge
2026-01-14T08:17:38.9925811Z   path: pytorch/ao
2026-01-14T08:17:38.9926042Z   fetch-depth: 1
2026-01-14T08:17:38.9926268Z   submodules: recursive
2026-01-14T08:17:38.9926645Z   token: ***
2026-01-14T08:17:38.9926877Z   ssh-strict: true
2026-01-14T08:17:38.9927096Z   ssh-user: git
2026-01-14T08:17:38.9927330Z   persist-credentials: true
2026-01-14T08:17:38.9927582Z   clean: true
2026-01-14T08:17:38.9927826Z   sparse-checkout-cone-mode: true
2026-01-14T08:17:38.9928114Z   fetch-tags: false
2026-01-14T08:17:38.9928349Z   show-progress: true
2026-01-14T08:17:38.9928581Z   lfs: false
2026-01-14T08:17:38.9928805Z   set-safe-directory: true
2026-01-14T08:17:38.9929048Z env:
2026-01-14T08:17:38.9929298Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:38.9929694Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:38.9929940Z   PR_NUMBER: 3500
2026-01-14T08:17:38.9931713Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:38.9933607Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:38.9934207Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:38.9934773Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:38.9935176Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:38.9935481Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:38.9935844Z ##[endgroup]
2026-01-14T08:17:39.1002630Z Syncing repository: pytorch/ao
2026-01-14T08:17:39.1011778Z ##[group]Getting Git version info
2026-01-14T08:17:39.1012247Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao'
2026-01-14T08:17:39.1039229Z [command]/usr/bin/git version
2026-01-14T08:17:39.1088362Z git version 2.50.1
2026-01-14T08:17:39.1114740Z ##[endgroup]
2026-01-14T08:17:39.1128857Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/d281323b-1c04-45b9-9baa-a5d3280a35f1' before making global git config changes
2026-01-14T08:17:39.1129881Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:17:39.1144281Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:39.1184393Z ##[group]Initializing the repository
2026-01-14T08:17:39.1189121Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:39.1240085Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:17:39.1240719Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:17:39.1241303Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:17:39.1241716Z hint:
2026-01-14T08:17:39.1241991Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:17:39.1242333Z hint:
2026-01-14T08:17:39.1242663Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:17:39.1243237Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:17:39.1243679Z hint:
2026-01-14T08:17:39.1243884Z hint: 	git branch -m <name>
2026-01-14T08:17:39.1244125Z hint:
2026-01-14T08:17:39.1244487Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:17:39.1245193Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/
2026-01-14T08:17:39.1253320Z [command]/usr/bin/git remote add origin https://github.com/pytorch/ao
2026-01-14T08:17:39.1292407Z ##[endgroup]
2026-01-14T08:17:39.1292823Z ##[group]Disabling automatic garbage collection
2026-01-14T08:17:39.1296682Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:17:39.1333670Z ##[endgroup]
2026-01-14T08:17:39.1334048Z ##[group]Setting up auth
2026-01-14T08:17:39.1339311Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:17:39.1375955Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:17:39.1786595Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:17:39.1823347Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:17:39.2230488Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:39.2276950Z ##[endgroup]
2026-01-14T08:17:39.2277352Z ##[group]Fetching the repository
2026-01-14T08:17:39.2284364Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/pull/3500/merge:refs/remotes/pull/3500/merge
2026-01-14T08:17:39.9754510Z From https://github.com/pytorch/ao
2026-01-14T08:17:39.9754899Z  * [new ref]         refs/pull/3500/merge -> pull/3500/merge
2026-01-14T08:17:39.9789213Z ##[endgroup]
2026-01-14T08:17:39.9789607Z ##[group]Determining the checkout info
2026-01-14T08:17:39.9791712Z ##[endgroup]
2026-01-14T08:17:39.9795995Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:17:39.9855599Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:17:39.9890904Z ##[group]Checking out the ref
2026-01-14T08:17:39.9894170Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/3500/merge
2026-01-14T08:17:40.1322490Z Note: switching to 'refs/remotes/pull/3500/merge'.
2026-01-14T08:17:40.1322763Z 
2026-01-14T08:17:40.1322985Z You are in 'detached HEAD' state. You can look around, make experimental
2026-01-14T08:17:40.1323559Z changes and commit them, and you can discard any commits you make in this
2026-01-14T08:17:40.1324116Z state without impacting any branches by switching back to a branch.
2026-01-14T08:17:40.1324450Z 
2026-01-14T08:17:40.1324659Z If you want to create a new branch to retain commits you create, you may
2026-01-14T08:17:40.1325172Z do so (now or later) by using -c with the switch command. Example:
2026-01-14T08:17:40.1325471Z 
2026-01-14T08:17:40.1325586Z   git switch -c <new-branch-name>
2026-01-14T08:17:40.1325777Z 
2026-01-14T08:17:40.1325903Z Or undo this operation with:
2026-01-14T08:17:40.1326082Z 
2026-01-14T08:17:40.1326167Z   git switch -
2026-01-14T08:17:40.1326507Z 
2026-01-14T08:17:40.1326754Z Turn off this advice by setting config variable advice.detachedHead to false
2026-01-14T08:17:40.1327125Z 
2026-01-14T08:17:40.1327535Z HEAD is now at b34f898 Merge f07387cd29b2a97703e501a48808c413bf9d95ea into 985d970b5e16b58c1e5b8bab440169d3da78cf16
2026-01-14T08:17:40.1344426Z ##[endgroup]
2026-01-14T08:17:40.1356587Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:17:40.1357314Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:40.1402757Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:17:40.1437687Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:17:40.1477222Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:17:40.1509442Z ##[endgroup]
2026-01-14T08:17:40.1509837Z ##[group]Fetching submodules
2026-01-14T08:17:40.1512962Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:17:40.1925436Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:17:40.2319531Z Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass) registered for path 'third_party/cutlass'
2026-01-14T08:17:40.2354936Z Cloning into '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/third_party/cutlass'...
2026-01-14T08:17:43.1930422Z From https://github.com/NVIDIA/cutlass
2026-01-14T08:17:43.1930934Z  * branch            e51efbfe18fe4f4cbb66ab814c55bf4aa0185491 -> FETCH_HEAD
2026-01-14T08:17:43.9821709Z Submodule path 'third_party/cutlass': checked out 'e51efbfe18fe4f4cbb66ab814c55bf4aa0185491'
2026-01-14T08:17:43.9873708Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:17:44.0267069Z Entering 'third_party/cutlass'
2026-01-14T08:17:44.0350434Z ##[endgroup]
2026-01-14T08:17:44.0350867Z ##[group]Persisting credentials for submodules
2026-01-14T08:17:44.0360549Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:17:44.0760528Z Entering 'third_party/cutlass'
2026-01-14T08:17:44.0870326Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:17:44.1258163Z Entering 'third_party/cutlass'
2026-01-14T08:17:44.1329682Z file:/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/modules/third_party/cutlass/config	remote.origin.url
2026-01-14T08:17:44.1397774Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:17:44.1783594Z Entering 'third_party/cutlass'
2026-01-14T08:17:44.1871149Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:17:44.2259540Z Entering 'third_party/cutlass'
2026-01-14T08:17:44.2342833Z ##[endgroup]
2026-01-14T08:17:44.2387809Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:17:44.2417706Z b34f89824bef6a4573349bfbefa82a7db14ede35
2026-01-14T08:17:44.2696022Z Prepare all required actions
2026-01-14T08:17:44.2696801Z Getting action download info
2026-01-14T08:17:44.4255321Z Download action repository 'nick-fields/retry@v3.0.0' (SHA:7152eba30c6575329ac0576536151aca5a72780e)
2026-01-14T08:17:44.5976938Z ##[group]Run ./test-infra/.github/actions/calculate-docker-image
2026-01-14T08:17:44.5977346Z with:
2026-01-14T08:17:44.5977570Z   use-custom-docker-registry: true
2026-01-14T08:17:44.5977975Z   docker-image-name: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.5978389Z   docker-build-dir: .ci/docker
2026-01-14T08:17:44.5978676Z   working-directory: pytorch/ao
2026-01-14T08:17:44.5979188Z   docker-build-script: ./build.sh
2026-01-14T08:17:44.5979570Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:44.5979977Z   force-push: false
2026-01-14T08:17:44.5980190Z env:
2026-01-14T08:17:44.5980448Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.5980800Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:44.5981089Z   PR_NUMBER: 3500
2026-01-14T08:17:44.5982749Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:44.5984622Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:44.5985225Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:44.5985794Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:44.5986202Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:44.5986525Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:44.5986883Z ##[endgroup]
2026-01-14T08:17:44.6028861Z ##[group]Run set -ex
2026-01-14T08:17:44.6029157Z [36;1mset -ex[0m
2026-01-14T08:17:44.6029368Z [36;1m[0m
2026-01-14T08:17:44.6029769Z [36;1m# If the docker build directory or the build script doesn't exist, the action will[0m
2026-01-14T08:17:44.6030475Z [36;1m# gracefully return the docker image name as it is.  Pulling docker image in Linux[0m
2026-01-14T08:17:44.6031075Z [36;1m# job could then download the pre-built image as usual[0m
2026-01-14T08:17:44.6031831Z [36;1mif [[ -d "${DOCKER_BUILD_DIR}" ]] && [[ -f "${DOCKER_BUILD_DIR}/${DOCKER_BUILD_SCRIPT}" ]] && [[ "${USE_CUSTOM_DOCKER_REGISTRY}" == "true" ]]; then[0m
2026-01-14T08:17:44.6032548Z [36;1m  echo "skip=false" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6032881Z [36;1melse[0m
2026-01-14T08:17:44.6033127Z [36;1m  echo "skip=true" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6033580Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6033997Z [36;1m[0m
2026-01-14T08:17:44.6034576Z [36;1m  echo "Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ${REPO_NAME} repo..."[0m
2026-01-14T08:17:44.6035261Z [36;1m  exit 0[0m
2026-01-14T08:17:44.6035467Z [36;1mfi[0m
2026-01-14T08:17:44.6035670Z [36;1m[0m
2026-01-14T08:17:44.6036006Z [36;1mif [[ "${DOCKER_IMAGE_NAME}" == *"${DOCKER_REGISTRY}/${REPO_NAME}"* ]]; then[0m
2026-01-14T08:17:44.6036644Z [36;1m  # The docker image name already includes the ECR prefix and tag, so we can just[0m
2026-01-14T08:17:44.6037213Z [36;1m  # use it as it is, but first let's extract the tag[0m
2026-01-14T08:17:44.6037708Z [36;1m  DOCKER_TAG=$(echo "${DOCKER_IMAGE_NAME}" | awk -F '[:,]' '{print $2}')[0m
2026-01-14T08:17:44.6038261Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6038761Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6039179Z [36;1melse[0m
2026-01-14T08:17:44.6039449Z [36;1m  if [[ "${DOCKER_IMAGE_NAME}" == *:* ]]; then[0m
2026-01-14T08:17:44.6040045Z [36;1m    CUSTOM_TAG_PREFIX=${DOCKER_IMAGE_NAME#*:}[0m
2026-01-14T08:17:44.6040457Z [36;1m    DOCKER_IMAGE_NAME=${DOCKER_IMAGE_NAME%%:*}[0m
2026-01-14T08:17:44.6040793Z [36;1m  fi[0m
2026-01-14T08:17:44.6041274Z [36;1m  DOCKER_TAG=${CUSTOM_TAG_PREFIX:+${CUSTOM_TAG_PREFIX}-}$(git rev-parse HEAD:"${DOCKER_BUILD_DIR}")[0m
2026-01-14T08:17:44.6041920Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6042598Z [36;1m  echo "docker-image=${DOCKER_REGISTRY}/${REPO_NAME}/${DOCKER_IMAGE_NAME}:${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6043350Z [36;1m  echo "custom-tag-prefix=${CUSTOM_TAG_PREFIX}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:44.6043881Z [36;1mfi[0m
2026-01-14T08:17:44.6053363Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:44.6053731Z env:
2026-01-14T08:17:44.6053994Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.6054353Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:44.6054622Z   PR_NUMBER: 3500
2026-01-14T08:17:44.6056291Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:44.6058163Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:44.6058772Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:44.6059348Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:44.6059745Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:44.6060058Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:44.6060414Z   REPO_NAME: ao
2026-01-14T08:17:44.6060711Z   DOCKER_IMAGE_NAME: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.6061077Z   DOCKER_BUILD_DIR: .ci/docker
2026-01-14T08:17:44.6061359Z   DOCKER_BUILD_SCRIPT: ./build.sh
2026-01-14T08:17:44.6061729Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:44.6062140Z   USE_CUSTOM_DOCKER_REGISTRY: true
2026-01-14T08:17:44.6062435Z   CUSTOM_TAG_PREFIX: 
2026-01-14T08:17:44.6062670Z ##[endgroup]
2026-01-14T08:17:44.6093941Z + [[ -d .ci/docker ]]
2026-01-14T08:17:44.6094245Z + echo skip=true
2026-01-14T08:17:44.6094570Z + echo docker-image=pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.6095265Z + echo 'Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...'
2026-01-14T08:17:44.6095906Z + exit 0
2026-01-14T08:17:44.6096402Z Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...
2026-01-14T08:17:44.6139541Z ##[group]Run set -eux
2026-01-14T08:17:44.6139816Z [36;1mset -eux[0m
2026-01-14T08:17:44.6140283Z [36;1m# It's ok if this steps fails, it would then be an anonymous user like what we used to have[0m
2026-01-14T08:17:44.6141543Z [36;1maws secretsmanager get-secret-value --secret-id docker_hub_readonly_token | jq --raw-output '.SecretString' | jq -r .docker_hub_readonly_token | docker login --username pytorchbot --password-stdin || true[0m
2026-01-14T08:17:44.6151529Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:44.6151905Z env:
2026-01-14T08:17:44.6152179Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:44.6152553Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:44.6152808Z   PR_NUMBER: 3500
2026-01-14T08:17:44.6154691Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:44.6156587Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:44.6157198Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:44.6157788Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:44.6158188Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:44.6158525Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:44.6158905Z ##[endgroup]
2026-01-14T08:17:44.6192532Z + aws secretsmanager get-secret-value --secret-id docker_hub_readonly_token
2026-01-14T08:17:44.6193227Z + jq --raw-output .SecretString
2026-01-14T08:17:44.6194884Z + jq -r .docker_hub_readonly_token
2026-01-14T08:17:44.6195824Z + docker login --username pytorchbot --password-stdin
2026-01-14T08:17:45.2190003Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:45.2190646Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:45.2191207Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:45.2191610Z 
2026-01-14T08:17:45.2191738Z Login Succeeded
2026-01-14T08:17:45.2273346Z Prepare all required actions
2026-01-14T08:17:45.2314833Z ##[group]Run ./test-infra/.github/actions/pull-docker-image
2026-01-14T08:17:45.2315203Z with:
2026-01-14T08:17:45.2315463Z   docker-image: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:45.2315921Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:45.2316306Z env:
2026-01-14T08:17:45.2316580Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:45.2316939Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:45.2317197Z   PR_NUMBER: 3500
2026-01-14T08:17:45.2318869Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:45.2320785Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:45.2321390Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:45.2321964Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:45.2322378Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:45.2322690Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:45.2323058Z ##[endgroup]
2026-01-14T08:17:45.2358390Z ##[group]Run set -x
2026-01-14T08:17:45.2358655Z [36;1mset -x[0m
2026-01-14T08:17:45.2358869Z [36;1mset +e[0m
2026-01-14T08:17:45.2359067Z [36;1m[0m
2026-01-14T08:17:45.2359271Z [36;1mlogin() {[0m
2026-01-14T08:17:45.2359752Z [36;1m  aws ecr get-login-password --region us-east-1 | docker login -u AWS --password-stdin "$1"[0m
2026-01-14T08:17:45.2360303Z [36;1m}[0m
2026-01-14T08:17:45.2360497Z [36;1m[0m
2026-01-14T08:17:45.2360696Z [36;1mretry () {[0m
2026-01-14T08:17:45.2360964Z [36;1m  $*  || (sleep 1 && $*) || (sleep 2 && $*)[0m
2026-01-14T08:17:45.2361283Z [36;1m}[0m
2026-01-14T08:17:45.2361471Z [36;1m[0m
2026-01-14T08:17:45.2361699Z [36;1mretry login "${DOCKER_REGISTRY}"[0m
2026-01-14T08:17:45.2361999Z [36;1m[0m
2026-01-14T08:17:45.2362501Z [36;1mIMAGE_SIZE=$(docker manifest inspect "${DOCKER_IMAGE}" | jq '[.layers[].size, .config.size] | add / 1024 / 1024')[0m
2026-01-14T08:17:45.2363203Z [36;1mecho "Compressed size of image in MB: ${IMAGE_SIZE}"[0m
2026-01-14T08:17:45.2363582Z [36;1m[0m
2026-01-14T08:17:45.2363786Z [36;1mset -e[0m
2026-01-14T08:17:45.2364120Z [36;1m# ignore output since only exit code is used for conditional[0m
2026-01-14T08:17:45.2364631Z [36;1m# only pull docker image if it's not available locally[0m
2026-01-14T08:17:45.2365194Z [36;1mif ! docker inspect --type=image "${DOCKER_IMAGE}" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:17:45.2365711Z [36;1m  retry docker pull "${DOCKER_IMAGE}"[0m
2026-01-14T08:17:45.2366032Z [36;1mfi[0m
2026-01-14T08:17:45.2376639Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:45.2377007Z env:
2026-01-14T08:17:45.2377254Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:45.2377609Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:45.2377854Z   PR_NUMBER: 3500
2026-01-14T08:17:45.2379511Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:45.2381549Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:45.2382146Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:45.2382714Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:45.2383265Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:45.2383577Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:45.2384041Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:45.2384419Z ##[endgroup]
2026-01-14T08:17:45.2418285Z + set +e
2026-01-14T08:17:45.2418620Z + retry login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:45.2419167Z + login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:45.2422387Z + aws ecr get-login-password --region us-east-1
2026-01-14T08:17:45.2424184Z + docker login -u AWS --password-stdin 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:45.8106304Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:45.8106939Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:45.8107517Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:45.8107915Z 
2026-01-14T08:17:45.8108055Z Login Succeeded
2026-01-14T08:17:45.8144578Z ++ docker manifest inspect pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:45.8145417Z ++ jq '[.layers[].size, .config.size] | add / 1024 / 1024'
2026-01-14T08:17:46.0049834Z + IMAGE_SIZE=7985.954789161682
2026-01-14T08:17:46.0050253Z + echo 'Compressed size of image in MB: 7985.954789161682'
2026-01-14T08:17:46.0050604Z + set -e
2026-01-14T08:17:46.0050925Z + docker inspect --type=image pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:46.0051385Z Compressed size of image in MB: 7985.954789161682
2026-01-14T08:17:46.0223745Z + retry docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:46.0224154Z + docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:46.1975055Z cuda12.6: Pulling from pytorch/almalinux-builder
2026-01-14T08:17:46.1975639Z 19877a9af8e3: Pulling fs layer
2026-01-14T08:17:46.1976061Z 7335f5694751: Pulling fs layer
2026-01-14T08:17:46.1976462Z e89b428500ef: Pulling fs layer
2026-01-14T08:17:46.1976878Z 2890bcc97ae2: Pulling fs layer
2026-01-14T08:17:46.1977269Z 8e7a9d654295: Pulling fs layer
2026-01-14T08:17:46.1977547Z 55070e1f6d59: Pulling fs layer
2026-01-14T08:17:46.1977816Z a6ffcda215dd: Pulling fs layer
2026-01-14T08:17:46.1978080Z 4f4fb700ef54: Pulling fs layer
2026-01-14T08:17:46.1978353Z d4e5a2339eb1: Pulling fs layer
2026-01-14T08:17:46.1978620Z 3b50177ed801: Pulling fs layer
2026-01-14T08:17:46.1978878Z 657cfc9d9d43: Pulling fs layer
2026-01-14T08:17:46.1979156Z 039239a19e2c: Pulling fs layer
2026-01-14T08:17:46.1979416Z 301a59dd8ea1: Pulling fs layer
2026-01-14T08:17:46.1979685Z 747a1c0117bc: Pulling fs layer
2026-01-14T08:17:46.1979947Z 2d6f0c29ad9f: Pulling fs layer
2026-01-14T08:17:46.1980227Z 5b7921a1b019: Pulling fs layer
2026-01-14T08:17:46.1980496Z a4392ccb83ef: Pulling fs layer
2026-01-14T08:17:46.1980758Z 3f0968dff130: Pulling fs layer
2026-01-14T08:17:46.1981020Z 9323969b3930: Pulling fs layer
2026-01-14T08:17:46.1981278Z b9f6732b07f0: Pulling fs layer
2026-01-14T08:17:46.1981544Z 32117f6e66ab: Pulling fs layer
2026-01-14T08:17:46.1981809Z bed95346686d: Pulling fs layer
2026-01-14T08:17:46.1982082Z a73f5cbdff4f: Pulling fs layer
2026-01-14T08:17:46.1982339Z 039239a19e2c: Waiting
2026-01-14T08:17:46.1982570Z a6ffcda215dd: Waiting
2026-01-14T08:17:46.1982792Z 4f4fb700ef54: Waiting
2026-01-14T08:17:46.1983016Z d4e5a2339eb1: Waiting
2026-01-14T08:17:46.1983236Z 301a59dd8ea1: Waiting
2026-01-14T08:17:46.1983459Z 3b50177ed801: Waiting
2026-01-14T08:17:46.1984603Z 747a1c0117bc: Waiting
2026-01-14T08:17:46.1984821Z 2d6f0c29ad9f: Waiting
2026-01-14T08:17:46.1985046Z 657cfc9d9d43: Waiting
2026-01-14T08:17:46.1985258Z 5b7921a1b019: Waiting
2026-01-14T08:17:46.1985484Z a4392ccb83ef: Waiting
2026-01-14T08:17:46.1985696Z 8e7a9d654295: Waiting
2026-01-14T08:17:46.1985912Z 55070e1f6d59: Waiting
2026-01-14T08:17:46.1986124Z 3f0968dff130: Waiting
2026-01-14T08:17:46.1986344Z b9f6732b07f0: Waiting
2026-01-14T08:17:46.1986560Z 32117f6e66ab: Waiting
2026-01-14T08:17:46.1986779Z bed95346686d: Waiting
2026-01-14T08:17:46.1987160Z 9323969b3930: Waiting
2026-01-14T08:17:46.1987387Z a73f5cbdff4f: Waiting
2026-01-14T08:17:46.1987611Z 2890bcc97ae2: Waiting
2026-01-14T08:17:46.2783400Z e89b428500ef: Verifying Checksum
2026-01-14T08:17:46.2783713Z e89b428500ef: Download complete
2026-01-14T08:17:46.6574496Z 2890bcc97ae2: Verifying Checksum
2026-01-14T08:17:46.6575390Z 2890bcc97ae2: Download complete
2026-01-14T08:17:46.9368740Z 19877a9af8e3: Verifying Checksum
2026-01-14T08:17:46.9369074Z 19877a9af8e3: Download complete
2026-01-14T08:17:47.0030081Z 55070e1f6d59: Download complete
2026-01-14T08:17:47.4844099Z a6ffcda215dd: Verifying Checksum
2026-01-14T08:17:47.4844414Z a6ffcda215dd: Download complete
2026-01-14T08:17:47.5351827Z 4f4fb700ef54: Download complete
2026-01-14T08:17:47.5766037Z d4e5a2339eb1: Download complete
2026-01-14T08:17:47.6220303Z 3b50177ed801: Download complete
2026-01-14T08:17:47.6851767Z 657cfc9d9d43: Verifying Checksum
2026-01-14T08:17:47.6852385Z 657cfc9d9d43: Download complete
2026-01-14T08:17:47.7387651Z 039239a19e2c: Download complete
2026-01-14T08:17:47.9828868Z 7335f5694751: Verifying Checksum
2026-01-14T08:17:47.9829445Z 7335f5694751: Download complete
2026-01-14T08:17:48.1043325Z 747a1c0117bc: Verifying Checksum
2026-01-14T08:17:48.1043638Z 747a1c0117bc: Download complete
2026-01-14T08:17:48.1612173Z 2d6f0c29ad9f: Verifying Checksum
2026-01-14T08:17:48.1612501Z 2d6f0c29ad9f: Download complete
2026-01-14T08:17:48.7423317Z 8e7a9d654295: Verifying Checksum
2026-01-14T08:17:48.7423649Z 8e7a9d654295: Download complete
2026-01-14T08:17:48.7830253Z a4392ccb83ef: Verifying Checksum
2026-01-14T08:17:48.7830833Z a4392ccb83ef: Download complete
2026-01-14T08:17:48.8278849Z 3f0968dff130: Verifying Checksum
2026-01-14T08:17:48.8279299Z 3f0968dff130: Download complete
2026-01-14T08:17:48.8770441Z 9323969b3930: Verifying Checksum
2026-01-14T08:17:48.8770753Z 9323969b3930: Download complete
2026-01-14T08:17:49.0244639Z b9f6732b07f0: Verifying Checksum
2026-01-14T08:17:49.0244974Z b9f6732b07f0: Download complete
2026-01-14T08:17:49.0700250Z 32117f6e66ab: Verifying Checksum
2026-01-14T08:17:49.0700569Z 32117f6e66ab: Download complete
2026-01-14T08:17:49.1165010Z bed95346686d: Download complete
2026-01-14T08:17:49.6490396Z 19877a9af8e3: Pull complete
2026-01-14T08:17:52.6859232Z 5b7921a1b019: Verifying Checksum
2026-01-14T08:17:52.6859557Z 5b7921a1b019: Download complete
2026-01-14T08:17:53.4624197Z 7335f5694751: Pull complete
2026-01-14T08:17:53.6644577Z e89b428500ef: Pull complete
2026-01-14T08:17:53.9524167Z 2890bcc97ae2: Pull complete
2026-01-14T08:17:55.0625993Z a73f5cbdff4f: Download complete
2026-01-14T08:18:00.1836390Z 8e7a9d654295: Pull complete
2026-01-14T08:18:00.1957994Z 55070e1f6d59: Pull complete
2026-01-14T08:18:01.4855500Z a6ffcda215dd: Pull complete
2026-01-14T08:18:01.5000665Z 4f4fb700ef54: Pull complete
2026-01-14T08:18:53.0566933Z d4e5a2339eb1: Pull complete
2026-01-14T08:18:53.0794408Z 3b50177ed801: Pull complete
2026-01-14T08:18:53.1017956Z 657cfc9d9d43: Pull complete
2026-01-14T08:18:53.1244386Z 039239a19e2c: Pull complete
2026-01-14T08:18:55.5081330Z 301a59dd8ea1: Verifying Checksum
2026-01-14T08:18:55.5081689Z 301a59dd8ea1: Download complete
2026-01-14T08:19:55.7137512Z 301a59dd8ea1: Pull complete
2026-01-14T08:19:56.3301643Z 747a1c0117bc: Pull complete
2026-01-14T08:19:56.8742118Z 2d6f0c29ad9f: Pull complete
2026-01-14T08:20:13.8703987Z 5b7921a1b019: Pull complete
2026-01-14T08:20:14.2087011Z a4392ccb83ef: Pull complete
2026-01-14T08:20:14.7267575Z 3f0968dff130: Pull complete
2026-01-14T08:20:15.2367250Z 9323969b3930: Pull complete
2026-01-14T08:20:15.8766292Z b9f6732b07f0: Pull complete
2026-01-14T08:20:16.4101038Z 32117f6e66ab: Pull complete
2026-01-14T08:20:16.8589194Z bed95346686d: Pull complete
2026-01-14T08:20:38.3156706Z a73f5cbdff4f: Pull complete
2026-01-14T08:20:38.5145028Z Digest: sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T08:20:38.6256099Z Status: Downloaded newer image for pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.6587586Z docker.io/pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.6658396Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:38.6659450Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:38.6670097Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:38.6670471Z env:
2026-01-14T08:20:38.6670729Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.6671084Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:38.6671334Z   PR_NUMBER: 3500
2026-01-14T08:20:38.6673012Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:38.6675430Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:38.6676188Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:38.6676853Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:38.6677244Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:38.6677564Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:38.6677909Z ##[endgroup]
2026-01-14T08:20:38.6897061Z Prepare all required actions
2026-01-14T08:20:38.6897423Z Getting action download info
2026-01-14T08:20:38.8731235Z ##[group]Run ./test-infra/.github/actions/setup-nvidia
2026-01-14T08:20:38.8731591Z with:
2026-01-14T08:20:38.8731797Z   driver-version: 580.65.06
2026-01-14T08:20:38.8732047Z env:
2026-01-14T08:20:38.8732300Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.8732663Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:38.8732913Z   PR_NUMBER: 3500
2026-01-14T08:20:38.8734565Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:38.8736479Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:38.8737075Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:38.8737638Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:38.8738037Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:38.8738346Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:38.8738702Z ##[endgroup]
2026-01-14T08:20:38.8880559Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:38.8881582Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:38.8891319Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:38.8891701Z env:
2026-01-14T08:20:38.8891969Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.8892512Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:38.8892770Z   PR_NUMBER: 3500
2026-01-14T08:20:38.8894433Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:38.8896300Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:38.8896894Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:38.8897462Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:38.8897852Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:38.8898165Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:38.8898521Z ##[endgroup]
2026-01-14T08:20:38.9028786Z ##[group]Run set -euo pipefail
2026-01-14T08:20:38.9029127Z [36;1mset -euo pipefail[0m
2026-01-14T08:20:38.9029375Z [36;1m[0m
2026-01-14T08:20:38.9029587Z [36;1mhas_gpu=false[0m
2026-01-14T08:20:38.9029829Z [36;1mdevices=""[0m
2026-01-14T08:20:38.9030058Z [36;1m[0m
2026-01-14T08:20:38.9030328Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:20:38.9030847Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:38.9031251Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:38.9031544Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:38.9031855Z [36;1m  fi[0m
2026-01-14T08:20:38.9032048Z [36;1mfi[0m
2026-01-14T08:20:38.9032241Z [36;1m[0m
2026-01-14T08:20:38.9032447Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:20:38.9032842Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:38.9033224Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:38.9033523Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:38.9033829Z [36;1m  fi[0m
2026-01-14T08:20:38.9034208Z [36;1mfi[0m
2026-01-14T08:20:38.9034409Z [36;1m[0m
2026-01-14T08:20:38.9034713Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:20:38.9035248Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:38.9035668Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:38.9035954Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:38.9036263Z [36;1m  fi[0m
2026-01-14T08:20:38.9036462Z [36;1mfi[0m
2026-01-14T08:20:38.9036647Z [36;1m[0m
2026-01-14T08:20:38.9036941Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:38.9037485Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:38.9047029Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:38.9047398Z env:
2026-01-14T08:20:38.9047658Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.9048004Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:38.9048262Z   PR_NUMBER: 3500
2026-01-14T08:20:38.9049990Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:38.9051859Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:38.9052463Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:38.9063857Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:38.9064303Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:38.9064612Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:38.9065164Z ##[endgroup]
2026-01-14T08:20:38.9962634Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:20:38.9963026Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:20:38.9963419Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:38.9963966Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:38.9964451Z [36;1melse[0m
2026-01-14T08:20:38.9964736Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:38.9965078Z [36;1mfi[0m
2026-01-14T08:20:38.9975399Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:38.9975771Z env:
2026-01-14T08:20:38.9976034Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:38.9976396Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:38.9976657Z   PR_NUMBER: 3500
2026-01-14T08:20:38.9978348Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:38.9980250Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:38.9980858Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:38.9981432Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:38.9981833Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:38.9982154Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:38.9982519Z   HAS_NVIDIA: true
2026-01-14T08:20:38.9982742Z ##[endgroup]
2026-01-14T08:20:39.0145137Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:20:39.0145565Z with:
2026-01-14T08:20:39.0145758Z   timeout_minutes: 10
2026-01-14T08:20:39.0146018Z   max_attempts: 3
2026-01-14T08:20:39.0179678Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:20:39.0213324Z   retry_wait_seconds: 10
2026-01-14T08:20:39.0213674Z   polling_interval_seconds: 1
2026-01-14T08:20:39.0213967Z   warning_on_retry: true
2026-01-14T08:20:39.0214228Z   continue_on_error: false
2026-01-14T08:20:39.0214491Z env:
2026-01-14T08:20:39.0214752Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:39.0215119Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:39.0215389Z   PR_NUMBER: 3500
2026-01-14T08:20:39.0217045Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:39.0218917Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:39.0219528Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:39.0220098Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:39.0220500Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:39.0220804Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:39.0221171Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:20:39.0221417Z ##[endgroup]
2026-01-14T08:20:39.1347084Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:20:39.1350240Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:20:39.1353408Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:20:39.4904644Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:20:39.4905342Z No packages marked for removal.
2026-01-14T08:20:39.4957178Z Dependencies resolved.
2026-01-14T08:20:39.4966601Z Nothing to do.
2026-01-14T08:20:39.4967058Z Complete!
2026-01-14T08:20:39.5834763Z + install_nvidia_driver_common
2026-01-14T08:20:39.5838746Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:20:39.5839187Z + lspci
2026-01-14T08:20:39.5839853Z Before installing NVIDIA driver
2026-01-14T08:20:39.5959384Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:39.5960715Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:39.5962185Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:39.5963642Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:39.5965064Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:39.5966387Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:39.5967438Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.5968352Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.5969270Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.5970072Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.5970611Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:39.5971074Z + lsmod
2026-01-14T08:20:39.6024695Z Module                  Size  Used by
2026-01-14T08:20:39.6025132Z veth                   36864  0
2026-01-14T08:20:39.6025559Z nvidia_modeset       1740800  0
2026-01-14T08:20:39.6025882Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:39.6026200Z wmi                    36864  1 video
2026-01-14T08:20:39.6026482Z nvidia_uvm           1921024  0
2026-01-14T08:20:39.6026808Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:39.6027162Z drm                   602112  1 nvidia
2026-01-14T08:20:39.6027488Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:39.6027869Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:39.6028236Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:39.6028631Z mgc                    86016  1
2026-01-14T08:20:39.6028992Z lustre               1085440  4
2026-01-14T08:20:39.6029564Z mdc                   294912  2 lustre
2026-01-14T08:20:39.6029849Z fid                    36864  1 mdc
2026-01-14T08:20:39.6030134Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:39.6030422Z osc                   479232  5 mdc
2026-01-14T08:20:39.6030695Z lmv                   225280  2 lustre
2026-01-14T08:20:39.6030973Z fld                    49152  2 lov,lmv
2026-01-14T08:20:39.6031329Z ksocklnd              188416  1
2026-01-14T08:20:39.6031812Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:39.6032486Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:39.6033114Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:39.6033737Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:39.6034272Z xt_conntrack           16384  1
2026-01-14T08:20:39.6034540Z nft_chain_nat          16384  3
2026-01-14T08:20:39.6034822Z xt_MASQUERADE          20480  1
2026-01-14T08:20:39.6035147Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:39.6035499Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:39.6035926Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:39.6036405Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:39.6036737Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:39.6037041Z xfrm_user              57344  1
2026-01-14T08:20:39.6037322Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:39.6037617Z xt_addrtype            16384  2
2026-01-14T08:20:39.6037890Z nft_compat             20480  4
2026-01-14T08:20:39.6038235Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:39.6038682Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:39.6039103Z br_netfilter           36864  0
2026-01-14T08:20:39.6039394Z bridge                323584  1 br_netfilter
2026-01-14T08:20:39.6039714Z stp                    16384  1 bridge
2026-01-14T08:20:39.6040223Z llc                    16384  2 bridge,stp
2026-01-14T08:20:39.6040530Z overlay               167936  0
2026-01-14T08:20:39.6040787Z tls                   139264  0
2026-01-14T08:20:39.6041056Z nls_ascii              16384  1
2026-01-14T08:20:39.6041324Z nls_cp437              20480  1
2026-01-14T08:20:39.6041579Z vfat                   24576  1
2026-01-14T08:20:39.6041843Z fat                    86016  1 vfat
2026-01-14T08:20:39.6042119Z sunrpc                700416  2 lnet
2026-01-14T08:20:39.6042412Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:39.6042673Z i8042                  45056  0
2026-01-14T08:20:39.6042944Z serio                  28672  3 i8042
2026-01-14T08:20:39.6043237Z ena                   196608  0
2026-01-14T08:20:39.6043498Z button                 24576  0
2026-01-14T08:20:39.6043756Z sch_fq_codel           20480  33
2026-01-14T08:20:39.6044039Z fuse                  184320  1
2026-01-14T08:20:39.6044288Z loop                   36864  0
2026-01-14T08:20:39.6044562Z dm_mod                188416  0
2026-01-14T08:20:39.6044817Z configfs               57344  1
2026-01-14T08:20:39.6045083Z dmi_sysfs              20480  0
2026-01-14T08:20:39.6045339Z crc32_pclmul           16384  0
2026-01-14T08:20:39.6045602Z crc32c_intel           24576  0
2026-01-14T08:20:39.6045853Z efivarfs               24576  1
2026-01-14T08:20:39.6046107Z + modinfo nvidia
2026-01-14T08:20:39.6046532Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:39.6047244Z import_ns:      DMA_BUF
2026-01-14T08:20:39.6062171Z alias:          char-major-195-*
2026-01-14T08:20:39.6062568Z version:        580.65.06
2026-01-14T08:20:39.6062921Z supported:      external
2026-01-14T08:20:39.6063267Z license:        Dual MIT/GPL
2026-01-14T08:20:39.6063674Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:39.6064040Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:39.6064524Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:39.6064868Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:39.6065237Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:39.6065612Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:39.6065981Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:39.6066343Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:39.6066690Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:39.6067047Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:39.6067370Z depends:        i2c-core,drm
2026-01-14T08:20:39.6067630Z retpoline:      Y
2026-01-14T08:20:39.6067846Z name:           nvidia
2026-01-14T08:20:39.6068233Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:39.6068766Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:39.6069248Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:39.6069711Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:39.6070087Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:39.6070404Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:39.6070727Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:39.6071043Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:39.6071354Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:39.6071734Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:39.6072154Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:39.6072497Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:39.6072820Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:39.6073128Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:39.6073514Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:39.6073937Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:39.6074355Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:39.6075231Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:39.6075689Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:39.6076139Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:39.6076577Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:39.6076943Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:39.6077330Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:39.6077729Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:39.6078088Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:39.6078413Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:39.6078748Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:39.6079084Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:39.6079413Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:39.6079778Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:39.6080177Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:39.6080598Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:39.6080986Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:39.6081333Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:39.6081701Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:39.6082067Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:39.6082429Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:39.6082788Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:39.6083135Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:39.6083434Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:39.6083768Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:39.6084117Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:39.6084579Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:39.6084934Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:39.6085309Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:39.6085689Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:39.6086041Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:39.6086403Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:39.6086769Z parm:           rm_firmware_active:charp
2026-01-14T08:20:39.6087081Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:20:39.6087328Z ++ command -v nvidia-smi
2026-01-14T08:20:39.6087588Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:20:39.6087958Z + set +e
2026-01-14T08:20:39.6088422Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:20:39.6592546Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:20:39.6592985Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:39.6593313Z + '[' 0 -ne 0 ']'
2026-01-14T08:20:39.6593610Z + '[' 580.65.06 '!=' 580.65.06 ']'
2026-01-14T08:20:39.6593985Z + HAS_NVIDIA_DRIVER=1
2026-01-14T08:20:39.6594572Z + echo 'NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation'
2026-01-14T08:20:39.6595276Z + set -e
2026-01-14T08:20:39.6595539Z + '[' 1 -eq 0 ']'
2026-01-14T08:20:39.6596093Z NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation
2026-01-14T08:20:39.6596625Z + post_install_nvidia_driver_common
2026-01-14T08:20:39.6600049Z + sudo modprobe nvidia
2026-01-14T08:20:39.7577261Z + echo 'After installing NVIDIA driver'
2026-01-14T08:20:39.7577728Z + lspci
2026-01-14T08:20:39.7578028Z After installing NVIDIA driver
2026-01-14T08:20:39.7694135Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:39.7694862Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:39.7695612Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:39.7696214Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:39.7696973Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:39.7697566Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:39.7698203Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.7698844Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.7699476Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.7700112Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:39.7700837Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:39.7701328Z + lsmod
2026-01-14T08:20:39.7745246Z Module                  Size  Used by
2026-01-14T08:20:39.7745665Z veth                   36864  0
2026-01-14T08:20:39.7746051Z nvidia_modeset       1740800  0
2026-01-14T08:20:39.7746462Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:39.7746881Z wmi                    36864  1 video
2026-01-14T08:20:39.7747234Z nvidia_uvm           1921024  0
2026-01-14T08:20:39.7747548Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:39.7747950Z drm                   602112  1 nvidia
2026-01-14T08:20:39.7748306Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:39.7748677Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:39.7749039Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:39.7749322Z mgc                    86016  1
2026-01-14T08:20:39.7749575Z lustre               1085440  4
2026-01-14T08:20:39.7749836Z mdc                   294912  2 lustre
2026-01-14T08:20:39.7750156Z fid                    36864  1 mdc
2026-01-14T08:20:39.7750438Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:39.7750724Z osc                   479232  5 mdc
2026-01-14T08:20:39.7751006Z lmv                   225280  2 lustre
2026-01-14T08:20:39.7751465Z fld                    49152  2 lov,lmv
2026-01-14T08:20:39.7751749Z ksocklnd              188416  1
2026-01-14T08:20:39.7752088Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:39.7752586Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:39.7753105Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:39.7753730Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:39.7754256Z xt_conntrack           16384  1
2026-01-14T08:20:39.7754514Z nft_chain_nat          16384  3
2026-01-14T08:20:39.7754781Z xt_MASQUERADE          20480  1
2026-01-14T08:20:39.7755090Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:39.7755451Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:39.7755873Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:39.7756362Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:39.7756688Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:39.7757009Z xfrm_user              57344  1
2026-01-14T08:20:39.7757282Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:39.7757576Z xt_addrtype            16384  2
2026-01-14T08:20:39.7757839Z nft_compat             20480  4
2026-01-14T08:20:39.7758150Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:39.7758605Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:39.7759010Z br_netfilter           36864  0
2026-01-14T08:20:39.7759294Z bridge                323584  1 br_netfilter
2026-01-14T08:20:39.7759603Z stp                    16384  1 bridge
2026-01-14T08:20:39.7759913Z llc                    16384  2 bridge,stp
2026-01-14T08:20:39.7760235Z overlay               167936  0
2026-01-14T08:20:39.7760489Z tls                   139264  0
2026-01-14T08:20:39.7760743Z nls_ascii              16384  1
2026-01-14T08:20:39.7761002Z nls_cp437              20480  1
2026-01-14T08:20:39.7761362Z vfat                   24576  1
2026-01-14T08:20:39.7761612Z fat                    86016  1 vfat
2026-01-14T08:20:39.7761893Z sunrpc                700416  2 lnet
2026-01-14T08:20:39.7762178Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:39.7762439Z i8042                  45056  0
2026-01-14T08:20:39.7762704Z serio                  28672  3 i8042
2026-01-14T08:20:39.7762973Z ena                   196608  0
2026-01-14T08:20:39.7763226Z button                 24576  0
2026-01-14T08:20:39.7763476Z sch_fq_codel           20480  33
2026-01-14T08:20:39.7763735Z fuse                  184320  1
2026-01-14T08:20:39.7763979Z loop                   36864  0
2026-01-14T08:20:39.7764229Z dm_mod                188416  0
2026-01-14T08:20:39.7764478Z configfs               57344  1
2026-01-14T08:20:39.7764741Z dmi_sysfs              20480  0
2026-01-14T08:20:39.7764998Z crc32_pclmul           16384  0
2026-01-14T08:20:39.7765255Z crc32c_intel           24576  0
2026-01-14T08:20:39.7765515Z efivarfs               24576  1
2026-01-14T08:20:39.7765769Z + modinfo nvidia
2026-01-14T08:20:39.7768221Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:39.7768823Z import_ns:      DMA_BUF
2026-01-14T08:20:39.7769070Z alias:          char-major-195-*
2026-01-14T08:20:39.7769345Z version:        580.65.06
2026-01-14T08:20:39.7769590Z supported:      external
2026-01-14T08:20:39.7769905Z license:        Dual MIT/GPL
2026-01-14T08:20:39.7770190Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:39.7770544Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:39.7770874Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:39.7771246Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:39.7771620Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:39.7771981Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:39.7772465Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:39.7772818Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:39.7773172Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:39.7773520Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:39.7773850Z depends:        i2c-core,drm
2026-01-14T08:20:39.7774102Z retpoline:      Y
2026-01-14T08:20:39.7774317Z name:           nvidia
2026-01-14T08:20:39.7774873Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:39.7775393Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:39.7775878Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:39.7776328Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:39.7776651Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:39.7776953Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:39.7777285Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:39.7777599Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:39.7777923Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:39.7778305Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:39.7778716Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:39.7779071Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:39.7779382Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:39.7779703Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:39.7780107Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:39.7780571Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:39.7780987Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:39.7781427Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:39.7781879Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:39.7782320Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:39.7782770Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:39.7783277Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:39.7783679Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:39.7784088Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:39.7784446Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:39.7784784Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:39.7785127Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:39.7785467Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:39.7785787Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:39.7786161Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:39.7786543Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:39.7786925Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:39.7787324Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:39.7787677Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:39.7788048Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:39.7788415Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:39.7788782Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:39.7789140Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:39.7789494Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:39.7789790Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:39.7790180Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:39.7790524Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:39.7790850Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:39.7791199Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:39.7791569Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:39.7791952Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:39.7792287Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:39.7792785Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:39.7793146Z parm:           rm_firmware_active:charp
2026-01-14T08:20:39.7793444Z + set +e
2026-01-14T08:20:39.7793638Z + nvidia-smi
2026-01-14T08:20:39.8207016Z Wed Jan 14 08:20:39 2026       
2026-01-14T08:20:39.8208057Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:39.8209206Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:20:39.8210216Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:39.8210814Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:20:39.8211422Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:20:39.8211940Z |                                         |                        |               MIG M. |
2026-01-14T08:20:39.8212361Z |=========================================+========================+======================|
2026-01-14T08:20:39.8816716Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:20:39.8817917Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:39.8818809Z |                                         |                        |                  N/A |
2026-01-14T08:20:39.8819748Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:39.8820453Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:20:39.8820964Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:39.8821416Z |                                         |                        |                  N/A |
2026-01-14T08:20:39.8821882Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:39.8822604Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:20:39.8823107Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:39.8823569Z |                                         |                        |                  N/A |
2026-01-14T08:20:39.8824038Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:39.8824571Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:20:39.8825088Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:39.8825536Z |                                         |                        |                  N/A |
2026-01-14T08:20:39.8826011Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:39.8844616Z 
2026-01-14T08:20:39.8845195Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:39.8845763Z | Processes:                                                                              |
2026-01-14T08:20:39.8846290Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:20:39.8846789Z |        ID   ID                                                               Usage      |
2026-01-14T08:20:39.8847205Z |=========================================================================================|
2026-01-14T08:20:39.8883529Z |  No running processes found                                                             |
2026-01-14T08:20:39.8884101Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:40.9416659Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:20:40.9602593Z NVIDIA A10G
2026-01-14T08:20:40.9879963Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:40.9880446Z + '[' 0 -eq 0 ']'
2026-01-14T08:20:40.9880830Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:20:40.9881227Z + set -e
2026-01-14T08:20:40.9881518Z INFO: Ignoring allowed status 0
2026-01-14T08:20:40.9891607Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:20:40.9896314Z + sudo yum install -y yum-utils
2026-01-14T08:20:41.4797789Z Last metadata expiration check: 0:03:41 ago on Wed Jan 14 08:17:00 2026.
2026-01-14T08:20:41.5084348Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:20:41.5713697Z Dependencies resolved.
2026-01-14T08:20:41.6076611Z Nothing to do.
2026-01-14T08:20:41.6077023Z Complete!
2026-01-14T08:20:41.7396824Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:20:41.7397656Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:41.7398718Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:42.0718111Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:42.1226788Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:20:42.6741975Z nvidia-container-toolkit                         18 kB/s | 833  B     00:00    
2026-01-14T08:20:42.7023223Z Package nvidia-container-toolkit-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:42.7031074Z Package libnvidia-container-tools-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:42.7035874Z Package libnvidia-container1-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:42.7045113Z Package nvidia-container-toolkit-base-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:42.7681267Z Dependencies resolved.
2026-01-14T08:20:42.8045568Z Nothing to do.
2026-01-14T08:20:42.8045820Z Complete!
2026-01-14T08:20:42.8871707Z + sudo systemctl restart docker
2026-01-14T08:21:22.5651497Z nvidia-persistenced failed to initialize. Check syslog for more details.
2026-01-14T08:21:22.6114239Z Wed Jan 14 08:21:22 2026       
2026-01-14T08:21:22.6118003Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:22.6119209Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:22.6120323Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:22.6121461Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:22.6122658Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:22.6123490Z |                                         |                        |               MIG M. |
2026-01-14T08:21:22.6123913Z |=========================================+========================+======================|
2026-01-14T08:21:22.6715871Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:22.6716848Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:22.6717665Z |                                         |                        |                  N/A |
2026-01-14T08:21:22.6718517Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:22.6719452Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:22.6720354Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:22.6721166Z |                                         |                        |                  N/A |
2026-01-14T08:21:22.6722006Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:22.6723320Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:22.6723827Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:22.6724275Z |                                         |                        |                  N/A |
2026-01-14T08:21:22.6724739Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:22.6725247Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:22.6725742Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:22.6726184Z |                                         |                        |                  N/A |
2026-01-14T08:21:22.6726651Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:22.6743817Z 
2026-01-14T08:21:22.6744163Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:22.6744672Z | Processes:                                                                              |
2026-01-14T08:21:22.6745193Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:22.6745672Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:22.6746088Z |=========================================================================================|
2026-01-14T08:21:22.6783276Z |  No running processes found                                                             |
2026-01-14T08:21:22.6783821Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:23.7474605Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:21:23.9688957Z 3.13: Pulling from docker/library/python
2026-01-14T08:21:24.0395087Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:21:24.0395437Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:21:24.0395979Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:21:24.0396251Z 26d823e3848f: Pulling fs layer
2026-01-14T08:21:24.0396518Z ca4b54413202: Pulling fs layer
2026-01-14T08:21:24.0396776Z b6513238a015: Pulling fs layer
2026-01-14T08:21:24.0397052Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:21:24.0397302Z ca4b54413202: Waiting
2026-01-14T08:21:24.0397534Z 9b57076d00d4: Waiting
2026-01-14T08:21:24.0397763Z b6513238a015: Waiting
2026-01-14T08:21:24.1827100Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:21:24.1827554Z 82e18c5e1c15: Download complete
2026-01-14T08:21:24.2209294Z 2ca1bfae7ba8: Download complete
2026-01-14T08:21:24.3040443Z ca4b54413202: Verifying Checksum
2026-01-14T08:21:24.3040882Z ca4b54413202: Download complete
2026-01-14T08:21:24.3144154Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:21:24.3144581Z be442a7e0d6f: Download complete
2026-01-14T08:21:24.3480728Z 9b57076d00d4: Verifying Checksum
2026-01-14T08:21:24.3481188Z 9b57076d00d4: Download complete
2026-01-14T08:21:24.4430462Z b6513238a015: Verifying Checksum
2026-01-14T08:21:24.4430887Z b6513238a015: Download complete
2026-01-14T08:21:24.8208193Z 26d823e3848f: Verifying Checksum
2026-01-14T08:21:24.8209008Z 26d823e3848f: Download complete
2026-01-14T08:21:25.9934633Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:21:26.7287810Z 82e18c5e1c15: Pull complete
2026-01-14T08:21:29.2648448Z be442a7e0d6f: Pull complete
2026-01-14T08:21:36.0371694Z 26d823e3848f: Pull complete
2026-01-14T08:21:36.3287125Z ca4b54413202: Pull complete
2026-01-14T08:21:37.1201681Z b6513238a015: Pull complete
2026-01-14T08:21:37.1436718Z 9b57076d00d4: Pull complete
2026-01-14T08:21:37.1576818Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:21:37.1619850Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:21:43.8020891Z Wed Jan 14 08:21:43 2026       
2026-01-14T08:21:43.8021372Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:43.8022422Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:43.8023088Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:43.8023761Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:43.8024379Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:43.8024891Z |                                         |                        |               MIG M. |
2026-01-14T08:21:43.8025306Z |=========================================+========================+======================|
2026-01-14T08:21:43.8629739Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:43.8630783Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:43.8631742Z |                                         |                        |                  N/A |
2026-01-14T08:21:43.8632699Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:43.8633738Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:43.8634729Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:43.8635614Z |                                         |                        |                  N/A |
2026-01-14T08:21:43.8636544Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:43.8637559Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:43.8638546Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:43.8639448Z |                                         |                        |                  N/A |
2026-01-14T08:21:43.8640272Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:43.8640803Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:43.8641302Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:43.8641757Z |                                         |                        |                  N/A |
2026-01-14T08:21:43.8642235Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:43.8657653Z 
2026-01-14T08:21:43.8658072Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:43.8658597Z | Processes:                                                                              |
2026-01-14T08:21:43.8659134Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:43.8659636Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:43.8660065Z |=========================================================================================|
2026-01-14T08:21:43.8696005Z |  No running processes found                                                             |
2026-01-14T08:21:43.8696573Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:46.1303653Z Command completed after 1 attempt(s).
2026-01-14T08:21:46.1418970Z ##[group]Run set -ex
2026-01-14T08:21:46.1419250Z [36;1mset -ex[0m
2026-01-14T08:21:46.1419465Z [36;1m{[0m
2026-01-14T08:21:46.1419677Z [36;1m  echo "#!/usr/bin/env bash";[0m
2026-01-14T08:21:46.1419992Z [36;1m  echo "set -eou pipefail";[0m
2026-01-14T08:21:46.1420307Z [36;1m  # shellcheck disable=SC2016[0m
2026-01-14T08:21:46.1420649Z [36;1m  echo 'eval "$(conda shell.bash hook)"';[0m
2026-01-14T08:21:46.1421183Z [36;1m  echo "set -x";[0m
2026-01-14T08:21:46.1421443Z [36;1m  echo "${SCRIPT}";[0m
2026-01-14T08:21:46.1421731Z [36;1m} > "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:46.1422065Z [36;1mchmod +x "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:46.1422717Z [36;1mpython3 "/home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py" ""[0m
2026-01-14T08:21:46.1438367Z shell: /usr/bin/bash -e {0}
2026-01-14T08:21:46.1438630Z env:
2026-01-14T08:21:46.1438879Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:21:46.1439265Z   REPOSITORY: pytorch/ao
2026-01-14T08:21:46.1439515Z   PR_NUMBER: 3500
2026-01-14T08:21:46.1441249Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:21:46.1443135Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:21:46.1443742Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:21:46.1444317Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:21:46.1444724Z   HAS_NVIDIA_GPU: true
2026-01-14T08:21:46.1445041Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:21:46.1445674Z   ALL_SECRETS: {
  "github_token": "***"
}
2026-01-14T08:21:46.1445983Z ##[endgroup]
2026-01-14T08:21:46.1491477Z + echo '#!/usr/bin/env bash'
2026-01-14T08:21:46.1491778Z + echo 'set -eou pipefail'
2026-01-14T08:21:46.1492055Z + echo 'eval "$(conda shell.bash hook)"'
2026-01-14T08:21:46.1492365Z + echo 'set -x'
2026-01-14T08:21:46.1492733Z + echo 'conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:46.1493201Z conda activate venv
2026-01-14T08:21:46.1493449Z python -m pip install --upgrade pip
2026-01-14T08:21:46.1493757Z pip install torch==2.7.1
2026-01-14T08:21:46.1494022Z sed -i '\'''\'' dev-requirements.txt
2026-01-14T08:21:46.1494337Z pip install -r dev-requirements.txt
2026-01-14T08:21:46.1494649Z pip install . --no-build-isolation
2026-01-14T08:21:46.1494975Z export CONDA=$(dirname $(dirname $(which conda)))
2026-01-14T08:21:46.1495370Z export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
2026-01-14T08:21:46.1495715Z pytest test --verbose -s
2026-01-14T08:21:46.1495956Z '
2026-01-14T08:21:46.1496242Z + chmod +x /home/ec2-user/actions-runner/_work/_temp/exec_script
2026-01-14T08:21:46.1508322Z + python3 /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py ''
2026-01-14T08:22:06.4756337Z Running command: 
2026-01-14T08:22:06.4762427Z         docker run             -e PR_NUMBER             -e RUNNER_ARTIFACT_DIR=/artifacts             -e RUNNER_DOCS_DIR=/docs             -e RUNNER_TEST_RESULTS_DIR=/test-results             --env-file="/home/ec2-user/actions-runner/_work/_temp/github_env_20985547555"             `# It is unknown why the container sees a different value for this.`             -e GITHUB_STEP_SUMMARY             -e SECRET_GITHUB_TOKEN             --cap-add=SYS_PTRACE             --detach             --ipc=host             --security-opt seccomp=unconfined             --shm-size=2g             --tty             --ulimit stack=10485760:83886080             --ulimit core=0             --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all             -v "/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao:/pytorch/ao"             -v "/home/ec2-user/actions-runner/_work/ao/ao/test-infra:/test-infra"             -v "/home/ec2-user/actions-runner/_work/_temp/artifacts:/artifacts"             -v "/home/ec2-user/actions-runner/_work/_temp/docs:/docs"             -v "/home/ec2-user/actions-runner/_work/_temp/test-results:/test-results"             -v "/home/ec2-user/actions-runner/_work/_temp/exec_script:/exec"             -v "/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_db43fa70-4ca2-4b2c-8c75-7d00e40baa7c":"/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_db43fa70-4ca2-4b2c-8c75-7d00e40baa7c"             -w /pytorch/ao             "pytorch/almalinux-builder:cuda12.6"
2026-01-14T08:22:06.4768450Z         
2026-01-14T08:22:06.4768778Z 0d27adf25a38e1a64debb637d15a1e61ad304be7eef367fecb8976cebad085fb
2026-01-14T08:22:06.4769499Z Running command: docker exec -t 0d27adf25a38e1a64debb637d15a1e61ad304be7eef367fecb8976cebad085fb /exec
2026-01-14T08:22:06.4770348Z + conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:06.4770778Z + local cmd=create
2026-01-14T08:22:06.4770987Z + case "$cmd" in
2026-01-14T08:22:06.4771346Z + __conda_exe create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:06.4771982Z + /opt/conda/bin/conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:06.4772497Z Could not load conda plugin `menuinst`:
2026-01-14T08:22:06.4772713Z 
2026-01-14T08:22:06.4772834Z Plugin requires `conda` to be installed.
2026-01-14T08:22:06.4773899Z Collecting package metadata (current_repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:22:06.4775271Z Solving environment: \ unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.
2026-01-14T08:22:06.4776793Z Collecting package metadata (repodata.json): / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:22:06.4777774Z Solving environment: \ | / - \ | done
2026-01-14T08:22:06.4778025Z 
2026-01-14T08:22:06.4778030Z 
2026-01-14T08:22:06.4778162Z ==> WARNING: A newer version of conda exists. <==
2026-01-14T08:22:06.4778507Z   current version: 23.5.2
2026-01-14T08:22:06.4778762Z   latest version: 25.11.1
2026-01-14T08:22:06.4778925Z 
2026-01-14T08:22:06.4779037Z Please update conda by running
2026-01-14T08:22:06.4779219Z 
2026-01-14T08:22:06.4779337Z     $ conda update -n base -c defaults conda
2026-01-14T08:22:06.4779575Z 
2026-01-14T08:22:06.4779786Z Or to minimize the number of packages updated during conda update use
2026-01-14T08:22:06.4780112Z 
2026-01-14T08:22:06.4780221Z      conda install conda=25.11.1
2026-01-14T08:22:06.4780404Z 
2026-01-14T08:22:06.4780408Z 
2026-01-14T08:22:06.4780412Z 
2026-01-14T08:22:06.4780500Z ## Package Plan ##
2026-01-14T08:22:06.4780637Z 
2026-01-14T08:22:06.4780768Z   environment location: /opt/conda/envs/venv
2026-01-14T08:22:06.4780995Z 
2026-01-14T08:22:06.4781094Z   added / updated specs:
2026-01-14T08:22:06.4781349Z     - libgcc-ng=11.2.0
2026-01-14T08:22:06.4781587Z     - libstdcxx-ng=11.2.0
2026-01-14T08:22:06.4781839Z     - python=3.10
2026-01-14T08:22:06.4781975Z 
2026-01-14T08:22:06.4782027Z 
2026-01-14T08:22:06.4782148Z The following packages will be downloaded:
2026-01-14T08:22:06.4782372Z 
2026-01-14T08:22:06.4782489Z     package                    |            build
2026-01-14T08:22:06.4782819Z     ---------------------------|-----------------
2026-01-14T08:22:06.4783193Z     bzip2-1.0.8                |       h5eee18b_6         262 KB
2026-01-14T08:22:06.4783794Z     ld_impl_linux-64-2.44      |       h153f514_2         672 KB
2026-01-14T08:22:06.4784228Z     libffi-3.4.4               |       h6a678d5_1         141 KB
2026-01-14T08:22:06.4784644Z     libnsl-2.0.0               |       h5eee18b_0          31 KB
2026-01-14T08:22:06.4785049Z     libxcb-1.17.0              |       h9b100fa_0         430 KB
2026-01-14T08:22:06.4785466Z     libzlib-1.3.1              |       hb25bd0a_0          59 KB
2026-01-14T08:22:06.4785990Z     ncurses-6.5                |       h7934f7d_0         1.1 MB
2026-01-14T08:22:06.4786395Z     pip-25.3                   |     pyhc872135_0         1.1 MB
2026-01-14T08:22:06.4786811Z     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
2026-01-14T08:22:06.4787248Z     python-3.10.19             |       h6fa692b_0        24.5 MB
2026-01-14T08:22:06.4787670Z     readline-8.3               |       hc2a1206_0         471 KB
2026-01-14T08:22:06.4788094Z     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB
2026-01-14T08:22:06.4788531Z     sqlite-3.51.0              |       h2a70700_0         1.2 MB
2026-01-14T08:22:06.4788920Z     tk-8.6.15                  |       h54e0aa7_0         3.4 MB
2026-01-14T08:22:06.4789321Z     tzdata-2025b               |       h04d1e81_0         116 KB
2026-01-14T08:22:06.4789723Z     wheel-0.45.1               |  py310h06a4308_0         115 KB
2026-01-14T08:22:06.4790146Z     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
2026-01-14T08:22:06.4790591Z     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
2026-01-14T08:22:06.4791025Z     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
2026-01-14T08:22:06.4791480Z     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
2026-01-14T08:22:06.4791893Z     xz-5.6.4                   |       h5eee18b_1         567 KB
2026-01-14T08:22:06.4792283Z     zlib-1.3.1                 |       hb25bd0a_0          96 KB
2026-01-14T08:22:06.4792669Z     ------------------------------------------------------------
2026-01-14T08:22:06.4793043Z                                            Total:        37.1 MB
2026-01-14T08:22:06.4793278Z 
2026-01-14T08:22:06.4793416Z The following NEW packages will be INSTALLED:
2026-01-14T08:22:06.4793656Z 
2026-01-14T08:22:06.4793859Z   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
2026-01-14T08:22:06.4794350Z   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
2026-01-14T08:22:06.4794815Z   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 
2026-01-14T08:22:06.4795344Z   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 
2026-01-14T08:22:06.4795878Z   expat              pkgs/main/linux-64::expat-2.7.3-h3385a95_0 
2026-01-14T08:22:06.4796363Z   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 
2026-01-14T08:22:06.4796869Z   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
2026-01-14T08:22:06.4797331Z   libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
2026-01-14T08:22:06.4797812Z   libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
2026-01-14T08:22:06.4798279Z   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 
2026-01-14T08:22:06.4798760Z   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
2026-01-14T08:22:06.4799270Z   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
2026-01-14T08:22:06.4799731Z   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
2026-01-14T08:22:06.4800192Z   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:06.4800649Z   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 
2026-01-14T08:22:06.4801110Z   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 
2026-01-14T08:22:06.4801557Z   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 
2026-01-14T08:22:06.4802031Z   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
2026-01-14T08:22:06.4802639Z   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 
2026-01-14T08:22:06.4803103Z   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 
2026-01-14T08:22:06.4803618Z   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 
2026-01-14T08:22:06.4804134Z   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 
2026-01-14T08:22:06.4804555Z   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 
2026-01-14T08:22:06.4805057Z   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 
2026-01-14T08:22:06.4805506Z   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 
2026-01-14T08:22:06.4806049Z   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
2026-01-14T08:22:06.4806564Z   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
2026-01-14T08:22:06.4807090Z   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
2026-01-14T08:22:06.4807663Z   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
2026-01-14T08:22:06.4810967Z   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 
2026-01-14T08:22:06.4811390Z   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:06.4811660Z 
2026-01-14T08:22:06.4811664Z 
2026-01-14T08:22:06.4811668Z 
2026-01-14T08:22:06.4811785Z Downloading and Extracting Packages
2026-01-14T08:22:06.4811989Z 
2026-01-14T08:22:06.4812138Z sqlite-3.51.0        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]
2026-01-14T08:22:06.4812419Z 
2026-01-14T08:22:06.4812725Z xorg-xorgproto-2024. | 580 KB    | :   0% 0/1 [00:00<?, ?it/s][A
2026-01-14T08:22:06.4813024Z 
2026-01-14T08:22:06.4813028Z 
2026-01-14T08:22:06.4813263Z libzlib-1.3.1        | 59 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A
2026-01-14T08:22:06.4813551Z 
2026-01-14T08:22:06.4813555Z 
2026-01-14T08:22:06.4813558Z 
2026-01-14T08:22:06.4813790Z libnsl-2.0.0         | 31 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A
2026-01-14T08:22:06.4814071Z 
2026-01-14T08:22:06.4814082Z 
2026-01-14T08:22:06.4814085Z 
2026-01-14T08:22:06.4814096Z 
2026-01-14T08:22:06.4814332Z bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A
2026-01-14T08:22:06.4814617Z 
2026-01-14T08:22:06.4814621Z 
2026-01-14T08:22:06.4814625Z 
2026-01-14T08:22:06.4814628Z 
2026-01-14T08:22:06.4814632Z 
2026-01-14T08:22:06.4814871Z zlib-1.3.1           | 96 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A
2026-01-14T08:22:06.4815162Z 
2026-01-14T08:22:06.4815165Z 
2026-01-14T08:22:06.4815169Z 
2026-01-14T08:22:06.4815173Z 
2026-01-14T08:22:06.4815176Z 
2026-01-14T08:22:06.4815180Z 
2026-01-14T08:22:06.4815457Z xorg-libxau-1.0.12   | 13 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A
2026-01-14T08:22:06.4815775Z 
2026-01-14T08:22:06.4815779Z 
2026-01-14T08:22:06.4815782Z 
2026-01-14T08:22:06.4815786Z 
2026-01-14T08:22:06.4815789Z 
2026-01-14T08:22:06.4815793Z 
2026-01-14T08:22:06.4815796Z 
2026-01-14T08:22:06.4816080Z ld_impl_linux-64-2.4 | 672 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A
2026-01-14T08:22:06.4816420Z 
2026-01-14T08:22:06.4816424Z 
2026-01-14T08:22:06.4816428Z 
2026-01-14T08:22:06.4816431Z 
2026-01-14T08:22:06.4816435Z 
2026-01-14T08:22:06.4816438Z 
2026-01-14T08:22:06.4816442Z 
2026-01-14T08:22:06.4816445Z 
2026-01-14T08:22:06.4816725Z tzdata-2025b         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A
2026-01-14T08:22:06.4817055Z 
2026-01-14T08:22:06.4817058Z 
2026-01-14T08:22:06.4817067Z 
2026-01-14T08:22:06.4817071Z 
2026-01-14T08:22:06.4817074Z 
2026-01-14T08:22:06.4817078Z 
2026-01-14T08:22:06.4817082Z 
2026-01-14T08:22:06.4817085Z 
2026-01-14T08:22:06.4817089Z 
2026-01-14T08:22:06.4817386Z setuptools-80.9.0    | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:06.4817736Z 
2026-01-14T08:22:06.4817739Z 
2026-01-14T08:22:06.4817743Z 
2026-01-14T08:22:06.4817747Z 
2026-01-14T08:22:06.4817750Z 
2026-01-14T08:22:06.4817754Z 
2026-01-14T08:22:06.4817758Z 
2026-01-14T08:22:06.4817761Z 
2026-01-14T08:22:06.4817765Z 
2026-01-14T08:22:06.4817768Z 
2026-01-14T08:22:06.4818216Z pthread-stubs-0.3    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:06.4818577Z 
2026-01-14T08:22:06.4818580Z 
2026-01-14T08:22:06.4818584Z 
2026-01-14T08:22:06.4818587Z 
2026-01-14T08:22:06.4818591Z 
2026-01-14T08:22:06.4818594Z 
2026-01-14T08:22:06.4818598Z 
2026-01-14T08:22:06.4818602Z 
2026-01-14T08:22:06.4818605Z 
2026-01-14T08:22:06.4819928Z 
2026-01-14T08:22:06.4819932Z 
2026-01-14T08:22:08.6590382Z tk-8.6.15            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6590842Z 
2026-01-14T08:22:08.6590847Z 
2026-01-14T08:22:08.6590850Z 
2026-01-14T08:22:08.6590854Z 
2026-01-14T08:22:08.6590857Z 
2026-01-14T08:22:08.6590861Z 
2026-01-14T08:22:08.6590864Z 
2026-01-14T08:22:08.6590868Z 
2026-01-14T08:22:08.6590871Z 
2026-01-14T08:22:08.6590875Z 
2026-01-14T08:22:08.6590878Z 
2026-01-14T08:22:08.6590882Z 
2026-01-14T08:22:08.6591210Z wheel-0.45.1         | 115 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6591558Z 
2026-01-14T08:22:08.6591562Z 
2026-01-14T08:22:08.6591566Z 
2026-01-14T08:22:08.6591569Z 
2026-01-14T08:22:08.6591573Z 
2026-01-14T08:22:08.6591577Z 
2026-01-14T08:22:08.6591580Z 
2026-01-14T08:22:08.6591584Z 
2026-01-14T08:22:08.6591587Z 
2026-01-14T08:22:08.6591591Z 
2026-01-14T08:22:08.6591595Z 
2026-01-14T08:22:08.6591598Z 
2026-01-14T08:22:08.6591612Z 
2026-01-14T08:22:08.6591945Z readline-8.3         | 471 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6592304Z 
2026-01-14T08:22:08.6592307Z 
2026-01-14T08:22:08.6592311Z 
2026-01-14T08:22:08.6592314Z 
2026-01-14T08:22:08.6592318Z 
2026-01-14T08:22:08.6592321Z 
2026-01-14T08:22:08.6592325Z 
2026-01-14T08:22:08.6592329Z 
2026-01-14T08:22:08.6592332Z 
2026-01-14T08:22:08.6592342Z 
2026-01-14T08:22:08.6592346Z 
2026-01-14T08:22:08.6592350Z 
2026-01-14T08:22:08.6592353Z 
2026-01-14T08:22:08.6592357Z 
2026-01-14T08:22:08.6592684Z libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6593041Z 
2026-01-14T08:22:08.6593045Z 
2026-01-14T08:22:08.6593049Z 
2026-01-14T08:22:08.6593052Z 
2026-01-14T08:22:08.6593056Z 
2026-01-14T08:22:08.6593066Z 
2026-01-14T08:22:08.6593069Z 
2026-01-14T08:22:08.6593073Z 
2026-01-14T08:22:08.6593077Z 
2026-01-14T08:22:08.6593080Z 
2026-01-14T08:22:08.6593089Z 
2026-01-14T08:22:08.6593092Z 
2026-01-14T08:22:08.6593096Z 
2026-01-14T08:22:08.6593099Z 
2026-01-14T08:22:08.6593103Z 
2026-01-14T08:22:08.6593437Z python-3.10.19       | 24.5 MB   | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6593808Z 
2026-01-14T08:22:08.6593811Z 
2026-01-14T08:22:08.6593815Z 
2026-01-14T08:22:08.6593818Z 
2026-01-14T08:22:08.6593822Z 
2026-01-14T08:22:08.6593826Z 
2026-01-14T08:22:08.6593829Z 
2026-01-14T08:22:08.6593833Z 
2026-01-14T08:22:08.6593837Z 
2026-01-14T08:22:08.6593840Z 
2026-01-14T08:22:08.6593844Z 
2026-01-14T08:22:08.6593852Z 
2026-01-14T08:22:08.6593856Z 
2026-01-14T08:22:08.6593860Z 
2026-01-14T08:22:08.6593863Z 
2026-01-14T08:22:08.6593867Z 
2026-01-14T08:22:08.6594221Z xorg-libx11-1.8.12   | 895 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6594627Z 
2026-01-14T08:22:08.6594630Z 
2026-01-14T08:22:08.6594634Z 
2026-01-14T08:22:08.6594638Z 
2026-01-14T08:22:08.6594646Z 
2026-01-14T08:22:08.6594649Z 
2026-01-14T08:22:08.6594653Z 
2026-01-14T08:22:08.6594656Z 
2026-01-14T08:22:08.6594660Z 
2026-01-14T08:22:08.6594663Z 
2026-01-14T08:22:08.6594667Z 
2026-01-14T08:22:08.6594670Z 
2026-01-14T08:22:08.6594674Z 
2026-01-14T08:22:08.6594678Z 
2026-01-14T08:22:08.6594681Z 
2026-01-14T08:22:08.6594685Z 
2026-01-14T08:22:08.6594694Z 
2026-01-14T08:22:08.6595035Z libxcb-1.17.0        | 430 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6595407Z 
2026-01-14T08:22:08.6595411Z 
2026-01-14T08:22:08.6595414Z 
2026-01-14T08:22:08.6595618Z 
2026-01-14T08:22:08.6595623Z 
2026-01-14T08:22:08.6595627Z 
2026-01-14T08:22:08.6595630Z 
2026-01-14T08:22:08.6595634Z 
2026-01-14T08:22:08.6595637Z 
2026-01-14T08:22:08.6595652Z 
2026-01-14T08:22:08.6595656Z 
2026-01-14T08:22:08.6595659Z 
2026-01-14T08:22:08.6595663Z 
2026-01-14T08:22:08.6595667Z 
2026-01-14T08:22:08.6595670Z 
2026-01-14T08:22:08.6595674Z 
2026-01-14T08:22:08.6595796Z 
2026-01-14T08:22:08.6595799Z 
2026-01-14T08:22:08.6596145Z pip-25.3             | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6596527Z 
2026-01-14T08:22:08.6596530Z 
2026-01-14T08:22:08.6596534Z 
2026-01-14T08:22:08.6596537Z 
2026-01-14T08:22:08.6596541Z 
2026-01-14T08:22:08.6596545Z 
2026-01-14T08:22:08.6596548Z 
2026-01-14T08:22:08.6596552Z 
2026-01-14T08:22:08.6596556Z 
2026-01-14T08:22:08.6596559Z 
2026-01-14T08:22:08.6596563Z 
2026-01-14T08:22:08.6596566Z 
2026-01-14T08:22:08.6596570Z 
2026-01-14T08:22:08.6596574Z 
2026-01-14T08:22:08.6596583Z 
2026-01-14T08:22:08.6596586Z 
2026-01-14T08:22:08.6596590Z 
2026-01-14T08:22:08.6596594Z 
2026-01-14T08:22:08.6596597Z 
2026-01-14T08:22:08.6596857Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6597167Z 
2026-01-14T08:22:08.6597171Z 
2026-01-14T08:22:08.6597174Z 
2026-01-14T08:22:08.6597178Z 
2026-01-14T08:22:08.6597512Z bzip2-1.0.8          | 262 KB    | :   6% 0.06104685823297961/1 [00:00<00:02,  2.56s/it][A[A[A[A
2026-01-14T08:22:08.6597888Z 
2026-01-14T08:22:08.6598221Z xorg-xorgproto-2024. | 580 KB    | :   3% 0.02757436782092818/1 [00:00<00:05,  6.10s/it][A
2026-01-14T08:22:08.6598782Z sqlite-3.51.0        | 1.2 MB    | :   1% 0.013350140517073497/1 [00:00<00:12, 12.83s/it]
2026-01-14T08:22:08.6599104Z 
2026-01-14T08:22:08.6599108Z 
2026-01-14T08:22:08.6599112Z 
2026-01-14T08:22:08.6599417Z libnsl-2.0.0         | 31 KB     | :  52% 0.515966492410405/1 [00:00<00:00,  2.73it/s][A[A[A
2026-01-14T08:22:08.6599756Z 
2026-01-14T08:22:08.6599765Z 
2026-01-14T08:22:08.6600064Z libzlib-1.3.1        | 59 KB     | :  27% 0.2699309685816432/1 [00:00<00:00,  1.39it/s][A[A
2026-01-14T08:22:08.6600396Z 
2026-01-14T08:22:08.6600400Z 
2026-01-14T08:22:08.6600403Z 
2026-01-14T08:22:08.6600407Z 
2026-01-14T08:22:08.6600411Z 
2026-01-14T08:22:08.6600751Z zlib-1.3.1           | 96 KB     | :  17% 0.16692817116658176/1 [00:00<00:00,  1.14s/it][A[A[A[A[A
2026-01-14T08:22:08.6601118Z 
2026-01-14T08:22:08.6601121Z 
2026-01-14T08:22:08.6601125Z 
2026-01-14T08:22:08.6601128Z 
2026-01-14T08:22:08.6601132Z 
2026-01-14T08:22:08.6601136Z 
2026-01-14T08:22:08.6601449Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.39it/s][A[A[A[A[A[A
2026-01-14T08:22:08.6601793Z 
2026-01-14T08:22:08.6601796Z 
2026-01-14T08:22:08.6601800Z 
2026-01-14T08:22:08.6601804Z 
2026-01-14T08:22:08.6602117Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  2.56s/it]                [A[A[A[A
2026-01-14T08:22:08.6602469Z 
2026-01-14T08:22:08.6602476Z 
2026-01-14T08:22:08.6602480Z 
2026-01-14T08:22:08.6602484Z 
2026-01-14T08:22:08.6602488Z 
2026-01-14T08:22:08.6602491Z 
2026-01-14T08:22:08.6602495Z 
2026-01-14T08:22:08.6602498Z 
2026-01-14T08:22:08.6602893Z tzdata-2025b         | 116 KB    | :  14% 0.13742430088406501/1 [00:00<00:01,  1.70s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6603315Z 
2026-01-14T08:22:08.6603318Z 
2026-01-14T08:22:08.6603326Z 
2026-01-14T08:22:08.6603621Z libnsl-2.0.0         | 31 KB     | : 100% 1.0/1 [00:00<00:00,  2.73it/s]              [A[A[A
2026-01-14T08:22:08.6603950Z 
2026-01-14T08:22:08.6603953Z 
2026-01-14T08:22:08.6603957Z 
2026-01-14T08:22:08.6603961Z 
2026-01-14T08:22:08.6603971Z 
2026-01-14T08:22:08.6603975Z 
2026-01-14T08:22:08.6603978Z 
2026-01-14T08:22:08.6603982Z 
2026-01-14T08:22:08.6603986Z 
2026-01-14T08:22:08.6603989Z 
2026-01-14T08:22:08.6604332Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  4.14it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6604706Z 
2026-01-14T08:22:08.6604804Z 
2026-01-14T08:22:08.6604809Z 
2026-01-14T08:22:08.6604813Z 
2026-01-14T08:22:08.6604824Z 
2026-01-14T08:22:08.6604827Z 
2026-01-14T08:22:08.6604831Z 
2026-01-14T08:22:08.6605231Z ld_impl_linux-64-2.4 | 672 KB    | :   2% 0.02380578754961961/1 [00:00<00:10, 10.38s/it][A[A[A[A[A[A[A
2026-01-14T08:22:08.6605647Z 
2026-01-14T08:22:08.6605651Z 
2026-01-14T08:22:08.6605654Z 
2026-01-14T08:22:08.6605731Z 
2026-01-14T08:22:08.6605735Z 
2026-01-14T08:22:08.6605738Z 
2026-01-14T08:22:08.6605748Z 
2026-01-14T08:22:08.6605751Z 
2026-01-14T08:22:08.6605755Z 
2026-01-14T08:22:08.6606193Z setuptools-80.9.0    | 1.4 MB    | :   1% 0.010887210650647725/1 [00:00<00:23, 23.61s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6606667Z 
2026-01-14T08:22:08.6606670Z 
2026-01-14T08:22:08.6606674Z 
2026-01-14T08:22:08.6606678Z 
2026-01-14T08:22:08.6606681Z 
2026-01-14T08:22:08.6606685Z 
2026-01-14T08:22:08.6606688Z 
2026-01-14T08:22:08.6606698Z 
2026-01-14T08:22:08.6606702Z 
2026-01-14T08:22:08.6606705Z 
2026-01-14T08:22:08.6606717Z 
2026-01-14T08:22:08.6606720Z 
2026-01-14T08:22:08.6607145Z wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:01,  1.96s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6607585Z 
2026-01-14T08:22:08.6607589Z 
2026-01-14T08:22:08.6607891Z libzlib-1.3.1        | 59 KB     | : 100% 1.0/1 [00:00<00:00,  1.39it/s]               [A[A
2026-01-14T08:22:08.6608229Z 
2026-01-14T08:22:08.6608232Z 
2026-01-14T08:22:08.6608236Z 
2026-01-14T08:22:08.6608240Z 
2026-01-14T08:22:08.6608243Z 
2026-01-14T08:22:08.6608247Z 
2026-01-14T08:22:08.6608250Z 
2026-01-14T08:22:08.6608254Z 
2026-01-14T08:22:08.6608257Z 
2026-01-14T08:22:08.6608261Z 
2026-01-14T08:22:08.6608264Z 
2026-01-14T08:22:08.6608668Z tk-8.6.15            | 3.4 MB    | :   0% 0.00453827661272385/1 [00:00<01:03, 63.31s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6609084Z 
2026-01-14T08:22:08.6609088Z 
2026-01-14T08:22:08.6609091Z 
2026-01-14T08:22:08.6609095Z 
2026-01-14T08:22:08.6609099Z 
2026-01-14T08:22:08.6609107Z 
2026-01-14T08:22:08.6609111Z 
2026-01-14T08:22:08.6609114Z 
2026-01-14T08:22:08.6609118Z 
2026-01-14T08:22:08.6609121Z 
2026-01-14T08:22:08.6609131Z 
2026-01-14T08:22:08.6609134Z 
2026-01-14T08:22:08.6609138Z 
2026-01-14T08:22:08.6609573Z readline-8.3         | 471 KB    | :   3% 0.03400397653924861/1 [00:00<00:08,  8.46s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6610102Z 
2026-01-14T08:22:08.6610106Z 
2026-01-14T08:22:08.6610109Z 
2026-01-14T08:22:08.6610113Z 
2026-01-14T08:22:08.6610116Z 
2026-01-14T08:22:08.6610435Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:00<00:00,  3.81it/s]                [A[A[A[A[A
2026-01-14T08:22:08.6610778Z 
2026-01-14T08:22:08.6610782Z 
2026-01-14T08:22:08.6610785Z 
2026-01-14T08:22:08.6610789Z 
2026-01-14T08:22:08.6610792Z 
2026-01-14T08:22:08.6611062Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:00<00:00,  3.81it/s][A[A[A[A[A
2026-01-14T08:22:08.6611371Z 
2026-01-14T08:22:08.6611375Z 
2026-01-14T08:22:08.6611383Z 
2026-01-14T08:22:08.6611387Z 
2026-01-14T08:22:08.6611391Z 
2026-01-14T08:22:08.6611394Z 
2026-01-14T08:22:08.6611398Z 
2026-01-14T08:22:08.6611402Z 
2026-01-14T08:22:08.6611405Z 
2026-01-14T08:22:08.6611409Z 
2026-01-14T08:22:08.6611412Z 
2026-01-14T08:22:08.6611416Z 
2026-01-14T08:22:08.6611420Z 
2026-01-14T08:22:08.6611423Z 
2026-01-14T08:22:08.6611427Z 
2026-01-14T08:22:08.6611909Z python-3.10.19       | 24.5 MB   | :   0% 0.0006386825426160966/1 [00:00<08:22, 503.18s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6612393Z 
2026-01-14T08:22:08.6612396Z 
2026-01-14T08:22:08.6612400Z 
2026-01-14T08:22:08.6612404Z 
2026-01-14T08:22:08.6612407Z 
2026-01-14T08:22:08.6612411Z 
2026-01-14T08:22:08.6612415Z 
2026-01-14T08:22:08.6612418Z 
2026-01-14T08:22:08.6612422Z 
2026-01-14T08:22:08.6612426Z 
2026-01-14T08:22:08.6612436Z 
2026-01-14T08:22:08.6612439Z 
2026-01-14T08:22:08.6612443Z 
2026-01-14T08:22:08.6612446Z 
2026-01-14T08:22:08.6612979Z libffi-3.4.4         | 141 KB    | :  11% 0.11323440988036575/1 [00:00<00:02,  2.87s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6613435Z 
2026-01-14T08:22:08.6613438Z 
2026-01-14T08:22:08.6613442Z 
2026-01-14T08:22:08.6613446Z 
2026-01-14T08:22:08.6613449Z 
2026-01-14T08:22:08.6613459Z 
2026-01-14T08:22:08.6613463Z 
2026-01-14T08:22:08.6613466Z 
2026-01-14T08:22:08.6613470Z 
2026-01-14T08:22:08.6613474Z 
2026-01-14T08:22:08.6613551Z 
2026-01-14T08:22:08.6613554Z 
2026-01-14T08:22:08.6613558Z 
2026-01-14T08:22:08.6613561Z 
2026-01-14T08:22:08.6613565Z 
2026-01-14T08:22:08.6613569Z 
2026-01-14T08:22:08.6614060Z xorg-libx11-1.8.12   | 895 KB    | :   2% 0.017882324178246957/1 [00:00<00:19, 19.96s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6614561Z 
2026-01-14T08:22:08.6614564Z 
2026-01-14T08:22:08.6614568Z 
2026-01-14T08:22:08.6614571Z 
2026-01-14T08:22:08.6614575Z 
2026-01-14T08:22:08.6614579Z 
2026-01-14T08:22:08.6614884Z xorg-libxau-1.0.12   | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.39it/s][A[A[A[A[A[A
2026-01-14T08:22:08.6615229Z 
2026-01-14T08:22:08.6615242Z 
2026-01-14T08:22:08.6615245Z 
2026-01-14T08:22:08.6615249Z 
2026-01-14T08:22:08.6615253Z 
2026-01-14T08:22:08.6615256Z 
2026-01-14T08:22:08.6615260Z 
2026-01-14T08:22:08.6615264Z 
2026-01-14T08:22:08.6615267Z 
2026-01-14T08:22:08.6615271Z 
2026-01-14T08:22:08.6615274Z 
2026-01-14T08:22:08.6615278Z 
2026-01-14T08:22:08.6615282Z 
2026-01-14T08:22:08.6615291Z 
2026-01-14T08:22:08.6615294Z 
2026-01-14T08:22:08.6615298Z 
2026-01-14T08:22:08.6615302Z 
2026-01-14T08:22:08.6615769Z libxcb-1.17.0        | 430 KB    | :   4% 0.03717806167600808/1 [00:00<00:09, 10.13s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6616253Z 
2026-01-14T08:22:08.6616256Z 
2026-01-14T08:22:08.6616260Z 
2026-01-14T08:22:08.6616263Z 
2026-01-14T08:22:08.6616267Z 
2026-01-14T08:22:08.6616270Z 
2026-01-14T08:22:08.6616274Z 
2026-01-14T08:22:08.6616277Z 
2026-01-14T08:22:08.6616281Z 
2026-01-14T08:22:08.6616285Z 
2026-01-14T08:22:08.6616288Z 
2026-01-14T08:22:08.6616694Z tk-8.6.15            | 3.4 MB    | :  66% 0.6580501088449582/1 [00:00<00:00,  2.17it/s] [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6617110Z 
2026-01-14T08:22:08.6617113Z 
2026-01-14T08:22:08.6617117Z 
2026-01-14T08:22:08.6617120Z 
2026-01-14T08:22:08.6617124Z 
2026-01-14T08:22:08.6617127Z 
2026-01-14T08:22:08.6617131Z 
2026-01-14T08:22:08.6617134Z 
2026-01-14T08:22:08.6617142Z 
2026-01-14T08:22:08.6617146Z 
2026-01-14T08:22:08.6617149Z 
2026-01-14T08:22:08.6617153Z 
2026-01-14T08:22:08.6617157Z 
2026-01-14T08:22:08.6617160Z 
2026-01-14T08:22:08.6617164Z 
2026-01-14T08:22:08.6617174Z 
2026-01-14T08:22:08.6617178Z 
2026-01-14T08:22:08.6617181Z 
2026-01-14T08:22:08.6617645Z pip-25.3             | 1.1 MB    | :   1% 0.013906347741873605/1 [00:00<00:27, 27.88s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6618117Z 
2026-01-14T08:22:08.6618120Z 
2026-01-14T08:22:08.6618124Z 
2026-01-14T08:22:08.6618128Z 
2026-01-14T08:22:08.6618131Z 
2026-01-14T08:22:08.6618138Z 
2026-01-14T08:22:08.6618148Z 
2026-01-14T08:22:08.6618152Z 
2026-01-14T08:22:08.6618155Z 
2026-01-14T08:22:08.6618159Z 
2026-01-14T08:22:08.6618163Z 
2026-01-14T08:22:08.6618166Z 
2026-01-14T08:22:08.6618170Z 
2026-01-14T08:22:08.6618173Z 
2026-01-14T08:22:08.6618246Z 
2026-01-14T08:22:08.6618706Z python-3.10.19       | 24.5 MB   | :  10% 0.09707974647764668/1 [00:00<00:03,  3.36s/it]   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6619188Z 
2026-01-14T08:22:08.6619192Z 
2026-01-14T08:22:08.6619196Z 
2026-01-14T08:22:08.6619199Z 
2026-01-14T08:22:08.6619203Z 
2026-01-14T08:22:08.6619207Z 
2026-01-14T08:22:08.6619210Z 
2026-01-14T08:22:08.6619214Z 
2026-01-14T08:22:08.6619217Z 
2026-01-14T08:22:08.6619221Z 
2026-01-14T08:22:08.6619225Z 
2026-01-14T08:22:08.6619228Z 
2026-01-14T08:22:08.6619232Z 
2026-01-14T08:22:08.6619235Z 
2026-01-14T08:22:08.6619239Z 
2026-01-14T08:22:08.6619242Z 
2026-01-14T08:22:08.6619246Z 
2026-01-14T08:22:08.6619249Z 
2026-01-14T08:22:08.6619253Z 
2026-01-14T08:22:08.6619638Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6620145Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]                 
2026-01-14T08:22:08.6620633Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]
2026-01-14T08:22:08.6620916Z 
2026-01-14T08:22:08.6620919Z 
2026-01-14T08:22:08.6620997Z 
2026-01-14T08:22:08.6621000Z 
2026-01-14T08:22:08.6621004Z 
2026-01-14T08:22:08.6621008Z 
2026-01-14T08:22:08.6621011Z 
2026-01-14T08:22:08.6621015Z 
2026-01-14T08:22:08.6621018Z 
2026-01-14T08:22:08.6621022Z 
2026-01-14T08:22:08.6621375Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  4.14it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6621757Z 
2026-01-14T08:22:08.6621760Z 
2026-01-14T08:22:08.6621764Z 
2026-01-14T08:22:08.6621768Z 
2026-01-14T08:22:08.6621771Z 
2026-01-14T08:22:08.6621775Z 
2026-01-14T08:22:08.6621779Z 
2026-01-14T08:22:08.6621782Z 
2026-01-14T08:22:08.6621791Z 
2026-01-14T08:22:08.6621794Z 
2026-01-14T08:22:08.6621805Z 
2026-01-14T08:22:08.6621808Z 
2026-01-14T08:22:08.6621812Z 
2026-01-14T08:22:08.6621815Z 
2026-01-14T08:22:08.6621819Z 
2026-01-14T08:22:08.6622268Z python-3.10.19       | 24.5 MB   | :  21% 0.20629446126499917/1 [00:00<00:01,  1.85s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6622733Z 
2026-01-14T08:22:08.6622741Z 
2026-01-14T08:22:08.6622745Z 
2026-01-14T08:22:08.6622749Z 
2026-01-14T08:22:08.6622758Z 
2026-01-14T08:22:08.6622762Z 
2026-01-14T08:22:08.6622765Z 
2026-01-14T08:22:08.6622769Z 
2026-01-14T08:22:08.6622773Z 
2026-01-14T08:22:08.6622776Z 
2026-01-14T08:22:08.6622780Z 
2026-01-14T08:22:08.6622784Z 
2026-01-14T08:22:08.6622787Z 
2026-01-14T08:22:08.6622791Z 
2026-01-14T08:22:08.6622794Z 
2026-01-14T08:22:08.6623241Z python-3.10.19       | 24.5 MB   | :  34% 0.33658569995868287/1 [00:00<00:00,  1.30s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6623709Z 
2026-01-14T08:22:08.6623713Z 
2026-01-14T08:22:08.6623721Z 
2026-01-14T08:22:08.6623724Z 
2026-01-14T08:22:08.6623728Z 
2026-01-14T08:22:08.6623732Z 
2026-01-14T08:22:08.6623735Z 
2026-01-14T08:22:08.6623739Z 
2026-01-14T08:22:08.6623742Z 
2026-01-14T08:22:08.6623746Z 
2026-01-14T08:22:08.6623749Z 
2026-01-14T08:22:08.6623753Z 
2026-01-14T08:22:08.6624137Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  1.68it/s]                [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6624552Z 
2026-01-14T08:22:08.6624556Z 
2026-01-14T08:22:08.6624559Z 
2026-01-14T08:22:08.6624563Z 
2026-01-14T08:22:08.6624567Z 
2026-01-14T08:22:08.6624570Z 
2026-01-14T08:22:08.6624574Z 
2026-01-14T08:22:08.6624578Z 
2026-01-14T08:22:08.6624581Z 
2026-01-14T08:22:08.6624585Z 
2026-01-14T08:22:08.6624589Z 
2026-01-14T08:22:08.6624593Z 
2026-01-14T08:22:08.6624929Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  1.68it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6625309Z 
2026-01-14T08:22:08.6625313Z 
2026-01-14T08:22:08.6625320Z 
2026-01-14T08:22:08.6625324Z 
2026-01-14T08:22:08.6625327Z 
2026-01-14T08:22:08.6625331Z 
2026-01-14T08:22:08.6625335Z 
2026-01-14T08:22:08.6625338Z 
2026-01-14T08:22:08.6625342Z 
2026-01-14T08:22:08.6625345Z 
2026-01-14T08:22:08.6625349Z 
2026-01-14T08:22:08.6625353Z 
2026-01-14T08:22:08.6625356Z 
2026-01-14T08:22:08.6625360Z 
2026-01-14T08:22:08.6625364Z 
2026-01-14T08:22:08.6625823Z python-3.10.19       | 24.5 MB   | :  47% 0.46687693865236657/1 [00:00<00:00,  1.07s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6626285Z 
2026-01-14T08:22:08.6626289Z 
2026-01-14T08:22:08.6626292Z 
2026-01-14T08:22:08.6626296Z 
2026-01-14T08:22:08.6626300Z 
2026-01-14T08:22:08.6626303Z 
2026-01-14T08:22:08.6626307Z 
2026-01-14T08:22:08.6626677Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:00<00:00,  1.46it/s]                [A[A[A[A[A[A[A
2026-01-14T08:22:08.6627071Z 
2026-01-14T08:22:08.6627074Z 
2026-01-14T08:22:08.6627078Z 
2026-01-14T08:22:08.6627081Z 
2026-01-14T08:22:08.6627171Z 
2026-01-14T08:22:08.6627176Z 
2026-01-14T08:22:08.6627179Z 
2026-01-14T08:22:08.6627503Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:00<00:00,  1.46it/s][A[A[A[A[A[A[A
2026-01-14T08:22:08.6627856Z 
2026-01-14T08:22:08.6628185Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.35it/s]                [A
2026-01-14T08:22:08.6628557Z 
2026-01-14T08:22:08.6628926Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.35it/s][A
2026-01-14T08:22:08.6629254Z 
2026-01-14T08:22:08.6629257Z 
2026-01-14T08:22:08.6629261Z 
2026-01-14T08:22:08.6629264Z 
2026-01-14T08:22:08.6629268Z 
2026-01-14T08:22:08.6629289Z 
2026-01-14T08:22:08.6629293Z 
2026-01-14T08:22:08.6629296Z 
2026-01-14T08:22:08.6629300Z 
2026-01-14T08:22:08.6629304Z 
2026-01-14T08:22:08.6629307Z 
2026-01-14T08:22:08.6629311Z 
2026-01-14T08:22:08.6629315Z 
2026-01-14T08:22:08.6629318Z 
2026-01-14T08:22:08.6629322Z 
2026-01-14T08:22:08.6629771Z python-3.10.19       | 24.5 MB   | :  61% 0.60866446311314/1 [00:00<00:00,  1.08it/s]   [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6630234Z 
2026-01-14T08:22:08.6630238Z 
2026-01-14T08:22:08.6630241Z 
2026-01-14T08:22:08.6630245Z 
2026-01-14T08:22:08.6630249Z 
2026-01-14T08:22:08.6630252Z 
2026-01-14T08:22:08.6630256Z 
2026-01-14T08:22:08.6630259Z 
2026-01-14T08:22:08.6630263Z 
2026-01-14T08:22:08.6630266Z 
2026-01-14T08:22:08.6630270Z 
2026-01-14T08:22:08.6630278Z 
2026-01-14T08:22:08.6630281Z 
2026-01-14T08:22:08.6644485Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  1.29it/s]                [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6644945Z 
2026-01-14T08:22:08.6644949Z 
2026-01-14T08:22:08.6644953Z 
2026-01-14T08:22:08.6644956Z 
2026-01-14T08:22:08.6644960Z 
2026-01-14T08:22:08.6644964Z 
2026-01-14T08:22:08.6644967Z 
2026-01-14T08:22:08.6644971Z 
2026-01-14T08:22:08.6644974Z 
2026-01-14T08:22:08.6644978Z 
2026-01-14T08:22:08.6644982Z 
2026-01-14T08:22:08.6644999Z 
2026-01-14T08:22:08.6645003Z 
2026-01-14T08:22:08.6645427Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  1.29it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6645824Z 
2026-01-14T08:22:08.6645828Z 
2026-01-14T08:22:08.6645832Z 
2026-01-14T08:22:08.6645836Z 
2026-01-14T08:22:08.6645840Z 
2026-01-14T08:22:08.6645843Z 
2026-01-14T08:22:08.6645847Z 
2026-01-14T08:22:08.6645859Z 
2026-01-14T08:22:08.6645862Z 
2026-01-14T08:22:08.6645873Z 
2026-01-14T08:22:08.6645877Z 
2026-01-14T08:22:08.6645881Z 
2026-01-14T08:22:08.6645884Z 
2026-01-14T08:22:08.6645888Z 
2026-01-14T08:22:08.6645891Z 
2026-01-14T08:22:08.6646390Z python-3.10.19       | 24.5 MB   | :  74% 0.7376783367215916/1 [00:00<00:00,  1.14it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6646879Z 
2026-01-14T08:22:08.6646882Z 
2026-01-14T08:22:08.6646892Z 
2026-01-14T08:22:08.6646896Z 
2026-01-14T08:22:08.6646900Z 
2026-01-14T08:22:08.6646903Z 
2026-01-14T08:22:08.6646907Z 
2026-01-14T08:22:08.6646911Z 
2026-01-14T08:22:08.6646914Z 
2026-01-14T08:22:08.6646921Z 
2026-01-14T08:22:08.6646924Z 
2026-01-14T08:22:08.6646928Z 
2026-01-14T08:22:08.6646931Z 
2026-01-14T08:22:08.6646935Z 
2026-01-14T08:22:08.6646939Z 
2026-01-14T08:22:08.6647379Z python-3.10.19       | 24.5 MB   | :  86% 0.8622214325317303/1 [00:01<00:00,  1.17it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6647845Z 
2026-01-14T08:22:08.6647849Z 
2026-01-14T08:22:08.6647857Z 
2026-01-14T08:22:08.6647860Z 
2026-01-14T08:22:08.6647864Z 
2026-01-14T08:22:08.6647868Z 
2026-01-14T08:22:08.6647871Z 
2026-01-14T08:22:08.6647875Z 
2026-01-14T08:22:08.6647878Z 
2026-01-14T08:22:08.6647882Z 
2026-01-14T08:22:08.6647885Z 
2026-01-14T08:22:08.6647889Z 
2026-01-14T08:22:08.6647893Z 
2026-01-14T08:22:08.6647896Z 
2026-01-14T08:22:08.6647900Z 
2026-01-14T08:22:08.6648345Z python-3.10.19       | 24.5 MB   | :  99% 0.9912353061401818/1 [00:01<00:00,  1.21it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6648802Z 
2026-01-14T08:22:08.6648806Z 
2026-01-14T08:22:08.6648938Z 
2026-01-14T08:22:08.6648943Z 
2026-01-14T08:22:08.6648946Z 
2026-01-14T08:22:08.6648950Z 
2026-01-14T08:22:08.6648954Z 
2026-01-14T08:22:08.6648957Z 
2026-01-14T08:22:08.6648961Z 
2026-01-14T08:22:08.6648965Z 
2026-01-14T08:22:08.6648968Z 
2026-01-14T08:22:08.6648972Z 
2026-01-14T08:22:08.6648975Z 
2026-01-14T08:22:08.6648979Z 
2026-01-14T08:22:08.6649389Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6649946Z 
2026-01-14T08:22:08.6649950Z 
2026-01-14T08:22:08.6649954Z 
2026-01-14T08:22:08.6649957Z 
2026-01-14T08:22:08.6649961Z 
2026-01-14T08:22:08.6649965Z 
2026-01-14T08:22:08.6649968Z 
2026-01-14T08:22:08.6649972Z 
2026-01-14T08:22:08.6649975Z 
2026-01-14T08:22:08.6649987Z 
2026-01-14T08:22:08.6649990Z 
2026-01-14T08:22:08.6649994Z 
2026-01-14T08:22:08.6649998Z 
2026-01-14T08:22:08.6650001Z 
2026-01-14T08:22:08.6650366Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6650753Z 
2026-01-14T08:22:08.6650757Z 
2026-01-14T08:22:08.6650760Z 
2026-01-14T08:22:08.6650764Z 
2026-01-14T08:22:08.6650775Z 
2026-01-14T08:22:08.6650779Z 
2026-01-14T08:22:08.6650782Z 
2026-01-14T08:22:08.6650786Z 
2026-01-14T08:22:08.6651140Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]                [A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6651529Z 
2026-01-14T08:22:08.6651533Z 
2026-01-14T08:22:08.6651536Z 
2026-01-14T08:22:08.6651540Z 
2026-01-14T08:22:08.6651544Z 
2026-01-14T08:22:08.6651554Z 
2026-01-14T08:22:08.6651557Z 
2026-01-14T08:22:08.6651561Z 
2026-01-14T08:22:08.6651872Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6652224Z 
2026-01-14T08:22:08.6652228Z 
2026-01-14T08:22:08.6652232Z 
2026-01-14T08:22:08.6652235Z 
2026-01-14T08:22:08.6652239Z 
2026-01-14T08:22:08.6652242Z 
2026-01-14T08:22:08.6652246Z 
2026-01-14T08:22:08.6652256Z 
2026-01-14T08:22:08.6652263Z 
2026-01-14T08:22:08.6652267Z 
2026-01-14T08:22:08.6652270Z 
2026-01-14T08:22:08.6652274Z 
2026-01-14T08:22:08.6652277Z 
2026-01-14T08:22:08.6652281Z 
2026-01-14T08:22:08.6652285Z 
2026-01-14T08:22:08.6652288Z 
2026-01-14T08:22:08.6652720Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6653184Z 
2026-01-14T08:22:08.6653188Z 
2026-01-14T08:22:08.6653191Z 
2026-01-14T08:22:08.6653195Z 
2026-01-14T08:22:08.6653198Z 
2026-01-14T08:22:08.6653202Z 
2026-01-14T08:22:08.6653206Z 
2026-01-14T08:22:08.6653209Z 
2026-01-14T08:22:08.6653213Z 
2026-01-14T08:22:08.6653216Z 
2026-01-14T08:22:08.6653220Z 
2026-01-14T08:22:08.6653224Z 
2026-01-14T08:22:08.6653227Z 
2026-01-14T08:22:08.6653231Z 
2026-01-14T08:22:08.6653234Z 
2026-01-14T08:22:08.6653238Z 
2026-01-14T08:22:08.6653632Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6654058Z 
2026-01-14T08:22:08.6654061Z 
2026-01-14T08:22:08.6654065Z 
2026-01-14T08:22:08.6654069Z 
2026-01-14T08:22:08.6654072Z 
2026-01-14T08:22:08.6654076Z 
2026-01-14T08:22:08.6654079Z 
2026-01-14T08:22:08.6654083Z 
2026-01-14T08:22:08.6654087Z 
2026-01-14T08:22:08.6654090Z 
2026-01-14T08:22:08.6654094Z 
2026-01-14T08:22:08.6654097Z 
2026-01-14T08:22:08.6654101Z 
2026-01-14T08:22:08.6654108Z 
2026-01-14T08:22:08.6654111Z 
2026-01-14T08:22:08.6654115Z 
2026-01-14T08:22:08.6654118Z 
2026-01-14T08:22:08.6654546Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.40s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6654982Z 
2026-01-14T08:22:08.6654985Z 
2026-01-14T08:22:08.6654989Z 
2026-01-14T08:22:08.6654992Z 
2026-01-14T08:22:08.6654996Z 
2026-01-14T08:22:08.6654999Z 
2026-01-14T08:22:08.6655003Z 
2026-01-14T08:22:08.6655007Z 
2026-01-14T08:22:08.6655010Z 
2026-01-14T08:22:08.6655023Z 
2026-01-14T08:22:08.6655026Z 
2026-01-14T08:22:08.6655126Z 
2026-01-14T08:22:08.6655130Z 
2026-01-14T08:22:08.6655134Z 
2026-01-14T08:22:08.6655137Z 
2026-01-14T08:22:08.6655141Z 
2026-01-14T08:22:08.6655144Z 
2026-01-14T08:22:08.6655529Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.40s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6655940Z 
2026-01-14T08:22:08.6655952Z 
2026-01-14T08:22:08.6656027Z 
2026-01-14T08:22:08.6656031Z 
2026-01-14T08:22:08.6656034Z 
2026-01-14T08:22:08.6656038Z 
2026-01-14T08:22:08.6656042Z 
2026-01-14T08:22:08.6656045Z 
2026-01-14T08:22:08.6656049Z 
2026-01-14T08:22:08.6656052Z 
2026-01-14T08:22:08.6656056Z 
2026-01-14T08:22:08.6656059Z 
2026-01-14T08:22:08.6656063Z 
2026-01-14T08:22:08.6656067Z 
2026-01-14T08:22:08.6656070Z 
2026-01-14T08:22:08.6656074Z 
2026-01-14T08:22:08.6656077Z 
2026-01-14T08:22:08.6656081Z 
2026-01-14T08:22:08.6656500Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6656934Z 
2026-01-14T08:22:08.6656938Z 
2026-01-14T08:22:08.6656942Z 
2026-01-14T08:22:08.6656945Z 
2026-01-14T08:22:08.6656949Z 
2026-01-14T08:22:08.6656952Z 
2026-01-14T08:22:08.6656956Z 
2026-01-14T08:22:08.6656959Z 
2026-01-14T08:22:08.6656963Z 
2026-01-14T08:22:08.6656967Z 
2026-01-14T08:22:08.6656970Z 
2026-01-14T08:22:08.6656974Z 
2026-01-14T08:22:08.6656982Z 
2026-01-14T08:22:08.6656986Z 
2026-01-14T08:22:08.6656989Z 
2026-01-14T08:22:08.6656993Z 
2026-01-14T08:22:08.6657004Z 
2026-01-14T08:22:08.6657007Z 
2026-01-14T08:22:08.6657382Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  1.97s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6657782Z 
2026-01-14T08:22:08.6657785Z 
2026-01-14T08:22:08.6657789Z 
2026-01-14T08:22:08.6657793Z 
2026-01-14T08:22:08.6657796Z 
2026-01-14T08:22:08.6657800Z 
2026-01-14T08:22:08.6657803Z 
2026-01-14T08:22:08.6657814Z 
2026-01-14T08:22:08.6657818Z 
2026-01-14T08:22:08.6658200Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:02<00:00,  2.06s/it]                 [A[A[A[A[A[A[A[A[A
2026-01-14T08:22:08.6658603Z 
2026-01-14T08:22:08.6658606Z 
2026-01-14T08:22:08.6658610Z 
2026-01-14T08:22:08.6658614Z 
2026-01-14T08:22:08.6658617Z 
2026-01-14T08:22:08.6658621Z 
2026-01-14T08:22:08.6658624Z 
2026-01-14T08:22:08.6658628Z 
2026-01-14T08:22:08.6658639Z 
2026-01-14T08:22:17.3243174Z setuptools-80.9.0    | 1.4 MB    | : 100% 1.0/1 [00:02<00:00,  2.06s/it][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3243673Z 
2026-01-14T08:22:17.3243680Z 
2026-01-14T08:22:17.3243684Z 
2026-01-14T08:22:17.3243688Z 
2026-01-14T08:22:17.3243691Z 
2026-01-14T08:22:17.3243695Z 
2026-01-14T08:22:17.3243699Z 
2026-01-14T08:22:17.3243702Z 
2026-01-14T08:22:17.3243706Z 
2026-01-14T08:22:17.3243709Z 
2026-01-14T08:22:17.3243713Z 
2026-01-14T08:22:17.3244087Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:02<00:00,  2.17it/s]               [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3244482Z 
2026-01-14T08:22:17.3244511Z 
2026-01-14T08:22:17.3244516Z 
2026-01-14T08:22:17.3244519Z 
2026-01-14T08:22:17.3244523Z 
2026-01-14T08:22:17.3244526Z 
2026-01-14T08:22:17.3244530Z 
2026-01-14T08:22:17.3244533Z 
2026-01-14T08:22:17.3244537Z 
2026-01-14T08:22:17.3244540Z 
2026-01-14T08:22:17.3244553Z 
2026-01-14T08:22:17.3244557Z 
2026-01-14T08:22:17.3244561Z 
2026-01-14T08:22:17.3244564Z 
2026-01-14T08:22:17.3244579Z 
2026-01-14T08:22:17.3244583Z 
2026-01-14T08:22:17.3244587Z 
2026-01-14T08:22:17.3244590Z 
2026-01-14T08:22:17.3244594Z 
2026-01-14T08:22:17.3244854Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3245173Z 
2026-01-14T08:22:17.3245184Z 
2026-01-14T08:22:17.3245187Z 
2026-01-14T08:22:17.3245191Z 
2026-01-14T08:22:17.3245195Z 
2026-01-14T08:22:17.3245198Z 
2026-01-14T08:22:17.3245202Z 
2026-01-14T08:22:17.3245205Z 
2026-01-14T08:22:17.3245209Z 
2026-01-14T08:22:17.3245213Z 
2026-01-14T08:22:17.3245216Z 
2026-01-14T08:22:17.3245220Z 
2026-01-14T08:22:17.3245594Z 
2026-01-14T08:22:17.3245598Z 
2026-01-14T08:22:17.3245602Z 
2026-01-14T08:22:17.3245605Z 
2026-01-14T08:22:17.3245609Z 
2026-01-14T08:22:17.3245613Z 
2026-01-14T08:22:17.3245616Z 
2026-01-14T08:22:17.3245880Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3246193Z 
2026-01-14T08:22:17.3246196Z 
2026-01-14T08:22:17.3246200Z 
2026-01-14T08:22:17.3246367Z 
2026-01-14T08:22:17.3246371Z 
2026-01-14T08:22:17.3246375Z 
2026-01-14T08:22:17.3246378Z 
2026-01-14T08:22:17.3246382Z 
2026-01-14T08:22:17.3246386Z 
2026-01-14T08:22:17.3246389Z 
2026-01-14T08:22:17.3246393Z 
2026-01-14T08:22:17.3246397Z 
2026-01-14T08:22:17.3246400Z 
2026-01-14T08:22:17.3246404Z 
2026-01-14T08:22:17.3246407Z 
2026-01-14T08:22:17.3246841Z python-3.10.19       | 24.5 MB   | : 100% 1.0/1 [00:03<00:00,  1.21it/s]               [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3247272Z 
2026-01-14T08:22:17.3247275Z 
2026-01-14T08:22:17.3247279Z 
2026-01-14T08:22:17.3247288Z 
2026-01-14T08:22:17.3247292Z 
2026-01-14T08:22:17.3247296Z 
2026-01-14T08:22:17.3247299Z 
2026-01-14T08:22:17.3247303Z 
2026-01-14T08:22:17.3247306Z 
2026-01-14T08:22:17.3247310Z 
2026-01-14T08:22:17.3247321Z 
2026-01-14T08:22:17.3247324Z 
2026-01-14T08:22:17.3247328Z 
2026-01-14T08:22:17.3247331Z 
2026-01-14T08:22:17.3247335Z 
2026-01-14T08:22:17.3247339Z 
2026-01-14T08:22:17.3247342Z 
2026-01-14T08:22:17.3247350Z 
2026-01-14T08:22:17.3247353Z 
2026-01-14T08:22:17.3247438Z                       
2026-01-14T08:22:17.3247770Z [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3248132Z                                                                         
2026-01-14T08:22:17.3248389Z 
2026-01-14T08:22:17.3248393Z 
2026-01-14T08:22:17.3248590Z                                                                         [A
2026-01-14T08:22:17.3248838Z 
2026-01-14T08:22:17.3248842Z 
2026-01-14T08:22:17.3249050Z                                                                         [A[A
2026-01-14T08:22:17.3249301Z 
2026-01-14T08:22:17.3249305Z 
2026-01-14T08:22:17.3249308Z 
2026-01-14T08:22:17.3249508Z                                                                         [A[A[A
2026-01-14T08:22:17.3249840Z 
2026-01-14T08:22:17.3249844Z 
2026-01-14T08:22:17.3249848Z 
2026-01-14T08:22:17.3249851Z 
2026-01-14T08:22:17.3250056Z                                                                         [A[A[A[A
2026-01-14T08:22:17.3250460Z 
2026-01-14T08:22:17.3250464Z 
2026-01-14T08:22:17.3250467Z 
2026-01-14T08:22:17.3250479Z 
2026-01-14T08:22:17.3250482Z 
2026-01-14T08:22:17.3250692Z                                                                         [A[A[A[A[A
2026-01-14T08:22:17.3250959Z 
2026-01-14T08:22:17.3250963Z 
2026-01-14T08:22:17.3250967Z 
2026-01-14T08:22:17.3250970Z 
2026-01-14T08:22:17.3250974Z 
2026-01-14T08:22:17.3250977Z 
2026-01-14T08:22:17.3251199Z                                                                         [A[A[A[A[A[A
2026-01-14T08:22:17.3251477Z 
2026-01-14T08:22:17.3251481Z 
2026-01-14T08:22:17.3251485Z 
2026-01-14T08:22:17.3251488Z 
2026-01-14T08:22:17.3251492Z 
2026-01-14T08:22:17.3251495Z 
2026-01-14T08:22:17.3251499Z 
2026-01-14T08:22:17.3251728Z                                                                         [A[A[A[A[A[A[A
2026-01-14T08:22:17.3252000Z 
2026-01-14T08:22:17.3252004Z 
2026-01-14T08:22:17.3252014Z 
2026-01-14T08:22:17.3252018Z 
2026-01-14T08:22:17.3252021Z 
2026-01-14T08:22:17.3252025Z 
2026-01-14T08:22:17.3252028Z 
2026-01-14T08:22:17.3252032Z 
2026-01-14T08:22:17.3252262Z                                                                         [A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3252552Z 
2026-01-14T08:22:17.3252555Z 
2026-01-14T08:22:17.3252559Z 
2026-01-14T08:22:17.3252562Z 
2026-01-14T08:22:17.3252566Z 
2026-01-14T08:22:17.3252569Z 
2026-01-14T08:22:17.3252573Z 
2026-01-14T08:22:17.3252576Z 
2026-01-14T08:22:17.3252580Z 
2026-01-14T08:22:17.3252991Z                                                                         [A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3253319Z 
2026-01-14T08:22:17.3253323Z 
2026-01-14T08:22:17.3253326Z 
2026-01-14T08:22:17.3253330Z 
2026-01-14T08:22:17.3253333Z 
2026-01-14T08:22:17.3253336Z 
2026-01-14T08:22:17.3253340Z 
2026-01-14T08:22:17.3253343Z 
2026-01-14T08:22:17.3253347Z 
2026-01-14T08:22:17.3253350Z 
2026-01-14T08:22:17.3253627Z                                                                         [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3254036Z 
2026-01-14T08:22:17.3254040Z 
2026-01-14T08:22:17.3254043Z 
2026-01-14T08:22:17.3254046Z 
2026-01-14T08:22:17.3254050Z 
2026-01-14T08:22:17.3254053Z 
2026-01-14T08:22:17.3254057Z 
2026-01-14T08:22:17.3254060Z 
2026-01-14T08:22:17.3254063Z 
2026-01-14T08:22:17.3254067Z 
2026-01-14T08:22:17.3254070Z 
2026-01-14T08:22:17.3254361Z                                                                         [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3254802Z 
2026-01-14T08:22:17.3254806Z 
2026-01-14T08:22:17.3254815Z 
2026-01-14T08:22:17.3254819Z 
2026-01-14T08:22:17.3254822Z 
2026-01-14T08:22:17.3254826Z 
2026-01-14T08:22:17.3254829Z 
2026-01-14T08:22:17.3254833Z 
2026-01-14T08:22:17.3254836Z 
2026-01-14T08:22:17.3254840Z 
2026-01-14T08:22:17.3254843Z 
2026-01-14T08:22:17.3254847Z 
2026-01-14T08:22:17.3255110Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3255413Z 
2026-01-14T08:22:17.3255416Z 
2026-01-14T08:22:17.3255420Z 
2026-01-14T08:22:17.3255423Z 
2026-01-14T08:22:17.3255427Z 
2026-01-14T08:22:17.3255431Z 
2026-01-14T08:22:17.3255434Z 
2026-01-14T08:22:17.3255438Z 
2026-01-14T08:22:17.3255441Z 
2026-01-14T08:22:17.3255445Z 
2026-01-14T08:22:17.3255448Z 
2026-01-14T08:22:17.3255452Z 
2026-01-14T08:22:17.3255455Z 
2026-01-14T08:22:17.3255727Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3256032Z 
2026-01-14T08:22:17.3256036Z 
2026-01-14T08:22:17.3256043Z 
2026-01-14T08:22:17.3256047Z 
2026-01-14T08:22:17.3256050Z 
2026-01-14T08:22:17.3256054Z 
2026-01-14T08:22:17.3256058Z 
2026-01-14T08:22:17.3256061Z 
2026-01-14T08:22:17.3256065Z 
2026-01-14T08:22:17.3256075Z 
2026-01-14T08:22:17.3256078Z 
2026-01-14T08:22:17.3256082Z 
2026-01-14T08:22:17.3256086Z 
2026-01-14T08:22:17.3256089Z 
2026-01-14T08:22:17.3256356Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3256671Z 
2026-01-14T08:22:17.3256675Z 
2026-01-14T08:22:17.3256678Z 
2026-01-14T08:22:17.3256682Z 
2026-01-14T08:22:17.3256686Z 
2026-01-14T08:22:17.3256696Z 
2026-01-14T08:22:17.3256700Z 
2026-01-14T08:22:17.3256703Z 
2026-01-14T08:22:17.3256707Z 
2026-01-14T08:22:17.3256710Z 
2026-01-14T08:22:17.3256714Z 
2026-01-14T08:22:17.3256718Z 
2026-01-14T08:22:17.3256721Z 
2026-01-14T08:22:17.3256725Z 
2026-01-14T08:22:17.3256729Z 
2026-01-14T08:22:17.3257006Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3257327Z 
2026-01-14T08:22:17.3257331Z 
2026-01-14T08:22:17.3257334Z 
2026-01-14T08:22:17.3257338Z 
2026-01-14T08:22:17.3257341Z 
2026-01-14T08:22:17.3257345Z 
2026-01-14T08:22:17.3257348Z 
2026-01-14T08:22:17.3257352Z 
2026-01-14T08:22:17.3257356Z 
2026-01-14T08:22:17.3257359Z 
2026-01-14T08:22:17.3257363Z 
2026-01-14T08:22:17.3257374Z 
2026-01-14T08:22:17.3257378Z 
2026-01-14T08:22:17.3257381Z 
2026-01-14T08:22:17.3257385Z 
2026-01-14T08:22:17.3257389Z 
2026-01-14T08:22:17.3257668Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3257995Z 
2026-01-14T08:22:17.3257998Z 
2026-01-14T08:22:17.3258002Z 
2026-01-14T08:22:17.3258006Z 
2026-01-14T08:22:17.3258009Z 
2026-01-14T08:22:17.3258013Z 
2026-01-14T08:22:17.3258016Z 
2026-01-14T08:22:17.3258020Z 
2026-01-14T08:22:17.3258024Z 
2026-01-14T08:22:17.3258027Z 
2026-01-14T08:22:17.3258127Z 
2026-01-14T08:22:17.3258131Z 
2026-01-14T08:22:17.3258135Z 
2026-01-14T08:22:17.3258138Z 
2026-01-14T08:22:17.3258142Z 
2026-01-14T08:22:17.3258146Z 
2026-01-14T08:22:17.3258158Z 
2026-01-14T08:22:17.3258450Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3258778Z 
2026-01-14T08:22:17.3258782Z 
2026-01-14T08:22:17.3258863Z 
2026-01-14T08:22:17.3258867Z 
2026-01-14T08:22:17.3258870Z 
2026-01-14T08:22:17.3258874Z 
2026-01-14T08:22:17.3258877Z 
2026-01-14T08:22:17.3258881Z 
2026-01-14T08:22:17.3258892Z 
2026-01-14T08:22:17.3258895Z 
2026-01-14T08:22:17.3258899Z 
2026-01-14T08:22:17.3258902Z 
2026-01-14T08:22:17.3258906Z 
2026-01-14T08:22:17.3258910Z 
2026-01-14T08:22:17.3258913Z 
2026-01-14T08:22:17.3258917Z 
2026-01-14T08:22:17.3258920Z 
2026-01-14T08:22:17.3258924Z 
2026-01-14T08:22:17.3259225Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:17.3259572Z 
2026-01-14T08:22:17.3259576Z 
2026-01-14T08:22:17.3259579Z 
2026-01-14T08:22:17.3259677Z [A
2026-01-14T08:22:17.3259784Z 
2026-01-14T08:22:17.3259787Z 
2026-01-14T08:22:17.3259898Z [A[A
2026-01-14T08:22:17.3260008Z 
2026-01-14T08:22:17.3260174Z Preparing transaction: - \ | done
2026-01-14T08:22:17.3260795Z Verifying transaction: - \ | / - \ | / - \ | / - \ done
2026-01-14T08:22:17.3261485Z Executing transaction: / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:22:17.3261964Z #
2026-01-14T08:22:17.3262168Z # To activate this environment, use
2026-01-14T08:22:17.3262458Z #
2026-01-14T08:22:17.3262647Z #     $ conda activate venv
2026-01-14T08:22:17.3262894Z #
2026-01-14T08:22:17.3263107Z # To deactivate an active environment, use
2026-01-14T08:22:17.3263411Z #
2026-01-14T08:22:17.3263612Z #     $ conda deactivate
2026-01-14T08:22:17.3263771Z 
2026-01-14T08:22:17.3263867Z + conda activate venv
2026-01-14T08:22:17.3264108Z + local cmd=activate
2026-01-14T08:22:17.3264337Z + case "$cmd" in
2026-01-14T08:22:17.3264680Z + __conda_activate activate venv
2026-01-14T08:22:17.3264946Z + '[' -n '' ']'
2026-01-14T08:22:17.3265156Z + local ask_conda
2026-01-14T08:22:17.3265372Z ++ PS1='(base) '
2026-01-14T08:22:17.3265617Z ++ __conda_exe shell.posix activate venv
2026-01-14T08:22:17.3265975Z ++ /opt/conda/bin/conda shell.posix activate venv
2026-01-14T08:22:17.3266330Z + ask_conda='PS1='\''(venv) '\''
2026-01-14T08:22:17.3267417Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:17.3268631Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:17.3268978Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:17.3269263Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:17.3269595Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:17.3269944Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:17.3270272Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:17.3270596Z export _CE_M='\'''\''
2026-01-14T08:22:17.3270839Z export _CE_CONDA='\'''\''
2026-01-14T08:22:17.3271157Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:17.3271524Z + eval 'PS1='\''(venv) '\''
2026-01-14T08:22:17.3272576Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:17.3273722Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:17.3274061Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:17.3274349Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:17.3274849Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:17.3275357Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:17.3275694Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:17.3276021Z export _CE_M='\'''\''
2026-01-14T08:22:17.3276300Z export _CE_CONDA='\'''\''
2026-01-14T08:22:17.3276612Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:17.3276970Z ++ PS1='(venv) '
2026-01-14T08:22:17.3277962Z ++ export PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:17.3279909Z ++ PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:17.3280992Z ++ export CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:17.3281319Z ++ CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:17.3281633Z ++ export CONDA_SHLVL=2
2026-01-14T08:22:17.3281867Z ++ CONDA_SHLVL=2
2026-01-14T08:22:17.3282104Z ++ export CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:17.3282378Z ++ CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:17.3282657Z ++ export 'CONDA_PROMPT_MODIFIER=(venv) '
2026-01-14T08:22:17.3282984Z ++ CONDA_PROMPT_MODIFIER='(venv) '
2026-01-14T08:22:17.3283291Z ++ export CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:17.3283601Z ++ CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:17.3283884Z ++ export CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:17.3284196Z ++ CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:17.3284470Z ++ export _CE_M=
2026-01-14T08:22:17.3284687Z ++ _CE_M=
2026-01-14T08:22:17.3284885Z ++ export _CE_CONDA=
2026-01-14T08:22:17.3285114Z ++ _CE_CONDA=
2026-01-14T08:22:17.3285370Z ++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:17.3285736Z ++ CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:17.3286029Z + __conda_hashr
2026-01-14T08:22:17.3286242Z + '[' -n '' ']'
2026-01-14T08:22:17.3286460Z + '[' -n '' ']'
2026-01-14T08:22:17.3286659Z + hash -r
2026-01-14T08:22:17.3286897Z + python -m pip install --upgrade pip
2026-01-14T08:22:17.3287429Z Requirement already satisfied: pip in /opt/conda/envs/venv/lib/python3.10/site-packages (25.3)
2026-01-14T08:22:17.3289679Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:22:17.3291507Z [0m+ pip install torch==2.7.1
2026-01-14T08:22:17.3291784Z Collecting torch==2.7.1
2026-01-14T08:22:17.3292205Z   Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)
2026-01-14T08:22:17.3292697Z Collecting filelock (from torch==2.7.1)
2026-01-14T08:22:17.3293139Z   Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:22:17.3293635Z Collecting typing-extensions>=4.10.0 (from torch==2.7.1)
2026-01-14T08:22:17.3294165Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:22:17.3294651Z Collecting sympy>=1.13.3 (from torch==2.7.1)
2026-01-14T08:22:17.3295082Z   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:22:17.3295514Z Collecting networkx (from torch==2.7.1)
2026-01-14T08:22:17.3295930Z   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:22:17.3296375Z Collecting jinja2 (from torch==2.7.1)
2026-01-14T08:22:17.3296774Z   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-01-14T08:22:17.3297205Z Collecting fsspec (from torch==2.7.1)
2026-01-14T08:22:17.3297617Z   Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:22:17.3298145Z Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.1)
2026-01-14T08:22:17.3298901Z   Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:17.3299586Z Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.1)
2026-01-14T08:22:17.3300336Z   Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:17.3301080Z Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.1)
2026-01-14T08:22:17.3301931Z   Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
2026-01-14T08:22:17.3302640Z Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.1)
2026-01-14T08:22:17.3303234Z   Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)
2026-01-14T08:22:17.3303845Z Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.1)
2026-01-14T08:22:17.3304548Z   Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:17.3305275Z Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.1)
2026-01-14T08:22:17.3305954Z   Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:17.3306662Z Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.1)
2026-01-14T08:22:23.6154340Z   Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:23.6155410Z Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.1)
2026-01-14T08:22:23.6156329Z   Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
2026-01-14T08:22:23.6157066Z Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.1)
2026-01-14T08:22:23.6157783Z   Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
2026-01-14T08:22:23.6158517Z Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.1)
2026-01-14T08:22:23.6159137Z   Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)
2026-01-14T08:22:23.6159744Z Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.1)
2026-01-14T08:22:23.6160414Z   Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
2026-01-14T08:22:23.6161093Z Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.1)
2026-01-14T08:22:23.6161775Z   Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)
2026-01-14T08:22:23.6162467Z Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.1)
2026-01-14T08:22:23.6163188Z   Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:23.6163901Z Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.1)
2026-01-14T08:22:23.6164597Z   Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:23.6165249Z Collecting triton==3.3.1 (from torch==2.7.1)
2026-01-14T08:22:23.6165826Z   Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)
2026-01-14T08:22:23.6166852Z Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from triton==3.3.1->torch==2.7.1) (80.9.0)
2026-01-14T08:22:23.6167688Z Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1)
2026-01-14T08:22:23.6168203Z   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
2026-01-14T08:22:23.6168677Z Collecting MarkupSafe>=2.0 (from jinja2->torch==2.7.1)
2026-01-14T08:22:23.6169414Z   Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
2026-01-14T08:22:23.6170309Z Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)
2026-01-14T08:22:23.6171788Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/821.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:23.6172703Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m68.2/821.2 MB[0m [31m344.7 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:23.6173645Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m131.6/821.2 MB[0m [31m327.5 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:23.6174565Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.2/821.2 MB[0m [31m322.1 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6176000Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m258.2/821.2 MB[0m [31m320.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6176933Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m317.7/821.2 MB[0m [31m309.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6177879Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m375.7/821.2 MB[0m [31m303.7 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6178797Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m438.8/821.2 MB[0m [31m304.1 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6179715Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m501.2/821.2 MB[0m [31m301.3 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:23.6180629Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m563.1/821.2 MB[0m [31m304.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6181571Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m625.0/821.2 MB[0m [31m309.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6182498Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m688.9/821.2 MB[0m [31m310.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6183420Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m750.8/821.2 MB[0m [31m309.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6184333Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m812.6/821.2 MB[0m [31m311.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6185209Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6186075Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6186961Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6187826Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6188695Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6189699Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6190578Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6191439Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6193205Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6194068Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6194933Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6195812Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6196670Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6197539Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:23.6198392Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6163845Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6165092Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6165965Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6166851Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6167716Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6168564Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6169437Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6173141Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6174034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6175258Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6176122Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6176973Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6177818Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6178865Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6179719Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m821.0/821.2 MB[0m [31m294.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6180522Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m821.2/821.2 MB[0m [31m38.1 MB/s[0m  [33m0:00:08[0m
2026-01-14T08:22:30.6181427Z [?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)
2026-01-14T08:22:30.6182315Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/393.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:30.6183153Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m64.7/393.1 MB[0m [31m323.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:30.6184225Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m129.0/393.1 MB[0m [31m321.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6185142Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m187.7/393.1 MB[0m [31m311.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6186054Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m250.6/393.1 MB[0m [31m311.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6186996Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m307.2/393.1 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6187911Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m375.4/393.1 MB[0m [31m306.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6188796Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6189657Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6190741Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6191721Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6192687Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6193799Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6194667Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6195525Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6196407Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6197259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6198126Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6199008Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6199865Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6200727Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:30.6201602Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m393.0/393.1 MB[0m [31m305.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9614361Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m393.1/393.1 MB[0m [31m66.2 MB/s[0m  [33m0:00:04[0m
2026-01-14T08:22:36.9616049Z [?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)
2026-01-14T08:22:36.9616957Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:36.9618027Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.9/8.9 MB[0m [31m50.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:36.9618833Z [?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)
2026-01-14T08:22:36.9619632Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/23.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:36.9620409Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.7/23.7 MB[0m [31m134.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:36.9621489Z [?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)
2026-01-14T08:22:36.9622392Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/897.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:36.9623173Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m897.7/897.7 kB[0m [31m85.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:36.9623957Z [?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)
2026-01-14T08:22:36.9624764Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/571.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:36.9625642Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m66.6/571.0 MB[0m [31m332.6 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:36.9626577Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m126.1/571.0 MB[0m [31m314.4 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:36.9627524Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m185.3/571.0 MB[0m [31m307.3 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:36.9628442Z [2K   [91m━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m246.4/571.0 MB[0m [31m306.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:36.9629367Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m303.0/571.0 MB[0m [31m296.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9630308Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m358.6/571.0 MB[0m [31m288.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9631226Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m418.4/571.0 MB[0m [31m291.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9632150Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m482.9/571.0 MB[0m [31m294.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9633094Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m545.5/571.0 MB[0m [31m298.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9633988Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9634860Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9635817Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9636683Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9637542Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9638496Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9639356Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9640209Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9641085Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9641944Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9642799Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9643656Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9644530Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9645379Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9646239Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9647110Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9647967Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9648825Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9649694Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m570.9/571.0 MB[0m [31m301.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:36.9650597Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m571.0/571.0 MB[0m [31m55.4 MB/s[0m  [33m0:00:05[0m
2026-01-14T08:22:36.9651465Z [?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)
2026-01-14T08:22:42.5294472Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/200.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5295540Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m60.8/200.2 MB[0m [31m314.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5296497Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m127.4/200.2 MB[0m [31m317.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5297434Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m186.1/200.2 MB[0m [31m308.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5298553Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m200.0/200.2 MB[0m [31m303.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5299405Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m200.0/200.2 MB[0m [31m303.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5300266Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m200.0/200.2 MB[0m [31m303.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5301142Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m200.0/200.2 MB[0m [31m303.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5301958Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m200.2/200.2 MB[0m [31m140.1 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:42.5302842Z [?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)
2026-01-14T08:22:42.5303731Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5304478Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.1/1.1 MB[0m [31m111.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:42.5305344Z [?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)
2026-01-14T08:22:42.5306298Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/56.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5307455Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m56.1/56.3 MB[0m [31m312.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5308278Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m56.3/56.3 MB[0m [31m148.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:42.5309165Z [?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)
2026-01-14T08:22:42.5310190Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/158.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5311024Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.5/158.2 MB[0m [31m300.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5311953Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m133.7/158.2 MB[0m [31m334.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5312944Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m158.1/158.2 MB[0m [31m333.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5313804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m158.1/158.2 MB[0m [31m333.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5314658Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m158.1/158.2 MB[0m [31m333.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5315512Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m158.1/158.2 MB[0m [31m333.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5316336Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m158.2/158.2 MB[0m [31m129.3 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:42.5317283Z [?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)
2026-01-14T08:22:42.5318165Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/216.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5319025Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m60.8/216.6 MB[0m [31m306.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5320074Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m118.8/216.6 MB[0m [31m295.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5321005Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m165.7/216.6 MB[0m [31m275.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5321927Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m216.5/216.6 MB[0m [31m283.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5322783Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m216.5/216.6 MB[0m [31m283.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5323638Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m216.5/216.6 MB[0m [31m283.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5324612Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m216.5/216.6 MB[0m [31m283.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5325471Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m216.5/216.6 MB[0m [31m283.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5326286Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m216.6/216.6 MB[0m [31m128.3 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:42.5327100Z [?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)
2026-01-14T08:22:42.5328004Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/156.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:42.5328839Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m52.7/156.8 MB[0m [31m267.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5329751Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m107.0/156.8 MB[0m [31m268.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:42.5330852Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6451715Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6452692Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6453596Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6454447Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6455291Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6456165Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m156.8/156.8 MB[0m [31m288.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6456979Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m156.8/156.8 MB[0m [31m81.3 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:47.6457844Z [?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)
2026-01-14T08:22:47.6458733Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/201.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:47.6459592Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m58.7/201.3 MB[0m [31m296.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6460521Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m118.8/201.3 MB[0m [31m295.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6461447Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m182.5/201.3 MB[0m [31m302.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6462636Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6463512Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6464370Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6465367Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6466221Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6467079Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6467933Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6468823Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6469690Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6470550Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m201.1/201.3 MB[0m [31m304.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6471383Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m201.3/201.3 MB[0m [31m73.5 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:22:47.6472262Z [?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)
2026-01-14T08:22:47.6473149Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/19.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:47.6473921Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19.7/19.7 MB[0m [31m151.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:47.6474969Z [?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
2026-01-14T08:22:47.6475796Z Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)
2026-01-14T08:22:47.6476620Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/155.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:47.6485868Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.5/155.6 MB[0m [31m297.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6486907Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m120.8/155.6 MB[0m [31m301.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6487828Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.5/155.6 MB[0m [31m307.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6488891Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.5/155.6 MB[0m [31m307.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6489766Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m155.5/155.6 MB[0m [31m307.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:47.6490680Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m155.6/155.6 MB[0m [31m129.2 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:47.6491319Z [?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
2026-01-14T08:22:47.6492099Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:47.6492867Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.3/6.3 MB[0m [31m216.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:47.6493481Z [?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)
2026-01-14T08:22:47.6494121Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/536.2 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:47.6494902Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m536.2/536.2 kB[0m [31m56.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:47.6495593Z [?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-01-14T08:22:47.6496097Z Downloading filelock-3.20.3-py3-none-any.whl (16 kB)
2026-01-14T08:22:47.6496526Z Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)
2026-01-14T08:22:47.6496949Z Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-01-14T08:22:47.6497654Z Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)
2026-01-14T08:22:47.6498385Z Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
2026-01-14T08:22:57.3618142Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:57.3618975Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m146.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:57.3621562Z [?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch
2026-01-14T08:22:57.3623682Z [?25l
2026-01-14T08:22:57.3624123Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3624792Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3625448Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3626101Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3627045Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3627720Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3628369Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3629023Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3629857Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/24[0m [nvidia-cusparselt-cu12]
2026-01-14T08:22:57.3630517Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/24[0m [mpmath]
2026-01-14T08:22:57.3631241Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/24[0m [mpmath]
2026-01-14T08:22:57.3631893Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/24[0m [mpmath]
2026-01-14T08:22:57.3632629Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 2/24[0m [typing-extensions]
2026-01-14T08:22:57.3633333Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3633988Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3634654Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3635330Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3635992Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3636822Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3637548Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3638397Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3639060Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3639727Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3640507Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3641298Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3641980Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3642633Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/24[0m [triton]
2026-01-14T08:22:57.3643289Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3643968Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3644616Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3645272Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3645918Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3646595Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3647247Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3647892Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3648542Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3649208Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3649917Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3650564Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3651217Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:22:57.3651891Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5925813Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5926532Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5927201Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5928157Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5928955Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5929623Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5930348Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5931959Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5932641Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5933308Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5933967Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5934733Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5935517Z [2K   [91m━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/24[0m [sympy]
2026-01-14T08:23:04.5936211Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 5/24[0m [nvidia-nvtx-cu12]
2026-01-14T08:23:04.5936985Z [2K   [91m━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/24[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:04.5937887Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5938618Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5939453Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5940185Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5941024Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5941762Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5942493Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5943231Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5944079Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5944802Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5945532Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/24[0m [nvidia-nccl-cu12]
2026-01-14T08:23:04.5946289Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/24[0m [nvidia-curand-cu12]
2026-01-14T08:23:04.5947039Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/24[0m [nvidia-curand-cu12]
2026-01-14T08:23:04.5947805Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:04.5948584Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m11/24[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:04.5949386Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m12/24[0m [nvidia-cuda-cupti-cu12]
2026-01-14T08:23:04.5950136Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5950880Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5951745Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5952504Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5953254Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5953991Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5954865Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5955778Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5956622Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5957508Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5958366Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:04.5959121Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8022652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8023473Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8024506Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8025268Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8026016Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8026799Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8027562Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8028309Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8029074Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m13/24[0m [nvidia-cublas-cu12]
2026-01-14T08:23:11.8029818Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8030500Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8031342Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8032018Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8032897Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8033599Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8034265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━[0m [32m14/24[0m [networkx]
2026-01-14T08:23:11.8034960Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m15/24[0m [MarkupSafe]
2026-01-14T08:23:11.8035752Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━[0m [32m16/24[0m [fsspec]
2026-01-14T08:23:11.8036432Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m17/24[0m [filelock]
2026-01-14T08:23:11.8037162Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8037933Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8038729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8039495Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8040265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8041051Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8041811Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8042585Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8043345Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8044129Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8044900Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8045661Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m18/24[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:11.8046433Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8047173Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8047915Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8048662Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8049508Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8050357Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8051091Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8051837Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8052685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8053421Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━[0m [32m19/24[0m [nvidia-cufft-cu12]
2026-01-14T08:23:11.8054165Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:11.8054926Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0063103Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0063907Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0064664Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0065430Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0066167Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0066907Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0067637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0068652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0069407Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0070152Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0071053Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0071785Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0072524Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0073255Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0074010Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0075020Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0075758Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0076496Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0077243Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0077981Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0078714Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0079445Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0080209Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0080946Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0081685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0082426Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0083162Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0083896Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0084620Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0085516Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0086255Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m20/24[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:19.0087008Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0087771Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0088663Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0089423Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0090252Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0091034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0091790Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0092544Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0093306Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0094076Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m22/24[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:19.0094767Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:19.0095404Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7128970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7130027Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7130740Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7131373Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7132027Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7132968Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7133602Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7134258Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7134891Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7135704Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7136352Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7136982Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7137621Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7138276Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7138917Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7139562Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7140192Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7140852Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7141484Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7142130Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7142777Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7143433Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7144072Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7144697Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7145331Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7146067Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7146698Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7147330Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7147962Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7148699Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7149329Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7149961Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7150593Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7151248Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7151889Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7152518Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7153153Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7153804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7154430Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7155061Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7155687Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7156428Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7157066Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7157692Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7158326Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:26.7159056Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3563147Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3564078Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3564783Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3565458Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3566092Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3566729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3567356Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3568021Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3568656Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3569282Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3569997Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3570650Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3571283Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3571927Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3572557Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3573216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3573847Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3574481Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3575314Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3576268Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3576917Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3577541Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3578305Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3579210Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3579847Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3580478Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3581109Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3581767Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3582390Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3583023Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3583660Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3584305Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3584939Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3585569Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3586201Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3586947Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3587579Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3588216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3588838Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3589566Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m23/24[0m [torch]
2026-01-14T08:23:33.3590150Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m24/24[0m [torch]
2026-01-14T08:23:33.3590542Z [?25h
2026-01-14T08:23:33.3593509Z [1A[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.3 fsspec-2026.1.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1 typing-extensions-4.15.0
2026-01-14T08:23:44.7833165Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:23:44.7835078Z [0m+ sed -i '' dev-requirements.txt
2026-01-14T08:23:44.7835403Z + pip install -r dev-requirements.txt
2026-01-14T08:23:44.7835822Z Collecting pytest==8.4.2 (from -r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7836334Z   Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)
2026-01-14T08:23:44.7836911Z Collecting unittest-xml-reporting (from -r dev-requirements.txt (line 3))
2026-01-14T08:23:44.7837553Z   Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl.metadata (11 kB)
2026-01-14T08:23:44.7838159Z Collecting parameterized (from -r dev-requirements.txt (line 4))
2026-01-14T08:23:44.7838733Z   Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)
2026-01-14T08:23:44.7839289Z Collecting packaging (from -r dev-requirements.txt (line 5))
2026-01-14T08:23:44.7839801Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:23:44.7840318Z Collecting transformers (from -r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7840861Z   Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)
2026-01-14T08:23:44.7841393Z Collecting hypothesis (from -r dev-requirements.txt (line 7))
2026-01-14T08:23:44.7841914Z   Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:23:44.7842462Z Collecting sentencepiece (from -r dev-requirements.txt (line 8))
2026-01-14T08:23:44.7843174Z   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
2026-01-14T08:23:44.7843889Z Collecting expecttest (from -r dev-requirements.txt (line 9))
2026-01-14T08:23:44.7844404Z   Downloading expecttest-0.3.0-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:23:44.7844923Z Collecting pyyaml (from -r dev-requirements.txt (line 10))
2026-01-14T08:23:44.7845720Z   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
2026-01-14T08:23:44.7846491Z Collecting bitsandbytes (from -r dev-requirements.txt (line 13))
2026-01-14T08:23:44.7847092Z   Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)
2026-01-14T08:23:44.7847697Z Collecting matplotlib (from -r dev-requirements.txt (line 14))
2026-01-14T08:23:44.7848395Z   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)
2026-01-14T08:23:44.7849383Z Collecting pandas (from -r dev-requirements.txt (line 15))
2026-01-14T08:23:44.7850115Z   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
2026-01-14T08:23:44.7850771Z Collecting fire (from -r dev-requirements.txt (line 16))
2026-01-14T08:23:44.7851231Z   Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)
2026-01-14T08:23:44.7851887Z Collecting tabulate (from -r dev-requirements.txt (line 17))
2026-01-14T08:23:44.7852385Z   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
2026-01-14T08:23:44.7852884Z Collecting tiktoken (from -r dev-requirements.txt (line 18))
2026-01-14T08:23:44.7853465Z   Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
2026-01-14T08:23:44.7854049Z Collecting blobfile (from -r dev-requirements.txt (line 19))
2026-01-14T08:23:44.7854551Z   Downloading blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
2026-01-14T08:23:44.7855043Z Collecting lm_eval (from -r dev-requirements.txt (line 20))
2026-01-14T08:23:44.7855534Z   Downloading lm_eval-0.4.9.2-py3-none-any.whl.metadata (53 kB)
2026-01-14T08:23:44.7856036Z Collecting diskcache (from -r dev-requirements.txt (line 22))
2026-01-14T08:23:44.7856553Z   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
2026-01-14T08:23:44.7857081Z Collecting pycocotools (from -r dev-requirements.txt (line 23))
2026-01-14T08:23:44.7857881Z   Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)
2026-01-14T08:23:44.7858666Z Collecting tqdm (from -r dev-requirements.txt (line 24))
2026-01-14T08:23:44.7859126Z   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2026-01-14T08:23:44.7859661Z Collecting importlib_metadata (from -r dev-requirements.txt (line 25))
2026-01-14T08:23:44.7860258Z   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:23:44.7860804Z Collecting ninja (from -r dev-requirements.txt (line 28))
2026-01-14T08:23:44.7861432Z   Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
2026-01-14T08:23:44.7862111Z Collecting cmake<4.0.0,>=3.19.0 (from -r dev-requirements.txt (line 31))
2026-01-14T08:23:44.7862787Z   Downloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:23:44.7863440Z Collecting ruff==0.11.6 (from -r dev-requirements.txt (line 34))
2026-01-14T08:23:44.7864084Z   Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2026-01-14T08:23:44.7864726Z Collecting pre-commit (from -r dev-requirements.txt (line 35))
2026-01-14T08:23:44.7865263Z   Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)
2026-01-14T08:23:44.7865885Z Collecting exceptiongroup>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7866515Z   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
2026-01-14T08:23:44.7867121Z Collecting iniconfig>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7867692Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:23:44.7868258Z Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7868823Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-01-14T08:23:44.7869377Z Collecting pygments>=2.7.2 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7869967Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:23:44.7870510Z Collecting tomli>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:23:44.7871055Z   Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:44.7871613Z Collecting lxml (from unittest-xml-reporting->-r dev-requirements.txt (line 3))
2026-01-14T08:23:44.7872350Z   Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-01-14T08:23:44.7873504Z Requirement already satisfied: filelock in /opt/conda/envs/venv/lib/python3.10/site-packages (from transformers->-r dev-requirements.txt (line 6)) (3.20.3)
2026-01-14T08:23:44.7874522Z Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7875454Z   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:23:44.7876736Z Collecting numpy>=1.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7885378Z   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
2026-01-14T08:23:44.7886121Z Collecting regex!=2019.12.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7886950Z   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
2026-01-14T08:23:44.7887771Z Collecting requests (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7888358Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-01-14T08:23:44.7888965Z Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7889825Z   Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-01-14T08:23:44.7890580Z Collecting safetensors>=0.4.3 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7891352Z   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
2026-01-14T08:23:44.7892588Z Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (2026.1.0)
2026-01-14T08:23:44.7894212Z Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (4.15.0)
2026-01-14T08:23:44.7895489Z Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:23:44.7896313Z   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
2026-01-14T08:23:44.7897076Z Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->-r dev-requirements.txt (line 7))
2026-01-14T08:23:44.7897781Z   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:44.7898758Z Requirement already satisfied: torch<3,>=2.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from bitsandbytes->-r dev-requirements.txt (line 13)) (2.7.1)
2026-01-14T08:23:44.7900129Z Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.14.0)
2026-01-14T08:23:44.7901539Z Requirement already satisfied: networkx in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.2)
2026-01-14T08:23:44.7902911Z Requirement already satisfied: jinja2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.1.6)
2026-01-14T08:23:44.7904392Z Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:44.7906003Z Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:57.3430922Z Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.80)
2026-01-14T08:23:57.3433251Z Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (9.5.1.17)
2026-01-14T08:23:57.3434841Z Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.4.1)
2026-01-14T08:23:57.3436583Z Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.3.0.4)
2026-01-14T08:23:57.3438152Z Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (10.3.7.77)
2026-01-14T08:23:57.3439747Z Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.7.1.2)
2026-01-14T08:23:57.3441338Z Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.5.4.2)
2026-01-14T08:23:57.3442906Z Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (0.6.3)
2026-01-14T08:23:57.3444467Z Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (2.26.2)
2026-01-14T08:23:57.3445998Z Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.77)
2026-01-14T08:23:57.3447565Z Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.6.85)
2026-01-14T08:23:57.3449147Z Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.11.1.6)
2026-01-14T08:23:57.3450768Z Requirement already satisfied: triton==3.3.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.3.1)
2026-01-14T08:23:57.3452256Z Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from triton==3.3.1->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (80.9.0)
2026-01-14T08:23:57.3453356Z Collecting contourpy>=1.0.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3454121Z   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
2026-01-14T08:23:57.3454867Z Collecting cycler>=0.10 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3455447Z   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:23:57.3456027Z Collecting fonttools>=4.22.0 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3456800Z   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)
2026-01-14T08:23:57.3457584Z Collecting kiwisolver>=1.3.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3458336Z   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:23:57.3459099Z Collecting pillow>=8 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3459845Z   Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
2026-01-14T08:23:57.3460595Z Collecting pyparsing>=3 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3461283Z   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:23:57.3461913Z Collecting python-dateutil>=2.7 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:23:57.3462625Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:23:57.3463268Z Collecting pytz>=2020.1 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:23:57.3463927Z   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
2026-01-14T08:23:57.3464500Z Collecting tzdata>=2022.7 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:23:57.3465095Z   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
2026-01-14T08:23:57.3465649Z Collecting termcolor (from fire->-r dev-requirements.txt (line 16))
2026-01-14T08:23:57.3466190Z   Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)
2026-01-14T08:23:57.3466789Z Collecting pycryptodomex>=3.8 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:23:57.3467594Z   Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
2026-01-14T08:23:57.3468375Z Collecting urllib3<3,>=1.25.3 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:23:57.3468960Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-01-14T08:23:57.3469545Z Collecting accelerate>=0.26.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3470159Z   Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:23:57.3470721Z Collecting evaluate (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3471295Z   Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
2026-01-14T08:23:57.3471852Z Collecting datasets>=2.16.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3472441Z   Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:23:57.3472994Z Collecting jsonlines (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3473583Z   Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
2026-01-14T08:23:57.3474148Z Collecting numexpr (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3475041Z   Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)
2026-01-14T08:23:57.3475758Z Collecting peft>=0.2.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3476290Z   Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:23:57.3476840Z Collecting pybind11>=2.6.2 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3477429Z   Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)
2026-01-14T08:23:57.3478023Z Collecting pytablewriter (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3478634Z   Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)
2026-01-14T08:23:57.3479240Z Collecting rouge-score>=0.0.4 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3479772Z   Downloading rouge_score-0.1.2.tar.gz (17 kB)
2026-01-14T08:23:57.3480456Z   Installing build dependencies ... [?25l- \ | / done
2026-01-14T08:23:57.3481020Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:57.3481556Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.3482211Z [?25hCollecting sacrebleu>=1.5.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3482846Z   Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:23:57.3483440Z Collecting scikit-learn>=0.24.1 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3484242Z   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
2026-01-14T08:23:57.3484994Z Collecting sqlitedict (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3485509Z   Downloading sqlitedict-2.1.0.tar.gz (21 kB)
2026-01-14T08:23:57.3486121Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:23:57.3486626Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:57.3487164Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.3487817Z [?25hCollecting tqdm-multiprocess (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3488505Z   Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)
2026-01-14T08:23:57.3489269Z Collecting zstandard (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3490090Z   Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)
2026-01-14T08:23:57.3490825Z Collecting dill (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3491320Z   Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:23:57.3491862Z Collecting word2number (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3492361Z   Downloading word2number-1.1.zip (9.7 kB)
2026-01-14T08:23:57.3492818Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:23:57.3493321Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:23:57.3493861Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:23:57.3494496Z [?25hCollecting more_itertools (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:23:57.3495125Z   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:23:57.3495754Z Collecting zipp>=3.20 (from importlib_metadata->-r dev-requirements.txt (line 25))
2026-01-14T08:23:57.3496350Z   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
2026-01-14T08:23:57.3496914Z Collecting cfgv>=2.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:57.3497484Z   Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)
2026-01-14T08:23:57.3498069Z Collecting identify>=1.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:23:57.3498706Z   Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)
2026-01-14T08:23:57.3499318Z Collecting nodeenv>=0.11.1 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:06.6892097Z   Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)
2026-01-14T08:24:06.6893158Z Collecting virtualenv>=20.10.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:06.6894207Z   Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:24:06.6895176Z Collecting psutil (from accelerate>=0.26.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6896624Z   Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)
2026-01-14T08:24:06.6898043Z Collecting pyarrow>=21.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6899191Z   Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
2026-01-14T08:24:06.6900340Z Collecting httpx<1.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6901323Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-01-14T08:24:06.6902343Z Collecting xxhash (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6903746Z   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:06.6905258Z Collecting multiprocess<0.70.19 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6906375Z   Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)
2026-01-14T08:24:06.6907442Z Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:06.6908365Z   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:06.6909541Z Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6911105Z   Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
2026-01-14T08:24:06.6912443Z Collecting anyio (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6913379Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:06.6914556Z Collecting certifi (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6915497Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:06.6916456Z Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6917393Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-01-14T08:24:06.6918266Z Collecting idna (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6919185Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:24:06.6920153Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6921161Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-01-14T08:24:06.6922456Z Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6923838Z   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
2026-01-14T08:24:06.6925094Z Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6926298Z   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:06.6927568Z Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6928895Z   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
2026-01-14T08:24:06.6930271Z Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6931505Z   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:06.6932720Z Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6934285Z   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
2026-01-14T08:24:06.6935898Z Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6937567Z   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
2026-01-14T08:24:06.6939174Z Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6940754Z   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:06.6942357Z Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6943934Z   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
2026-01-14T08:24:06.6945202Z Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:06.6946135Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-01-14T08:24:06.6947231Z Collecting charset_normalizer<4,>=2 (from requests->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:06.6948610Z   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-01-14T08:24:06.6949904Z Collecting absl-py (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6950930Z   Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:24:06.6951770Z Collecting nltk (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6952688Z   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:24:06.6953537Z Collecting portalocker (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6954506Z   Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)
2026-01-14T08:24:06.6955408Z Collecting colorama (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6956297Z   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
2026-01-14T08:24:06.6957197Z Collecting scipy>=1.8.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6958269Z   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
2026-01-14T08:24:06.6959441Z Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6960367Z   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
2026-01-14T08:24:06.6961329Z Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6962376Z   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
2026-01-14T08:24:06.6963865Z Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.3.0)
2026-01-14T08:24:06.6965497Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:06.6966483Z   Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)
2026-01-14T08:24:06.6967512Z Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:06.6968583Z   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:06.6970172Z Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.0.3)
2026-01-14T08:24:06.6971812Z Collecting click (from nltk->rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6972691Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-01-14T08:24:06.6973602Z Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6974611Z   Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)
2026-01-14T08:24:06.6975823Z Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6976803Z   Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:06.6977785Z Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6978753Z   Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:06.6979668Z Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6980574Z   Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:06.6981465Z Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6982404Z   Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:24:06.6983679Z Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6984756Z   Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)
2026-01-14T08:24:06.6985778Z Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:06.6986835Z   Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
2026-01-14T08:24:06.6987695Z Downloading pytest-8.4.2-py3-none-any.whl (365 kB)
2026-01-14T08:24:07.7609277Z Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
2026-01-14T08:24:07.7610398Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/11.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7611178Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m11.5/11.5 MB[0m [31m185.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7612008Z [?25hDownloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)
2026-01-14T08:24:07.7612818Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/27.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7613569Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.8/27.8 MB[0m [31m168.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7614177Z [?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-01-14T08:24:07.7614694Z Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:07.7615244Z Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:07.7615710Z Downloading packaging-25.0-py3-none-any.whl (66 kB)
2026-01-14T08:24:07.7616153Z Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)
2026-01-14T08:24:07.7616824Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7617592Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.0/12.0 MB[0m [31m160.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7618246Z [?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
2026-01-14T08:24:07.7618932Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/566.1 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7619686Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m566.1/566.1 kB[0m [31m58.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7620507Z [?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:07.7621305Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7622043Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m186.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7622865Z [?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:07.7623916Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7624672Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m181.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7625313Z [?25hDownloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
2026-01-14T08:24:07.7625975Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/542.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7626904Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m542.7/542.7 kB[0m [31m53.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7627595Z [?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
2026-01-14T08:24:07.7628311Z Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
2026-01-14T08:24:07.7629156Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7629919Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m107.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7630551Z [?25hDownloading expecttest-0.3.0-py3-none-any.whl (8.2 kB)
2026-01-14T08:24:07.7631264Z Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
2026-01-14T08:24:07.7632160Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/770.3 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7632934Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m770.3/770.3 kB[0m [31m90.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7633683Z [?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)
2026-01-14T08:24:07.7634448Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/59.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7635259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m59.0/59.1 MB[0m [31m316.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:07.7636095Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.1/59.1 MB[0m [31m200.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7636933Z [?25hDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
2026-01-14T08:24:07.7637782Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7638548Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.7/8.7 MB[0m [31m207.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7639355Z [?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
2026-01-14T08:24:07.7640178Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7640933Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.8/12.8 MB[0m [31m135.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7641671Z [?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)
2026-01-14T08:24:07.7642099Z Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
2026-01-14T08:24:07.7642607Z Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)
2026-01-14T08:24:07.7643330Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7644069Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m119.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7644777Z [?25hDownloading blobfile-3.1.0-py3-none-any.whl (75 kB)
2026-01-14T08:24:07.7645213Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-01-14T08:24:07.7645632Z Downloading lm_eval-0.4.9.2-py3-none-any.whl (8.2 MB)
2026-01-14T08:24:07.7646255Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:07.7647007Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.2/8.2 MB[0m [31m197.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:07.7647630Z [?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)
2026-01-14T08:24:07.7648357Z Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (472 kB)
2026-01-14T08:24:07.7649065Z Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
2026-01-14T08:24:07.7649519Z Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)
2026-01-14T08:24:07.7650192Z Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
2026-01-14T08:24:07.7650801Z Downloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)
2026-01-14T08:24:07.7651260Z Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
2026-01-14T08:24:07.7651691Z Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)
2026-01-14T08:24:07.7652276Z Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
2026-01-14T08:24:07.7652882Z Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
2026-01-14T08:24:07.7653304Z Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
2026-01-14T08:24:08.7553909Z Downloading dill-0.4.0-py3-none-any.whl (119 kB)
2026-01-14T08:24:08.7554462Z Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)
2026-01-14T08:24:08.7555019Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-01-14T08:24:08.7555524Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-01-14T08:24:08.7556089Z Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)
2026-01-14T08:24:08.7556808Z Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
2026-01-14T08:24:08.7557768Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7558519Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m148.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7559152Z [?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
2026-01-14T08:24:08.7560087Z Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)
2026-01-14T08:24:08.7561031Z Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)
2026-01-14T08:24:08.7561745Z Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
2026-01-14T08:24:08.7562213Z Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:08.7562757Z Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
2026-01-14T08:24:08.7563161Z Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
2026-01-14T08:24:08.7563605Z Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
2026-01-14T08:24:08.7564236Z Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)
2026-01-14T08:24:08.7565061Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/4.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7565825Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m177.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7566746Z [?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)
2026-01-14T08:24:08.7567428Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-01-14T08:24:08.7567851Z Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)
2026-01-14T08:24:08.7568275Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-01-14T08:24:08.7568684Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:08.7569283Z Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
2026-01-14T08:24:08.7570209Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7570965Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m152.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7571762Z [?25hDownloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
2026-01-14T08:24:08.7572625Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7573367Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.3/5.3 MB[0m [31m202.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7574000Z [?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)
2026-01-14T08:24:08.7574626Z Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
2026-01-14T08:24:08.7575721Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/16.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7576482Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16.8/16.8 MB[0m [31m225.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7577081Z [?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)
2026-01-14T08:24:08.7577728Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/557.0 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7578498Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m557.0/557.0 kB[0m [31m55.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7579323Z [?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
2026-01-14T08:24:08.7580144Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/7.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7580896Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m176.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7581827Z [?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)
2026-01-14T08:24:08.7582635Z Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
2026-01-14T08:24:08.7583410Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/47.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7584371Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m357.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:08.7585184Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m47.6/47.6 MB[0m [31m186.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7585802Z [?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)
2026-01-14T08:24:08.7586438Z Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2026-01-14T08:24:08.7587412Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/2.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7588165Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.3/2.3 MB[0m [31m175.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7588776Z [?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-01-14T08:24:08.7589422Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7590184Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m128.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7590798Z [?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)
2026-01-14T08:24:08.7591337Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-01-14T08:24:08.7591848Z Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
2026-01-14T08:24:08.7592556Z Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)
2026-01-14T08:24:08.7593455Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/791.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7594230Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m791.7/791.7 kB[0m [31m93.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7594854Z [?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-01-14T08:24:08.7595615Z Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
2026-01-14T08:24:08.7596371Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-01-14T08:24:08.7596809Z Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)
2026-01-14T08:24:08.7597421Z Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
2026-01-14T08:24:08.7598220Z Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
2026-01-14T08:24:08.7599055Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/9.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:08.7599808Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9.7/9.7 MB[0m [31m176.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:08.7600408Z [?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)
2026-01-14T08:24:08.7601003Z Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
2026-01-14T08:24:13.3080846Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/37.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:13.3081795Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m37.5/37.7 MB[0m [31m244.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:13.3082647Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m37.7/37.7 MB[0m [31m159.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:13.3083460Z [?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-01-14T08:24:13.3084000Z Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
2026-01-14T08:24:13.3084439Z Downloading tomli-2.4.0-py3-none-any.whl (14 kB)
2026-01-14T08:24:13.3084865Z Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
2026-01-14T08:24:13.3085317Z Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)
2026-01-14T08:24:13.3085986Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:13.3086776Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.0/6.0 MB[0m [31m204.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:13.3087411Z [?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)
2026-01-14T08:24:13.3087884Z Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)
2026-01-14T08:24:13.3088302Z Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
2026-01-14T08:24:13.3088704Z Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)
2026-01-14T08:24:13.3089118Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-01-14T08:24:13.3089545Z Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
2026-01-14T08:24:13.3090064Z Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
2026-01-14T08:24:13.3090525Z Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)
2026-01-14T08:24:13.3090966Z Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
2026-01-14T08:24:13.3091583Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:13.3092360Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.5/1.5 MB[0m [31m131.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:13.3092959Z [?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)
2026-01-14T08:24:13.3093564Z Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)
2026-01-14T08:24:13.3094187Z Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)
2026-01-14T08:24:13.3094871Z Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)
2026-01-14T08:24:13.3095591Z Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)
2026-01-14T08:24:13.3096051Z Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)
2026-01-14T08:24:13.3096515Z Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)
2026-01-14T08:24:13.3096948Z Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
2026-01-14T08:24:13.3097380Z Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)
2026-01-14T08:24:13.3097823Z Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)
2026-01-14T08:24:13.3098347Z Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)
2026-01-14T08:24:13.3098777Z Downloading typepy-1.3.4-py3-none-any.whl (31 kB)
2026-01-14T08:24:13.3099204Z Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)
2026-01-14T08:24:13.3099671Z Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)
2026-01-14T08:24:13.3108143Z Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
2026-01-14T08:24:13.3109144Z Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)
2026-01-14T08:24:13.3110014Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:13.3110774Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.6/5.6 MB[0m [31m198.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:13.3111494Z [?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number
2026-01-14T08:24:13.3112179Z   Building wheel for rouge-score (pyproject.toml) ... [?25l- done
2026-01-14T08:24:13.3113273Z [?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=5f3c0b3592da151dcc19554c275cbc6095505e73cff3f9cd8102e91eec4bd57f
2026-01-14T08:24:13.3114374Z   Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4
2026-01-14T08:24:13.3115138Z   Building wheel for sqlitedict (pyproject.toml) ... [?25l- done
2026-01-14T08:24:13.3116197Z [?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16957 sha256=7c7a740e10ccff022291bbcc8ef8176dc030bd2a815c130f2f7523873b66e7bf
2026-01-14T08:24:13.3117302Z   Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd
2026-01-14T08:24:13.3118058Z   Building wheel for word2number (pyproject.toml) ... [?25l- done
2026-01-14T08:24:13.3119128Z [?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5659 sha256=628c96a752efb57233467f42cf450e176cdc11ddeaa9cb9a5df4b99b6c178d49
2026-01-14T08:24:13.3120387Z   Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
2026-01-14T08:24:13.3121044Z Successfully built rouge-score sqlitedict word2number
2026-01-14T08:24:13.3126519Z Installing collected packages: word2number, sqlitedict, sortedcontainers, pytz, distlib, zstandard, zipp, xxhash, urllib3, tzdata, tqdm, tomli, threadpoolctl, termcolor, tcolorpy, tabulate, six, sentencepiece, safetensors, ruff, regex, pyyaml, pyparsing, pygments, pycryptodomex, pybind11, pyarrow, psutil, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, parameterized, packaging, numpy, nodeenv, ninja, multidict, more_itertools, lxml, kiwisolver, joblib, iniconfig, idna, identify, hf-xet, h11, fsspec, frozenlist, fonttools, expecttest, exceptiongroup, diskcache, dill, cycler, colorama, cmake, click, charset_normalizer, chardet, cfgv, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, virtualenv, unittest-xml-reporting, tqdm-multiprocess, scipy, sacrebleu, requests, python-dateutil, pytest, pycocotools, numexpr, nltk, multiprocess, mbstrdecoder, jsonlines, importlib_metadata, hypothesis, httpcore, fire, contourpy, blobfile, anyio, aiosignal, typepy, tiktoken, scikit-learn, rouge-score, pre-commit, pandas, matplotlib, huggingface-hub, httpx, aiohttp, tokenizers, bitsandbytes, accelerate, transformers, datasets, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval
2026-01-14T08:24:13.3132483Z [?25l
2026-01-14T08:24:13.3132936Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  4/112[0m [distlib]
2026-01-14T08:24:13.3133622Z [2K   [91m━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  7/112[0m [xxhash]
2026-01-14T08:24:13.3134295Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  9/112[0m [tzdata]
2026-01-14T08:24:13.3135122Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 18/112[0m [safetensors]
2026-01-14T08:24:13.3135818Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 20/112[0m [regex]
2026-01-14T08:24:13.3136494Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:13.3137180Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:13.3137964Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:13.3138655Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:13.3139364Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:13.3140084Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:13.3140814Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1323459Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1324176Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1324919Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1325619Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1326292Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1326975Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:20.1327903Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:24:20.1328598Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:24:20.1329298Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 35/112[0m [packaging]
2026-01-14T08:24:20.1330049Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1330914Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1331587Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1332261Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1332928Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1333620Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1334299Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1334966Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1335642Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:20.1336338Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 41/112[0m [lxml]
2026-01-14T08:24:20.1337005Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 43/112[0m [joblib]
2026-01-14T08:24:20.1337675Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:20.1338173Z [2K  Attempting uninstall: fsspec
2026-01-14T08:24:20.1338692Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:20.1339255Z [2K    Found existing installation: fsspec 2026.1.0
2026-01-14T08:24:20.1339835Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:20.1340333Z [2K    Uninstalling fsspec-2026.1.0:
2026-01-14T08:24:20.1340848Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:20.1341369Z [2K      Successfully uninstalled fsspec-2026.1.0
2026-01-14T08:24:20.1341939Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:20.1342600Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m 49/112[0m [fsspec]
2026-01-14T08:24:20.1343292Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:20.1343982Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:20.1344782Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:20.1345474Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:20.1346150Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m 55/112[0m [dill]
2026-01-14T08:24:20.1346819Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1347576Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1348241Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1348893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1349548Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1350226Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:20.1350877Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 59/112[0m [click]
2026-01-14T08:24:20.1351548Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 61/112[0m [chardet]
2026-01-14T08:24:20.1352230Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m 69/112[0m [virtualenv]
2026-01-14T08:24:20.1352933Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:20.1353600Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:20.1354261Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:20.1354927Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7307706Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7308421Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7309096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7309761Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7310769Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7311421Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7312084Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7312743Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7313569Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7314236Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7314893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7315554Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7316235Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7316886Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:27.7317555Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 76/112[0m [pytest]
2026-01-14T08:24:27.7318241Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m 77/112[0m [pycocotools]
2026-01-14T08:24:27.7318945Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:27.7319607Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:27.7320252Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:27.7320939Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m 80/112[0m [multiprocess]
2026-01-14T08:24:27.7321700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:24:27.7322659Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:24:27.7323525Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━[0m [32m 88/112[0m [blobfile]
2026-01-14T08:24:27.7324347Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7325074Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7325781Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7326499Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7327309Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7328046Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7328771Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7329471Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7330275Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7330977Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:27.7331668Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m 95/112[0m [pre-commit]
2026-01-14T08:24:27.7332345Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7333018Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7333685Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7334350Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7334999Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7335673Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7336322Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7336987Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7337652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:27.7338467Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2457604Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2458340Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2459016Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2459981Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2460657Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2461310Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2461995Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2462648Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2463311Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2463968Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:35.2464663Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2465375Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2466063Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2466740Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2467450Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2468131Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:35.2468842Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:24:35.2469575Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:24:35.2470376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m100/112[0m [aiohttp]
2026-01-14T08:24:35.2471074Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:35.2471778Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:35.2472485Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:35.2473372Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:35.2474065Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:35.2475065Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m103/112[0m [accelerate]
2026-01-14T08:24:35.2475777Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2476491Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2477186Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2477888Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2478598Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2479299Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2480002Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2480738Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2481584Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2482279Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2482977Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2483664Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2484506Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2485207Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2485895Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2486588Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2487294Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2487990Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:35.2488686Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3205974Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3206745Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3207468Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3208171Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3208900Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3209597Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3210375Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3211068Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3211784Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3212521Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3213213Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3213899Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3214970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3215676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:41.3216351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:24:41.3217214Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m106/112[0m [DataProperty]
2026-01-14T08:24:41.3217883Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m108/112[0m [peft]
2026-01-14T08:24:41.3218535Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m [32m110/112[0m [pytablewriter]
2026-01-14T08:24:41.3219167Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3219769Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3220397Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3220992Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3221590Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3222233Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3222858Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3223455Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3224050Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3224646Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3225403Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3226013Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3226611Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3227204Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3227912Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3228506Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3229110Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3229712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3230332Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:24:41.3230915Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m112/112[0m [lm_eval]
2026-01-14T08:24:41.3231308Z [?25h
2026-01-14T08:32:08.2888444Z [1A[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.3.1 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 bitsandbytes-0.49.1 blobfile-3.1.0 certifi-2026.1.4 cfgv-3.5.0 chardet-5.2.0 charset_normalizer-3.4.4 click-8.3.1 cmake-3.31.10 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.2 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 evaluate-0.4.6 exceptiongroup-1.3.1 expecttest-0.3.0 fire-0.7.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hypothesis-6.150.2 identify-2.6.16 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 joblib-1.5.3 jsonlines-4.0.0 kiwisolver-1.4.9 lm_eval-0.4.9.2 lxml-6.0.2 matplotlib-3.10.8 mbstrdecoder-1.1.4 more_itertools-10.8.0 multidict-6.7.0 multiprocess-0.70.18 ninja-1.13.0 nltk-3.9.2 nodeenv-1.10.0 numexpr-2.14.1 numpy-2.2.6 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pathvalidate-3.3.1 peft-0.18.1 pillow-12.1.0 platformdirs-4.5.1 pluggy-1.6.0 portalocker-3.2.0 pre-commit-4.5.1 propcache-0.4.1 psutil-7.2.1 pyarrow-22.0.0 pybind11-3.0.1 pycocotools-2.0.11 pycryptodomex-3.23.0 pygments-2.19.2 pyparsing-3.3.1 pytablewriter-1.2.1 pytest-8.4.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 rouge-score-0.1.2 ruff-0.11.6 sacrebleu-2.6.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 six-1.17.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 termcolor-3.3.0 threadpoolctl-3.6.0 tiktoken-0.12.0 tokenizers-0.22.2 tomli-2.4.0 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.57.5 typepy-1.3.4 tzdata-2025.3 unittest-xml-reporting-4.0.0 urllib3-2.6.3 virtualenv-20.36.1 word2number-1.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0
2026-01-14T08:32:08.2898075Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:08.2899876Z [0m+ pip install . --no-build-isolation
2026-01-14T08:32:08.2900196Z Processing /pytorch/ao
2026-01-14T08:32:08.2900568Z   Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:32:08.2901049Z [?25hBuilding wheels for collected packages: torchao
2026-01-14T08:32:08.2901768Z   Building wheel for torchao (pyproject.toml) ... [?25l- \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:32:08.2903456Z [?25h  Created wheel for torchao: filename=torchao-0.16.0+gitb34f898-cp310-abi3-linux_x86_64.whl size=4857329 sha256=89be2322432cd3425e9723b8b0f5062d773c35956a44b2c95025edf7b56c3bc8
2026-01-14T08:32:08.2904751Z   Stored in directory: /tmp/pip-ephem-wheel-cache-r9ry3szs/wheels/d2/8b/29/aa26bc7679794c5ecae292c3b064b585980cbedb836e694414
2026-01-14T08:32:08.2905441Z Successfully built torchao
2026-01-14T08:32:08.2905727Z Installing collected packages: torchao
2026-01-14T08:32:08.2906071Z Successfully installed torchao-0.16.0+gitb34f898
2026-01-14T08:32:08.2908267Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:08.2910020Z [0m++++ which conda
2026-01-14T08:32:08.2910262Z +++ dirname /opt/conda/condabin/conda
2026-01-14T08:32:08.2910565Z ++ dirname /opt/conda/condabin
2026-01-14T08:32:08.2910840Z + export CONDA=/opt/conda
2026-01-14T08:32:08.2911085Z + CONDA=/opt/conda
2026-01-14T08:32:08.2911604Z + export LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:08.2912470Z + LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:08.2913047Z + pytest test --verbose -s
2026-01-14T08:32:08.2913464Z [1m============================= test session starts ==============================[0m
2026-01-14T08:32:08.2914087Z platform linux -- Python 3.10.19, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/envs/venv/bin/python3.10
2026-01-14T08:32:08.2914617Z cachedir: .pytest_cache
2026-01-14T08:32:08.2915269Z hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
2026-01-14T08:32:08.2915966Z rootdir: /pytorch/ao
2026-01-14T08:32:08.2916214Z configfile: pyproject.toml
2026-01-14T08:32:08.2916509Z plugins: hypothesis-6.150.2, anyio-4.12.1
2026-01-14T08:32:08.2916860Z [1mcollecting ... [0m[1m
2026-01-14T08:32:08.2917292Z collecting 0 items                                                             [0m[1m
2026-01-14T08:32:08.2917871Z collecting 28 items                                                            [0m[1m
2026-01-14T08:32:08.2918455Z collecting 28 items                                                            [0m[1m
2026-01-14T08:32:08.2919037Z collecting 177 items                                                           [0m[1m
2026-01-14T08:32:08.2919665Z collecting 872 items / 3 skipped                                               [0m[1m
2026-01-14T08:32:08.2920312Z collecting 927 items / 5 skipped                                               [0m[1m
2026-01-14T08:32:08.2920968Z collecting 1011 items / 24 skipped                                             [0m[1m
2026-01-14T08:32:08.2930869Z collecting 2573 items / 24 skipped                                             [0m[1m
2026-01-14T08:32:08.2931704Z collecting 3991 items / 24 skipped                                             [0m[1m
2026-01-14T08:32:08.2932365Z collected 5946 items / 24 skipped                                              [0m
2026-01-14T08:32:08.2932713Z 
2026-01-14T08:32:08.2933141Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config0] [32mPASSED[0m
2026-01-14T08:32:08.2933971Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config1] [32mPASSED[0m
2026-01-14T08:32:08.2934792Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config2] [32mPASSED[0m
2026-01-14T08:32:08.2935595Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config3] [32mPASSED[0m
2026-01-14T08:32:08.2936402Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config4] [32mPASSED[0m
2026-01-14T08:32:08.2937213Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5] [32mPASSED[0m
2026-01-14T08:32:08.2938138Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config6] [32mPASSED[0m
2026-01-14T08:32:08.2938959Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7] [32mPASSED[0m
2026-01-14T08:32:08.2939763Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config8] [32mPASSED[0m
2026-01-14T08:32:08.2940575Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config9] [32mPASSED[0m
2026-01-14T08:32:08.2941478Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config10] [32mPASSED[0m
2026-01-14T08:32:08.2942297Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config11] [32mPASSED[0m
2026-01-14T08:32:08.2943135Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config12] [32mPASSED[0m
2026-01-14T08:32:08.2943951Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13] [32mPASSED[0m
2026-01-14T08:32:08.2944773Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14] [32mPASSED[0m
2026-01-14T08:32:08.2945582Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config15] [32mPASSED[0m
2026-01-14T08:32:08.2946397Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config16] [32mPASSED[0m
2026-01-14T08:32:08.2947209Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config17] [32mPASSED[0m
2026-01-14T08:32:08.2948026Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config18] [32mPASSED[0m
2026-01-14T08:32:08.2948853Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config19] [32mPASSED[0m
2026-01-14T08:32:08.2949665Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config20] [32mPASSED[0m
2026-01-14T08:32:08.2950486Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config21] [32mPASSED[0m
2026-01-14T08:32:08.2951279Z test/core/test_config.py::test_granularity_serialization[granularity0] [33mSKIPPED[0m
2026-01-14T08:32:08.2952046Z test/core/test_config.py::test_granularity_serialization[granularity1] [33mSKIPPED[0m
2026-01-14T08:32:08.2952814Z test/core/test_config.py::test_granularity_serialization[granularity2] [33mSKIPPED[0m
2026-01-14T08:32:08.2953480Z test/core/test_config.py::test_disallowed_modules [32mPASSED[0m
2026-01-14T08:32:08.2954052Z test/core/test_config.py::test_version_mismatch [32mPASSED[0m
2026-01-14T08:32:08.2954614Z test/core/test_config.py::test_default_version [32mPASSED[0m
2026-01-14T08:32:08.2955456Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:08.2958880Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:08.2959943Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:08.2961002Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:08.2962057Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:08.7565605Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module [32mPASSED[0m
2026-01-14T08:32:08.7566842Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_register_new_dispatch [32mPASSED[0m
2026-01-14T08:32:08.7567833Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_tensor_core_layout_transpose [32mPASSED[0m
2026-01-14T08:32:08.7569023Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:08.7570089Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:08.7571382Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:08.7572497Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:08.7573509Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:08.7574519Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_affine_quantized_intx_static [32mPASSED[0m
2026-01-14T08:32:08.7575964Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:08.7577135Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:08.7578058Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:08.7578984Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:08.7579874Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only [32mPASSED[0m
2026-01-14T08:32:08.7580804Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7581828Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7583088Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7584257Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7585366Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_matmul_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7586354Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_mm_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7587603Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_and_copy_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7588694Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:08.7589925Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_float16 [33mSKIPPED[0m
2026-01-14T08:32:08.7590978Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7592212Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7593600Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_float32 [32mPASSED[0m
2026-01-14T08:32:08.7595176Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_bfloat16 [32mPASSED[0m
2026-01-14T08:32:08.7596737Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_float32 [32mPASSED[0m
2026-01-14T08:32:08.7598192Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:08.7599680Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:08.7601175Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:08.7602670Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:08.7604305Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:08.7605795Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:08.7607276Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:08.7608865Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:08.7610428Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:08.7611895Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:08.7613375Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:08.7614860Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:08.7616570Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:08.7618071Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:08.7619749Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:08.7621219Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:08.7622627Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_scale_broadcasting [32mPASSED[0m
2026-01-14T08:32:08.7623960Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity0 [33mSKIPPED[0m
2026-01-14T08:32:08.7625271Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity1 [33mSKIPPED[0m
2026-01-14T08:32:08.7626759Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:08.7628402Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:08.7630053Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:08.7631699Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:08.7633333Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:08.7634974Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:08.7636613Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:08.7638561Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:08.7640389Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:08.7642030Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:08.7643804Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:00.9634943Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:00.9637328Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:00.9638996Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:00.9640614Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:33:00.9642242Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:33:00.9643591Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_invalid_granularity [32mPASSED[0m
2026-01-14T08:33:00.9644743Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_mismatched_granularity [32mPASSED[0m
2026-01-14T08:33:00.9645881Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_per_row_with_float32 [33mSKIPPED[0m
2026-01-14T08:33:00.9647051Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_preprocess_scale_3d_reshape [32mPASSED[0m
2026-01-14T08:33:00.9648340Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:00.9649281Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:00.9649699Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:33:00.9650330Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:00.9650830Z graph_break []
2026-01-14T08:33:00.9651068Z aten_mm_info []
2026-01-14T08:33:00.9651331Z [32mPASSED[0m
2026-01-14T08:33:00.9652146Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:00.9653073Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:00.9653601Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:00.9654158Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:33:00.9654523Z graph_break []
2026-01-14T08:33:00.9654733Z aten_mm_info []
2026-01-14T08:33:00.9654967Z [32mPASSED[0m
2026-01-14T08:33:00.9655770Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:00.9656692Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:00.9657230Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:00.9658201Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:33:00.9658574Z graph_break []
2026-01-14T08:33:00.9658779Z aten_mm_info []
2026-01-14T08:33:00.9659030Z [32mPASSED[0m
2026-01-14T08:33:00.9659826Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:33:00.9660744Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:33:00.9661493Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:00.9662052Z inductor [('extern_calls', 4), ('fxgraph_cache_miss', 2)]
2026-01-14T08:33:00.9662417Z graph_break []
2026-01-14T08:33:00.9662620Z aten_mm_info []
2026-01-14T08:33:00.9662867Z [32mPASSED[0m
2026-01-14T08:33:00.9663575Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_serialization_mode_static [33mSKIPPED[0m
2026-01-14T08:33:00.9664752Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_unsupported_granularity [32mPASSED[0m
2026-01-14T08:33:00.9666962Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_bfloat16 /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9668784Z   warnings.warn(
2026-01-14T08:33:00.9669981Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9671306Z   warnings.warn(
2026-01-14T08:33:00.9672507Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9673764Z   warnings.warn(
2026-01-14T08:33:00.9675142Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9676411Z   warnings.warn(
2026-01-14T08:33:00.9676654Z [32mPASSED[0m
2026-01-14T08:33:00.9678359Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float16 /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9680141Z   warnings.warn(
2026-01-14T08:33:00.9681384Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9682649Z   warnings.warn(
2026-01-14T08:33:00.9683830Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9685092Z   warnings.warn(
2026-01-14T08:33:00.9686277Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9687674Z   warnings.warn(
2026-01-14T08:33:00.9687929Z [32mPASSED[0m
2026-01-14T08:33:00.9689635Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float32 /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9691620Z   warnings.warn(
2026-01-14T08:33:00.9692807Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9694072Z   warnings.warn(
2026-01-14T08:33:00.9695254Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9696509Z   warnings.warn(
2026-01-14T08:33:00.9697688Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:00.9698956Z   warnings.warn(
2026-01-14T08:33:00.9699202Z [32mPASSED[0m
2026-01-14T08:33:00.9699928Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt4woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:00.9701153Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestGemliteLayoutTensorParallel::test_tp_gemlite_float16 [33mSKIPPED[0m
2026-01-14T08:33:00.9702368Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8dqAffineQuantizedTensorParallel::test_tp_bfloat16 [32mPASSED[0m
2026-01-14T08:33:00.9703254Z test/dtypes/test_bitpacking.py::test_CPU[0-1] [32mPASSED[0m
2026-01-14T08:33:00.9703808Z test/dtypes/test_bitpacking.py::test_CPU[0-2] [32mPASSED[0m
2026-01-14T08:33:00.9704346Z test/dtypes/test_bitpacking.py::test_CPU[0-3] [32mPASSED[0m
2026-01-14T08:33:00.9704875Z test/dtypes/test_bitpacking.py::test_CPU[0-4] [32mPASSED[0m
2026-01-14T08:33:00.9705423Z test/dtypes/test_bitpacking.py::test_CPU[0-5] [32mPASSED[0m
2026-01-14T08:33:00.9705949Z test/dtypes/test_bitpacking.py::test_CPU[0-6] [32mPASSED[0m
2026-01-14T08:33:00.9706483Z test/dtypes/test_bitpacking.py::test_CPU[0-7] [32mPASSED[0m
2026-01-14T08:33:00.9707018Z test/dtypes/test_bitpacking.py::test_CPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:00.9707561Z test/dtypes/test_bitpacking.py::test_CPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:00.9708102Z test/dtypes/test_bitpacking.py::test_CPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:04.7142388Z test/dtypes/test_bitpacking.py::test_CPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:04.7143238Z test/dtypes/test_bitpacking.py::test_CPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:04.7145065Z test/dtypes/test_bitpacking.py::test_CPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:04.7145825Z test/dtypes/test_bitpacking.py::test_CPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:04.7146483Z test/dtypes/test_bitpacking.py::test_CPU[1-1] [32mPASSED[0m
2026-01-14T08:33:04.7147156Z test/dtypes/test_bitpacking.py::test_CPU[1-2] [32mPASSED[0m
2026-01-14T08:33:04.7147838Z test/dtypes/test_bitpacking.py::test_CPU[1-3] [32mPASSED[0m
2026-01-14T08:33:04.7148482Z test/dtypes/test_bitpacking.py::test_CPU[1-4] [32mPASSED[0m
2026-01-14T08:33:04.7149136Z test/dtypes/test_bitpacking.py::test_CPU[1-5] [32mPASSED[0m
2026-01-14T08:33:04.7149778Z test/dtypes/test_bitpacking.py::test_CPU[1-6] [32mPASSED[0m
2026-01-14T08:33:04.7150420Z test/dtypes/test_bitpacking.py::test_CPU[1-7] [32mPASSED[0m
2026-01-14T08:33:04.7151053Z test/dtypes/test_bitpacking.py::test_GPU[0-1] [32mPASSED[0m
2026-01-14T08:33:04.7152205Z test/dtypes/test_bitpacking.py::test_GPU[0-2] [32mPASSED[0m
2026-01-14T08:33:04.7152865Z test/dtypes/test_bitpacking.py::test_GPU[0-3] [32mPASSED[0m
2026-01-14T08:33:04.7153503Z test/dtypes/test_bitpacking.py::test_GPU[0-4] [32mPASSED[0m
2026-01-14T08:33:04.7154144Z test/dtypes/test_bitpacking.py::test_GPU[0-5] [32mPASSED[0m
2026-01-14T08:33:04.7154776Z test/dtypes/test_bitpacking.py::test_GPU[0-6] [32mPASSED[0m
2026-01-14T08:33:04.7155618Z test/dtypes/test_bitpacking.py::test_GPU[0-7] [32mPASSED[0m
2026-01-14T08:33:04.7156266Z test/dtypes/test_bitpacking.py::test_GPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:04.7156919Z test/dtypes/test_bitpacking.py::test_GPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:04.7157578Z test/dtypes/test_bitpacking.py::test_GPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:04.7158260Z test/dtypes/test_bitpacking.py::test_GPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:04.7158919Z test/dtypes/test_bitpacking.py::test_GPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:04.7159574Z test/dtypes/test_bitpacking.py::test_GPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:04.7160230Z test/dtypes/test_bitpacking.py::test_GPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:04.7160902Z test/dtypes/test_bitpacking.py::test_GPU[1-1] [32mPASSED[0m
2026-01-14T08:33:04.7161553Z test/dtypes/test_bitpacking.py::test_GPU[1-2] [32mPASSED[0m
2026-01-14T08:33:04.7162236Z test/dtypes/test_bitpacking.py::test_GPU[1-3] [32mPASSED[0m
2026-01-14T08:33:04.7162912Z test/dtypes/test_bitpacking.py::test_GPU[1-4] [32mPASSED[0m
2026-01-14T08:33:04.7163588Z test/dtypes/test_bitpacking.py::test_GPU[1-5] [32mPASSED[0m
2026-01-14T08:33:04.7164256Z test/dtypes/test_bitpacking.py::test_GPU[1-6] [32mPASSED[0m
2026-01-14T08:33:04.7164924Z test/dtypes/test_bitpacking.py::test_GPU[1-7] [32mPASSED[0m
2026-01-14T08:33:04.7165612Z test/dtypes/test_bitpacking.py::test_compile[0-1] [32mPASSED[0m
2026-01-14T08:33:04.7166340Z test/dtypes/test_bitpacking.py::test_compile[0-2] [32mPASSED[0m
2026-01-14T08:33:04.7167084Z test/dtypes/test_bitpacking.py::test_compile[0-3] [32mPASSED[0m
2026-01-14T08:33:04.7167831Z test/dtypes/test_bitpacking.py::test_compile[0-4] [32mPASSED[0m
2026-01-14T08:33:04.7168607Z test/dtypes/test_bitpacking.py::test_compile[0-5] [32mPASSED[0m
2026-01-14T08:33:04.7169362Z test/dtypes/test_bitpacking.py::test_compile[0-6] [32mPASSED[0m
2026-01-14T08:33:04.7170243Z test/dtypes/test_bitpacking.py::test_compile[0-7] [32mPASSED[0m
2026-01-14T08:33:04.7171017Z test/dtypes/test_bitpacking.py::test_compile[-1-1] [32mPASSED[0m
2026-01-14T08:33:04.7171790Z test/dtypes/test_bitpacking.py::test_compile[-1-2] [32mPASSED[0m
2026-01-14T08:33:04.7172569Z test/dtypes/test_bitpacking.py::test_compile[-1-3] [32mPASSED[0m
2026-01-14T08:33:04.7173324Z test/dtypes/test_bitpacking.py::test_compile[-1-4] [32mPASSED[0m
2026-01-14T08:33:04.7174122Z test/dtypes/test_bitpacking.py::test_compile[-1-5] [32mPASSED[0m
2026-01-14T08:33:04.7175155Z test/dtypes/test_bitpacking.py::test_compile[-1-6] [32mPASSED[0m
2026-01-14T08:33:04.7175926Z test/dtypes/test_bitpacking.py::test_compile[-1-7] [32mPASSED[0m
2026-01-14T08:33:04.7176742Z test/dtypes/test_bitpacking.py::test_compile[1-1] [32mPASSED[0m
2026-01-14T08:33:04.7177566Z test/dtypes/test_bitpacking.py::test_compile[1-2] [32mPASSED[0m
2026-01-14T08:33:04.7178390Z test/dtypes/test_bitpacking.py::test_compile[1-3] [32mPASSED[0m
2026-01-14T08:33:04.7179205Z test/dtypes/test_bitpacking.py::test_compile[1-4] [32mPASSED[0m
2026-01-14T08:33:04.7180043Z test/dtypes/test_bitpacking.py::test_compile[1-5] [32mPASSED[0m
2026-01-14T08:33:04.7180866Z test/dtypes/test_bitpacking.py::test_compile[1-6] [32mPASSED[0m
2026-01-14T08:33:04.7181641Z test/dtypes/test_bitpacking.py::test_compile[1-7] [32mPASSED[0m
2026-01-14T08:33:04.7182745Z test/dtypes/test_bitpacking.py::test_pack_example tensor([  0, 105, 151,  37], device='cuda:0', dtype=torch.uint8) tensor([ 39, 146], device='cuda:0', dtype=torch.uint8)
2026-01-14T08:33:04.7183750Z [32mPASSED[0m
2026-01-14T08:33:04.7184655Z test/dtypes/test_bitpacking.py::test_pack_example_CPU tensor([  0, 105, 151,  37], dtype=torch.uint8) tensor([ 39, 146], dtype=torch.uint8)
2026-01-14T08:33:04.7185505Z [32mPASSED[0m
2026-01-14T08:33:04.7186115Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:33:04.7187056Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:33:04.7188130Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:33:04.7189218Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7190408Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7191596Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7192788Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7193980Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7195163Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7196332Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7197524Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7198699Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7199874Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7201059Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7202223Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7203391Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7204561Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7205740Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7206912Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:04.7208079Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:04.7209257Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:04.7210371Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size0 [32mPASSED[0m
2026-01-14T08:33:04.7211231Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size1 [32mPASSED[0m
2026-01-14T08:33:04.7212198Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:33:04.7213149Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float16 [32mPASSED[0m
2026-01-14T08:33:04.7214112Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float32 [32mPASSED[0m
2026-01-14T08:33:04.7215064Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:33:04.7216030Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float16 [32mPASSED[0m
2026-01-14T08:33:04.7216986Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float32 [32mPASSED[0m
2026-01-14T08:33:04.7218032Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_bfloat16 [32mPASSED[0m
2026-01-14T08:33:04.7218983Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float16 [32mPASSED[0m
2026-01-14T08:33:04.7219917Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float32 [32mPASSED[0m
2026-01-14T08:33:04.7220837Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:04.7221851Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float16 [33mSKIPPED[0m
2026-01-14T08:33:04.7222723Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float32 [33mSKIPPED[0m
2026-01-14T08:33:04.7223620Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:33:04.7224524Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:33:04.7225432Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:33:04.7226338Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_False [32mPASSED[0m
2026-01-14T08:33:04.7227241Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_True [32mPASSED[0m
2026-01-14T08:33:04.7228217Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:04.7229241Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float16 [33mSKIPPED[0m
2026-01-14T08:33:04.7230270Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float32 [33mSKIPPED[0m
2026-01-14T08:33:04.7231241Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_bfloat16 [32mPASSED[0m
2026-01-14T08:33:11.7767535Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float16 [32mPASSED[0m
2026-01-14T08:33:11.7768555Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float32 [32mPASSED[0m
2026-01-14T08:33:11.7769505Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_bfloat16 [32mPASSED[0m
2026-01-14T08:33:11.7770536Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:11.7771715Z   triton_mm_10 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:33:11.7773034Z   triton_mm_0 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:33:11.7774357Z   triton_mm_1 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7775876Z   triton_mm_2 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7777179Z   triton_mm_4 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7778474Z   triton_mm_5 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7779771Z   triton_mm_6 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7781068Z   triton_mm_7 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:33:11.7782354Z   triton_mm_9 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:33:11.7783661Z   triton_mm_11 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:33:11.7785372Z SingleProcess AUTOTUNE benchmarking takes 0.4186 seconds and 0.3224 seconds precompiling for 13 choices
2026-01-14T08:33:11.7786116Z [32mPASSED[0m
2026-01-14T08:33:11.7786701Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float16 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:11.7787849Z   triton_mm_17 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7789351Z   triton_mm_18 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7790660Z   triton_mm_14 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7791965Z   triton_mm_15 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:33:11.7793264Z   triton_mm_16 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7794563Z   triton_mm_19 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:33:11.7795922Z   triton_mm_20 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:33:11.7797270Z   triton_mm_22 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:33:11.7798566Z   triton_mm_23 0.0225 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:33:11.7799921Z   triton_mm_12 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:33:11.7801301Z SingleProcess AUTOTUNE benchmarking takes 0.3661 seconds and 0.2480 seconds precompiling for 13 choices
2026-01-14T08:33:11.7803051Z [32mPASSED[0m
2026-01-14T08:33:11.7803687Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float32 AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:11.7805164Z   triton_mm_30 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7806856Z   triton_mm_32 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:33:11.7808425Z   triton_mm_26 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7809865Z   triton_mm_28 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:33:11.7811203Z   triton_mm_29 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7812525Z   triton_mm_31 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:33:11.7813843Z   triton_mm_33 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:33:11.7815225Z   triton_mm_35 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:33:11.7816669Z   triton_mm_25 0.0215 ms 90.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:33:11.7817987Z   triton_mm_24 0.0225 ms 86.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:33:11.7819171Z SingleProcess AUTOTUNE benchmarking takes 0.2390 seconds and 0.1749 seconds precompiling for 13 choices
2026-01-14T08:33:11.7819916Z [32mPASSED[0m
2026-01-14T08:33:11.7820604Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float16 [32mPASSED[0m
2026-01-14T08:33:11.7821506Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float32 [32mPASSED[0m
2026-01-14T08:33:11.7822370Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16 [32mPASSED[0m
2026-01-14T08:33:11.7823181Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_device [32mPASSED[0m
2026-01-14T08:33:11.7823972Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16 [32mPASSED[0m
2026-01-14T08:33:11.7824783Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32 [32mPASSED[0m
2026-01-14T08:33:11.7825587Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_bfloat16 [32mPASSED[0m
2026-01-14T08:33:11.7826406Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float16 [32mPASSED[0m
2026-01-14T08:33:11.7827216Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float32 [32mPASSED[0m
2026-01-14T08:33:11.7827978Z test/dtypes/test_nf4.py::TestFSDPOps::test_pin_memory [32mPASSED[0m
2026-01-14T08:33:11.7828834Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_2d_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:33:11.7829816Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:33:11.7830835Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:33:11.7831832Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size1 [32mPASSED[0m
2026-01-14T08:33:11.7832820Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size2 [32mPASSED[0m
2026-01-14T08:33:11.7833844Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:33:11.7834814Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size1 [32mPASSED[0m
2026-01-14T08:33:11.7835719Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size2 [32mPASSED[0m
2026-01-14T08:33:11.7836654Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size_262144 [32mPASSED[0m
2026-01-14T08:33:11.7837632Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:33:11.7838630Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size2 [32mPASSED[0m
2026-01-14T08:33:11.7839652Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size_262144 [32mPASSED[0m
2026-01-14T08:33:11.7840669Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size1 [32mPASSED[0m
2026-01-14T08:33:11.7841636Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size2 [32mPASSED[0m
2026-01-14T08:33:11.7842644Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:33:11.7843594Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_1d_invalid [32mPASSED[0m
2026-01-14T08:33:11.7844504Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_2d_invalid [32mPASSED[0m
2026-01-14T08:33:11.7845403Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.9472930Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.9476639Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.9477528Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.9478672Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.9479451Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.9480124Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cpu [32mPASSED[0m
2026-01-14T08:35:33.9480708Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cuda [32mPASSED[0m
2026-01-14T08:35:33.9481487Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_module [32mPASSED[0m
2026-01-14T08:35:33.9482195Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_3d_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.9483029Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.9483871Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.9484748Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size_261632 [32mPASSED[0m
2026-01-14T08:35:33.9485576Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.9486337Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.9487125Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.9487776Z test/dtypes/test_nf4.py::TestQLoRA::test_qlora_fsdp2 dist init r=1, world=2
2026-01-14T08:35:33.9488225Z dist init r=0, world=2
2026-01-14T08:35:33.9489208Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:35:33.9490348Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.9491363Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:35:33.9492398Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.9492712Z [32mPASSED[0m
2026-01-14T08:35:33.9493043Z test/dtypes/test_nf4.py::TestComm::test_comm dist init r=1, world=2
2026-01-14T08:35:33.9493459Z dist init r=0, world=2
2026-01-14T08:35:33.9494421Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:35:33.9495470Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.9496481Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:35:33.9497510Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.9497820Z [32mPASSED[0m
2026-01-14T08:35:33.9498342Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9499171Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9499996Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9500802Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9501619Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9502425Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9503239Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9504050Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9504952Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9505769Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9506621Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9507436Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9508325Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9509126Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9509941Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9510760Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9511581Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9512399Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9513216Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9514039Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9514855Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9515671Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9516494Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9517314Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9518109Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9518903Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9519694Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9520479Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9521276Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9522078Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9522862Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9523655Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9524442Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9525239Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9526023Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9526825Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9527634Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9528438Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9529238Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9530080Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9530880Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9531682Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9532583Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9533419Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9534244Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9535160Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9535992Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9536813Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9537642Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9538464Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9539297Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9540126Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.9540951Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.9541782Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.9542613Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.9543439Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.9544284Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.9545119Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.9545997Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7526665Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7527564Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7528594Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7531011Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7531913Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7532667Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7533415Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7534165Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7534908Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7535646Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7536392Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7537140Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7537892Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7538641Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7539378Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7540124Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7541257Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7542013Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7542769Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7543518Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7544485Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7545233Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7545993Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7546752Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7547495Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7548271Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7549046Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7549822Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7550610Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7551395Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7552166Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7552950Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7553768Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7554551Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7555327Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7556093Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7556870Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7557645Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7558417Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7559201Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7559982Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7560767Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7561556Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7562340Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7563122Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7563905Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7564625Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7565263Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7565907Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7566543Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7567181Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7567914Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7568548Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7569229Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7570008Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7570811Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7571514Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7572217Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7572911Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7573663Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7574332Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype0] [32mPASSED[0m
2026-01-14T08:35:56.7575137Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype1] [32mPASSED[0m
2026-01-14T08:35:56.7575759Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype2] [32mPASSED[0m
2026-01-14T08:35:56.7576386Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype3] [32mPASSED[0m
2026-01-14T08:35:56.7577010Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype4] [32mPASSED[0m
2026-01-14T08:35:56.7577638Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype5] [32mPASSED[0m
2026-01-14T08:35:56.7578262Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype6] [32mPASSED[0m
2026-01-14T08:35:56.7578872Z test/dtypes/test_uintx.py::test_uintx_api_deprecation [32mPASSED[0m
2026-01-14T08:35:56.7579783Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims0-valid.layer-filter_fqns0-True] [32mPASSED[0m
2026-01-14T08:35:56.7580995Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims1-skip_layer.linear-filter_fqns1-False] [32mPASSED[0m
2026-01-14T08:35:56.7582192Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims2-valid.layer-filter_fqns2-False] [32mPASSED[0m
2026-01-14T08:35:56.7583345Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims3-valid.layer-filter_fqns3-True] [32mPASSED[0m
2026-01-14T08:35:56.7584521Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims4-skip_layer.linear-filter_fqns4-False] [32mPASSED[0m
2026-01-14T08:35:56.7585691Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims5-valid.layer-filter_fqns5-False] [32mPASSED[0m
2026-01-14T08:35:56.7586625Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_rowwise [32mPASSED[0m
2026-01-14T08:35:56.7587394Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_tensorwise [32mPASSED[0m
2026-01-14T08:35:56.7588106Z test/float8/test_auto_filter.py::test_partial_fqn_matching [32mPASSED[0m
2026-01-14T08:35:56.7588829Z test/float8/test_base.py::TestFloat8TrainingTensor::test_preserves_dtype [32mPASSED[0m
2026-01-14T08:35:56.7589659Z test/float8/test_base.py::TestFloat8TrainingTensor::test_differentiable_casts [32mPASSED[0m
2026-01-14T08:35:56.7590438Z test/float8/test_base.py::TestFloat8TrainingTensor::test_split_cat [32mPASSED[0m
2026-01-14T08:35:56.7591158Z test/float8/test_base.py::TestFloat8TrainingTensor::test_index_put [32mPASSED[0m
2026-01-14T08:35:56.7591867Z test/float8/test_base.py::TestFloat8TrainingTensor::test_copy_ [32mPASSED[0m
2026-01-14T08:35:56.7592567Z test/float8/test_base.py::TestFloat8TrainingTensor::test_transpose [32mPASSED[0m
2026-01-14T08:35:56.7593437Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape0] [32mPASSED[0m
2026-01-14T08:35:56.7594430Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape1] [32mPASSED[0m
2026-01-14T08:35:56.7595557Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape2] [32mPASSED[0m
2026-01-14T08:35:56.7596556Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape0] [32mPASSED[0m
2026-01-14T08:35:56.7597549Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape1] [32mPASSED[0m
2026-01-14T08:35:56.7598543Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape2] [32mPASSED[0m
2026-01-14T08:35:56.7599662Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape0] [32mPASSED[0m
2026-01-14T08:35:56.9843728Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape1] [32mPASSED[0m
2026-01-14T08:35:56.9844765Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape2] [32mPASSED[0m
2026-01-14T08:35:56.9845781Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape0] [32mPASSED[0m
2026-01-14T08:35:56.9846804Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape1] [32mPASSED[0m
2026-01-14T08:35:56.9847812Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape2] [32mPASSED[0m
2026-01-14T08:35:56.9848708Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_reshape [32mPASSED[0m
2026-01-14T08:35:56.9849973Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:35:56.9851498Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:35:56.9853056Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:35:56.9854592Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:35:56.9856138Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:35:56.9857679Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:35:56.9859227Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:35:56.9860763Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:35:56.9862309Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:35:56.9863435Z test/float8/test_base.py::TestFloat8TrainingTensor::test_fp8_dtype [32mPASSED[0m
2026-01-14T08:35:56.9864794Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9866699Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9868611Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9870509Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9872562Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9874466Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9876762Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9878648Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9880547Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9882430Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9884368Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9886256Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9888133Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9890074Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9891961Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9893851Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9895743Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9897641Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9899517Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9901398Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9903330Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9905199Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:35:56.9907212Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:35:56.9909095Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:35:56.9910695Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:56.9912229Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:56.9913630Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:56.9915030Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:56.9916445Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:56.9917844Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:56.9919262Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:56.9920690Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:56.9922096Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5069178Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5070624Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5072042Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5073489Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5075227Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5076656Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5078061Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5079467Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5080865Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5082277Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5083696Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5085101Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5086679Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5088102Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5089512Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5091102Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5092498Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5093960Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5095362Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5096752Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5098164Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5099567Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5100975Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5102388Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5103855Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5105261Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:35:57.5106678Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:35:57.5108046Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:35:57.5109330Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:35:57.5110617Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:35:57.5111876Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:35:57.5113119Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:35:57.5114365Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:35:57.5115658Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:35:57.5116998Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:35:57.5118424Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:35:57.5119390Z test/float8/test_base.py::TestFloat8Linear::test_repr [32mPASSED[0m
2026-01-14T08:35:57.5120057Z test/float8/test_base.py::TestFloat8Linear::test_inference_mode [33mSKIPPED[0m
2026-01-14T08:35:57.5120763Z test/float8/test_base.py::TestFloat8Linear::test_quantize [33mSKIPPED[0m (C...)
2026-01-14T08:35:57.5121655Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:35:57.5122537Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:35:57.5123470Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:35:57.5124362Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:35:57.5125256Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:35:57.5126152Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:35:57.5126964Z test/float8/test_base.py::TestScaledMM::test_different_configs_error [33mSKIPPED[0m
2026-01-14T08:35:57.5127753Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:35:57.5128577Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:35:57.5129384Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:35:57.5130253Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:35:57.5131071Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:35:57.5131895Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:35:57.5132707Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype0] [32mPASSED[0m
2026-01-14T08:35:57.5133554Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype1] [32mPASSED[0m
2026-01-14T08:35:57.5134395Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype2] [32mPASSED[0m
2026-01-14T08:35:57.5135210Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype3] [32mPASSED[0m
2026-01-14T08:35:57.5136033Z test/float8/test_base.py::TestFloat8LinearUtils::test_fp8_tensor_statistics [32mPASSED[0m
2026-01-14T08:35:57.5136872Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_linears_with_filters [32mPASSED[0m
2026-01-14T08:35:57.5137681Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear [32mPASSED[0m
2026-01-14T08:35:57.5138558Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear_with_children_raises [32mPASSED[0m
2026-01-14T08:35:57.5139452Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears [32mPASSED[0m
2026-01-14T08:35:57.5140332Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears_with_skip [32mPASSED[0m
2026-01-14T08:35:57.5141513Z test/float8/test_compile.py::test_eager_only[dtype0-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:35:57.5142928Z test/float8/test_compile.py::test_eager_only[dtype1-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:36:09.4035013Z test/float8/test_compile.py::test_aot_eager[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:36:09.4037413Z test/float8/test_compile.py::test_aot_eager[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:36:09.4039277Z test/float8/test_compile.py::test_inductor_from_config_params[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:36:09.4040898Z test/float8/test_compile.py::test_inductor_from_config_params[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:36:09.4042175Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:36:09.4043361Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:36:09.4044267Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_input [33mSKIPPED[0m
2026-01-14T08:36:09.4045050Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_output [33mSKIPPED[0m
2026-01-14T08:36:09.4045913Z test/float8/test_compile.py::TestGraphBreaks::test_float8_with_graph_break_in_the_middle [33mSKIPPED[0m
2026-01-14T08:36:09.4046791Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype0] [33mSKIPPED[0m
2026-01-14T08:36:09.4047623Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype1] [33mSKIPPED[0m
2026-01-14T08:36:09.4048433Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype2] [33mSKIPPED[0m
2026-01-14T08:36:09.4049251Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype0] [33mSKIPPED[0m
2026-01-14T08:36:09.4050147Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype1] [33mSKIPPED[0m
2026-01-14T08:36:09.4050969Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype2] [33mSKIPPED[0m
2026-01-14T08:36:09.4051860Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case0] [32mPASSED[0m
2026-01-14T08:36:09.4052805Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case1] [32mPASSED[0m
2026-01-14T08:36:09.4053746Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case2] [32mPASSED[0m
2026-01-14T08:36:09.4054688Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case3] [32mPASSED[0m
2026-01-14T08:36:09.4055631Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case4] [32mPASSED[0m
2026-01-14T08:36:09.4056574Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case5] [32mPASSED[0m
2026-01-14T08:36:09.4057518Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case6] [32mPASSED[0m
2026-01-14T08:36:09.4058455Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case7] [32mPASSED[0m
2026-01-14T08:36:09.4059295Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype0] [32mPASSED[0m
2026-01-14T08:36:09.4060058Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype1] [32mPASSED[0m
2026-01-14T08:36:09.4060825Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype2] [32mPASSED[0m
2026-01-14T08:36:09.4061578Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype3] [32mPASSED[0m
2026-01-14T08:36:09.4062333Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype4] [32mPASSED[0m
2026-01-14T08:36:09.4063080Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype5] [32mPASSED[0m
2026-01-14T08:36:09.4063853Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype6] [32mPASSED[0m
2026-01-14T08:36:09.4064609Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype7] [32mPASSED[0m
2026-01-14T08:36:09.4073965Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_config_params[ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC] [33mSKIPPED[0m
2026-01-14T08:36:09.4076230Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:36:09.4077872Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:36:09.4078973Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_2bit [32mPASSED[0m
2026-01-14T08:36:09.4079606Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_3bit [32mPASSED[0m
2026-01-14T08:36:09.4080368Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_4bit [32mPASSED[0m
2026-01-14T08:36:09.4080991Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_5bit [32mPASSED[0m
2026-01-14T08:36:09.4081621Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_6bit [32mPASSED[0m
2026-01-14T08:36:09.4082243Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_7bit [32mPASSED[0m
2026-01-14T08:36:09.4082873Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_8bit [32mPASSED[0m
2026-01-14T08:36:09.4083617Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm AUTOTUNE int_mm(32x32, 32x16)
2026-01-14T08:36:09.4084627Z   triton_mm_36 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:36:09.4085714Z   triton_mm_37 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=2
2026-01-14T08:36:09.4086849Z   triton_mm_38 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=2
2026-01-14T08:36:09.4087913Z   triton_mm_39 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:36:09.4088604Z   _int_mm 0.0348 ms 61.8% 
2026-01-14T08:36:09.4089123Z SingleProcess AUTOTUNE benchmarking takes 0.0881 seconds and 0.1723 seconds precompiling for 5 choices
2026-01-14T08:36:09.4089780Z [32mPASSED[0m
2026-01-14T08:36:09.4090467Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm_eager_and_torch_compile_numerics AUTOTUNE int_mm(17x1536, 1536x1536)
2026-01-14T08:36:09.4091627Z   triton_mm_49 0.0717 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:36:09.4092705Z   triton_mm_52 0.0870 ms 82.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:36:09.4093769Z   triton_mm_48 0.0952 ms 75.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:36:09.4094834Z   triton_mm_50 0.0952 ms 75.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:36:09.4095907Z   triton_mm_44 0.1044 ms 68.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:09.4096997Z   triton_mm_46 0.1044 ms 68.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:09.4097701Z   _int_mm 0.1219 ms 58.8% 
2026-01-14T08:36:09.4098338Z   triton_mm_54 0.1444 ms 49.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:36:09.4099426Z   triton_mm_47 0.1618 ms 44.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:36:09.4100503Z   triton_mm_51 0.1618 ms 44.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:36:09.4101459Z SingleProcess AUTOTUNE benchmarking takes 0.5149 seconds and 0.9214 seconds precompiling for 12 choices
2026-01-14T08:36:09.4102135Z AUTOTUNE int_mm(136x4096, 4096x1536)
2026-01-14T08:36:09.4102815Z   triton_mm_60 0.2181 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:36:09.4103881Z   triton_mm_63 0.2304 ms 94.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:36:09.4105028Z   triton_mm_55 0.2683 ms 81.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:09.4106088Z   triton_mm_59 0.2918 ms 74.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:36:09.4107214Z   triton_mm_57 0.3041 ms 71.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:09.4107906Z   _int_mm 0.3144 ms 69.4% 
2026-01-14T08:36:09.4108535Z   triton_mm_61 0.3461 ms 63.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:36:09.4109602Z   triton_mm_58 0.4383 ms 49.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:36:09.4110676Z   triton_mm_56 0.4516 ms 48.3% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:55.6887668Z   triton_mm_62 0.4966 ms 43.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:36:55.6888690Z SingleProcess AUTOTUNE benchmarking takes 0.7060 seconds and 1.8529 seconds precompiling for 12 choices
2026-01-14T08:36:55.6889494Z [32mPASSED[0m
2026-01-14T08:36:55.6890329Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cpu [32mPASSED[0m
2026-01-14T08:36:55.6891524Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cuda [33mSKIPPED[0m
2026-01-14T08:36:55.6892617Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cpu [32mPASSED[0m
2026-01-14T08:36:55.6893610Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cuda [32mPASSED[0m
2026-01-14T08:36:55.6894638Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cpu [32mPASSED[0m
2026-01-14T08:36:55.6895661Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cuda [32mPASSED[0m
2026-01-14T08:36:55.6896755Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6897927Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6899077Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6900215Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:36:55.6901339Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:36:55.6902460Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:36:55.6903621Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6904803Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6906299Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6907482Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:36:55.6908627Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:36:55.6909976Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:36:55.6911082Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6912124Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6913183Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:36:55.6914202Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:36:55.6915214Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:36:55.6916220Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:36:55.6917214Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:36:55.6918195Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:36:55.6919164Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:36:55.6920101Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_3 AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:36:55.6921144Z   triton_mm_70 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:55.6922217Z   triton_mm_67 0.0225 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:55.6923285Z   triton_mm_68 0.0225 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:36:55.6924346Z   triton_mm_69 0.0225 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:36:55.6925406Z   triton_mm_66 0.0236 ms 95.5% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:55.6926093Z   _int_mm 0.0369 ms 61.0% 
2026-01-14T08:36:55.6926615Z SingleProcess AUTOTUNE benchmarking takes 0.2909 seconds and 0.1407 seconds precompiling for 6 choices
2026-01-14T08:36:55.6927217Z [32mPASSED[0m
2026-01-14T08:36:55.6927797Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_4 [32mPASSED[0m
2026-01-14T08:36:55.6928746Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_5 [32mPASSED[0m
2026-01-14T08:36:55.6929798Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:36:55.6930825Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:36:55.6931852Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:36:55.6932854Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_3 [32mPASSED[0m
2026-01-14T08:36:55.6933941Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_4 [32mPASSED[0m
2026-01-14T08:36:55.6934940Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_5 [32mPASSED[0m
2026-01-14T08:36:55.6935939Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:36:55.6936963Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:36:55.6938064Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:36:55.6939026Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:36:55.6940079Z   triton_mm_82 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:55.6941181Z   triton_mm_84 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:36:55.6942282Z   triton_mm_88 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:55.6943374Z   triton_mm_89 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:36:55.6944467Z   triton_mm_90 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:36:55.6945561Z   triton_mm_81 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:36:55.6946647Z   triton_mm_83 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:36:55.6947724Z   triton_mm_85 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:55.6948801Z   triton_mm_86 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:36:55.6949873Z   triton_mm_87 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:36:55.6950840Z SingleProcess AUTOTUNE benchmarking takes 0.2012 seconds and 0.2457 seconds precompiling for 11 choices
2026-01-14T08:36:55.6951449Z [32mPASSED[0m
2026-01-14T08:36:55.6952012Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:36:55.6953071Z   triton_mm_100 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:36:55.6954161Z   triton_mm_96 0.0204 ms 95.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9952729Z   triton_mm_92 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9954220Z   triton_mm_93 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:13.9955497Z   triton_mm_95 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9957254Z   triton_mm_97 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:13.9958557Z   triton_mm_98 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:13.9959651Z   triton_mm_99 0.0205 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:13.9960922Z   triton_mm_91 0.0214 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:13.9962005Z   triton_mm_94 0.0215 ms 90.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:13.9962980Z SingleProcess AUTOTUNE benchmarking takes 0.1996 seconds and 0.1979 seconds precompiling for 11 choices
2026-01-14T08:37:13.9963783Z [32mPASSED[0m
2026-01-14T08:37:13.9964386Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:37:13.9965443Z   triton_mm_107 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:13.9966597Z   triton_mm_103 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:13.9967699Z   triton_mm_106 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9968780Z   triton_mm_108 0.0225 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:13.9969991Z   triton_mm_101 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:13.9971085Z   triton_mm_102 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9972166Z   triton_mm_104 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:13.9973250Z   triton_mm_105 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:13.9974338Z   triton_mm_109 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:13.9975764Z   triton_mm_110 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:13.9976771Z SingleProcess AUTOTUNE benchmarking takes 0.2015 seconds and 0.1941 seconds precompiling for 11 choices
2026-01-14T08:37:13.9977379Z [32mPASSED[0m
2026-01-14T08:37:13.9978026Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9979054Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9980085Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9981099Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:37:13.9982087Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:37:13.9983076Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:37:13.9984226Z test/integration/test_integration.py::TestSubclass::test_autoquantizable_flatten_unflatten [32mPASSED[0m
2026-01-14T08:37:13.9985152Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9985994Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9986843Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_2_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9987809Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_3 [33mSKIPPED[0m
2026-01-14T08:37:13.9988621Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_4 [33mSKIPPED[0m
2026-01-14T08:37:13.9989424Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_5 [33mSKIPPED[0m
2026-01-14T08:37:13.9990382Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9991469Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:13.9992535Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:37:13.9993588Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:37:13.9994619Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:37:13.9995648Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_5 AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:37:13.9996788Z   triton_mm_112 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:37:13.9997908Z   triton_mm_115 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:37:13.9999003Z   triton_mm_111 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:37:14.0000094Z   triton_mm_113 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:37:14.0001178Z   triton_mm_114 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:37:14.0001881Z   addmm 0.0481 ms 42.6% 
2026-01-14T08:37:14.0002128Z   bias_addmm 0.0788 ms 26.0% 
2026-01-14T08:37:14.0002669Z SingleProcess AUTOTUNE benchmarking takes 0.1274 seconds and 0.1434 seconds precompiling for 7 choices
2026-01-14T08:37:14.0003270Z [32mPASSED[0m
2026-01-14T08:37:14.0003906Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:14.0004964Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:14.0005991Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:37:14.0007059Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:37:14.0008068Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:37:14.0009087Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_5 [32mPASSED[0m
2026-01-14T08:37:14.0010221Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_0_cpu [33mSKIPPED[0m
2026-01-14T08:37:14.0011338Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_1_cpu [33mSKIPPED[0m
2026-01-14T08:37:14.0012543Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_2_cpu [32mPASSED[0m
2026-01-14T08:37:14.0013646Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_3 [33mSKIPPED[0m
2026-01-14T08:37:14.0014729Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_4 [33mSKIPPED[0m
2026-01-14T08:37:14.0015924Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_5 AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:37:14.0017072Z   triton_mm_116 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:14.0018182Z   triton_mm_117 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:37:14.0019296Z   triton_mm_118 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:37:33.6770422Z   triton_mm_119 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6771901Z   triton_mm_120 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6773048Z   triton_mm_121 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:33.6774165Z   triton_mm_122 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:33.6775588Z   triton_mm_124 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:37:33.6776702Z   triton_mm_125 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:37:33.6777819Z   triton_mm_126 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:37:33.6778819Z SingleProcess AUTOTUNE benchmarking takes 0.2468 seconds and 0.2148 seconds precompiling for 13 choices
2026-01-14T08:37:33.6779408Z AUTOTUNE addmm(256x8, 256x8, 8x8)
2026-01-14T08:37:33.6780100Z   triton_mm_161 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:37:33.6781208Z   triton_mm_162 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:37:33.6782372Z   triton_mm_163 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6783480Z   triton_mm_164 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6784573Z   triton_mm_166 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:33.6785683Z   triton_mm_167 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:33.6786794Z   triton_mm_168 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:37:33.6788185Z   triton_mm_169 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:37:33.6789306Z   triton_mm_170 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:37:33.6790412Z   triton_mm_160 0.0216 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:33.6791543Z SingleProcess AUTOTUNE benchmarking takes 0.2488 seconds and 0.2098 seconds precompiling for 13 choices
2026-01-14T08:37:33.6792348Z [32mPASSED[0m
2026-01-14T08:37:33.6792998Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_00_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6794023Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_01_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6795044Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_02_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6796045Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_03_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6797053Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_04_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6798053Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_05_cpu [33mSKIPPED[0m
2026-01-14T08:37:33.6799054Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_06 [33mSKIPPED[0m
2026-01-14T08:37:33.6800030Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_07 [33mSKIPPED[0m
2026-01-14T08:37:33.6800994Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_08 [33mSKIPPED[0m
2026-01-14T08:37:33.6802009Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_09 [33mSKIPPED[0m
2026-01-14T08:37:33.6803141Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_10 [33mSKIPPED[0m
2026-01-14T08:37:33.6804362Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_11 [33mSKIPPED[0m
2026-01-14T08:37:33.6805370Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_0_cpu [32mPASSED[0m
2026-01-14T08:37:33.6806404Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_1_cpu [32mPASSED[0m
2026-01-14T08:37:33.6807431Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:37:33.6808391Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:37:33.6809456Z   triton_mm_207 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6810643Z   triton_mm_204 0.0215 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:33.6811794Z   triton_mm_205 0.0215 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6812909Z   triton_mm_208 0.0215 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6814012Z   triton_mm_211 0.0215 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:33.6815109Z   triton_mm_213 0.0215 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:33.6816345Z   triton_mm_206 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6817445Z   triton_mm_209 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6818552Z   triton_mm_210 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:33.6819739Z   triton_mm_212 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:33.6820711Z SingleProcess AUTOTUNE benchmarking takes 0.2011 seconds and 0.2365 seconds precompiling for 11 choices
2026-01-14T08:37:33.6821293Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:37:33.6822016Z   triton_mm_214 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:33.6823127Z   triton_mm_216 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6824250Z   triton_mm_219 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:37:33.6825357Z   triton_mm_218 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:37:33.6826462Z   triton_mm_215 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6827564Z   triton_mm_217 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:37:33.6828256Z   mm 0.0369 ms 58.3% 
2026-01-14T08:37:33.6828767Z SingleProcess AUTOTUNE benchmarking takes 0.1247 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:37:33.6829374Z [32mPASSED[0m
2026-01-14T08:37:33.6829946Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:37:33.6831011Z   triton_mm_220 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:37:33.6832132Z   triton_mm_222 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:37:33.6833253Z   triton_mm_223 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0235623Z   triton_mm_224 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0236788Z   triton_mm_225 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0237931Z   triton_mm_228 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0239067Z   triton_mm_221 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0240202Z   triton_mm_226 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0241309Z   triton_mm_227 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0242730Z   triton_mm_229 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0243724Z SingleProcess AUTOTUNE benchmarking takes 0.2037 seconds and 0.1441 seconds precompiling for 11 choices
2026-01-14T08:38:07.0244303Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:07.0244967Z   triton_mm_230 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:07.0246258Z   triton_mm_231 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0247362Z   triton_mm_234 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0248470Z   triton_mm_233 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0249567Z   triton_mm_232 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0250736Z   triton_mm_235 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0251437Z   mm 0.0369 ms 58.3% 
2026-01-14T08:38:07.0251962Z SingleProcess AUTOTUNE benchmarking takes 0.1310 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:07.0252767Z [32mPASSED[0m
2026-01-14T08:38:07.0253349Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:07.0254412Z   triton_mm_236 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:07.0255533Z   triton_mm_237 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0256635Z   triton_mm_238 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0257745Z   triton_mm_239 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0258862Z   triton_mm_240 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0259961Z   triton_mm_241 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0261078Z   triton_mm_243 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0262243Z   triton_mm_244 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0263344Z   triton_mm_242 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0264449Z   triton_mm_245 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0265422Z SingleProcess AUTOTUNE benchmarking takes 0.2074 seconds and 0.1039 seconds precompiling for 11 choices
2026-01-14T08:38:07.0266007Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:07.0266766Z   triton_mm_249 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0267875Z   triton_mm_246 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:07.0268973Z   triton_mm_247 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0270144Z   triton_mm_250 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0271243Z   triton_mm_251 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0272344Z   triton_mm_248 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0273032Z   mm 0.0379 ms 54.1% 
2026-01-14T08:38:07.0273542Z SingleProcess AUTOTUNE benchmarking takes 0.1245 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:07.0274153Z [32mPASSED[0m
2026-01-14T08:38:07.0274995Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_0_cpu AUTOTUNE packed_linear(32x64, 1459233x1, 32x64)
2026-01-14T08:38:07.0275780Z   cpp_CppMicroGemmFP32Vec_0 0.0059 ms 100.0% 
2026-01-14T08:38:07.0276105Z   _mkl_linear 0.0270 ms 21.9% 
2026-01-14T08:38:07.0276638Z SingleProcess AUTOTUNE benchmarking takes 0.2469 seconds and 2.1608 seconds precompiling for 2 choices
2026-01-14T08:38:07.0277238Z AUTOTUNE packed_linear(32x32, 1459233x1, 32x32)
2026-01-14T08:38:07.0277600Z   cpp_CppMicroGemmFP32Vec_1 0.0058 ms 100.0% 
2026-01-14T08:38:07.0277915Z   _mkl_linear 0.0270 ms 21.5% 
2026-01-14T08:38:07.0278444Z SingleProcess AUTOTUNE benchmarking takes 0.2465 seconds and 2.1615 seconds precompiling for 2 choices
2026-01-14T08:38:07.0279042Z [32mPASSED[0m
2026-01-14T08:38:07.0279614Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_1_cpu AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:07.0280306Z   cpp_CppMicroGemmFP32Vec_2 0.0062 ms 100.0% 
2026-01-14T08:38:07.0280610Z   mm 0.0293 ms 21.2% 
2026-01-14T08:38:07.0281110Z SingleProcess AUTOTUNE benchmarking takes 0.2465 seconds and 2.2974 seconds precompiling for 2 choices
2026-01-14T08:38:07.0281680Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:07.0281964Z   cpp_CppMicroGemmFP32Vec_3 0.0062 ms 100.0% 
2026-01-14T08:38:07.0282273Z   mm 0.0319 ms 19.3% 
2026-01-14T08:38:07.0282759Z SingleProcess AUTOTUNE benchmarking takes 0.2463 seconds and 2.2796 seconds precompiling for 2 choices
2026-01-14T08:38:07.0283354Z [32mPASSED[0m
2026-01-14T08:38:07.0284003Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_2_cpu AUTOTUNE _weight_int8pack_mm(32x64, 32x64, 32)
2026-01-14T08:38:07.0284778Z   cpp_CppMicroGemmFP32Vec_4 0.0064 ms 100.0% 
2026-01-14T08:38:07.0285113Z   _weight_int8pack_mm 0.0172 ms 36.9% 
2026-01-14T08:38:07.0285664Z SingleProcess AUTOTUNE benchmarking takes 0.2474 seconds and 2.2827 seconds precompiling for 2 choices
2026-01-14T08:38:07.0286266Z AUTOTUNE _weight_int8pack_mm(32x32, 32x32, 32)
2026-01-14T08:38:07.0286613Z   cpp_CppMicroGemmFP32Vec_5 0.0063 ms 100.0% 
2026-01-14T08:38:07.0286943Z   _weight_int8pack_mm 0.0173 ms 36.3% 
2026-01-14T08:38:07.0287493Z SingleProcess AUTOTUNE benchmarking takes 0.2476 seconds and 2.2806 seconds precompiling for 2 choices
2026-01-14T08:38:07.0288087Z [32mPASSED[0m
2026-01-14T08:38:07.0288637Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:07.0289694Z   triton_mm_258 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:07.0290996Z   triton_mm_254 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0292098Z   triton_mm_260 0.0216 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:07.0293252Z   triton_mm_252 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:07.0294459Z   triton_mm_253 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:07.0295554Z   triton_mm_255 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:07.0296657Z   triton_mm_256 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4946413Z   triton_mm_257 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4947829Z   triton_mm_259 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4949159Z   triton_mm_261 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4950356Z SingleProcess AUTOTUNE benchmarking takes 0.2023 seconds and 0.3337 seconds precompiling for 11 choices
2026-01-14T08:38:16.4951049Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:16.4951840Z   triton_mm_262 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:16.4953183Z   triton_mm_263 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4954554Z   triton_mm_267 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4955871Z   triton_mm_264 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.4957197Z   triton_mm_265 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4958506Z   triton_mm_266 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4959339Z   mm 0.0369 ms 58.3% 
2026-01-14T08:38:16.4959939Z SingleProcess AUTOTUNE benchmarking takes 0.1289 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:16.4960866Z [32mPASSED[0m
2026-01-14T08:38:16.4961562Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:16.4962816Z   triton_mm_269 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4964171Z   triton_mm_275 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4965503Z   triton_mm_276 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4966828Z   triton_mm_271 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.4977982Z   triton_mm_273 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4979110Z   triton_mm_272 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4980221Z   triton_mm_268 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:16.4981521Z   triton_mm_270 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.4982617Z   triton_mm_274 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4983722Z   triton_mm_277 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4984754Z SingleProcess AUTOTUNE benchmarking takes 0.2080 seconds and 0.1362 seconds precompiling for 11 choices
2026-01-14T08:38:16.4985332Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:16.4985995Z   triton_mm_280 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.4987115Z   triton_mm_281 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4988225Z   triton_mm_278 0.0216 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:16.4989328Z   triton_mm_279 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4990424Z   triton_mm_282 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4991529Z   triton_mm_283 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4992229Z   mm 0.0389 ms 55.3% 
2026-01-14T08:38:16.4992724Z SingleProcess AUTOTUNE benchmarking takes 0.1322 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:16.4993403Z [32mPASSED[0m
2026-01-14T08:38:16.4993971Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:16.4995033Z   triton_mm_285 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.4996201Z   triton_mm_291 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.4997313Z   triton_mm_293 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.4998426Z   triton_mm_286 0.0216 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.4999528Z   triton_mm_284 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:16.5000630Z   triton_mm_287 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.5001730Z   triton_mm_288 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.5002917Z   triton_mm_289 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.5004019Z   triton_mm_290 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.5005147Z   triton_mm_292 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.5006221Z SingleProcess AUTOTUNE benchmarking takes 0.2052 seconds and 0.1402 seconds precompiling for 11 choices
2026-01-14T08:38:16.5006799Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:16.5007457Z   triton_mm_294 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:16.5008579Z   triton_mm_295 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.5009689Z   triton_mm_296 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:16.5010884Z   triton_mm_299 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:16.5011996Z   triton_mm_298 0.0225 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:16.5013094Z   triton_mm_297 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:16.5013781Z   mm 0.0379 ms 56.8% 
2026-01-14T08:38:16.5014282Z SingleProcess AUTOTUNE benchmarking takes 0.1321 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:16.5014887Z [32mPASSED[0m
2026-01-14T08:38:16.5015414Z test/integration/test_integration.py::TestDynamicQuant::test_dynamic_quant [32mPASSED[0m
2026-01-14T08:38:16.5016403Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_embedding_quant [32mPASSED[0m
2026-01-14T08:38:16.5017497Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_quant [32mPASSED[0m
2026-01-14T08:38:16.5018491Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant [32mPASSED[0m
2026-01-14T08:38:16.5019534Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.0384490Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.0385711Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.0386767Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_3 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:38:33.0387885Z   triton_mm_301 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:38:33.0389020Z   triton_mm_304 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:38:33.0390201Z   triton_mm_300 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:38:33.0391322Z   triton_mm_302 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:38:33.0392734Z   triton_mm_303 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:38:33.0393441Z   mm 0.0358 ms 60.0% 
2026-01-14T08:38:33.0393955Z SingleProcess AUTOTUNE benchmarking takes 0.1113 seconds and 0.2032 seconds precompiling for 6 choices
2026-01-14T08:38:33.0394529Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:38:33.0395195Z   triton_mm_306 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:38:33.0396488Z   triton_mm_307 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:38:33.0397605Z   triton_mm_308 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:33.0398751Z   triton_mm_314 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:38:33.0399880Z   triton_mm_305 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:33.0400988Z   triton_mm_309 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:33.0402106Z   triton_mm_310 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:33.0403214Z   triton_mm_311 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:33.0404344Z   triton_mm_312 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:33.0405479Z   triton_mm_313 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:38:33.0406460Z SingleProcess AUTOTUNE benchmarking takes 0.2277 seconds and 0.2002 seconds precompiling for 12 choices
2026-01-14T08:38:33.0407058Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:38:33.0407720Z   triton_mm_319 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:38:33.0408839Z   triton_mm_317 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:38:33.0410111Z   triton_mm_316 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:38:33.0411229Z   triton_mm_318 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:38:33.0412338Z   triton_mm_320 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:38:33.0413046Z   mm 0.0348 ms 61.8% 
2026-01-14T08:38:33.0413546Z SingleProcess AUTOTUNE benchmarking takes 0.1107 seconds and 0.1930 seconds precompiling for 6 choices
2026-01-14T08:38:33.0414169Z [32mPASSED[0m
2026-01-14T08:38:33.0414780Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_4 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:38:33.0415878Z   triton_mm_321 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:38:33.0417107Z   triton_mm_323 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:38:33.0418230Z   triton_mm_324 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:38:33.0419358Z   triton_mm_325 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:38:33.0420613Z   triton_mm_322 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:38:33.0421312Z   mm 0.0430 ms 50.0% 
2026-01-14T08:38:33.0421816Z SingleProcess AUTOTUNE benchmarking takes 0.1125 seconds and 0.1992 seconds precompiling for 6 choices
2026-01-14T08:38:33.0422397Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:38:33.0423063Z   triton_mm_327 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:38:33.0424202Z   triton_mm_329 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:38:33.0425320Z   triton_mm_330 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:38:33.0426446Z   triton_mm_332 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:38:33.0427585Z   triton_mm_334 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:38:33.0428717Z   triton_mm_335 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:38:33.0429858Z   triton_mm_331 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:33.0430969Z   triton_mm_328 0.0225 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:38:33.0432097Z   triton_mm_326 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:38:33.0433228Z   triton_mm_333 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:38:33.0434211Z SingleProcess AUTOTUNE benchmarking takes 0.2251 seconds and 0.2252 seconds precompiling for 12 choices
2026-01-14T08:38:33.0434791Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:38:33.0435453Z   triton_mm_340 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:38:33.0436577Z   triton_mm_341 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:38:33.0437699Z   triton_mm_337 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:38:33.0438811Z   triton_mm_338 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:38:33.0439936Z   triton_mm_339 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:38:33.0440686Z   mm 0.0461 ms 51.1% 
2026-01-14T08:38:33.0441187Z SingleProcess AUTOTUNE benchmarking takes 0.1158 seconds and 0.1819 seconds precompiling for 6 choices
2026-01-14T08:38:33.0441801Z [32mPASSED[0m
2026-01-14T08:38:33.0442493Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_5 AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:38:33.0443596Z   triton_mm_342 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:39:07.5015359Z   triton_mm_345 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:39:07.5018124Z   triton_mm_346 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:39:07.5019442Z   triton_mm_343 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:39:07.5020708Z   triton_mm_344 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:39:07.5021417Z   mm 0.0369 ms 58.3% 
2026-01-14T08:39:07.5021921Z SingleProcess AUTOTUNE benchmarking takes 0.1103 seconds and 0.2017 seconds precompiling for 6 choices
2026-01-14T08:39:07.5022501Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:07.5023168Z   triton_mm_348 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:39:07.5024301Z   triton_mm_349 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:39:07.5025422Z   triton_mm_351 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:07.5026554Z   triton_mm_355 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:39:07.5027680Z   triton_mm_357 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:39:07.5028804Z   triton_mm_347 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:07.5029913Z   triton_mm_350 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:07.5031020Z   triton_mm_352 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5032126Z   triton_mm_353 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:07.5033232Z   triton_mm_354 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5034216Z SingleProcess AUTOTUNE benchmarking takes 0.2248 seconds and 0.2098 seconds precompiling for 12 choices
2026-01-14T08:39:07.5034794Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:07.5035437Z   triton_mm_359 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=2, num_warps=1
2026-01-14T08:39:07.5036563Z   triton_mm_358 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=1, num_warps=1
2026-01-14T08:39:07.5037666Z   triton_mm_361 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=3, num_warps=1
2026-01-14T08:39:07.5039072Z   triton_mm_362 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=4, num_warps=1
2026-01-14T08:39:07.5040386Z   triton_mm_360 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, num_stages=5, num_warps=1
2026-01-14T08:39:07.5041158Z   mm 0.0368 ms 55.7% 
2026-01-14T08:39:07.5041703Z SingleProcess AUTOTUNE benchmarking takes 0.1094 seconds and 0.1595 seconds precompiling for 6 choices
2026-01-14T08:39:07.5042624Z [32mPASSED[0m
2026-01-14T08:39:07.5043346Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5044477Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5045593Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5046699Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_3 [32mPASSED[0m
2026-01-14T08:39:07.5047794Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_4 [32mPASSED[0m
2026-01-14T08:39:07.5048859Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_5 [32mPASSED[0m
2026-01-14T08:39:07.5049960Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5050966Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5051907Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5052791Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_3 AUTOTUNE int_mm(32x32, 32x32)
2026-01-14T08:39:07.5053816Z   triton_mm_432 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5054920Z   triton_mm_433 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:07.5055999Z   triton_mm_431 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:07.5057080Z   triton_mm_434 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:07.5057770Z   _int_mm 0.0369 ms 55.6% 
2026-01-14T08:39:07.5058282Z SingleProcess AUTOTUNE benchmarking takes 0.0894 seconds and 0.1450 seconds precompiling for 5 choices
2026-01-14T08:39:07.5058860Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:39:07.5059520Z   triton_mm_426 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:07.5060608Z   triton_mm_427 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5061686Z   triton_mm_429 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:07.5062776Z   triton_mm_428 0.0225 ms 95.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:07.5063850Z   triton_mm_430 0.0225 ms 95.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5064530Z   _int_mm 0.0358 ms 60.0% 
2026-01-14T08:39:07.5065044Z SingleProcess AUTOTUNE benchmarking takes 0.1094 seconds and 0.0001 seconds precompiling for 6 choices
2026-01-14T08:39:07.5065645Z [32mPASSED[0m
2026-01-14T08:39:07.5066297Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_4 [32mPASSED[0m
2026-01-14T08:39:07.5067200Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_5 [32mPASSED[0m
2026-01-14T08:39:07.5068139Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5069126Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:07.5070201Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:39:07.5071195Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:39:07.5072144Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:39:07.5073041Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_5 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:07.5074074Z   triton_mm_461 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:07.5075577Z   triton_mm_453 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:07.5076700Z   triton_mm_456 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:07.5077796Z   triton_mm_457 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:07.5078901Z   triton_mm_460 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:07.5080007Z   triton_mm_455 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3513607Z   triton_mm_462 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3514932Z   triton_mm_458 0.0245 ms 87.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3516089Z   triton_mm_454 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3517195Z   triton_mm_459 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3518185Z SingleProcess AUTOTUNE benchmarking takes 0.2127 seconds and 0.1316 seconds precompiling for 11 choices
2026-01-14T08:39:19.3518793Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:39:19.3519490Z   triton_mm_468 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3520614Z   triton_mm_463 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:19.3521722Z   triton_mm_465 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3522834Z   triton_mm_466 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3523937Z   triton_mm_467 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3525425Z   triton_mm_464 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3526143Z   addmm 0.0492 ms 41.7% 
2026-01-14T08:39:19.3526401Z   bias_addmm 0.0768 ms 26.7% 
2026-01-14T08:39:19.3526929Z SingleProcess AUTOTUNE benchmarking takes 0.1453 seconds and 0.0001 seconds precompiling for 8 choices
2026-01-14T08:39:19.3527908Z [32mPASSED[0m
2026-01-14T08:39:19.3528536Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_0_cpu [32mPASSED[0m
2026-01-14T08:39:19.3529535Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_1_cpu [32mPASSED[0m
2026-01-14T08:39:19.3530621Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_2_cpu [32mPASSED[0m
2026-01-14T08:39:19.3531543Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_3 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:19.3532592Z   triton_mm_474 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3533710Z   triton_mm_478 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3534824Z   triton_mm_472 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3535945Z   triton_mm_477 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3537044Z   triton_mm_469 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:19.3538152Z   triton_mm_470 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3539249Z   triton_mm_471 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3540361Z   triton_mm_473 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3541474Z   triton_mm_475 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3542572Z   triton_mm_476 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3543554Z SingleProcess AUTOTUNE benchmarking takes 0.2016 seconds and 0.2814 seconds precompiling for 11 choices
2026-01-14T08:39:19.3544148Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:19.3544810Z   triton_mm_481 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3545931Z   triton_mm_479 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:19.3547041Z   triton_mm_480 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3548146Z   triton_mm_482 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3549247Z   triton_mm_483 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3550433Z   triton_mm_484 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3551141Z   mm 0.0358 ms 57.1% 
2026-01-14T08:39:19.3551652Z SingleProcess AUTOTUNE benchmarking takes 0.1250 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:19.3552262Z [32mPASSED[0m
2026-01-14T08:39:19.3552810Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_4 AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:19.3553973Z   triton_mm_486 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3555096Z   triton_mm_487 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3556222Z   triton_mm_488 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3557331Z   triton_mm_489 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3558447Z   triton_mm_491 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3559565Z   triton_mm_492 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3560684Z   triton_mm_494 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3561797Z   triton_mm_485 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:19.3562900Z   triton_mm_490 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3564004Z   triton_mm_493 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3564988Z SingleProcess AUTOTUNE benchmarking takes 0.2045 seconds and 0.1058 seconds precompiling for 11 choices
2026-01-14T08:39:19.3565569Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:19.3566237Z   triton_mm_499 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:19.3567351Z   triton_mm_497 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:19.3568459Z   triton_mm_498 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3569562Z   triton_mm_500 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:39:19.3570716Z   triton_mm_495 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:19.3571824Z   triton_mm_496 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:19.3572522Z   mm 0.0379 ms 54.1% 
2026-01-14T08:39:19.3573026Z SingleProcess AUTOTUNE benchmarking takes 0.1258 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:19.3573670Z [32mPASSED[0m
2026-01-14T08:39:40.8921893Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_5 [32mPASSED[0m
2026-01-14T08:39:40.8924741Z test/integration/test_integration.py::UtilsUnitTest::test_shape_logger [32mPASSED[0m
2026-01-14T08:39:40.8925707Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_00_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8926856Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_01_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8928005Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_02_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8929390Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_03_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8930359Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_04_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8931262Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_05_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8932155Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_06_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8933064Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_07_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8933965Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_08_cpu [33mSKIPPED[0m
2026-01-14T08:39:40.8934843Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_09 [33mSKIPPED[0m
2026-01-14T08:39:40.8935708Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_10 [33mSKIPPED[0m
2026-01-14T08:39:40.8936656Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_11 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:39:40.8937552Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:39:40.8938062Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:39:40.8938783Z   triton_mm_517 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:40.8939923Z   triton_mm_518 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8941035Z   triton_mm_520 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8942152Z   triton_mm_521 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8943269Z   triton_mm_524 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:39:40.8944362Z   triton_mm_530 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8945466Z   triton_mm_519 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:39:40.8946566Z   triton_mm_523 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8947663Z   triton_mm_526 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8948774Z   triton_mm_531 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:39:40.8949748Z SingleProcess AUTOTUNE benchmarking takes 0.3767 seconds and 3.3677 seconds precompiling for 19 choices
2026-01-14T08:39:40.8950616Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:39:40.8951225Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:39:40.8952000Z   triton_mm_538 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8953125Z   triton_mm_540 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8954233Z   triton_mm_539 0.0205 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8955420Z   triton_mm_543 0.0205 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8956529Z   triton_mm_534 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:39:40.8957637Z   triton_mm_535 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8958745Z   triton_mm_536 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:39:40.8959847Z   triton_mm_537 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8960997Z   triton_mm_541 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:39:40.8962105Z   triton_mm_542 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8963086Z SingleProcess AUTOTUNE benchmarking takes 0.3289 seconds and 1.9109 seconds precompiling for 18 choices
2026-01-14T08:39:40.8964047Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:39:40.8965116Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.010ms 
2026-01-14T08:39:40.8965807Z AUTOTUNE int_mm(32x128, 128x128)
2026-01-14T08:39:40.8966489Z   triton_mm_553 0.0195 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8967583Z   triton_mm_557 0.0205 ms 95.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:39:40.8968663Z   triton_mm_552 0.0205 ms 94.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8969796Z   triton_mm_551 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:39:40.8970887Z   triton_mm_554 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:39:40.8971962Z   triton_mm_555 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:39:40.8973045Z   triton_mm_556 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:39:40.8974123Z   triton_mm_558 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:39:40.8975396Z   triton_mm_559 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:39:40.8976647Z   triton_mm_560 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:39:40.8977622Z SingleProcess AUTOTUNE benchmarking takes 0.2025 seconds and 0.2383 seconds precompiling for 11 choices
2026-01-14T08:39:40.8978610Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:39:40.8979707Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:39:40.8980189Z 
2026-01-14T08:39:40.8980324Z [32mPASSED[0m
2026-01-14T08:39:40.8980874Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_12 [33mSKIPPED[0m
2026-01-14T08:39:40.8981740Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_13 [33mSKIPPED[0m
2026-01-14T08:39:40.8982688Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_14 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:39:40.8983582Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:39:40.8984079Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:39:40.8984794Z   triton_mm_570 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:39:40.8985913Z   triton_mm_562 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4237566Z   triton_mm_563 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:07.4240577Z   triton_mm_564 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4241772Z   triton_mm_565 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4242888Z   triton_mm_567 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4243988Z   triton_mm_568 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:40:07.4245106Z   triton_mm_572 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:07.4246222Z   triton_mm_573 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:07.4247328Z   triton_mm_574 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:07.4248314Z SingleProcess AUTOTUNE benchmarking takes 0.3603 seconds and 0.3346 seconds precompiling for 19 choices
2026-01-14T08:40:07.4249155Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:07.4249735Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:07.4250523Z   triton_mm_587 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:07.4251659Z   triton_mm_590 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:07.4252787Z   triton_mm_594 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:07.4254304Z   triton_mm_585 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:40:07.4255413Z   triton_mm_586 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4256522Z   triton_mm_578 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:07.4257792Z   triton_mm_579 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4258898Z   triton_mm_580 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:07.4260001Z   triton_mm_581 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4261107Z   triton_mm_582 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4262088Z SingleProcess AUTOTUNE benchmarking takes 0.3318 seconds and 0.2757 seconds precompiling for 18 choices
2026-01-14T08:40:07.4263053Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:40:07.4264118Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.006ms 
2026-01-14T08:40:07.4265215Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:07.4266193Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:07.4266684Z 
2026-01-14T08:40:07.4266984Z [32mPASSED[0m
2026-01-14T08:40:07.4267593Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_15 [33mSKIPPED[0m
2026-01-14T08:40:07.4268488Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_16 [33mSKIPPED[0m
2026-01-14T08:40:07.4269450Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_17 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:07.4270360Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:40:07.4270873Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:07.4271596Z   triton_mm_616 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:07.4280580Z   triton_mm_610 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4281734Z   triton_mm_617 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:07.4282867Z   triton_mm_621 0.0205 ms 94.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:07.4283972Z   triton_mm_605 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:07.4285089Z   triton_mm_606 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4286200Z   triton_mm_607 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:07.4287300Z   triton_mm_608 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4288593Z   triton_mm_609 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4289701Z   triton_mm_611 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4290750Z SingleProcess AUTOTUNE benchmarking takes 0.3561 seconds and 0.3404 seconds precompiling for 19 choices
2026-01-14T08:40:07.4291731Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:07.4292305Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:07.4292997Z   triton_mm_626 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4294134Z   triton_mm_637 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:40:07.4295242Z   triton_mm_622 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:07.4296353Z   triton_mm_623 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4297506Z   triton_mm_625 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4298613Z   triton_mm_627 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4299713Z   triton_mm_628 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:07.4300808Z   triton_mm_629 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:40:07.4301914Z   triton_mm_630 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:07.4303026Z   triton_mm_631 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:07.4304008Z SingleProcess AUTOTUNE benchmarking takes 0.3320 seconds and 0.3448 seconds precompiling for 18 choices
2026-01-14T08:40:07.4304970Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:40:07.4306025Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:40:07.4307139Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:40:07.4308169Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:40:07.4308649Z 
2026-01-14T08:40:07.4308806Z [32mPASSED[0m
2026-01-14T08:40:24.7417216Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:24.7419271Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:24.7421172Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:24.7422941Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_3 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:24.7423864Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:24.7424371Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:24.7425493Z   triton_mm_649 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:24.7426633Z   triton_mm_650 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:40:24.7427764Z   triton_mm_655 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7429053Z   triton_mm_657 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7430170Z   triton_mm_653 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:24.7431294Z   triton_mm_652 0.0225 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:24.7432400Z   triton_mm_654 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7433504Z   triton_mm_651 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7434614Z   triton_mm_656 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7435715Z   triton_mm_662 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7436690Z SingleProcess AUTOTUNE benchmarking takes 0.3547 seconds and 1.5631 seconds precompiling for 19 choices
2026-01-14T08:40:24.7437541Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:24.7438116Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:24.7438807Z   triton_mm_678 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:24.7439944Z   triton_mm_667 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:40:24.7441053Z   triton_mm_668 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7442165Z   triton_mm_670 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:24.7443272Z   triton_mm_671 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7444371Z   triton_mm_672 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7445473Z   triton_mm_673 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7446578Z   triton_mm_674 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7447687Z   triton_mm_677 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7448792Z   triton_mm_679 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7449937Z SingleProcess AUTOTUNE benchmarking takes 0.3244 seconds and 0.7661 seconds precompiling for 18 choices
2026-01-14T08:40:24.7450903Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.010ms 
2026-01-14T08:40:24.7451963Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.009ms 
2026-01-14T08:40:24.7452740Z AUTOTUNE int_mm(16x128, 128x128)
2026-01-14T08:40:24.7453468Z   triton_mm_683 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7454568Z   triton_mm_684 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7455670Z   triton_mm_685 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7456756Z   triton_mm_689 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7457837Z   triton_mm_687 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:24.7458923Z   triton_mm_688 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:24.7459998Z   triton_mm_690 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:40:24.7461078Z   triton_mm_691 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7462179Z   triton_mm_692 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:40:24.7463319Z   triton_mm_686 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:40:24.7464292Z SingleProcess AUTOTUNE benchmarking takes 0.1914 seconds and 0.1779 seconds precompiling for 11 choices
2026-01-14T08:40:24.7465301Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:24.7466278Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:24.7466772Z 
2026-01-14T08:40:24.7466907Z [32mPASSED[0m
2026-01-14T08:40:24.7467561Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_4 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:24.7468482Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:40:24.7468991Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:24.7469703Z   triton_mm_709 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:24.7470832Z   triton_mm_693 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:24.7471937Z   triton_mm_695 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7473054Z   triton_mm_697 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:24.7474251Z   triton_mm_698 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7475529Z   triton_mm_699 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:24.7476635Z   triton_mm_700 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7477883Z   triton_mm_701 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:24.7478991Z   triton_mm_702 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:24.7480108Z   triton_mm_703 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:40:49.7211042Z SingleProcess AUTOTUNE benchmarking takes 0.3593 seconds and 0.3068 seconds precompiling for 19 choices
2026-01-14T08:40:49.7212061Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:49.7212817Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:49.7213776Z   triton_mm_719 0.0204 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:49.7215154Z   triton_mm_714 0.0205 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7216653Z   triton_mm_717 0.0205 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:49.7217818Z   triton_mm_718 0.0205 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:49.7218950Z   triton_mm_710 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:49.7220070Z   triton_mm_711 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:40:49.7221197Z   triton_mm_713 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7222315Z   triton_mm_715 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:49.7223429Z   triton_mm_716 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:49.7224555Z   triton_mm_721 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:49.7225561Z SingleProcess AUTOTUNE benchmarking takes 0.3308 seconds and 0.2633 seconds precompiling for 18 choices
2026-01-14T08:40:49.7226529Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:40:49.7227619Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:40:49.7228730Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:49.7229730Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:49.7230221Z 
2026-01-14T08:40:49.7230540Z [32mPASSED[0m
2026-01-14T08:40:49.7231600Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_5 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:49.7232545Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:40:49.7233053Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:49.7233779Z   triton_mm_740 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7235131Z   triton_mm_743 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:40:49.7236254Z   triton_mm_747 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:40:49.7237397Z   triton_mm_749 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:49.7238532Z   triton_mm_751 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:49.7239658Z   triton_mm_752 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:40:49.7240795Z   triton_mm_737 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:49.7241951Z   triton_mm_738 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:40:49.7243068Z   triton_mm_739 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:49.7244199Z   triton_mm_741 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7245184Z SingleProcess AUTOTUNE benchmarking takes 0.3528 seconds and 0.2782 seconds precompiling for 19 choices
2026-01-14T08:40:49.7246038Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:49.7246617Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:49.7247314Z   triton_mm_766 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:49.7248456Z   triton_mm_765 0.0215 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:40:49.7249569Z   triton_mm_768 0.0215 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:40:49.7250800Z   triton_mm_770 0.0215 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:40:49.7251919Z   triton_mm_762 0.0225 ms 91.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:49.7253030Z   triton_mm_754 0.0225 ms 91.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:40:49.7254156Z   triton_mm_755 0.0225 ms 91.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:40:49.7255264Z   triton_mm_756 0.0225 ms 91.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:40:49.7256477Z   triton_mm_757 0.0225 ms 91.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7257599Z   triton_mm_758 0.0225 ms 91.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:40:49.7258585Z SingleProcess AUTOTUNE benchmarking takes 0.3293 seconds and 0.2594 seconds precompiling for 18 choices
2026-01-14T08:40:49.7259559Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.004ms 
2026-01-14T08:40:49.7260734Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.004ms 
2026-01-14T08:40:49.7261838Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:40:49.7262826Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:49.7263312Z 
2026-01-14T08:40:49.7263444Z [32mPASSED[0m
2026-01-14T08:40:49.7264025Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:49.7264926Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:49.7265831Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:49.7266692Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_3 [33mSKIPPED[0m
2026-01-14T08:40:49.7267549Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_4 [33mSKIPPED[0m
2026-01-14T08:40:49.7268390Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_5 [33mSKIPPED[0m
2026-01-14T08:40:49.7269332Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_hp_float activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:49.7270226Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:49.7271040Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>, to_beat: infms 
2026-01-14T08:40:49.7271775Z best_cls=<class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>
2026-01-14T08:40:49.7272150Z 
2026-01-14T08:40:49.7272312Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:49.7272852Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:49.7273607Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:40:49.7274352Z best_cls=<class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>
2026-01-14T08:40:49.7275049Z 
2026-01-14T08:40:49.7275219Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:49.7275760Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:07.9608408Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:41:07.9609202Z best_cls=<class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>
2026-01-14T08:41:07.9609591Z 
2026-01-14T08:41:07.9609965Z [32mPASSED[0m
2026-01-14T08:41:07.9610553Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9611477Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9612377Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9613232Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_3 [33mSKIPPED[0m
2026-01-14T08:41:07.9614084Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_4 [33mSKIPPED[0m
2026-01-14T08:41:07.9614920Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_5 [33mSKIPPED[0m
2026-01-14T08:41:07.9616167Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_00_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9617076Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_01_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9617962Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_02_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9618853Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_03_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9619914Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_04_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9620808Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_05_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9621703Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_06_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9622586Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_07_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9623483Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_08_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9624351Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_09 [33mSKIPPED[0m
2026-01-14T08:41:07.9625207Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_10 [33mSKIPPED[0m
2026-01-14T08:41:07.9626059Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_11 [32mPASSED[0m
2026-01-14T08:41:07.9626902Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_12 [33mSKIPPED[0m
2026-01-14T08:41:07.9627754Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_13 [33mSKIPPED[0m
2026-01-14T08:41:07.9628587Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_14 [32mPASSED[0m
2026-01-14T08:41:07.9629427Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_15 [33mSKIPPED[0m
2026-01-14T08:41:07.9630269Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_16 [33mSKIPPED[0m
2026-01-14T08:41:07.9631113Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_17 [32mPASSED[0m
2026-01-14T08:41:07.9631969Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9632838Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9633719Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9634565Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_3 [32mPASSED[0m
2026-01-14T08:41:07.9635395Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_4 [32mPASSED[0m
2026-01-14T08:41:07.9636221Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_5 [32mPASSED[0m
2026-01-14T08:41:07.9637055Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9637905Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9638744Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:07.9639665Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_3 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:07.9640548Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float32, bias_shape: torch.Size([4096])
2026-01-14T08:41:07.9641060Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:07.9641371Z   bias_addmm 0.1444 ms 100.0% 
2026-01-14T08:41:07.9641627Z   addmm 0.1485 ms 97.2% 
2026-01-14T08:41:07.9642290Z   triton_mm_788 0.2028 ms 71.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:07.9643498Z   triton_mm_783 0.2181 ms 66.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:07.9644610Z   triton_mm_795 0.2181 ms 66.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:41:07.9645710Z   triton_mm_784 0.2202 ms 65.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:41:07.9646939Z   triton_mm_794 0.2202 ms 65.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:07.9648054Z   triton_mm_782 0.2519 ms 57.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:41:07.9649174Z   triton_mm_785 0.2642 ms 54.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:41:07.9650342Z   triton_mm_787 0.2806 ms 51.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:07.9651322Z SingleProcess AUTOTUNE benchmarking takes 0.6278 seconds and 1.1983 seconds precompiling for 19 choices
2026-01-14T08:41:07.9652167Z >>time: 0.143ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:07.9653121Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.143ms 
2026-01-14T08:41:07.9654189Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.037ms 
2026-01-14T08:41:07.9654880Z AUTOTUNE int_mm(1x4096, 4096x4096)
2026-01-14T08:41:07.9655573Z   triton_mm_808 0.0471 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:07.9656694Z   triton_mm_807 0.0492 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:07.9657784Z   triton_mm_806 0.0532 ms 88.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:07.9658874Z   triton_mm_803 0.0553 ms 85.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:41:07.9659953Z   triton_mm_804 0.0563 ms 83.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:07.9661031Z   triton_mm_802 0.0614 ms 76.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:41:07.9662111Z   triton_mm_800 0.0758 ms 62.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:07.9663196Z   triton_mm_799 0.0799 ms 59.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:07.9664280Z   triton_mm_798 0.1341 ms 35.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:07.9665371Z   triton_mm_801 0.1341 ms 35.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:07.9666385Z SingleProcess AUTOTUNE benchmarking takes 0.2521 seconds and 0.3488 seconds precompiling for 12 choices
2026-01-14T08:41:07.9667382Z >>time: 0.047ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:41:07.9668356Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:41:07.9668942Z 
2026-01-14T08:41:07.9669071Z [32mPASSED[0m
2026-01-14T08:41:07.9669679Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_4 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:07.9670550Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float16, bias_shape: torch.Size([4096])
2026-01-14T08:41:07.9671068Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:07.9671868Z   triton_mm_817 0.0809 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:07.9672995Z   triton_mm_825 0.0829 ms 97.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:07.9674107Z   triton_mm_820 0.0850 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4361794Z   triton_mm_816 0.0860 ms 94.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4362952Z   triton_mm_811 0.0870 ms 92.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:35.4363663Z   addmm 0.0881 ms 91.9% 
2026-01-14T08:41:35.4364340Z   triton_mm_813 0.0891 ms 90.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:41:35.4365442Z   triton_mm_823 0.0942 ms 85.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:41:35.4366550Z   triton_mm_819 0.0973 ms 83.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:35.4367668Z   triton_mm_822 0.1004 ms 80.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4368642Z SingleProcess AUTOTUNE benchmarking takes 0.4756 seconds and 0.3971 seconds precompiling for 19 choices
2026-01-14T08:41:35.4369493Z >>time: 0.081ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:35.4370534Z >>time: 0.039ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.081ms 
2026-01-14T08:41:35.4371595Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.039ms 
2026-01-14T08:41:35.4372687Z >>time: 0.047ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:41:35.4373656Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:41:35.4374144Z 
2026-01-14T08:41:35.4374462Z [32mPASSED[0m
2026-01-14T08:41:35.4375269Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_5 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:35.4376152Z weight_shape: torch.Size([4096, 4096]), dtype: torch.bfloat16, bias_shape: torch.Size([4096])
2026-01-14T08:41:35.4376676Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:35.4377398Z   triton_mm_845 0.0819 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:35.4378526Z   triton_mm_853 0.0829 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:35.4379638Z   triton_mm_848 0.0840 ms 97.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4381891Z   triton_mm_839 0.0850 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:35.4383005Z   triton_mm_844 0.0860 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4383708Z   addmm 0.0881 ms 93.0% 
2026-01-14T08:41:35.4384348Z   triton_mm_841 0.0891 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:41:35.4385606Z   triton_mm_851 0.0901 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:41:35.4386700Z   triton_mm_847 0.0932 ms 87.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:35.4387806Z   triton_mm_850 0.0963 ms 85.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4388777Z SingleProcess AUTOTUNE benchmarking takes 0.4680 seconds and 0.3970 seconds precompiling for 19 choices
2026-01-14T08:41:35.4389608Z >>time: 0.081ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:35.4390552Z >>time: 0.039ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.081ms 
2026-01-14T08:41:35.4391616Z >>time: 0.039ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.039ms 
2026-01-14T08:41:35.4392704Z >>time: 0.047ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.039ms
2026-01-14T08:41:35.4393680Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:41:35.4394158Z 
2026-01-14T08:41:35.4394286Z [32mPASSED[0m
2026-01-14T08:41:35.4394924Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_0 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:35.4395817Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:35.4396316Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:35.4397031Z   triton_mm_873 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:35.4398141Z   triton_mm_872 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:35.4399229Z   triton_mm_865 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:41:35.4400340Z   triton_mm_866 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:35.4401427Z   triton_mm_867 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:35.4402514Z   triton_mm_868 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:35.4403611Z   triton_mm_869 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:35.4404747Z   triton_mm_871 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:35.4405837Z   triton_mm_874 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:35.4407015Z   triton_mm_875 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:35.4407993Z SingleProcess AUTOTUNE benchmarking takes 0.3705 seconds and 0.8707 seconds precompiling for 21 choices
2026-01-14T08:41:35.4408843Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:35.4410100Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.31756591796875
2026-01-14T08:41:35.4411750Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.40925216674805
2026-01-14T08:41:35.4413317Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.288150787353516
2026-01-14T08:41:35.4414472Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:35.4414852Z 
2026-01-14T08:41:35.4414975Z [32mPASSED[0m
2026-01-14T08:41:35.4415603Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_1 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:35.4416497Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:41:35.4417004Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:35.4417705Z   triton_mm_884 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:41:35.4418814Z   triton_mm_886 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:35.4419914Z   triton_mm_887 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:35.4421014Z   triton_mm_889 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:35.4422115Z   triton_mm_890 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:35.4423215Z   triton_mm_891 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:35.4424329Z   triton_mm_892 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:58.9778846Z   triton_mm_894 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:58.9780032Z   triton_mm_895 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9781207Z   triton_mm_897 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9782371Z SingleProcess AUTOTUNE benchmarking takes 0.3888 seconds and 0.6169 seconds precompiling for 21 choices
2026-01-14T08:41:58.9783258Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:58.9784440Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.3125
2026-01-14T08:41:58.9785930Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.0
2026-01-14T08:41:58.9787792Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.15625
2026-01-14T08:41:58.9788868Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:58.9789245Z 
2026-01-14T08:41:58.9789550Z [32mPASSED[0m
2026-01-14T08:41:58.9790199Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_2 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:58.9791283Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:41:58.9791790Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:58.9792510Z   triton_mm_919 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9793648Z   triton_mm_920 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9794758Z   triton_mm_903 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:41:58.9795855Z   triton_mm_904 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9796954Z   triton_mm_905 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:58.9798043Z   triton_mm_906 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:58.9799137Z   triton_mm_907 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:41:58.9800231Z   triton_mm_908 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9801324Z   triton_mm_909 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9802410Z   triton_mm_910 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:58.9803381Z SingleProcess AUTOTUNE benchmarking takes 0.3862 seconds and 0.6037 seconds precompiling for 21 choices
2026-01-14T08:41:58.9804224Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:58.9805385Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:41:58.9806860Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:41:58.9808340Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 46.25
2026-01-14T08:41:58.9809390Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:58.9809773Z 
2026-01-14T08:41:58.9809990Z [32mPASSED[0m
2026-01-14T08:41:58.9810516Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_00_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:58.9811147Z [33mSKIPPED[0m
2026-01-14T08:41:58.9811672Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_01_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:58.9812294Z [33mSKIPPED[0m
2026-01-14T08:41:58.9812820Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_02_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:58.9813545Z [33mSKIPPED[0m
2026-01-14T08:41:58.9814065Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_03_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:58.9822428Z [33mSKIPPED[0m
2026-01-14T08:41:58.9822974Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_04_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:58.9823620Z [33mSKIPPED[0m
2026-01-14T08:41:58.9824280Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_05_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:58.9824907Z [33mSKIPPED[0m
2026-01-14T08:41:58.9825432Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_06_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:58.9826058Z [33mSKIPPED[0m
2026-01-14T08:41:58.9826577Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_07_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:58.9827200Z [33mSKIPPED[0m
2026-01-14T08:41:58.9827726Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_08_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:58.9828353Z [33mSKIPPED[0m
2026-01-14T08:41:58.9828864Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_09_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:58.9829497Z [33mSKIPPED[0m
2026-01-14T08:41:58.9830011Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_10_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:58.9830654Z [33mSKIPPED[0m
2026-01-14T08:41:58.9831168Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_11_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:58.9831799Z [33mSKIPPED[0m
2026-01-14T08:41:58.9832317Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_12_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:58.9832936Z [33mSKIPPED[0m
2026-01-14T08:41:58.9833455Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_13_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:58.9834080Z [33mSKIPPED[0m
2026-01-14T08:41:58.9834603Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_14_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:58.9835227Z [33mSKIPPED[0m
2026-01-14T08:41:58.9835734Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_15 (m, k, n):  (16, 128, 128)
2026-01-14T08:41:58.9836347Z [32mPASSED[0m
2026-01-14T08:41:58.9836848Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_16 (m, k, n):  (64, 128, 128)
2026-01-14T08:41:58.9837509Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:41:58.9838044Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:58.9838553Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:41:58.9839272Z   triton_mm_922 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:41:58.9840408Z   triton_mm_923 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9841527Z   triton_mm_924 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:58.9842677Z   triton_mm_925 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:41:58.9843784Z   triton_mm_935 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9844894Z   triton_mm_928 0.0256 ms 84.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9846083Z   triton_mm_927 0.0266 ms 80.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:41:58.9847196Z   triton_mm_931 0.0297 ms 72.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:41:58.9848308Z   triton_mm_929 0.0338 ms 63.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:41:58.9849483Z   triton_mm_936 0.0338 ms 63.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:41:58.9850520Z SingleProcess AUTOTUNE benchmarking takes 0.4008 seconds and 10.0463 seconds precompiling for 19 choices
2026-01-14T08:41:58.9851409Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:58.9852002Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:42:20.7216611Z   triton_mm_948 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7218941Z   triton_mm_939 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:20.7220115Z   triton_mm_940 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7221361Z   triton_mm_943 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:20.7222836Z   triton_mm_945 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7223949Z   triton_mm_946 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:20.7225062Z   triton_mm_953 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:20.7226162Z   triton_mm_942 0.0215 ms 95.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:20.7227266Z   triton_mm_949 0.0225 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:20.7228421Z   triton_mm_941 0.0225 ms 90.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:20.7229401Z SingleProcess AUTOTUNE benchmarking takes 0.3485 seconds and 4.7257 seconds precompiling for 18 choices
2026-01-14T08:42:20.7230385Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:42:20.7231082Z AUTOTUNE int_mm(64x128, 128x128)
2026-01-14T08:42:20.7231755Z   triton_mm_960 0.0195 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:20.7232850Z   triton_mm_961 0.0205 ms 95.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:20.7233947Z   triton_mm_963 0.0205 ms 95.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:42:20.7235030Z   triton_mm_962 0.0215 ms 90.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:20.7236425Z   triton_mm_956 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7237514Z   triton_mm_957 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7238648Z   triton_mm_958 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7239935Z   triton_mm_959 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:20.7241012Z   triton_mm_964 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:20.7242102Z   triton_mm_965 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:20.7243088Z SingleProcess AUTOTUNE benchmarking takes 0.2017 seconds and 0.2257 seconds precompiling for 11 choices
2026-01-14T08:42:20.7244075Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.013ms
2026-01-14T08:42:20.7245202Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.054ms 
2026-01-14T08:42:20.7246400Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 2.33
2026-01-14T08:42:20.7247452Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:20.7247937Z 
2026-01-14T08:42:20.7248259Z [32mPASSED[0m
2026-01-14T08:42:20.7248787Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_17 (m, k, n):  (16, 128, 256)
2026-01-14T08:42:20.7249448Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:42:20.7250087Z weight_shape: torch.Size([256, 128]), dtype: torch.float32, bias_shape: torch.Size([256])
2026-01-14T08:42:20.7250592Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:42:20.7251319Z   triton_mm_977 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:42:20.7252445Z   triton_mm_979 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:20.7253575Z   triton_mm_980 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:20.7254693Z   triton_mm_982 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7255817Z   triton_mm_983 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7256936Z   triton_mm_976 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:20.7258038Z   triton_mm_978 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:20.7259156Z   triton_mm_981 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7260270Z   triton_mm_984 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:20.7261373Z   triton_mm_989 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7262498Z SingleProcess AUTOTUNE benchmarking takes 0.3553 seconds and 1.5514 seconds precompiling for 19 choices
2026-01-14T08:42:20.7263353Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:20.7263930Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:42:20.7264621Z   triton_mm_1001 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:20.7265842Z   triton_mm_1004 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7266972Z   triton_mm_993 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:20.7268156Z   triton_mm_994 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:42:20.7269262Z   triton_mm_996 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:20.7270382Z   triton_mm_997 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:20.7271494Z   triton_mm_998 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7272603Z   triton_mm_999 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:20.7273720Z   triton_mm_1002 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:20.7275225Z   triton_mm_1003 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:20.7276225Z SingleProcess AUTOTUNE benchmarking takes 0.3259 seconds and 0.7098 seconds precompiling for 18 choices
2026-01-14T08:42:20.7277187Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:42:20.7278257Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:42:20.7279008Z AUTOTUNE int_mm(16x128, 128x256)
2026-01-14T08:42:36.0196855Z   triton_mm_1018 0.0195 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0199527Z   triton_mm_1010 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:36.0201776Z   triton_mm_1011 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0203200Z   triton_mm_1012 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0204299Z   triton_mm_1013 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:36.0205406Z   triton_mm_1014 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:42:36.0206491Z   triton_mm_1015 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0209167Z   triton_mm_1016 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:36.0210350Z   triton_mm_1017 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:42:36.0211450Z   triton_mm_1019 0.0215 ms 90.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=256, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:36.0212671Z SingleProcess AUTOTUNE benchmarking takes 0.2123 seconds and 0.2067 seconds precompiling for 12 choices
2026-01-14T08:42:36.0213672Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:42:36.0214646Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:36.0215131Z 
2026-01-14T08:42:36.0215464Z [32mPASSED[0m
2026-01-14T08:42:36.0215992Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_18 (m, k, n):  (16, 256, 128)
2026-01-14T08:42:36.0216654Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:42:36.0217186Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:42:36.0217694Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:42:36.0218427Z   triton_mm_1025 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0219565Z   triton_mm_1022 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:42:36.0220689Z   triton_mm_1024 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0221807Z   triton_mm_1023 0.0246 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:36.0222965Z   triton_mm_1028 0.0246 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0224080Z   triton_mm_1034 0.0246 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0225196Z   triton_mm_1035 0.0246 ms 83.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:42:36.0226308Z   triton_mm_1021 0.0256 ms 80.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:36.0227424Z   triton_mm_1027 0.0276 ms 74.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:36.0228537Z   triton_mm_1026 0.0317 ms 64.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:36.0229524Z SingleProcess AUTOTUNE benchmarking takes 0.3304 seconds and 1.1218 seconds precompiling for 19 choices
2026-01-14T08:42:36.0230373Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:36.0230953Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:42:36.0231642Z   triton_mm_1048 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:36.0232765Z   triton_mm_1041 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0234027Z   triton_mm_1038 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:36.0235151Z   triton_mm_1039 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:42:36.0236264Z   triton_mm_1040 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:36.0237465Z   triton_mm_1042 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0238585Z   triton_mm_1044 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:36.0239694Z   triton_mm_1045 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0240817Z   triton_mm_1047 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0241939Z   triton_mm_1049 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0242921Z SingleProcess AUTOTUNE benchmarking takes 0.3076 seconds and 0.8439 seconds precompiling for 18 choices
2026-01-14T08:42:36.0243931Z >>time: 0.031ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.010ms 
2026-01-14T08:42:36.0245008Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.010ms 
2026-01-14T08:42:36.0245705Z AUTOTUNE int_mm(16x256, 256x128)
2026-01-14T08:42:36.0246380Z   triton_mm_1059 0.0205 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:42:36.0247480Z   triton_mm_1057 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0248566Z   triton_mm_1060 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:42:36.0249651Z   triton_mm_1063 0.0215 ms 95.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0250792Z   triton_mm_1055 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:36.0251880Z   triton_mm_1056 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:36.0252973Z   triton_mm_1061 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:36.0254066Z   triton_mm_1062 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:42:36.0255166Z   triton_mm_1064 0.0225 ms 90.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:36.0256268Z   triton_mm_1058 0.0236 ms 87.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:36.0257238Z SingleProcess AUTOTUNE benchmarking takes 0.1939 seconds and 0.2120 seconds precompiling for 11 choices
2026-01-14T08:42:36.0258228Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:42:36.0259297Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:42:36.0259785Z 
2026-01-14T08:42:36.0259911Z [32mPASSED[0m
2026-01-14T08:42:36.0260413Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_19 (m, k, n):  (64, 256, 128)
2026-01-14T08:42:36.0261066Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:42:57.2048988Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:42:57.2050226Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:42:57.2050964Z   triton_mm_1066 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2052112Z   triton_mm_1065 0.0328 ms 78.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:57.2053245Z   triton_mm_1067 0.0358 ms 71.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2054352Z   triton_mm_1068 0.0358 ms 71.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2055463Z   triton_mm_1078 0.0369 ms 69.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2056579Z   triton_mm_1070 0.0410 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2057692Z   triton_mm_1071 0.0410 ms 62.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2058809Z   triton_mm_1074 0.0420 ms 61.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2059926Z   triton_mm_1072 0.0471 ms 54.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:57.2061044Z   triton_mm_1076 0.0471 ms 54.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2062038Z SingleProcess AUTOTUNE benchmarking takes 0.3323 seconds and 3.3879 seconds precompiling for 19 choices
2026-01-14T08:42:57.2062887Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:57.2063478Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:42:57.2064162Z   triton_mm_1083 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2065305Z   triton_mm_1084 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2066432Z   triton_mm_1085 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2067543Z   triton_mm_1089 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:57.2068663Z   triton_mm_1095 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2069781Z   triton_mm_1096 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:57.2070887Z   triton_mm_1082 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:42:57.2072181Z   triton_mm_1088 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2073294Z   triton_mm_1087 0.0276 ms 81.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2074401Z   triton_mm_1091 0.0297 ms 75.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2075752Z SingleProcess AUTOTUNE benchmarking takes 0.3055 seconds and 2.9005 seconds precompiling for 18 choices
2026-01-14T08:42:57.2076707Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.016ms 
2026-01-14T08:42:57.2077402Z AUTOTUNE int_mm(64x256, 256x128)
2026-01-14T08:42:57.2078090Z   triton_mm_1099 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2079194Z   triton_mm_1100 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2080306Z   triton_mm_1102 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:57.2081413Z   triton_mm_1103 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:42:57.2082518Z   triton_mm_1104 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2083620Z   triton_mm_1105 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2084716Z   triton_mm_1107 0.0215 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:57.2085811Z   triton_mm_1101 0.0215 ms 99.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2086911Z   triton_mm_1108 0.0225 ms 95.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:57.2088016Z   triton_mm_1106 0.0225 ms 95.5% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:42:57.2088992Z SingleProcess AUTOTUNE benchmarking takes 0.2061 seconds and 0.2718 seconds precompiling for 11 choices
2026-01-14T08:42:57.2090037Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.012ms
2026-01-14T08:42:57.2091139Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.024ms 
2026-01-14T08:42:57.2092309Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.00
2026-01-14T08:42:57.2093356Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:57.2093851Z 
2026-01-14T08:42:57.2094165Z [32mPASSED[0m
2026-01-14T08:42:57.2094705Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_20 (m, k, n):  (16, 128, 128)
2026-01-14T08:42:57.2095319Z [32mPASSED[0m
2026-01-14T08:42:57.2095826Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_21 (m, k, n):  (64, 128, 128)
2026-01-14T08:42:57.2096479Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:42:57.2097022Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:42:57.2097666Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:42:57.2098398Z   triton_mm_1123 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:57.2099544Z   triton_mm_1132 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2100779Z   triton_mm_1120 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2101902Z   triton_mm_1121 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2103015Z   triton_mm_1122 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:42:57.2104128Z   triton_mm_1124 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2105241Z   triton_mm_1125 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:42:57.2106347Z   triton_mm_1126 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:42:57.2107472Z   triton_mm_1127 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:42:57.2108693Z   triton_mm_1128 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:42:57.2109928Z SingleProcess AUTOTUNE benchmarking takes 0.3593 seconds and 0.4652 seconds precompiling for 19 choices
2026-01-14T08:43:13.1045059Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:13.1045897Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:43:13.1046627Z   triton_mm_1141 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1048240Z   triton_mm_1142 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1049409Z   triton_mm_1143 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:43:13.1050606Z   triton_mm_1149 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1051746Z   triton_mm_1152 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:13.1052872Z   triton_mm_1138 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:13.1053988Z   triton_mm_1136 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:13.1055115Z   triton_mm_1137 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1056236Z   triton_mm_1139 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:13.1057624Z   triton_mm_1140 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:13.1058626Z SingleProcess AUTOTUNE benchmarking takes 0.3303 seconds and 0.3949 seconds precompiling for 18 choices
2026-01-14T08:43:13.1059583Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:43:13.1060684Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:43:13.1061737Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:43:13.1062115Z 
2026-01-14T08:43:13.1062419Z [32mPASSED[0m
2026-01-14T08:43:13.1062950Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_22 (m, k, n):  (16, 128, 256)
2026-01-14T08:43:13.1063599Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:43:13.1064132Z weight_shape: torch.Size([256, 128]), dtype: torch.float16, bias_shape: torch.Size([256])
2026-01-14T08:43:13.1064635Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:43:13.1065345Z   triton_mm_1167 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:13.1066486Z   triton_mm_1174 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1067617Z   triton_mm_1179 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:13.1068737Z   triton_mm_1163 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:13.1069853Z   triton_mm_1164 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:13.1070970Z   triton_mm_1166 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:13.1072075Z   triton_mm_1168 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1073184Z   triton_mm_1169 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1074343Z   triton_mm_1170 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1075668Z   triton_mm_1171 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:13.1076655Z SingleProcess AUTOTUNE benchmarking takes 0.3560 seconds and 0.3011 seconds precompiling for 19 choices
2026-01-14T08:43:13.1077494Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:13.1078075Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:43:13.1078743Z   triton_mm_1185 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1079869Z   triton_mm_1193 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1080992Z   triton_mm_1192 0.0195 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:43:13.1082113Z   triton_mm_1189 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1083412Z   triton_mm_1195 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:43:13.1084574Z   triton_mm_1186 0.0215 ms 90.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1085679Z   triton_mm_1180 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:13.1087001Z   triton_mm_1181 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:13.1088106Z   triton_mm_1182 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:13.1089222Z   triton_mm_1183 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:13.1090249Z SingleProcess AUTOTUNE benchmarking takes 0.3297 seconds and 0.2673 seconds precompiling for 18 choices
2026-01-14T08:43:13.1091197Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.004ms 
2026-01-14T08:43:13.1092263Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.004ms 
2026-01-14T08:43:13.1093357Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:43:13.1094340Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:13.1094820Z 
2026-01-14T08:43:13.1094955Z [32mPASSED[0m
2026-01-14T08:43:13.1095456Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_23 (m, k, n):  (16, 256, 128)
2026-01-14T08:43:13.1096117Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:43:13.1096644Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:43:13.1097144Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:43:13.1097858Z   triton_mm_1211 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:13.1098988Z   triton_mm_1212 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:13.1100112Z   triton_mm_1221 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1101229Z   triton_mm_1224 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:13.1102364Z   triton_mm_1209 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:13.1103477Z   triton_mm_1214 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:13.1104634Z   triton_mm_1215 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:13.1105750Z   triton_mm_1217 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0435777Z   triton_mm_1219 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0437407Z   triton_mm_1210 0.0225 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0438422Z SingleProcess AUTOTUNE benchmarking takes 0.3505 seconds and 0.3723 seconds precompiling for 19 choices
2026-01-14T08:43:32.0439270Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:32.0439858Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:43:32.0440732Z   triton_mm_1225 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:32.0441877Z   triton_mm_1226 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:32.0443017Z   triton_mm_1227 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0444149Z   triton_mm_1229 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:32.0445288Z   triton_mm_1230 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0446415Z   triton_mm_1231 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0447537Z   triton_mm_1232 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0448670Z   triton_mm_1233 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0449892Z   triton_mm_1234 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0451029Z   triton_mm_1235 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:43:32.0452022Z SingleProcess AUTOTUNE benchmarking takes 0.3245 seconds and 0.3454 seconds precompiling for 18 choices
2026-01-14T08:43:32.0452982Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:43:32.0454047Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:43:32.0455141Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:43:32.0456111Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:32.0456598Z 
2026-01-14T08:43:32.0456918Z [32mPASSED[0m
2026-01-14T08:43:32.0457439Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_24 (m, k, n):  (64, 256, 128)
2026-01-14T08:43:32.0458097Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:43:32.0458634Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:43:32.0459129Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:43:32.0459853Z   triton_mm_1253 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0460981Z   triton_mm_1254 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:32.0462109Z   triton_mm_1256 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0463333Z   triton_mm_1258 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0464455Z   triton_mm_1262 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:43:32.0465587Z   triton_mm_1263 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0466786Z   triton_mm_1265 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0467911Z   triton_mm_1268 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:32.0469093Z   triton_mm_1259 0.0215 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:43:32.0470202Z   triton_mm_1266 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:43:32.0471183Z SingleProcess AUTOTUNE benchmarking takes 0.3450 seconds and 0.5346 seconds precompiling for 19 choices
2026-01-14T08:43:32.0472033Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:32.0472611Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:43:32.0473294Z   triton_mm_1280 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0474418Z   triton_mm_1269 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:32.0475724Z   triton_mm_1270 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0476845Z   triton_mm_1272 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:32.0477958Z   triton_mm_1273 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0479134Z   triton_mm_1275 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:32.0480245Z   triton_mm_1276 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:43:32.0481360Z   triton_mm_1278 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0482482Z   triton_mm_1279 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:43:32.0483598Z   triton_mm_1282 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0484597Z SingleProcess AUTOTUNE benchmarking takes 0.3171 seconds and 0.4661 seconds precompiling for 18 choices
2026-01-14T08:43:32.0485548Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:43:32.0486646Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:43:32.0495626Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:43:32.0496094Z 
2026-01-14T08:43:32.0496435Z [32mPASSED[0m
2026-01-14T08:43:32.0496956Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_25 (m, k, n):  (16, 128, 128)
2026-01-14T08:43:32.0497582Z [32mPASSED[0m
2026-01-14T08:43:32.0498076Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_26 (m, k, n):  (64, 128, 128)
2026-01-14T08:43:32.0498728Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:43:32.0499380Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:43:32.0499891Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:43:32.0500617Z   triton_mm_1305 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:32.0501745Z   triton_mm_1298 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:32.0502867Z   triton_mm_1299 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:32.0503975Z   triton_mm_1300 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:32.0505091Z   triton_mm_1301 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5262920Z   triton_mm_1302 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5264094Z   triton_mm_1306 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:43:52.5265253Z   triton_mm_1307 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5266391Z   triton_mm_1308 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:43:52.5267519Z   triton_mm_1309 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5268512Z SingleProcess AUTOTUNE benchmarking takes 0.3623 seconds and 0.4838 seconds precompiling for 19 choices
2026-01-14T08:43:52.5269368Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:52.5269967Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:43:52.5270656Z   triton_mm_1317 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:52.5271800Z   triton_mm_1321 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:52.5272937Z   triton_mm_1322 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5274060Z   triton_mm_1315 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:52.5275355Z   triton_mm_1318 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5276478Z   triton_mm_1325 0.0205 ms 95.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:43:52.5277987Z   triton_mm_1313 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:52.5279106Z   triton_mm_1316 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:52.5280211Z   triton_mm_1319 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5282149Z   triton_mm_1320 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:43:52.5283132Z SingleProcess AUTOTUNE benchmarking takes 0.3330 seconds and 0.3929 seconds precompiling for 18 choices
2026-01-14T08:43:52.5284092Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:43:52.5285193Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:43:52.5286161Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:43:52.5286653Z 
2026-01-14T08:43:52.5286956Z [32mPASSED[0m
2026-01-14T08:43:52.5287489Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_27 (m, k, n):  (16, 128, 256)
2026-01-14T08:43:52.5288147Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:43:52.5288693Z weight_shape: torch.Size([256, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([256])
2026-01-14T08:43:52.5289193Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:43:52.5290001Z   triton_mm_1356 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:52.5291145Z   triton_mm_1341 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:52.5292256Z   triton_mm_1342 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:43:52.5293368Z   triton_mm_1343 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:52.5294486Z   triton_mm_1345 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5295635Z   triton_mm_1346 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5296747Z   triton_mm_1347 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5297860Z   triton_mm_1349 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5298968Z   triton_mm_1354 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:43:52.5300079Z   triton_mm_1355 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=8
2026-01-14T08:43:52.5301063Z SingleProcess AUTOTUNE benchmarking takes 0.3608 seconds and 0.2809 seconds precompiling for 19 choices
2026-01-14T08:43:52.5301907Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:43:52.5302478Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:43:52.5303261Z   triton_mm_1369 0.0214 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:43:52.5304403Z   triton_mm_1358 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:43:52.5305512Z   triton_mm_1360 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:52.5306713Z   triton_mm_1366 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5307832Z   triton_mm_1368 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5308939Z   triton_mm_1370 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:43:52.5310058Z   triton_mm_1373 0.0215 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:52.5311177Z   triton_mm_1361 0.0216 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:52.5312286Z   triton_mm_1362 0.0216 ms 99.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:43:52.5313404Z   triton_mm_1357 0.0225 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:43:52.5314372Z SingleProcess AUTOTUNE benchmarking takes 0.3313 seconds and 0.2722 seconds precompiling for 18 choices
2026-01-14T08:43:52.5315329Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.005ms 
2026-01-14T08:43:52.5316452Z >>time: 0.004ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.005ms 
2026-01-14T08:43:52.5317547Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.004ms
2026-01-14T08:43:52.5318524Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:43:52.5319005Z 
2026-01-14T08:43:52.5319137Z [32mPASSED[0m
2026-01-14T08:43:52.5319647Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_28 (m, k, n):  (16, 256, 128)
2026-01-14T08:43:52.5320307Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:43:52.5320846Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:43:52.5321352Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:43:52.5322072Z   triton_mm_1401 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:43:52.5323205Z   triton_mm_1388 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:43:52.5324323Z   triton_mm_1389 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:44:12.1317547Z   triton_mm_1391 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1319019Z   triton_mm_1392 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1320162Z   triton_mm_1393 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:44:12.1322217Z   triton_mm_1394 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1323361Z   triton_mm_1396 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1324472Z   triton_mm_1398 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1325762Z   triton_mm_1399 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=4
2026-01-14T08:44:12.1326752Z SingleProcess AUTOTUNE benchmarking takes 0.3525 seconds and 0.3318 seconds precompiling for 19 choices
2026-01-14T08:44:12.1327592Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:12.1328172Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:44:12.1328869Z   triton_mm_1410 0.0195 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:44:12.1330361Z   triton_mm_1408 0.0215 ms 90.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1331534Z   triton_mm_1402 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:44:12.1332657Z   triton_mm_1403 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=2
2026-01-14T08:44:12.1333776Z   triton_mm_1404 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:44:12.1334881Z   triton_mm_1405 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:44:12.1335994Z   triton_mm_1406 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=2
2026-01-14T08:44:12.1337111Z   triton_mm_1407 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1338216Z   triton_mm_1409 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1339327Z   triton_mm_1411 0.0215 ms 90.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1340313Z SingleProcess AUTOTUNE benchmarking takes 0.3249 seconds and 0.3045 seconds precompiling for 18 choices
2026-01-14T08:44:12.1341272Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:44:12.1342347Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.006ms 
2026-01-14T08:44:12.1343438Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:44:12.1344419Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:44:12.1344898Z 
2026-01-14T08:44:12.1345212Z [32mPASSED[0m
2026-01-14T08:44:12.1345742Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_29 (m, k, n):  (64, 256, 128)
2026-01-14T08:44:12.1346407Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:44:12.1346941Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:44:12.1347452Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:44:12.1348282Z   triton_mm_1432 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:44:12.1349413Z   triton_mm_1436 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=8
2026-01-14T08:44:12.1350629Z   triton_mm_1438 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1351811Z   triton_mm_1439 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:44:12.1352941Z   triton_mm_1440 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1354076Z   triton_mm_1443 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:44:12.1355195Z   triton_mm_1445 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:44:12.1356322Z   triton_mm_1442 0.0225 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1357447Z   triton_mm_1429 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:44:12.1358559Z   triton_mm_1430 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1359553Z SingleProcess AUTOTUNE benchmarking takes 0.3465 seconds and 0.5653 seconds precompiling for 19 choices
2026-01-14T08:44:12.1360405Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:44:12.1360984Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:44:12.1361666Z   triton_mm_1452 0.0205 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1362791Z   triton_mm_1450 0.0205 ms 99.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=4
2026-01-14T08:44:12.1363918Z   triton_mm_1446 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=1, num_warps=2
2026-01-14T08:44:12.1365042Z   triton_mm_1447 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1366157Z   triton_mm_1448 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=5, num_warps=8
2026-01-14T08:44:12.1367273Z   triton_mm_1451 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
2026-01-14T08:44:12.1368389Z   triton_mm_1455 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1369509Z   triton_mm_1456 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:44:12.1370691Z   triton_mm_1457 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
2026-01-14T08:44:12.1371898Z   triton_mm_1460 0.0215 ms 95.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=4, num_warps=8
2026-01-14T08:44:12.1372880Z SingleProcess AUTOTUNE benchmarking takes 0.3158 seconds and 0.4846 seconds precompiling for 18 choices
2026-01-14T08:44:12.1373841Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:44:12.1375330Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:44:12.1376381Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:44:12.1376761Z 
2026-01-14T08:44:12.1376900Z [32mPASSED[0m
2026-01-14T08:44:12.1377375Z test/integration/test_integration.py::TestAOTI::test_aoti_00 [33mSKIPPED[0m
2026-01-14T08:44:12.1378082Z test/integration/test_integration.py::TestAOTI::test_aoti_01 [33mSKIPPED[0m
2026-01-14T08:44:12.1378776Z test/integration/test_integration.py::TestAOTI::test_aoti_02 [33mSKIPPED[0m
2026-01-14T08:44:12.1379479Z test/integration/test_integration.py::TestAOTI::test_aoti_03 [33mSKIPPED[0m
2026-01-14T08:44:12.1380169Z test/integration/test_integration.py::TestAOTI::test_aoti_04 [33mSKIPPED[0m
2026-01-14T08:44:12.1380865Z test/integration/test_integration.py::TestAOTI::test_aoti_05 [33mSKIPPED[0m
2026-01-14T08:46:10.9545048Z test/integration/test_integration.py::TestAOTI::test_aoti_06 [33mSKIPPED[0m
2026-01-14T08:46:10.9547987Z test/integration/test_integration.py::TestAOTI::test_aoti_07 [33mSKIPPED[0m
2026-01-14T08:46:10.9549096Z test/integration/test_integration.py::TestAOTI::test_aoti_08 [33mSKIPPED[0m
2026-01-14T08:46:10.9549835Z test/integration/test_integration.py::TestAOTI::test_aoti_09 [33mSKIPPED[0m
2026-01-14T08:46:10.9550554Z test/integration/test_integration.py::TestAOTI::test_aoti_10 [33mSKIPPED[0m
2026-01-14T08:46:10.9551461Z test/integration/test_integration.py::TestAOTI::test_aoti_11 [33mSKIPPED[0m
2026-01-14T08:46:10.9552423Z test/integration/test_integration.py::TestAOTI::test_aoti_12 [33mSKIPPED[0m
2026-01-14T08:46:10.9553394Z test/integration/test_integration.py::TestAOTI::test_aoti_13 [33mSKIPPED[0m
2026-01-14T08:46:10.9554108Z test/integration/test_integration.py::TestAOTI::test_aoti_14 [33mSKIPPED[0m
2026-01-14T08:46:10.9554807Z test/integration/test_integration.py::TestAOTI::test_aoti_15 [33mSKIPPED[0m
2026-01-14T08:46:10.9555500Z test/integration/test_integration.py::TestAOTI::test_aoti_16 [33mSKIPPED[0m
2026-01-14T08:46:10.9556207Z test/integration/test_integration.py::TestAOTI::test_aoti_17 [33mSKIPPED[0m
2026-01-14T08:46:10.9556923Z test/integration/test_integration.py::TestExport::test_export_00 [32mPASSED[0m
2026-01-14T08:46:10.9557654Z test/integration/test_integration.py::TestExport::test_export_01 [32mPASSED[0m
2026-01-14T08:46:10.9558382Z test/integration/test_integration.py::TestExport::test_export_02 [32mPASSED[0m
2026-01-14T08:46:10.9559105Z test/integration/test_integration.py::TestExport::test_export_03 [32mPASSED[0m
2026-01-14T08:46:10.9559836Z test/integration/test_integration.py::TestExport::test_export_04 [32mPASSED[0m
2026-01-14T08:46:10.9560557Z test/integration/test_integration.py::TestExport::test_export_05 [32mPASSED[0m
2026-01-14T08:46:10.9561283Z test/integration/test_integration.py::TestExport::test_export_06 [32mPASSED[0m
2026-01-14T08:46:10.9562002Z test/integration/test_integration.py::TestExport::test_export_07 [32mPASSED[0m
2026-01-14T08:46:10.9562730Z test/integration/test_integration.py::TestExport::test_export_08 [32mPASSED[0m
2026-01-14T08:46:10.9563464Z test/integration/test_integration.py::TestExport::test_export_09 [32mPASSED[0m
2026-01-14T08:46:10.9564188Z test/integration/test_integration.py::TestExport::test_export_10 [32mPASSED[0m
2026-01-14T08:46:10.9564913Z test/integration/test_integration.py::TestExport::test_export_11 [32mPASSED[0m
2026-01-14T08:46:10.9565634Z test/integration/test_integration.py::TestExport::test_export_12 [32mPASSED[0m
2026-01-14T08:46:10.9566359Z test/integration/test_integration.py::TestExport::test_export_13 [32mPASSED[0m
2026-01-14T08:46:10.9567405Z test/integration/test_integration.py::TestExport::test_export_14 [32mPASSED[0m
2026-01-14T08:46:10.9568271Z test/integration/test_integration.py::TestExport::test_export_15 [32mPASSED[0m
2026-01-14T08:46:10.9569003Z test/integration/test_integration.py::TestExport::test_export_16 [32mPASSED[0m
2026-01-14T08:46:10.9569836Z test/integration/test_integration.py::TestExport::test_export_17 [32mPASSED[0m
2026-01-14T08:46:10.9570782Z test/integration/test_integration.py::TestExport::test_export_18 [32mPASSED[0m
2026-01-14T08:46:10.9571502Z test/integration/test_integration.py::TestExport::test_export_19 [32mPASSED[0m
2026-01-14T08:46:10.9572229Z test/integration/test_integration.py::TestExport::test_export_20 [32mPASSED[0m
2026-01-14T08:46:10.9572954Z test/integration/test_integration.py::TestExport::test_export_21 [32mPASSED[0m
2026-01-14T08:46:10.9573674Z test/integration/test_integration.py::TestExport::test_export_22 [32mPASSED[0m
2026-01-14T08:46:10.9574410Z test/integration/test_integration.py::TestExport::test_export_23 [32mPASSED[0m
2026-01-14T08:46:10.9575373Z test/integration/test_integration.py::TestExport::test_export_float8 [33mSKIPPED[0m
2026-01-14T08:46:10.9576243Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_00 [33mSKIPPED[0m
2026-01-14T08:46:10.9577079Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_01 [33mSKIPPED[0m
2026-01-14T08:46:10.9577909Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_02 [33mSKIPPED[0m
2026-01-14T08:46:10.9578735Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_03 [33mSKIPPED[0m
2026-01-14T08:46:10.9579560Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_04 [33mSKIPPED[0m
2026-01-14T08:46:10.9580385Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_05 [32mPASSED[0m
2026-01-14T08:46:10.9581211Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_06 [33mSKIPPED[0m
2026-01-14T08:46:10.9582042Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_07 [33mSKIPPED[0m
2026-01-14T08:46:10.9582870Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_08 [33mSKIPPED[0m
2026-01-14T08:46:10.9583688Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_09 [33mSKIPPED[0m
2026-01-14T08:46:10.9584518Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_10 [33mSKIPPED[0m
2026-01-14T08:46:10.9585331Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_11 [32mPASSED[0m
2026-01-14T08:46:10.9586176Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_12 [33mSKIPPED[0m
2026-01-14T08:46:10.9586999Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_13 [33mSKIPPED[0m
2026-01-14T08:46:10.9587818Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_14 [33mSKIPPED[0m
2026-01-14T08:46:10.9588647Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_15 [33mSKIPPED[0m
2026-01-14T08:46:10.9589475Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_16 [33mSKIPPED[0m
2026-01-14T08:46:10.9590288Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_17 [32mPASSED[0m
2026-01-14T08:46:10.9591157Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cpu [32mPASSED[0m
2026-01-14T08:46:10.9592069Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cuda [32mPASSED[0m
2026-01-14T08:46:10.9593154Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_hf_models_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:10.9594400Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:10.9595734Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:46:10.9596896Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info1 [33mSKIPPED[0m
2026-01-14T08:46:10.9598039Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info2 [33mSKIPPED[0m
2026-01-14T08:46:10.9599186Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info3 [33mSKIPPED[0m
2026-01-14T08:46:10.9600448Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info4 [33mSKIPPED[0m
2026-01-14T08:46:10.9601365Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda [32mPASSED[0m
2026-01-14T08:46:10.9602080Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda [32mPASSED[0m
2026-01-14T08:46:10.9602823Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_0_cuda [33mSKIPPED[0m
2026-01-14T08:46:10.9603608Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_1_cuda [33mSKIPPED[0m
2026-01-14T08:46:10.9604382Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda [32mPASSED[0m
2026-01-14T08:46:10.9605143Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu [32mPASSED[0m
2026-01-14T08:46:10.9605909Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda [32mPASSED[0m
2026-01-14T08:46:10.9606723Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu [32mPASSED[0m
2026-01-14T08:46:10.9607512Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-2-512-128] Relative Error: 0.052789
2026-01-14T08:46:10.9608136Z [32mPASSED[0m
2026-01-14T08:46:10.9608651Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-3-2048-2048] Relative Error: 0.052619
2026-01-14T08:46:10.9609278Z [32mPASSED[0m
2026-01-14T08:46:10.9609841Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-4-3584-640] Relative Error: 0.052605
2026-01-14T08:46:10.9610464Z [32mPASSED[0m
2026-01-14T08:46:10.9610975Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-13-8704-8576] Relative Error: 0.052641
2026-01-14T08:46:10.9611603Z [32mPASSED[0m
2026-01-14T08:46:10.9612119Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-26-18944-1664] Relative Error: 0.052629
2026-01-14T08:46:10.9612760Z [32mPASSED[0m
2026-01-14T08:46:10.9613271Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-67-6656-1408] Relative Error: 0.052626
2026-01-14T08:46:10.9613893Z [32mPASSED[0m
2026-01-14T08:46:10.9614372Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-2-512-128] Relative Error: 0.076733
2026-01-14T08:46:10.9614954Z [32mPASSED[0m
2026-01-14T08:46:10.9615448Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-3-2048-2048] Relative Error: 0.073021
2026-01-14T08:46:10.9616043Z [32mPASSED[0m
2026-01-14T08:46:10.9616531Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-4-3584-640] Relative Error: 0.073371
2026-01-14T08:46:10.9617128Z [32mPASSED[0m
2026-01-14T08:46:10.9617613Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-13-8704-8576] Relative Error: 0.073475
2026-01-14T08:46:10.9618219Z [32mPASSED[0m
2026-01-14T08:46:10.9618711Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-26-18944-1664] Relative Error: 0.073329
2026-01-14T08:46:10.9619331Z [32mPASSED[0m
2026-01-14T08:46:10.9619817Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-67-6656-1408] Relative Error: 0.073540
2026-01-14T08:46:10.9620425Z [32mPASSED[0m
2026-01-14T08:46:10.9621156Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:46:10.9622481Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:46:11.3952543Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:46:11.3954071Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:46:11.3955549Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:46:11.3957395Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:46:11.3958857Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:46:11.3960290Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:46:11.3961736Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:46:11.3963175Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:46:11.3964602Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:46:11.3966095Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:46:11.3967547Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:46:11.3968983Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:46:11.3970482Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[128] [33mSKIPPED[0m
2026-01-14T08:46:11.3971832Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[256] [33mSKIPPED[0m
2026-01-14T08:46:11.3973188Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[128] [33mSKIPPED[0m
2026-01-14T08:46:11.3974550Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[256] [33mSKIPPED[0m
2026-01-14T08:46:11.3976246Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:46:11.3977830Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:46:11.3979415Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:46:11.3980986Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:46:11.3982523Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:46:11.3984010Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:46:11.3985506Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:46:11.3987006Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:46:11.3988680Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[128] [33mSKIPPED[0m
2026-01-14T08:46:11.3990196Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[256] [33mSKIPPED[0m
2026-01-14T08:46:11.3991624Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_fp8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:46:11.3993072Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_int8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:46:11.3994436Z test/prototype/module_swap_quantization/test_kmeans_codebook.py::TestKmeansCodebook::test_kmeans_codebook [33mSKIPPED[0m
2026-01-14T08:46:11.3995773Z test/prototype/module_swap_quantization/test_llm_ptq_data_getter.py::TestPTQDataGetter::test_data_getter [33mSKIPPED[0m
2026-01-14T08:46:11.3997117Z test/prototype/module_swap_quantization/test_module_swap.py::TestEmbeddingSwap::test_embedding_swap [32mPASSED[0m
2026-01-14T08:46:11.3998611Z test/prototype/module_swap_quantization/test_module_swap_quantization_utils.py::TestQuantizedModuleUtils::test_set_bit_widths_by_name [32mPASSED[0m
2026-01-14T08:46:11.4000125Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic [32mPASSED[0m
2026-01-14T08:46:11.4001585Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic_vectorized [32mPASSED[0m
2026-01-14T08:46:11.4003034Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear [32mPASSED[0m
2026-01-14T08:46:11.4004453Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_init [32mPASSED[0m
2026-01-14T08:46:11.4005978Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients [32mPASSED[0m
2026-01-14T08:46:11.4007691Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_activation_scale [32mPASSED[0m
2026-01-14T08:46:11.4009480Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_weight_scale [32mPASSED[0m
2026-01-14T08:46:11.4011273Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_all_options [32mPASSED[0m
2026-01-14T08:46:11.4012943Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_correct [32mPASSED[0m
2026-01-14T08:46:11.4014493Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedEmbedding::test_quantized_embedding [32mPASSED[0m
2026-01-14T08:46:11.4015839Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_qmin_qmax [32mPASSED[0m
2026-01-14T08:46:11.4017126Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max [32mPASSED[0m
2026-01-14T08:46:11.4018535Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max_vectorized [32mPASSED[0m
2026-01-14T08:46:11.4019956Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_asymmetric [32mPASSED[0m
2026-01-14T08:46:11.4021357Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max [32mPASSED[0m
2026-01-14T08:46:11.4022830Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max_tensorized [32mPASSED[0m
2026-01-14T08:46:11.4024273Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_symmetric [32mPASSED[0m
2026-01-14T08:46:11.4025712Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_param_size [32mPASSED[0m
2026-01-14T08:46:11.4026995Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward [32mPASSED[0m
2026-01-14T08:46:11.4028398Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_asymmetric_clipping [32mPASSED[0m
2026-01-14T08:46:11.4029834Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric [32mPASSED[0m
2026-01-14T08:46:11.4031348Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric_clipping [32mPASSED[0m
2026-01-14T08:46:11.4032771Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_codebook_quantizer [32mPASSED[0m
2026-01-14T08:46:11.4034118Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_vector_quantizer [32mPASSED[0m
2026-01-14T08:46:11.4035518Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max [32mPASSED[0m
2026-01-14T08:46:11.4037020Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max_grouped [32mPASSED[0m
2026-01-14T08:46:11.4038463Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse [32mPASSED[0m
2026-01-14T08:46:11.4039887Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse_grouped [32mPASSED[0m
2026-01-14T08:46:18.0601198Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss [32mPASSED[0m
2026-01-14T08:46:18.0602839Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss_progressive [32mPASSED[0m
2026-01-14T08:46:18.0604429Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting [32mPASSED[0m
2026-01-14T08:46:18.0605966Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting_no_input [32mPASSED[0m
2026-01-14T08:46:18.0607447Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales [32mPASSED[0m
2026-01-14T08:46:18.0608998Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales_dont_change_per_channel [32mPASSED[0m
2026-01-14T08:46:18.0610511Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0611770Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0613011Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:46:18.0614246Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0615493Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0616740Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0617983Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0619275Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0620935Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0622237Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0623575Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0625056Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:46:18.0626374Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0627690Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0629070Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0642647Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0643970Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0645288Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:46:18.0646466Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_metadata_torchao [33mSKIPPED[0m
2026-01-14T08:46:18.0647587Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata0 [33mSKIPPED[0m
2026-01-14T08:46:18.0648821Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata1 [33mSKIPPED[0m
2026-01-14T08:46:18.0650054Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata2 [33mSKIPPED[0m
2026-01-14T08:46:18.0651229Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata3 [33mSKIPPED[0m
2026-01-14T08:46:18.0652408Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata4 [33mSKIPPED[0m
2026-01-14T08:46:18.0653578Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata5 [33mSKIPPED[0m
2026-01-14T08:46:18.0654750Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata6 [33mSKIPPED[0m
2026-01-14T08:46:18.0655924Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata7 [33mSKIPPED[0m
2026-01-14T08:46:18.0657101Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata8 [33mSKIPPED[0m
2026-01-14T08:46:18.0658348Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata9 [33mSKIPPED[0m
2026-01-14T08:46:18.0659234Z test/prototype/test_awq.py::TestAWQ::test_awq_config [32mPASSED[0m
2026-01-14T08:46:18.0659991Z test/prototype/test_awq.py::TestAWQ::test_awq_functionality_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:18.0660816Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:18.0661629Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_vllm_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:46:18.0662568Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook [33mSKIPPED[0m
2026-01-14T08:46:18.0665211Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook_row_grouping [33mSKIPPED[0m
2026-01-14T08:46:18.0666370Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [33mSKIPPED[0m
2026-01-14T08:46:18.0667508Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [33mSKIPPED[0m
2026-01-14T08:46:18.0668853Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float_row_grouping [33mSKIPPED[0m
2026-01-14T08:46:18.0669901Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_export [33mSKIPPED[0m
2026-01-14T08:46:18.0670781Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_quantize_api [33mSKIPPED[0m
2026-01-14T08:46:18.0671746Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook [32mPASSED[0m
2026-01-14T08:46:18.0672814Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:46:18.0673930Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [32mPASSED[0m
2026-01-14T08:46:18.0675220Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:46:18.0676139Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_accuracy [33mSKIPPED[0m
2026-01-14T08:46:18.0677460Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:46:18.0679100Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0681179Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0683239Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0685293Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0687345Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0689442Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0806122Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0809194Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0811323Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0813622Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0815833Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0817986Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0820269Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0822418Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0824559Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0826696Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0828844Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0831039Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0833178Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0835321Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0837468Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0839659Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0841788Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0843913Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0846052Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0848321Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0850498Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0853047Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0855771Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0858535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0861245Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0863947Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0866641Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0869388Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0872090Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0874995Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0877696Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0880401Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0976089Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0978807Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0981631Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0984312Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0986987Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0989723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.0992400Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.0995146Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.0997948Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1000734Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1003517Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1006301Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1009209Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1012060Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1014835Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1017702Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1020551Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1023325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1026096Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1028868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1031628Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1034388Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1037156Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1039974Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1042735Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1045594Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1048426Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1151451Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1157037Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1160190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1162956Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1165723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1168541Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1171364Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1174135Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1177105Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1179920Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1182837Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1185598Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1188463Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1191225Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1193971Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1196731Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1199524Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1202238Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1204950Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1207665Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1210462Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1213159Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1215864Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1218693Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1221395Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1224189Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1226892Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1320495Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1323218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1325914Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1328642Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1331408Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1334100Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1336784Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1339584Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1342534Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1345339Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1348300Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1351089Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1353869Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1356657Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1359448Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1362224Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1365015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1367806Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1370685Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1373468Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1376566Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1379348Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1382121Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1385016Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1387799Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1390638Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1393428Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1489960Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1492765Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1495574Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1498368Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1501167Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1503953Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1506874Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1509676Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1512577Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1515365Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1518163Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1520968Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1523740Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1526518Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1529340Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1532181Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1534938Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1537672Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1540556Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1543285Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1546083Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1548794Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1551511Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1554238Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1556958Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1559721Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1562439Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1655584Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1658323Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1661077Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1663786Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1666635Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1669351Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1672178Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1675098Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1677919Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1680782Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1683596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1686405Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1689249Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1692120Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1694929Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1697731Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1700657Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1703467Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1706380Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1709228Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1712008Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1714788Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1717582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1720421Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1723204Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1726001Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1728804Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1824901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1827882Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1830679Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1833460Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1836398Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1839197Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1841977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1844769Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1847565Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1850402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1853190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1855967Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1858791Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1861566Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1864433Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1867207Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1870086Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1872806Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1875733Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1878461Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1881182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1883886Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1886605Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1889371Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1892156Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1894868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1897713Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.1993599Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.1996336Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.1999209Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2001908Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2004609Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2007317Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2010135Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2012898Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2015723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2018588Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2021380Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2024183Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2027106Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2029911Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2032779Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2035582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2038377Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2041182Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2043973Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2046758Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2049604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2052448Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2055224Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2058018Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2060938Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2063725Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2066630Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2162466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2165285Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2168079Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2170922Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2173712Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2176644Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2179487Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2182267Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2185048Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2187976Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2190811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2193578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2196458Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2199244Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2202017Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2204790Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2207550Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2210393Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2213122Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2215860Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2218626Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2221344Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2224152Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2226862Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2229650Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2232366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2235074Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2327730Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2330580Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2333283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2335974Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2338720Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2341419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2344108Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2346865Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2349825Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2352641Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2355553Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2358402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2361196Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2363997Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2366805Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2369645Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2372507Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2375521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2378318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2381114Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2384067Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2386868Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2389815Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2392601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2395384Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2398234Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2401042Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2491309Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2494131Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2496928Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2499767Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2502556Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2505490Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2508293Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2511247Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2514043Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2516830Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2519671Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2522455Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2525222Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2528015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2530901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2533672Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2536419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2539204Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2542018Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2544738Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2547524Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2550288Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2552996Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2555704Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2558404Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2561118Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2563836Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2655154Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2657867Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2660564Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2663391Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2666085Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2668881Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2671571Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2674329Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2677300Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2680111Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2682904Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2685696Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2688538Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2691381Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2694169Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2696961Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2700845Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2703650Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2706560Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2709400Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2712190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2714963Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2717757Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2728954Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2731819Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2734631Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2737437Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2818186Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2821190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2823995Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2826891Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2829686Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2832474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2835264Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2838113Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2840909Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2843697Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2846488Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2849311Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2852153Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2855013Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2857791Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2860652Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2863413Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2866141Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2868882Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2871612Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2874333Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2877191Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2879969Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2882694Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2885407Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2888120Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2891028Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2981867Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2984739Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2987439Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2990188Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.2992898Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.2995597Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.2998333Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3001102Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3003926Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3006728Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3009543Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3012575Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3015381Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3018352Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3021156Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3023951Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3026747Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3029601Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3032383Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3035175Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3037969Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3040757Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3043543Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3046335Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3049254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3052121Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3054993Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3146973Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3151733Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3157313Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3160535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3163328Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3166129Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3168978Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3171832Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3174620Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3177754Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3180593Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3183478Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3186262Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3189048Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3191838Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3194607Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3197366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3200148Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3202869Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3205579Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3208339Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3211204Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3213927Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3216636Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3219435Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3222157Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3224855Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3310663Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3313398Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3316107Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3318863Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3321565Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3324265Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3326962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3329977Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3332803Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3335729Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3338540Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3341343Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3344143Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3346940Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3349794Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3352596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3355401Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3358243Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3361046Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3363917Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3366704Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3369564Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3372414Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3375336Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3378125Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3380932Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3383725Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3486981Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3490305Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3493098Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3495885Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3498684Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3501612Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3504399Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3507302Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3510093Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3512862Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3515655Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3518463Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3521233Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3524009Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:46:18.3526780Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:46:18.3529600Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3532174Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3534534Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3536895Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3539303Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3541732Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3544085Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3546386Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3548700Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3551015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3553365Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3555709Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3558049Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3560366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3678466Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3681109Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3683461Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3685984Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3688335Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3690824Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3693101Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3695412Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3697751Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3700149Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3702497Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3704799Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3707068Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3709435Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3711783Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3714121Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3716469Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3718921Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3721189Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3723576Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3725932Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3728332Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3730716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3733026Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3735296Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3737615Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3740020Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3742366Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3744716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3747026Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3749302Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3751616Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3983582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3985959Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3988427Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:46:18.3990033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_shared_embedding [33mSKIPPED[0m
2026-01-14T08:46:18.3991323Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.3992922Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.3994518Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.3996121Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.3997713Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.3999363Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4000965Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4002567Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4004159Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4005753Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4007347Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4008941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4010624Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4012214Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4013808Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4015488Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4017082Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4018839Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4020441Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4022038Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4023635Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4025233Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4026831Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4028471Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4030070Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4031655Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4033246Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4034832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4036408Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4037996Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4039569Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4041145Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4042728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4044303Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4045992Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4047579Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4049206Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4050924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4052505Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4054084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4055664Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4291255Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4293093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4294883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4296690Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4298506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4300334Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4302140Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4303932Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4305737Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4307544Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4309348Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4311155Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4312957Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4314907Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4316499Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4318076Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4319819Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4321409Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4322999Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4324577Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4326167Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4327751Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4329385Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4331034Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4332610Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4334190Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4335778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4337356Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4338952Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4340539Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4342120Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4343703Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4345292Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4346964Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4348554Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4350126Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4351779Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4353352Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4354929Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4356493Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4358068Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4359648Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4361213Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4362795Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4364362Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4365933Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4602794Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4604395Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4605969Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4607544Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4609114Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4610760Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4612331Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4614053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4615624Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4617200Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4618966Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4620532Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4622115Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4623693Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4625292Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4626899Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4628545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4630156Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4631761Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4633355Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4634963Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4636562Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4638162Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4639769Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4641369Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4642975Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4644583Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4646269Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4647864Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4649523Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4651270Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4652858Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4654467Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4656075Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4657666Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4659326Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4660914Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4662527Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4664126Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4665703Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4667293Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4668887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4670474Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4672060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4673661Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4675416Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4909625Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4911437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4913026Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4914621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4916324Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4917906Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4919554Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4921136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4922731Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4924315Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4925903Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4927494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4929133Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4930787Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4932376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4933957Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4935551Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4937145Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4938746Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4948695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4950404Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4952115Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4953700Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4955283Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4956947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4958574Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4960159Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4961737Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4963311Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4964890Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4966463Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4968044Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4969628Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4971277Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4972876Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4974469Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4976234Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4977817Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4979457Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4981049Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4982637Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.4984371Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.4985956Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.4987541Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.4989293Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.4990865Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5235074Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5238258Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5239947Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5241538Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5243120Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5244695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5246275Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5247863Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5249493Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5251132Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5252710Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5254282Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5255861Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5257437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5259055Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5260791Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5262368Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5263942Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5265642Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5267216Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5268848Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5270379Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5271835Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5273303Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5274970Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5276433Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5277897Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5279416Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5280867Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5282322Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5283768Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5285226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5286671Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5288139Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5289621Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5291125Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5292699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5294161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5295630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5298260Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5299705Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5301167Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5302636Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5304101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:46:18.5305542Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:46:18.5307084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5308735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5310324Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5544098Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5545710Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5547308Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5548945Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5550550Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5552140Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5553733Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5555334Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5556914Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5558708Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5560308Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5561890Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5563592Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5565184Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5566781Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5568372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5570089Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5571682Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5573277Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5575024Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5576622Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5578273Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5579873Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5581448Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5583038Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5584608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5586189Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5587778Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5589389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5591103Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5592688Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5594251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5595946Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5597524Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5599105Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5600683Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5602274Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5603850Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5605439Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5607033Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5608655Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5610288Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5611869Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5613438Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5615019Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5616609Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5853746Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5855357Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5856943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5858707Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5860299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5861887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5863581Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5865161Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5866749Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5868355Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5869951Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5871541Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5873114Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5874905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5876486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5878059Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5879638Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5881211Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5882805Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5884384Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5885962Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5887542Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5889165Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5890969Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5892559Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5894141Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5895825Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5897399Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5898976Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5900533Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5902101Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5903673Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5905233Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5906805Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5908416Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5909984Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5911560Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5913116Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5914697Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5916277Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5917834Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.5919455Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.5921010Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.5922659Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.5924226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.5925790Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6167914Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6169600Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6171218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6172772Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6174335Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6176114Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6177706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6179350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6180940Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6182534Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6184131Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6185719Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6187323Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6188965Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6190548Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6192140Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6193724Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6195465Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6197062Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6198650Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6200364Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6201957Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6203557Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6205145Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6206735Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6208380Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6210023Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6211616Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6213203Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6214787Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6216389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6217973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6219605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6221185Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6222759Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6224337Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6225919Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6227585Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6229164Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6230738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6232462Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6234033Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6235620Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6237193Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6238766Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6240357Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6474545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6476349Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6477930Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6479556Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6481130Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6482710Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6484291Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6485867Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6487453Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6489040Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6490676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6492428Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6494014Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6495590Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6497282Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6498916Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6500500Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6502078Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6503647Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6505240Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6506821Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6508407Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6509986Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6511571Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6513154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6514740Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6516327Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6517905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6519535Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6521122Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6522694Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6524360Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6525944Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6527522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6529222Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6530849Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6532426Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6533994Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6535555Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6537132Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6538752Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6540320Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6541891Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6543461Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6545031Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6546595Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6780651Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6782247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6783818Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6785392Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6786958Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6788730Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6790310Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6791879Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6793577Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6795154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6796732Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6798349Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6799939Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6801522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6803120Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6804725Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6806320Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6807921Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6809525Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6811182Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6812777Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6814373Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6815964Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6817572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6819223Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6820915Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6822522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6824115Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6825827Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6827428Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6829075Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6830674Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6832278Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6833872Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6835473Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6837078Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6838678Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6840287Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6841890Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6843468Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6845056Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.6846643Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.6848249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.6849915Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.6851495Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.6853162Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7092572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7094188Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7095924Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7097516Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7099180Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7100772Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7102382Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7103982Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7105569Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7107169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7108765Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7110347Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7111941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7113524Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7115124Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7116721Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7118332Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7119968Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7121569Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7123279Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7124876Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7126483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7128180Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7129885Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7131494Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7133083Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7134690Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7136284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7137875Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7139498Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7141088Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7142672Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7144264Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7145862Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7147451Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7149042Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7150622Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7152233Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7153831Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7155510Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7157107Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7158752Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7160422Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7162003Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7163592Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7165171Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7396431Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7398274Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7399904Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7401513Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7403126Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7404717Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7406323Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7407929Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7409522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7411190Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7412780Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7414373Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7415975Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7417736Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7419389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7420976Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7422706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7424289Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7425885Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7427477Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7429112Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7430726Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7432332Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7433954Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7435570Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7444507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7446222Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7447815Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7449456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7451257Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7453046Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7454843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7456641Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7458549Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7460147Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7461741Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7463404Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7464988Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7466592Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7468178Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7469766Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7471366Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7472941Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7474545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7476403Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7477976Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7702154Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7703921Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7705524Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7707100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7708729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7710307Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7711886Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7713630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7715209Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7716783Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7718480Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7720097Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7721676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7723251Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7724815Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7726402Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7727978Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7729603Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7731258Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7732832Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7734409Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7735982Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7737558Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7739137Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7740709Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7742287Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7743869Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7745543Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7747123Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7748761Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7750424Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7752006Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7753588Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7755166Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7756749Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7758383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7759964Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7761541Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7763124Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7764700Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7766276Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.7767857Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.7769435Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.7771063Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.7772641Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.7774227Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8066498Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8068247Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8071665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8075485Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8078523Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8080088Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8081660Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8083234Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8084796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8086379Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8087951Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8089517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8091177Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8092744Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8094315Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8095889Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8097457Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8099017Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8100587Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8102156Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8103719Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8105407Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8107183Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8108993Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8110845Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:18.8112606Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:18.8114169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:46:18.8115739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:46:18.8117292Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:46:18.8118622Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_bfloat16 [33mSKIPPED[0m
2026-01-14T08:46:18.8119661Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float16 [33mSKIPPED[0m
2026-01-14T08:46:18.8120673Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float32 [33mSKIPPED[0m
2026-01-14T08:46:18.8121633Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_choose_qparams_gguf [32mPASSED[0m
2026-01-14T08:46:18.8122602Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_gguf_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:46:18.8123515Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:46:18.8124620Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_00 [33mSKIPPED[0m
2026-01-14T08:46:18.8125966Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_01 [33mSKIPPED[0m
2026-01-14T08:46:18.8127305Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_02 [33mSKIPPED[0m
2026-01-14T08:46:18.8128639Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_03 [33mSKIPPED[0m
2026-01-14T08:46:18.8130041Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_04 [33mSKIPPED[0m
2026-01-14T08:46:18.8131378Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_05 [33mSKIPPED[0m
2026-01-14T08:46:18.8132712Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_06 [33mSKIPPED[0m
2026-01-14T08:46:18.8134062Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_07 [33mSKIPPED[0m
2026-01-14T08:46:18.8135410Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_08 [33mSKIPPED[0m
2026-01-14T08:46:18.8136748Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_09 [33mSKIPPED[0m
2026-01-14T08:46:18.8138183Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_10 [33mSKIPPED[0m
2026-01-14T08:46:18.8139527Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_11 [33mSKIPPED[0m
2026-01-14T08:46:18.8140857Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_12 [33mSKIPPED[0m
2026-01-14T08:46:18.8142280Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_13 [33mSKIPPED[0m
2026-01-14T08:46:18.8143616Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_14 [33mSKIPPED[0m
2026-01-14T08:46:18.8144951Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_15 [33mSKIPPED[0m
2026-01-14T08:46:18.8146266Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_00 [33mSKIPPED[0m
2026-01-14T08:46:35.4842677Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_01 [33mSKIPPED[0m
2026-01-14T08:46:35.4844372Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_02 [33mSKIPPED[0m
2026-01-14T08:46:35.4845964Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_03 [33mSKIPPED[0m
2026-01-14T08:46:35.4847523Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_04 [33mSKIPPED[0m
2026-01-14T08:46:35.4849076Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_05 [33mSKIPPED[0m
2026-01-14T08:46:35.4850731Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_06 [33mSKIPPED[0m
2026-01-14T08:46:35.4852288Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_07 [33mSKIPPED[0m
2026-01-14T08:46:35.4853827Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_08 [33mSKIPPED[0m
2026-01-14T08:46:35.4855395Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_09 [33mSKIPPED[0m
2026-01-14T08:46:35.4856961Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_10 [33mSKIPPED[0m
2026-01-14T08:46:35.4858516Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_11 [33mSKIPPED[0m
2026-01-14T08:46:35.4860093Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_12 [33mSKIPPED[0m
2026-01-14T08:46:35.4861647Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_13 [33mSKIPPED[0m
2026-01-14T08:46:35.4863264Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_14 [33mSKIPPED[0m
2026-01-14T08:46:35.4864836Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_15 [33mSKIPPED[0m
2026-01-14T08:46:35.4866300Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4867657Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4869108Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4871100Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4872598Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4874141Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4876034Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4877512Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4878988Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4880523Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4882332Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4884132Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4885942Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4887751Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4889554Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4891478Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4893290Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4895126Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4896927Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4898719Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4900543Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4902374Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4904246Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4906045Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4907858Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4909683Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4911495Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4913281Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4915252Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4917017Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4918801Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4920732Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4922529Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4924369Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4926174Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4927953Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4929753Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4931645Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4933340Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4934822Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4936298Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4937770Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4939240Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.4940710Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.4942455Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8139617Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8140921Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8142136Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8143389Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8144630Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8145876Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8147115Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8148331Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8149854Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8151083Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8152291Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8153634Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8154719Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8155804Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8156892Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8157970Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_False [32mPASSED[0m
2026-01-14T08:46:35.8159054Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_True [32mPASSED[0m
2026-01-14T08:46:35.8160086Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8161096Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8162092Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8163078Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8164070Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8165049Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8166040Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8167028Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8168013Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8168997Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8170048Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8171033Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8172023Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8172999Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8173980Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8175190Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8176178Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8177160Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8178136Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8179251Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8180337Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8181553Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8182738Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8184096Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8185271Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8186448Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8187627Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8188806Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8189974Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8191195Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8192378Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8193548Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8194675Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8195749Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8196837Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8197915Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8198980Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8200073Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8201143Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8202220Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8203301Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8204380Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8205454Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8206522Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8207598Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8208674Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8209750Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8210923Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8211987Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8214636Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8215732Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8216821Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8217896Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:35.8219060Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:35.8220139Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1086212Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1087197Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1088121Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1089025Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1090002Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1090903Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1091821Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1092712Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1093608Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1094554Z test/prototype/test_mixed_precision.py::TestWeightOnlyQuantNaive::test_quantization_intNwo [32mPASSED[0m
2026-01-14T08:46:43.1095458Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace [32mPASSED[0m
2026-01-14T08:46:43.1096293Z test/prototype/test_parametrization.py::TestFakeSparsity::test_masking_logic [32mPASSED[0m
2026-01-14T08:46:43.1097172Z test/prototype/test_parametrization.py::TestFakeSparsity::test_state_dict_preserved [32mPASSED[0m
2026-01-14T08:46:43.1098093Z test/prototype/test_parametrization.py::TestFakeSparsity::test_weights_parametrized [32mPASSED[0m
2026-01-14T08:46:43.1098932Z test/prototype/test_paretoq.py::TestParetoQ::test_quantize_functions [32mPASSED[0m
2026-01-14T08:46:43.1099677Z test/prototype/test_paretoq.py::TestParetoQ::test_quantized_linear [32mPASSED[0m
2026-01-14T08:46:43.1100741Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1102069Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1103393Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1104696Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1106063Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1107380Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1108679Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1110421Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1111749Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1113066Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1114553Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1115907Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1117218Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1118533Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1119831Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1121128Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1122446Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1123761Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1125078Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1126389Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1127702Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1129016Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1130375Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1131674Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1132982Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1134302Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1135615Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1136978Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1138285Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1139593Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1140987Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:46:43.1142290Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:46:43.1143375Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_e2e [33mSKIPPED[0m
2026-01-14T08:46:43.1144318Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_256 [33mSKIPPED[0m
2026-01-14T08:46:43.1145405Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_32 [33mSKIPPED[0m
2026-01-14T08:46:43.1146428Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.1147433Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_512 [32mPASSED[0m
2026-01-14T08:46:43.1148443Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.1149440Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_512 [32mPASSED[0m
2026-01-14T08:46:43.1150442Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.1151437Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_512 [32mPASSED[0m
2026-01-14T08:46:43.1152445Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.1153445Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_512 [32mPASSED[0m
2026-01-14T08:46:43.1154399Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_2 [32mPASSED[0m
2026-01-14T08:46:43.1155330Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_3 [32mPASSED[0m
2026-01-14T08:46:43.1156247Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_4 [32mPASSED[0m
2026-01-14T08:46:43.1157164Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_8 [32mPASSED[0m
2026-01-14T08:46:43.1158100Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only [32mPASSED[0m
2026-01-14T08:46:43.1159068Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_e2e [32mPASSED[0m
2026-01-14T08:46:43.4728916Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_parq_equivalent [32mPASSED[0m
2026-01-14T08:46:43.4730135Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_tied_embed_linear [32mPASSED[0m
2026-01-14T08:46:43.4731465Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4732923Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4734377Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4735867Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4737302Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4738737Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4740188Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4749421Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4750978Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4752422Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4753989Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4755432Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4756927Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4758373Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4759814Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4761249Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4762690Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4764121Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4765576Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4767078Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4768516Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4770028Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4771472Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:46:43.4772908Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:46:43.4774119Z test/prototype/test_parq.py::TestTorchAoConfigIntegration::test_tied_weights_quantization [32mPASSED[0m
2026-01-14T08:46:43.4775443Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:43.4776753Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:43.4778180Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4779716Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4781387Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4782930Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4784454Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4786105Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4787632Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4789147Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4790684Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4792201Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4793730Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4795252Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4796815Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4798346Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4799861Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:46:43.4801363Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:46:43.4802785Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity0 [33mSKIPPED[0m
2026-01-14T08:46:43.4804121Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity1 [33mSKIPPED[0m
2026-01-14T08:46:43.4805317Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_False [33mSKIPPED[0m
2026-01-14T08:46:43.4806464Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_True [33mSKIPPED[0m
2026-01-14T08:46:43.4807734Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:46:43.4809175Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:46:43.4810670Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:46:43.4812099Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9235304Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9236972Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9238428Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9240119Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9241551Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9242983Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9244421Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9245849Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9247280Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9248720Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9250236Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:48:57.9251685Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:48:57.9252961Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9254111Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9255377Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9256742Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9258109Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9259470Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9260820Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9262184Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9263534Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9264892Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9266302Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9267746Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9269114Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9270474Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9271928Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9273338Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9274919Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9276383Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9277784Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9279183Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9280592Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9281996Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9283400Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9284819Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9286222Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9287617Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9288969Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9290306Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9291595Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cpu [32mPASSED[0m
2026-01-14T08:48:57.9292865Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cuda [32mPASSED[0m
2026-01-14T08:48:57.9293867Z test/prototype/test_quantized_training.py::TestFSDP2::test_fsdp2_correctness dist init r=0, world=2
2026-01-14T08:48:57.9294442Z dist init r=1, world=2
2026-01-14T08:48:57.9295442Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9296517Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9297543Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9298590Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9299745Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9300799Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9301809Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9302958Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9303964Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9305001Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9306043Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9307100Z   warnings.warn(  # warn only once
2026-01-14T08:48:57.9308113Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:48:57.9309155Z   warnings.warn(  # warn only once
2026-01-14T08:49:07.9262943Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
2026-01-14T08:49:07.9264067Z   warnings.warn(  # warn only once
2026-01-14T08:49:07.9264602Z [32mPASSED[0m
2026-01-14T08:49:07.9265137Z test/prototype/test_quantized_training.py::TestFSDP2::test_precompute_bitnet_scale dist init r=1, world=2
2026-01-14T08:49:07.9265737Z dist init r=0, world=2
2026-01-14T08:49:07.9266037Z [32mPASSED[0m
2026-01-14T08:49:07.9266540Z test/prototype/test_scheduler.py::TestScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9267319Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler [32mPASSED[0m
2026-01-14T08:49:07.9268094Z test/prototype/test_scheduler.py::TestScheduler::test_order_of_steps [32mPASSED[0m
2026-01-14T08:49:07.9268823Z test/prototype/test_scheduler.py::TestScheduler::test_step [32mPASSED[0m
2026-01-14T08:49:07.9269563Z test/prototype/test_scheduler.py::TestCubicScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9270326Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step [32mPASSED[0m
2026-01-14T08:49:07.9271192Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_observer_insertion_base_config0 [32mPASSED[0m
2026-01-14T08:49:07.9272168Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_prepare_for_loading_base_config0 [32mPASSED[0m
2026-01-14T08:49:07.9273321Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:49:07.9274586Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:49:07.9276145Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:49:07.9277779Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:49:07.9278800Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9279586Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_convert [32mPASSED[0m
2026-01-14T08:49:07.9280355Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:07.9281707Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params1 [32mPASSED[0m
2026-01-14T08:49:07.9282641Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params2 [32mPASSED[0m
2026-01-14T08:49:07.9283567Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params3 [32mPASSED[0m
2026-01-14T08:49:07.9284431Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_prepare_config [32mPASSED[0m
2026-01-14T08:49:07.9285389Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_state_dict [32mPASSED[0m
2026-01-14T08:49:07.9286144Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:07.9286948Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9287819Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:07.9288712Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:49:07.9289580Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:49:07.9290519Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:07.9291338Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step_2_of_4 [32mPASSED[0m
2026-01-14T08:49:07.9292239Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9293145Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:49:07.9294038Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:49:07.9294950Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:49:07.9295841Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_step [32mPASSED[0m
2026-01-14T08:49:07.9296734Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module [32mPASSED[0m
2026-01-14T08:49:07.9297704Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_fail [32mPASSED[0m
2026-01-14T08:49:07.9298760Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_for_tensors [32mPASSED[0m
2026-01-14T08:49:07.9299824Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn [32mPASSED[0m
2026-01-14T08:49:07.9300928Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn_fail [32mPASSED[0m
2026-01-14T08:49:07.9301938Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn [32mPASSED[0m
2026-01-14T08:49:07.9302892Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_fail [32mPASSED[0m
2026-01-14T08:49:07.9303868Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_root [32mPASSED[0m
2026-01-14T08:49:07.9304911Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_lstm_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:49:07.9305999Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:49:07.9307050Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9308096Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:49:07.9309187Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9310242Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_linear [32mPASSED[0m
2026-01-14T08:49:07.9311478Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_activation_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9312655Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_bias_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9313780Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9315113Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_padding_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9316363Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_pool_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9317688Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_activation_linear [32mPASSED[0m
2026-01-14T08:49:07.9318917Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_bias_linear [32mPASSED[0m
2026-01-14T08:49:07.9320042Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_linear [32mPASSED[0m
2026-01-14T08:49:07.9321250Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:49:07.9322548Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_single_layer [32mPASSED[0m
2026-01-14T08:49:07.9323808Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:49:07.9325018Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_single_layer [32mPASSED[0m
2026-01-14T08:49:07.9326412Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_conv2d [32mPASSED[0m
2026-01-14T08:49:07.9327448Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_linear [32mPASSED[0m
2026-01-14T08:49:07.9328424Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_compute_distance [32mPASSED[0m
2026-01-14T08:49:07.9329316Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_update_mask [32mPASSED[0m
2026-01-14T08:49:07.9330355Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:07.9331430Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:07.9332489Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:07.9333544Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:07.9334611Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:07.9335671Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:07.9336722Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:07.9337785Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:07.9338837Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:07.9339902Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7573563Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7574843Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7576252Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7577334Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7578390Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7579452Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7580631Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7581677Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7582731Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7583786Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7584832Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7585888Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7586931Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7587988Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7589033Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7590086Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7591147Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7592189Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7593237Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7594286Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7595336Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7596384Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7597432Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7598667Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7599715Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7600811Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7601867Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7602911Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7603961Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7605015Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7606147Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7607199Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7608243Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7609297Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7610594Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7611638Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7612689Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:49:10.7613742Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:49:10.7614673Z test/prototype/test_tensor_conversion.py::test_int4_tensor_conversion [33mSKIPPED[0m
2026-01-14T08:49:10.7615657Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_attention_block [33mSKIPPED[0m
2026-01-14T08:49:10.7616745Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d [33mSKIPPED[0m
2026-01-14T08:49:10.7617831Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:49:10.7618957Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:49:10.7620161Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:49:10.7621354Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_filter_linear_recipe [33mSKIPPED[0m
2026-01-14T08:49:10.7622457Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear [33mSKIPPED[0m
2026-01-14T08:49:10.7623533Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary [33mSKIPPED[0m
2026-01-14T08:49:10.7624678Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic [33mSKIPPED[0m
2026-01-14T08:49:10.7625886Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic_qat [33mSKIPPED[0m
2026-01-14T08:49:10.7627070Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_qat [33mSKIPPED[0m
2026-01-14T08:49:10.7628178Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d [33mSKIPPED[0m
2026-01-14T08:49:10.7629307Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:49:10.7630523Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:49:10.7631711Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:49:10.7632995Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case1 [33mSKIPPED[0m
2026-01-14T08:49:10.7634357Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case2 [33mSKIPPED[0m
2026-01-14T08:49:10.7635757Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:49:10.7637191Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig [33mSKIPPED[0m
2026-01-14T08:49:10.7638496Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_for_dynamic_quant [33mSKIPPED[0m
2026-01-14T08:49:10.7639871Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_with_underscores [33mSKIPPED[0m
2026-01-14T08:49:10.7641291Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:49:10.7642477Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_avgpool_use_different_qconfig [32mPASSED[0m
2026-01-14T08:49:10.7643534Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_add_quant_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:10.7644563Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_need_for_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:10.7645562Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_simple_duplicate_dq [32mPASSED[0m
2026-01-14T08:49:10.7646493Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu [32mPASSED[0m
2026-01-14T08:49:10.7647737Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu W0114 08:49:10.648000 1006 site-packages/torch/fx/experimental/symbolic_shapes.py:2704] Failed to reduce inequalities: 1/2
2026-01-14T08:49:10.7648771Z [32mPASSED[0m
2026-01-14T08:49:33.1785586Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict W0114 08:49:10.756000 1006 site-packages/torch/fx/experimental/symbolic_shapes.py:2704] Failed to reduce inequalities: 1/2
2026-01-14T08:49:33.1787625Z [32mPASSED[0m
2026-01-14T08:49:33.1788516Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_calculate_qparams [32mPASSED[0m
2026-01-14T08:49:33.1789967Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_disable_range_learning [32mPASSED[0m
2026-01-14T08:49:33.1791372Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_observer [32mPASSED[0m
2026-01-14T08:49:33.1792736Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_range_learning [32mPASSED[0m
2026-01-14T08:49:33.1794119Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_error_conditions [32mPASSED[0m
2026-01-14T08:49:33.1795547Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_and_observer_control [32mPASSED[0m
2026-01-14T08:49:33.1797019Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_control [32mPASSED[0m
2026-01-14T08:49:33.1798427Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_fake_quant_disabled [32mPASSED[0m
2026-01-14T08:49:33.1799880Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_learning_enabled [32mPASSED[0m
2026-01-14T08:49:33.1801303Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_observer_enabled [32mPASSED[0m
2026-01-14T08:49:33.1802684Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_gradient_scaling [32mPASSED[0m
2026-01-14T08:49:33.1804082Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_channel [32mPASSED[0m
2026-01-14T08:49:33.1805535Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_tensor [32mPASSED[0m
2026-01-14T08:49:33.1807001Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_backward_per_tensor [32mPASSED[0m
2026-01-14T08:49:33.1808724Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_forward_per_tensor [32mPASSED[0m
2026-01-14T08:49:33.1810332Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_per_channel_quantization [32mPASSED[0m
2026-01-14T08:49:33.1811775Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_state_persistence [32mPASSED[0m
2026-01-14T08:49:33.1813101Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_symmetric_quantization [32mPASSED[0m
2026-01-14T08:49:33.1814345Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_device_compatibility [32mPASSED[0m
2026-01-14T08:49:33.1815684Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_integration_with_linear_layer [32mPASSED[0m
2026-01-14T08:49:33.1817061Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_multiple_fake_quant_modules [32mPASSED[0m
2026-01-14T08:49:33.1818480Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_optimizer_updates_scale_and_zero_point [32mPASSED[0m
2026-01-14T08:49:33.1819863Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_training_mode_switching [32mPASSED[0m
2026-01-14T08:49:33.1821230Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_numerical_consistency_per_tensor [32mPASSED[0m
2026-01-14T08:49:33.1822534Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_serialization [32mPASSED[0m
2026-01-14T08:49:33.1823672Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq [33mSKIPPED[0m
2026-01-14T08:49:33.1824788Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq_no_static_q [32mPASSED[0m
2026-01-14T08:49:33.1825905Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_two_dq [32mPASSED[0m
2026-01-14T08:49:33.1827054Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_with_no_quant_inbetween [32mPASSED[0m
2026-01-14T08:49:33.1828161Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting [32mPASSED[0m
2026-01-14T08:49:33.1829270Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting_through_unknown_ops [32mPASSED[0m
2026-01-14T08:49:33.1830386Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_simple_metadata_porting [32mPASSED[0m
2026-01-14T08:49:33.1831477Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_added_node_gets_unique_id [33mSKIPPED[0m
2026-01-14T08:49:33.1832550Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_control_flow [33mSKIPPED[0m
2026-01-14T08:49:33.1833604Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_copy_preserve_handle [33mSKIPPED[0m
2026-01-14T08:49:33.1834714Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_deepcopy_preserve_handle [33mSKIPPED[0m
2026-01-14T08:49:33.1835922Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_prepare_for_propagation_comparison [33mSKIPPED[0m
2026-01-14T08:49:33.1837127Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_re_export_preserve_handle [33mSKIPPED[0m
2026-01-14T08:49:33.1838352Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_map_handle_to_new_nodes [33mSKIPPED[0m
2026-01-14T08:49:33.1839613Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_same_handle_id [33mSKIPPED[0m
2026-01-14T08:49:33.1840774Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_simple [33mSKIPPED[0m
2026-01-14T08:49:33.1841791Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval [32mPASSED[0m
2026-01-14T08:49:33.1842900Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval_idempotent [32mPASSED[0m
2026-01-14T08:49:33.1843954Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing [32mPASSED[0m
2026-01-14T08:49:33.1845115Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing_with_shared_input_edge [32mPASSED[0m
2026-01-14T08:49:33.1846202Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_chunked_bn_fusion [32mPASSED[0m
2026-01-14T08:49:33.1848446Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_linear_conv [W114 08:49:33.640559411 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:33.1851646Z [W114 08:49:33.640592191 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:33.1854323Z [W114 08:49:33.640604451 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:33.1857041Z [W114 08:49:33.640620962 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:33.1859712Z [W114 08:49:33.640640062 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:49:33.1862382Z [W114 08:49:33.640646712 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8602669Z [W114 08:49:33.640662833 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8605404Z [W114 08:49:33.640671633 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8608395Z [W114 08:49:33.640702233 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8611138Z [W114 08:49:33.640718414 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8613985Z [W114 08:49:33.640725624 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8616659Z [W114 08:49:33.640734324 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8619317Z [W114 08:49:33.640751804 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8621991Z [W114 08:49:33.640765545 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8624669Z [W114 08:49:33.640792835 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8627333Z [W114 08:49:33.640810726 PyInterpreter.cpp:263] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:50:19.8629030Z [32mPASSED[0m
2026-01-14T08:50:19.8629687Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_throw [32mPASSED[0m
2026-01-14T08:50:19.8630824Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_transform_for_annotation [32mPASSED[0m
2026-01-14T08:50:19.8631903Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_folding_pass [32mPASSED[0m
2026-01-14T08:50:19.8632933Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_prop_preserve_metadata [32mPASSED[0m
2026-01-14T08:50:19.8633908Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv3d_bn_relu [32mPASSED[0m
2026-01-14T08:50:19.8634843Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_padding_bn_relu [32mPASSED[0m
2026-01-14T08:50:19.8635846Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose3d_bn_relu [32mPASSED[0m
2026-01-14T08:50:19.8636827Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:50:19.8637764Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec [32mPASSED[0m
2026-01-14T08:50:19.8638720Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec_per_channel [32mPASSED[0m
2026-01-14T08:50:19.8639786Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_disallow_eval_train [32mPASSED[0m
2026-01-14T08:50:19.8640814Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_dont_fold_other_constant [32mPASSED[0m
2026-01-14T08:50:19.8641855Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization [32mPASSED[0m
2026-01-14T08:50:19.8642877Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer [32mPASSED[0m
2026-01-14T08:50:19.8643984Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_observer_dedup [32mPASSED[0m
2026-01-14T08:50:19.8645020Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_ptq [32mPASSED[0m
2026-01-14T08:50:19.8646006Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_qat [32mPASSED[0m
2026-01-14T08:50:19.8647005Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize [32mPASSED[0m
2026-01-14T08:50:19.8647967Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize [32mPASSED[0m
2026-01-14T08:50:19.8648919Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize_per_channel [32mPASSED[0m
2026-01-14T08:50:19.8650047Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_groupwise_per_channel_quant [32mPASSED[0m
2026-01-14T08:50:19.8651061Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_input_edge_sanity_check [32mPASSED[0m
2026-01-14T08:50:19.8652029Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_max_pool2d_quantizer [32mPASSED[0m
2026-01-14T08:50:19.8652972Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported [32mPASSED[0m
2026-01-14T08:50:19.8653980Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cpu [32mPASSED[0m
2026-01-14T08:50:19.8655053Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cuda [32mPASSED[0m
2026-01-14T08:50:19.8656101Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout [32mPASSED[0m
2026-01-14T08:50:19.8657156Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout_inplace [32mPASSED[0m
2026-01-14T08:50:19.8658260Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_multi_users_without_output_observer [32mPASSED[0m
2026-01-14T08:50:19.8659262Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_observer_callback [32mPASSED[0m
2026-01-14T08:50:19.8660234Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_prepare_obs_or_fq_callback [32mPASSED[0m
2026-01-14T08:50:19.8661234Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_preserve_nn_module_stack [32mPASSED[0m
2026-01-14T08:50:19.8662311Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:50:19.8663450Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e5m2 [32mPASSED[0m
2026-01-14T08:50:19.8664554Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_int16 [32mPASSED[0m
2026-01-14T08:50:19.8665655Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:50:19.8666787Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e5m2 [32mPASSED[0m
2026-01-14T08:50:19.8667873Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_int16 [32mPASSED[0m
2026-01-14T08:50:19.8668823Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantize_in_place_ops input_act1 is a node
2026-01-14T08:50:19.8669467Z [32mPASSED[0m
2026-01-14T08:50:19.8670142Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant [32mPASSED[0m
2026-01-14T08:50:19.8671003Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load [32mPASSED[0m
2026-01-14T08:50:19.8671861Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec [32mPASSED[0m
2026-01-14T08:50:19.8672812Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity [32mPASSED[0m
2026-01-14T08:51:00.8164596Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity_case_2 [32mPASSED[0m
2026-01-14T08:51:00.8165876Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_simple_quantizer [32mPASSED[0m
2026-01-14T08:51:00.8166933Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_speed [32mPASSED[0m
2026-01-14T08:51:00.8168065Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_transform_for_annotation [32mPASSED[0m
2026-01-14T08:51:00.8169319Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_wo_annotate_conv_output_quantizer [32mPASSED[0m
2026-01-14T08:51:00.8170769Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_channel_group_quantization prepared model: GraphModule(
2026-01-14T08:51:00.8171711Z   (linear): Module()
2026-01-14T08:51:00.8172133Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:51:00.8172746Z   (activation_post_process_0): AffineQuantizedMinMaxObserver()
2026-01-14T08:51:00.8173210Z )
2026-01-14T08:51:00.8173355Z 
2026-01-14T08:51:00.8173360Z 
2026-01-14T08:51:00.8173365Z 
2026-01-14T08:51:00.8173476Z def forward(self, x):
2026-01-14T08:51:00.8173845Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:00.8174316Z     linear_weight = self.linear.weight
2026-01-14T08:51:00.8175189Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:51:00.8175866Z     linear_bias = self.linear.bias
2026-01-14T08:51:00.8176386Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:00.8177651Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:51:00.8178850Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:00.8179280Z     
2026-01-14T08:51:00.8179660Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:00.8180169Z quantized model GraphModule(
2026-01-14T08:51:00.8180489Z   (linear): Module()
2026-01-14T08:51:00.8180765Z )
2026-01-14T08:51:00.8180893Z 
2026-01-14T08:51:00.8180898Z 
2026-01-14T08:51:00.8180903Z 
2026-01-14T08:51:00.8181011Z def forward(self, x):
2026-01-14T08:51:00.8181385Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:00.8181832Z     _scale0 = self._scale0
2026-01-14T08:51:00.8182157Z     _zero_point0 = self._zero_point0
2026-01-14T08:51:00.8182533Z     quantize_affine = self._frozen_param0
2026-01-14T08:51:00.8183705Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:51:00.8184892Z     linear_bias = self.linear.bias
2026-01-14T08:51:00.8185232Z     _scale1 = self._scale1
2026-01-14T08:51:00.8185551Z     _zero_point1 = self._zero_point1
2026-01-14T08:51:00.8186273Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255);  x = None
2026-01-14T08:51:00.8187838Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine_1 = _scale1 = _zero_point1 = None
2026-01-14T08:51:00.8189935Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:51:00.8190985Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:00.8191420Z     
2026-01-14T08:51:00.8191778Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:00.8192317Z [32mPASSED[0m
2026-01-14T08:51:00.8193508Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_affine_act_per_channel_weights [32mPASSED[0m
2026-01-14T08:51:00.8195042Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_per_tok_act_per_group_weights prepared model: GraphModule(
2026-01-14T08:51:00.8196021Z   (linear): Module()
2026-01-14T08:51:00.8196420Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:51:00.8197057Z   (activation_post_process_0): AffineQuantizedPlaceholderObserver()
2026-01-14T08:51:00.8197550Z )
2026-01-14T08:51:00.8197683Z 
2026-01-14T08:51:00.8197688Z 
2026-01-14T08:51:00.8197692Z 
2026-01-14T08:51:00.8197799Z def forward(self, x):
2026-01-14T08:51:00.8198168Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:00.8198618Z     linear_weight = self.linear.weight
2026-01-14T08:51:00.8199265Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:51:00.8199940Z     linear_bias = self.linear.bias
2026-01-14T08:51:00.8200451Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:00.8201715Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:51:00.8202951Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:00.8203384Z     
2026-01-14T08:51:00.8203789Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:00.8204324Z quantized model GraphModule(
2026-01-14T08:51:00.8204654Z   (linear): Module()
2026-01-14T08:51:00.8204930Z )
2026-01-14T08:51:00.8205039Z 
2026-01-14T08:51:00.8205043Z 
2026-01-14T08:51:00.8205047Z 
2026-01-14T08:51:00.8205142Z def forward(self, x):
2026-01-14T08:51:00.8205441Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:00.8205814Z     _scale0 = self._scale0
2026-01-14T08:51:00.8206074Z     _zero_point0 = self._zero_point0
2026-01-14T08:51:00.8206385Z     quantize_affine = self._frozen_param0
2026-01-14T08:51:00.8207375Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.int8, -127, 127, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:51:00.8208381Z     linear_bias = self.linear.bias
2026-01-14T08:51:00.8209044Z     choose_qparams_affine = torch.ops.torchao.choose_qparams_affine(x, 'SYMMETRIC', (1, 128), torch.int8, -128, 127, None, None, None)
2026-01-14T08:51:00.8209736Z     getitem = choose_qparams_affine[0]
2026-01-14T08:51:00.8210209Z     getitem_1 = choose_qparams_affine[1];  choose_qparams_affine = None
2026-01-14T08:51:00.8210934Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), getitem, getitem_1, torch.int8, -128, 127);  x = None
2026-01-14T08:51:00.8212237Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), getitem, getitem_1, torch.int8, -128, 127, output_dtype = torch.float32);  quantize_affine_1 = getitem = getitem_1 = None
2026-01-14T08:51:00.8213768Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:51:00.8214642Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:51:00.8215005Z     
2026-01-14T08:51:00.8215305Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:00.8215848Z [32mPASSED[0m
2026-01-14T08:51:00.8216560Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_fold_bn_erases_bn_node [33mSKIPPED[0m
2026-01-14T08:51:00.8217770Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_bias_derived_qspec [33mSKIPPED[0m
2026-01-14T08:51:00.8218956Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion [33mSKIPPED[0m
2026-01-14T08:51:00.8220181Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:51:00.8221396Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_literal_args [33mSKIPPED[0m
2026-01-14T08:51:00.8222633Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:51:00.8223904Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_per_channel_weight_bias [33mSKIPPED[0m
2026-01-14T08:51:00.8225126Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion [33mSKIPPED[0m
2026-01-14T08:51:00.8226313Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:51:00.8227568Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:51:00.8228758Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_no_bias [33mSKIPPED[0m
2026-01-14T08:51:00.8229883Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn [33mSKIPPED[0m
2026-01-14T08:51:00.8231068Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn_relu [33mSKIPPED[0m
2026-01-14T08:51:00.8232285Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_inplace_add_relu [33mSKIPPED[0m
2026-01-14T08:51:00.8233508Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_per_channel_weight_custom_dtype [33mSKIPPED[0m
2026-01-14T08:51:00.8234768Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_preserve_source_fn_stack [33mSKIPPED[0m
2026-01-14T08:51:00.8235952Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_update_shared_qspec [33mSKIPPED[0m
2026-01-14T08:51:00.8237101Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:51:00.8238279Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:51:00.8239361Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:51:00.8240049Z   (conv): Module()
2026-01-14T08:51:00.8240265Z   (bn): Module()
2026-01-14T08:51:00.8240582Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:00.8241723Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:18.9877071Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:18.9877920Z   )
2026-01-14T08:51:18.9878316Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:18.9880140Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:18.9882090Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:51:18.9883027Z   )
2026-01-14T08:51:18.9883386Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:18.9884899Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:18.9886488Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:51:18.9887209Z   )
2026-01-14T08:51:18.9887457Z )
2026-01-14T08:51:18.9887600Z 
2026-01-14T08:51:18.9887606Z 
2026-01-14T08:51:18.9887612Z 
2026-01-14T08:51:18.9887732Z def forward(self, x):
2026-01-14T08:51:18.9888121Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:18.9888568Z     conv_weight = self.conv.weight
2026-01-14T08:51:18.9888926Z     conv_bias = self.conv.bias
2026-01-14T08:51:18.9889251Z     bn_weight = self.bn.weight
2026-01-14T08:51:18.9889577Z     bn_bias = self.bn.bias
2026-01-14T08:51:18.9890018Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:18.9890411Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:18.9890849Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:18.9891434Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:18.9892254Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:18.9892988Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:18.9893509Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:18.9894064Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:18.9894645Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:18.9895321Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:18.9896095Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:18.9896960Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:18.9898343Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:18.9899598Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:18.9900323Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:18.9901107Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:18.9901860Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:18.9903122Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:18.9904495Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:18.9905318Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:18.9905836Z     
2026-01-14T08:51:18.9906202Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:18.9906684Z model fx: GraphModule(
2026-01-14T08:51:18.9907095Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:18.9908553Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:18.9910146Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:18.9910852Z   )
2026-01-14T08:51:18.9911076Z   (conv): ConvBn1d(
2026-01-14T08:51:18.9911446Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:51:18.9911980Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:18.9912621Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:18.9914032Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:18.9915931Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:51:18.9916839Z     )
2026-01-14T08:51:18.9917053Z   )
2026-01-14T08:51:18.9917409Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:18.9918753Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:18.9920349Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:51:18.9921062Z   )
2026-01-14T08:51:18.9921272Z )
2026-01-14T08:51:18.9921400Z 
2026-01-14T08:51:18.9921405Z 
2026-01-14T08:51:18.9921410Z 
2026-01-14T08:51:18.9921517Z def forward(self, x):
2026-01-14T08:51:18.9921981Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:18.9922703Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:18.9923454Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:18.9924025Z     return activation_post_process_1
2026-01-14T08:51:18.9924364Z     
2026-01-14T08:51:18.9924758Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:18.9925293Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:18.9925601Z          [0., 0., 0.],
2026-01-14T08:51:18.9925921Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:18.9926269Z converted model pt2e: GraphModule(
2026-01-14T08:51:18.9926546Z   (conv): Module()
2026-01-14T08:51:18.9926759Z   (bn): Module()
2026-01-14T08:51:18.9926954Z )
2026-01-14T08:51:18.9927055Z 
2026-01-14T08:51:18.9927065Z 
2026-01-14T08:51:18.9927069Z 
2026-01-14T08:51:18.9927157Z def forward(self, x):
2026-01-14T08:51:18.9927457Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:18.9927840Z     conv_bias = self.conv.bias
2026-01-14T08:51:18.9928160Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:18.9928990Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:18.9930549Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:18.9931811Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:18.9932361Z     _scale_0 = self._scale_0
2026-01-14T08:51:18.9932638Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:51:18.9932964Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:51:18.9934159Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:51:18.9935818Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:51:18.9937278Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011089790612459183, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:18.9938930Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:18.9940140Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:51:18.9940615Z     
2026-01-14T08:51:18.9940917Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:18.9941342Z onverted model fx: GraphModule(
2026-01-14T08:51:18.9941751Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:18.9942166Z )
2026-01-14T08:51:18.9942267Z 
2026-01-14T08:51:18.9942272Z 
2026-01-14T08:51:18.9942276Z 
2026-01-14T08:51:18.9942369Z def forward(self, x):
2026-01-14T08:51:18.9943079Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:18.9944578Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:18.9945794Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:18.9946807Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011089790612459183, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:18.9948351Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:18.9949416Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:18.9949712Z     
2026-01-14T08:51:18.9950014Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:18.9950421Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:18.9950669Z          [0., 0., 0.],
2026-01-14T08:51:18.9950884Z          [0., 0., 0.]]])
2026-01-14T08:51:18.9951127Z model pt2e: GraphModule(
2026-01-14T08:51:18.9951364Z   (conv): Module()
2026-01-14T08:51:18.9951581Z   (bn): Module()
2026-01-14T08:51:18.9951900Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5642678Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:42.5644059Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:42.5644680Z   )
2026-01-14T08:51:42.5645005Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5646168Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:42.5647538Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:51:42.5648141Z   )
2026-01-14T08:51:42.5648448Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5649805Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:42.5651241Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:51:42.5651851Z   )
2026-01-14T08:51:42.5652185Z )
2026-01-14T08:51:42.5652295Z 
2026-01-14T08:51:42.5652299Z 
2026-01-14T08:51:42.5652303Z 
2026-01-14T08:51:42.5652406Z def forward(self, x):
2026-01-14T08:51:42.5652720Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:42.5653115Z     conv_weight = self.conv.weight
2026-01-14T08:51:42.5653449Z     conv_bias = self.conv.bias
2026-01-14T08:51:42.5653721Z     bn_weight = self.bn.weight
2026-01-14T08:51:42.5653996Z     bn_bias = self.bn.bias
2026-01-14T08:51:42.5654278Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:42.5654607Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:42.5654978Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:42.5655478Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:42.5656169Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:42.5656782Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:42.5657234Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:42.5657692Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:42.5658189Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:42.5658752Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:42.5659404Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:42.5660129Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:42.5661295Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:42.5662358Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:42.5662970Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:42.5663642Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:42.5664280Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:42.5665403Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:42.5666562Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:42.5667258Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:42.5667698Z     
2026-01-14T08:51:42.5668014Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:42.5668423Z model fx: GraphModule(
2026-01-14T08:51:42.5668782Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5669926Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:42.5671270Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:42.5671869Z   )
2026-01-14T08:51:42.5672057Z   (conv): ConvBn1d(
2026-01-14T08:51:42.5672302Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:51:42.5672849Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:42.5673405Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5674519Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:42.5676205Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:51:42.5676816Z     )
2026-01-14T08:51:42.5676996Z   )
2026-01-14T08:51:42.5677296Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:42.5678430Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:42.5679793Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:51:42.5680396Z   )
2026-01-14T08:51:42.5680582Z )
2026-01-14T08:51:42.5680684Z 
2026-01-14T08:51:42.5680688Z 
2026-01-14T08:51:42.5680692Z 
2026-01-14T08:51:42.5680794Z def forward(self, x):
2026-01-14T08:51:42.5681180Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:42.5681802Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:42.5682429Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:42.5682921Z     return activation_post_process_1
2026-01-14T08:51:42.5683207Z     
2026-01-14T08:51:42.5683504Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:42.5683924Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:42.5684177Z          [0., 0., 0.],
2026-01-14T08:51:42.5684441Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:42.5684773Z converted model pt2e: GraphModule(
2026-01-14T08:51:42.5685060Z   (conv): Module()
2026-01-14T08:51:42.5685273Z   (bn): Module()
2026-01-14T08:51:42.5685485Z )
2026-01-14T08:51:42.5685601Z 
2026-01-14T08:51:42.5685606Z 
2026-01-14T08:51:42.5685611Z 
2026-01-14T08:51:42.5685714Z def forward(self, x):
2026-01-14T08:51:42.5686046Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:42.5686425Z     conv_bias = self.conv.bias
2026-01-14T08:51:42.5686747Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:42.5687578Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:42.5689067Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:42.5690374Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:42.5690954Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:51:42.5691883Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002370834583416581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:51:42.5693412Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:51:42.5694851Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.01108943298459053, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:42.5696543Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:51:42.5697760Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:51:42.5698225Z     
2026-01-14T08:51:42.5698535Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:42.5698967Z onverted model fx: GraphModule(
2026-01-14T08:51:42.5699385Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:42.5707587Z )
2026-01-14T08:51:42.5707723Z 
2026-01-14T08:51:42.5707727Z 
2026-01-14T08:51:42.5707731Z 
2026-01-14T08:51:42.5707837Z def forward(self, x):
2026-01-14T08:51:42.5708555Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:42.5710044Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:42.5711258Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:42.5712260Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01108943298459053, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:42.5713789Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:42.5714894Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:42.5715200Z     
2026-01-14T08:51:42.5715507Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:42.5715919Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:42.5716177Z          [0., 0., 0.],
2026-01-14T08:51:42.5716395Z          [0., 0., 0.]]])
2026-01-14T08:51:42.5716814Z [32mPASSED[0m
2026-01-14T08:51:42.5717470Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:51:42.5718187Z   (conv): Module()
2026-01-14T08:51:42.5718398Z   (bn): Module()
2026-01-14T08:51:56.2388750Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2390228Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:56.2391853Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:56.2392445Z   )
2026-01-14T08:51:56.2392748Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2394211Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:56.2396170Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:51:56.2397051Z   )
2026-01-14T08:51:56.2397341Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2398756Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:56.2400657Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3961666822433472, max_val=1.4123179912567139)
2026-01-14T08:51:56.2401268Z   )
2026-01-14T08:51:56.2401454Z )
2026-01-14T08:51:56.2401561Z 
2026-01-14T08:51:56.2401566Z 
2026-01-14T08:51:56.2401570Z 
2026-01-14T08:51:56.2401663Z def forward(self, x):
2026-01-14T08:51:56.2401978Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:56.2402350Z     conv_weight = self.conv.weight
2026-01-14T08:51:56.2402813Z     conv_bias = self.conv.bias
2026-01-14T08:51:56.2403102Z     bn_weight = self.bn.weight
2026-01-14T08:51:56.2403377Z     bn_bias = self.bn.bias
2026-01-14T08:51:56.2403755Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:56.2404169Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:56.2404637Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:56.2405215Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:56.2405909Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:56.2406522Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:56.2406960Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:56.2407420Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:56.2407906Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:56.2408479Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:56.2409121Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:56.2409835Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:56.2411071Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:56.2412130Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:56.2412749Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:56.2413405Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:56.2414037Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:56.2415102Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:56.2416252Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:56.2416942Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:56.2417374Z     
2026-01-14T08:51:56.2417678Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:56.2418087Z model fx: GraphModule(
2026-01-14T08:51:56.2418435Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2419813Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:56.2421394Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:51:56.2421984Z   )
2026-01-14T08:51:56.2422168Z   (conv): ConvBn1d(
2026-01-14T08:51:56.2422409Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:51:56.2422856Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:56.2423397Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2424924Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:56.2426882Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:51:56.2427839Z     )
2026-01-14T08:51:56.2428023Z   )
2026-01-14T08:51:56.2428320Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:56.2429705Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:56.2431293Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3961666822433472, max_val=1.4123179912567139)
2026-01-14T08:51:56.2431894Z   )
2026-01-14T08:51:56.2432068Z )
2026-01-14T08:51:56.2432176Z 
2026-01-14T08:51:56.2432180Z 
2026-01-14T08:51:56.2432184Z 
2026-01-14T08:51:56.2432274Z def forward(self, x):
2026-01-14T08:51:56.2432663Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:56.2433271Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:56.2433901Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:56.2434381Z     return activation_post_process_1
2026-01-14T08:51:56.2434663Z     
2026-01-14T08:51:56.2434970Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:56.2435380Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:56.2435638Z          [0., 0., 0.],
2026-01-14T08:51:56.2435928Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:51:56.2436307Z converted model pt2e: GraphModule(
2026-01-14T08:51:56.2436587Z   (conv): Module()
2026-01-14T08:51:56.2436805Z   (bn): Module()
2026-01-14T08:51:56.2437005Z )
2026-01-14T08:51:56.2437115Z 
2026-01-14T08:51:56.2437119Z 
2026-01-14T08:51:56.2437123Z 
2026-01-14T08:51:56.2437210Z def forward(self, x):
2026-01-14T08:51:56.2437518Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:56.2437893Z     conv_bias = self.conv.bias
2026-01-14T08:51:56.2438242Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:56.2439262Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:56.2441078Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:56.2442331Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:56.2442871Z     _scale_0 = self._scale_0
2026-01-14T08:51:56.2443147Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:51:56.2443473Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:51:56.2444529Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:51:56.2446172Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:51:56.2447613Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011013665236532688, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:56.2449521Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011013665236532688, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:56.2450946Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:51:56.2451415Z     
2026-01-14T08:51:56.2451720Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:56.2453099Z onverted model fx: GraphModule(
2026-01-14T08:51:56.2453510Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:56.2453929Z )
2026-01-14T08:51:56.2454037Z 
2026-01-14T08:51:56.2454041Z 
2026-01-14T08:51:56.2454045Z 
2026-01-14T08:51:56.2454135Z def forward(self, x):
2026-01-14T08:51:56.2454843Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:51:56.2456317Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:14.5708664Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:14.5709726Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011013665236532688, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:52:14.5711310Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011013665236532688, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:14.5712366Z     return dequantize_per_tensor_default_1
2026-01-14T08:52:14.5712665Z     
2026-01-14T08:52:14.5712974Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:14.5713387Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:14.5713643Z          [0., 0., 0.],
2026-01-14T08:52:14.5713876Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:52:14.5714183Z model pt2e: GraphModule(
2026-01-14T08:52:14.5714462Z   (conv): Module()
2026-01-14T08:52:14.5714684Z   (bn): Module()
2026-01-14T08:52:14.5715069Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5716817Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:14.5718410Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:52:14.5719021Z   )
2026-01-14T08:52:14.5719313Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5720822Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:14.5722433Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:52:14.5723045Z   )
2026-01-14T08:52:14.5723343Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5724715Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:14.5726306Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3980178833007812, max_val=1.4123179912567139)
2026-01-14T08:52:14.5727152Z   )
2026-01-14T08:52:14.5727340Z )
2026-01-14T08:52:14.5727444Z 
2026-01-14T08:52:14.5727449Z 
2026-01-14T08:52:14.5727453Z 
2026-01-14T08:52:14.5727550Z def forward(self, x):
2026-01-14T08:52:14.5727855Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:14.5728245Z     conv_weight = self.conv.weight
2026-01-14T08:52:14.5728537Z     conv_bias = self.conv.bias
2026-01-14T08:52:14.5728984Z     bn_weight = self.bn.weight
2026-01-14T08:52:14.5729248Z     bn_bias = self.bn.bias
2026-01-14T08:52:14.5729527Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:14.5729960Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:14.5730338Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:14.5730827Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:14.5731513Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:14.5732130Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:14.5732565Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:14.5733018Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:14.5733507Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:14.5734070Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:14.5734718Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:14.5735432Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:14.5736597Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:14.5737650Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:14.5738264Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:14.5738921Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:14.5739557Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:14.5740620Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:14.5741777Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:14.5742463Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:14.5742898Z     
2026-01-14T08:52:14.5743202Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:14.5743606Z model fx: GraphModule(
2026-01-14T08:52:14.5743959Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5745335Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:14.5746933Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:52:14.5747533Z   )
2026-01-14T08:52:14.5747714Z   (conv): ConvBn1d(
2026-01-14T08:52:14.5747951Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:52:14.5748412Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:14.5748940Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5750395Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:14.5752023Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:52:14.5752622Z     )
2026-01-14T08:52:14.5752881Z   )
2026-01-14T08:52:14.5753172Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:14.5754554Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:14.5756151Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3980178833007812, max_val=1.4123179912567139)
2026-01-14T08:52:14.5756750Z   )
2026-01-14T08:52:14.5756931Z )
2026-01-14T08:52:14.5757036Z 
2026-01-14T08:52:14.5757040Z 
2026-01-14T08:52:14.5757044Z 
2026-01-14T08:52:14.5757140Z def forward(self, x):
2026-01-14T08:52:14.5757519Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:14.5758131Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:14.5758763Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:14.5759247Z     return activation_post_process_1
2026-01-14T08:52:14.5759520Z     
2026-01-14T08:52:14.5759822Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:14.5760228Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:14.5760475Z          [0., 0., 0.],
2026-01-14T08:52:14.5760762Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:52:14.5761127Z converted model pt2e: GraphModule(
2026-01-14T08:52:14.5761405Z   (conv): Module()
2026-01-14T08:52:14.5761616Z   (bn): Module()
2026-01-14T08:52:14.5761815Z )
2026-01-14T08:52:14.5761914Z 
2026-01-14T08:52:14.5761918Z 
2026-01-14T08:52:14.5761922Z 
2026-01-14T08:52:14.5762007Z def forward(self, x):
2026-01-14T08:52:14.5762315Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:14.5762676Z     conv_bias = self.conv.bias
2026-01-14T08:52:14.5762999Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:14.5763825Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:14.5765312Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:14.5766568Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:14.5767146Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:52:14.5768074Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:52:14.5769597Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:52:14.5771087Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.01102092582732439, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:52:14.5772659Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01102092582732439, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:52:14.5773966Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:52:14.5774433Z     
2026-01-14T08:52:14.5774915Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:14.5775336Z onverted model fx: GraphModule(
2026-01-14T08:52:14.5775747Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:52:14.5776159Z )
2026-01-14T08:52:14.5776270Z 
2026-01-14T08:52:14.5776399Z 
2026-01-14T08:52:14.5776403Z 
2026-01-14T08:52:38.2835628Z def forward(self, x):
2026-01-14T08:52:38.2836658Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:52:38.2838429Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:38.2839870Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:38.2841074Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01102092582732439, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:52:38.2842910Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01102092582732439, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:38.2844167Z     return dequantize_per_tensor_default_1
2026-01-14T08:52:38.2844533Z     
2026-01-14T08:52:38.2844895Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:38.2845390Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:52:38.2845685Z          [0., 0., 0.],
2026-01-14T08:52:38.2845971Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:52:38.2846550Z [32mPASSED[0m
2026-01-14T08:52:38.2847393Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:52:38.2848280Z   (conv): Module()
2026-01-14T08:52:38.2848539Z   (bn): Module()
2026-01-14T08:52:38.2848920Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2850360Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:38.2851990Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:38.2852708Z   )
2026-01-14T08:52:38.2853057Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2854516Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:38.2856434Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:52:38.2857340Z   )
2026-01-14T08:52:38.2857697Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2859061Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:38.2860676Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:52:38.2861440Z   )
2026-01-14T08:52:38.2861649Z )
2026-01-14T08:52:38.2861780Z 
2026-01-14T08:52:38.2861785Z 
2026-01-14T08:52:38.2861790Z 
2026-01-14T08:52:38.2861898Z def forward(self, x):
2026-01-14T08:52:38.2862564Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:38.2863022Z     conv_weight = self.conv.weight
2026-01-14T08:52:38.2863377Z     conv_bias = self.conv.bias
2026-01-14T08:52:38.2863699Z     bn_weight = self.bn.weight
2026-01-14T08:52:38.2864023Z     bn_bias = self.bn.bias
2026-01-14T08:52:38.2864352Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:38.2864746Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:38.2865333Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:38.2865926Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:38.2866747Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:38.2867484Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:38.2868004Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:38.2868545Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:38.2869140Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:38.2869812Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:38.2870587Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:38.2871441Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:38.2872869Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:38.2874148Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:38.2875110Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:38.2876081Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:38.2876853Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:38.2878130Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:38.2879503Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:38.2880332Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:38.2880866Z     
2026-01-14T08:52:38.2881233Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:38.2881716Z model fx: GraphModule(
2026-01-14T08:52:38.2882129Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2883489Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:38.2885110Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:38.2885814Z   )
2026-01-14T08:52:38.2886046Z   (conv): ConvBn1d(
2026-01-14T08:52:38.2886374Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:52:38.2886958Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:38.2887609Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2889019Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:38.2891203Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:52:38.2892178Z     )
2026-01-14T08:52:38.2892403Z   )
2026-01-14T08:52:38.2892781Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:38.2893975Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:38.2895482Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:52:38.2896080Z   )
2026-01-14T08:52:38.2896254Z )
2026-01-14T08:52:38.2896356Z 
2026-01-14T08:52:38.2896360Z 
2026-01-14T08:52:38.2896364Z 
2026-01-14T08:52:38.2896463Z def forward(self, x):
2026-01-14T08:52:38.2896849Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:38.2897467Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:38.2898098Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:38.2898590Z     return activation_post_process_1
2026-01-14T08:52:38.2898872Z     
2026-01-14T08:52:38.2899169Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:38.2899588Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:38.2899882Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:38.2900197Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:52:38.2900552Z converted model pt2e: GraphModule(
2026-01-14T08:52:38.2900842Z   (conv): Module()
2026-01-14T08:52:38.2901051Z   (bn): Module()
2026-01-14T08:52:38.2901252Z )
2026-01-14T08:52:38.2901352Z 
2026-01-14T08:52:38.2901356Z 
2026-01-14T08:52:38.2901360Z 
2026-01-14T08:52:38.2901454Z def forward(self, x):
2026-01-14T08:52:38.2901756Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:38.2902130Z     conv_bias = self.conv.bias
2026-01-14T08:52:38.2902453Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:38.2903287Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:52:38.2904799Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:38.2906074Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:38.2906623Z     _scale_0 = self._scale_0
2026-01-14T08:52:38.2906891Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:52:38.2907228Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:52:38.2908296Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:52:38.2909982Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:52:38.2911479Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011866639368236065, -46, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:52:56.6623149Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:56.6624662Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:52:56.6625219Z     
2026-01-14T08:52:56.6625588Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:56.6626418Z onverted model fx: GraphModule(
2026-01-14T08:52:56.6626976Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:52:56.6627539Z )
2026-01-14T08:52:56.6627670Z 
2026-01-14T08:52:56.6627675Z 
2026-01-14T08:52:56.6627680Z 
2026-01-14T08:52:56.6627786Z def forward(self, x):
2026-01-14T08:52:56.6628641Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:52:56.6630565Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:56.6631998Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:56.6633205Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011866639368236065, -46, -128, 127, torch.int8);  conv = None
2026-01-14T08:52:56.6635037Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:56.6636300Z     return dequantize_per_tensor_default_1
2026-01-14T08:52:56.6636647Z     
2026-01-14T08:52:56.6637020Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:56.6637515Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:56.6637861Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:56.6638175Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:52:56.6638503Z model pt2e: GraphModule(
2026-01-14T08:52:56.6638796Z   (conv): Module()
2026-01-14T08:52:56.6639045Z   (bn): Module()
2026-01-14T08:52:56.6639430Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6640782Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:56.6642388Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:56.6643092Z   )
2026-01-14T08:52:56.6643440Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6644803Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:56.6646407Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:52:56.6647140Z   )
2026-01-14T08:52:56.6647494Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6648830Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:56.6659261Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:52:56.6659986Z   )
2026-01-14T08:52:56.6660214Z )
2026-01-14T08:52:56.6660337Z 
2026-01-14T08:52:56.6660350Z 
2026-01-14T08:52:56.6660355Z 
2026-01-14T08:52:56.6660462Z def forward(self, x):
2026-01-14T08:52:56.6660832Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:56.6661287Z     conv_weight = self.conv.weight
2026-01-14T08:52:56.6661644Z     conv_bias = self.conv.bias
2026-01-14T08:52:56.6661968Z     bn_weight = self.bn.weight
2026-01-14T08:52:56.6662291Z     bn_bias = self.bn.bias
2026-01-14T08:52:56.6662617Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:52:56.6663015Z     bn_running_var = self.bn.running_var
2026-01-14T08:52:56.6663566Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:56.6664165Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:56.6664973Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:56.6665708Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:52:56.6666320Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:56.6666862Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:52:56.6667446Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:56.6668110Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:52:56.6668884Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:52:56.6669731Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:56.6671144Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:52:56.6672411Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:56.6673137Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:52:56.6673931Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:52:56.6675025Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:56.6676503Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:52:56.6677925Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:52:56.6678797Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:52:56.6679301Z     
2026-01-14T08:52:56.6679598Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:56.6680007Z model fx: GraphModule(
2026-01-14T08:52:56.6680356Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6681499Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:56.6682846Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:52:56.6683431Z   )
2026-01-14T08:52:56.6683619Z   (conv): ConvBn1d(
2026-01-14T08:52:56.6683884Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:52:56.6684390Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:56.6684925Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6686036Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:56.6687424Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:52:56.6688024Z     )
2026-01-14T08:52:56.6688211Z   )
2026-01-14T08:52:56.6688510Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:56.6689644Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:56.6691228Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:52:56.6691816Z   )
2026-01-14T08:52:56.6691995Z )
2026-01-14T08:52:56.6692100Z 
2026-01-14T08:52:56.6692104Z 
2026-01-14T08:52:56.6692108Z 
2026-01-14T08:52:56.6692202Z def forward(self, x):
2026-01-14T08:52:56.6692579Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:56.6693300Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:56.6693923Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:52:56.6694407Z     return activation_post_process_1
2026-01-14T08:52:56.6694677Z     
2026-01-14T08:52:56.6694979Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:56.6695386Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:56.6695681Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:52:56.6695999Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:52:56.6696350Z converted model pt2e: GraphModule(
2026-01-14T08:52:56.6696632Z   (conv): Module()
2026-01-14T08:52:56.6696838Z   (bn): Module()
2026-01-14T08:52:56.6697040Z )
2026-01-14T08:52:56.6697139Z 
2026-01-14T08:52:56.6697143Z 
2026-01-14T08:52:56.6697147Z 
2026-01-14T08:52:56.6697231Z def forward(self, x):
2026-01-14T08:52:56.6697543Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:56.6697915Z     conv_bias = self.conv.bias
2026-01-14T08:52:56.6698239Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:52:56.6699059Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:52:56.6700542Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:56.6701791Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:52:56.6702370Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:52:56.6703294Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024561204481869936, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:52:56.6704830Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:53:18.5380846Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011943548917770386, -44, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:18.5383200Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:18.5384696Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:18.5385346Z     
2026-01-14T08:53:18.5385746Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:18.5386280Z onverted model fx: GraphModule(
2026-01-14T08:53:18.5386796Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:53:18.5387269Z )
2026-01-14T08:53:18.5387378Z 
2026-01-14T08:53:18.5387382Z 
2026-01-14T08:53:18.5387386Z 
2026-01-14T08:53:18.5387473Z def forward(self, x):
2026-01-14T08:53:18.5388190Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:53:18.5390036Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:18.5391257Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:18.5392266Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011943548917770386, -44, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:18.5393963Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:18.5395028Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:18.5395320Z     
2026-01-14T08:53:18.5395628Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:18.5396036Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:18.5396328Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:53:18.5396597Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:53:18.5397074Z [32mPASSED[0m
2026-01-14T08:53:18.5397767Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:53:18.5398503Z   (conv): Module()
2026-01-14T08:53:18.5398719Z   (bn): Module()
2026-01-14T08:53:18.5399038Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5400184Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:18.5401548Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:18.5402142Z   )
2026-01-14T08:53:18.5402442Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5403736Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:18.5405318Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:53:18.5406079Z   )
2026-01-14T08:53:18.5406367Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5407502Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:18.5408835Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:18.5409417Z   )
2026-01-14T08:53:18.5409600Z )
2026-01-14T08:53:18.5409701Z 
2026-01-14T08:53:18.5409790Z 
2026-01-14T08:53:18.5409794Z 
2026-01-14T08:53:18.5409883Z def forward(self, x):
2026-01-14T08:53:18.5410197Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:18.5410575Z     conv_weight = self.conv.weight
2026-01-14T08:53:18.5410865Z     bn_weight = self.bn.weight
2026-01-14T08:53:18.5411143Z     bn_bias = self.bn.bias
2026-01-14T08:53:18.5411410Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:18.5411737Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:18.5412092Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:18.5412584Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:18.5413259Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:18.5413879Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:18.5414421Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:18.5414879Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:18.5415370Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:18.5415930Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:18.5416577Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:18.5417645Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:18.5418615Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:18.5419232Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:18.5420324Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:18.5421467Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:18.5422152Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:18.5422581Z     
2026-01-14T08:53:18.5422884Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:18.5423290Z model fx: GraphModule(
2026-01-14T08:53:18.5423633Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5424766Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:18.5426113Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:18.5426713Z   )
2026-01-14T08:53:18.5426894Z   (conv): ConvBn1d(
2026-01-14T08:53:18.5427150Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:18.5427632Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:18.5428168Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5429344Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:18.5430947Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:53:18.5431712Z     )
2026-01-14T08:53:18.5431891Z   )
2026-01-14T08:53:18.5432187Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:18.5433368Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:18.5434707Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:18.5435302Z   )
2026-01-14T08:53:18.5435477Z )
2026-01-14T08:53:18.5435578Z 
2026-01-14T08:53:18.5435589Z 
2026-01-14T08:53:18.5435593Z 
2026-01-14T08:53:18.5435679Z def forward(self, x):
2026-01-14T08:53:18.5436058Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:18.5436667Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:18.5437293Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:18.5437765Z     return activation_post_process_1
2026-01-14T08:53:18.5438042Z     
2026-01-14T08:53:18.5438422Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:18.5438833Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:18.5439077Z          [0., 0., 0.],
2026-01-14T08:53:18.5439299Z          [0., 0., 0.]],
2026-01-14T08:53:18.5439439Z 
2026-01-14T08:53:18.5439514Z         [[0., 0., 0.],
2026-01-14T08:53:18.5439726Z          [0., 0., 0.],
2026-01-14T08:53:18.5440015Z          [0., 0., 0.]],
2026-01-14T08:53:18.5440162Z 
2026-01-14T08:53:18.5440235Z         [[0., 0., 0.],
2026-01-14T08:53:18.5440449Z          [0., 0., 0.],
2026-01-14T08:53:18.5440689Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:18.5441023Z converted model pt2e: GraphModule(
2026-01-14T08:53:18.5441296Z   (conv): Module()
2026-01-14T08:53:18.5441504Z   (bn): Module()
2026-01-14T08:53:18.5441695Z )
2026-01-14T08:53:18.5441800Z 
2026-01-14T08:53:18.5441804Z 
2026-01-14T08:53:18.5441807Z 
2026-01-14T08:53:18.5441892Z def forward(self, x):
2026-01-14T08:53:18.5442200Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:18.5442612Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:18.5443439Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:18.5444911Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:18.5446167Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:18.5446711Z     _scale_0 = self._scale_0
2026-01-14T08:53:18.5446974Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:53:18.5447302Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:53:18.5448356Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:53:37.1493732Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:53:37.1494843Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:53:37.1496393Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:37.1497970Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:37.1499187Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:53:37.1499654Z     
2026-01-14T08:53:37.1499979Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:37.1500403Z onverted model fx: GraphModule(
2026-01-14T08:53:37.1500817Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:37.1501245Z )
2026-01-14T08:53:37.1501350Z 
2026-01-14T08:53:37.1501354Z 
2026-01-14T08:53:37.1501358Z 
2026-01-14T08:53:37.1501455Z def forward(self, x):
2026-01-14T08:53:37.1502176Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:37.1503661Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:37.1504872Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:37.1506238Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:37.1507768Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:37.1509040Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:37.1509336Z     
2026-01-14T08:53:37.1509648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:37.1510068Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:37.1510318Z          [0., 0., 0.],
2026-01-14T08:53:37.1510544Z          [0., 0., 0.]],
2026-01-14T08:53:37.1510687Z 
2026-01-14T08:53:37.1510765Z         [[0., 0., 0.],
2026-01-14T08:53:37.1510985Z          [0., 0., 0.],
2026-01-14T08:53:37.1511201Z          [0., 0., 0.]],
2026-01-14T08:53:37.1511351Z 
2026-01-14T08:53:37.1511439Z         [[0., 0., 0.],
2026-01-14T08:53:37.1511650Z          [0., 0., 0.],
2026-01-14T08:53:37.1511875Z          [0., 0., 0.]]])
2026-01-14T08:53:37.1512121Z model pt2e: GraphModule(
2026-01-14T08:53:37.1512365Z   (conv): Module()
2026-01-14T08:53:37.1512579Z   (bn): Module()
2026-01-14T08:53:37.1512899Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1514047Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:37.1515419Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:37.1516016Z   )
2026-01-14T08:53:37.1516322Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1517467Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:37.1518837Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:53:37.1519523Z   )
2026-01-14T08:53:37.1519819Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1520954Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:37.1522298Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:37.1522891Z   )
2026-01-14T08:53:37.1523071Z )
2026-01-14T08:53:37.1523173Z 
2026-01-14T08:53:37.1523178Z 
2026-01-14T08:53:37.1523182Z 
2026-01-14T08:53:37.1523276Z def forward(self, x):
2026-01-14T08:53:37.1523594Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:37.1523975Z     conv_weight = self.conv.weight
2026-01-14T08:53:37.1524269Z     bn_weight = self.bn.weight
2026-01-14T08:53:37.1524545Z     bn_bias = self.bn.bias
2026-01-14T08:53:37.1524820Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:37.1525151Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:37.1525519Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:37.1526016Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:37.1526698Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:37.1527316Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:37.1527761Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:37.1528220Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:37.1528806Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:37.1529374Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:37.1530115Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:37.1531104Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:37.1532164Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:37.1532778Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:37.1533878Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:37.1535034Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:37.1535725Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:37.1536161Z     
2026-01-14T08:53:37.1536469Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:37.1536874Z model fx: GraphModule(
2026-01-14T08:53:37.1537222Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1538371Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:37.1539776Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:37.1540378Z   )
2026-01-14T08:53:37.1540562Z   (conv): ConvBn1d(
2026-01-14T08:53:37.1540824Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:37.1541323Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:37.1541864Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1542975Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:37.1544357Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:53:37.1544964Z     )
2026-01-14T08:53:37.1545143Z   )
2026-01-14T08:53:37.1545442Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:37.1546568Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:37.1547917Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:53:37.1548538Z   )
2026-01-14T08:53:37.1548736Z )
2026-01-14T08:53:37.1548838Z 
2026-01-14T08:53:37.1548842Z 
2026-01-14T08:53:37.1548847Z 
2026-01-14T08:53:37.1548943Z def forward(self, x):
2026-01-14T08:53:37.1549327Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:37.1549948Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:37.1550575Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:37.1551067Z     return activation_post_process_1
2026-01-14T08:53:37.1551356Z     
2026-01-14T08:53:37.1551655Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:37.1552068Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:37.1552314Z          [0., 0., 0.],
2026-01-14T08:53:37.1552632Z          [0., 0., 0.]],
2026-01-14T08:53:37.1552780Z 
2026-01-14T08:53:37.1552858Z         [[0., 0., 0.],
2026-01-14T08:53:37.1553079Z          [0., 0., 0.],
2026-01-14T08:53:37.1553291Z          [0., 0., 0.]],
2026-01-14T08:53:37.1553444Z 
2026-01-14T08:53:37.1553523Z         [[0., 0., 0.],
2026-01-14T08:53:37.1553740Z          [0., 0., 0.],
2026-01-14T08:53:37.1553987Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:37.1554410Z converted model pt2e: GraphModule(
2026-01-14T08:53:37.1554693Z   (conv): Module()
2026-01-14T08:53:37.1554910Z   (bn): Module()
2026-01-14T08:53:37.1555106Z )
2026-01-14T08:53:37.1555214Z 
2026-01-14T08:53:37.1555218Z 
2026-01-14T08:53:37.1555222Z 
2026-01-14T08:53:37.1555308Z def forward(self, x):
2026-01-14T08:53:37.1555609Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:37.1556038Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:37.1556871Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:37.1558356Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:37.1559612Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:37.1560197Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:53:37.1561122Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:53:37.1562069Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:53:39.9479352Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:53:39.9480919Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:53:39.9482498Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:39.9483716Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:39.9484199Z     
2026-01-14T08:53:39.9484504Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:39.9484935Z onverted model fx: GraphModule(
2026-01-14T08:53:39.9485352Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:39.9485769Z )
2026-01-14T08:53:39.9485875Z 
2026-01-14T08:53:39.9485879Z 
2026-01-14T08:53:39.9485883Z 
2026-01-14T08:53:39.9485991Z def forward(self, x):
2026-01-14T08:53:39.9486707Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:39.9488207Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:39.9489439Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:39.9490496Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:39.9492034Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:39.9493299Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:39.9493607Z     
2026-01-14T08:53:39.9493913Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:39.9494327Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:39.9494578Z          [0., 0., 0.],
2026-01-14T08:53:39.9494796Z          [0., 0., 0.]],
2026-01-14T08:53:39.9494944Z 
2026-01-14T08:53:39.9495168Z         [[0., 0., 0.],
2026-01-14T08:53:39.9495385Z          [0., 0., 0.],
2026-01-14T08:53:39.9495605Z          [0., 0., 0.]],
2026-01-14T08:53:39.9495749Z 
2026-01-14T08:53:39.9495829Z         [[0., 0., 0.],
2026-01-14T08:53:39.9496053Z          [0., 0., 0.],
2026-01-14T08:53:39.9496281Z          [0., 0., 0.]]])
2026-01-14T08:53:39.9496523Z model pt2e: GraphModule(
2026-01-14T08:53:39.9496774Z   (conv1): Module()
2026-01-14T08:53:39.9496988Z   (bn1): Module()
2026-01-14T08:53:39.9497208Z   (conv2): Module()
2026-01-14T08:53:39.9497418Z   (bn2): Module()
2026-01-14T08:53:39.9497755Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:39.9498894Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:39.9500258Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:39.9500871Z   )
2026-01-14T08:53:39.9501165Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:39.9502379Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:39.9503958Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:53:39.9504715Z   )
2026-01-14T08:53:39.9505016Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:39.9506222Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:39.9507812Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:53:39.9508569Z   )
2026-01-14T08:53:39.9508861Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:39.9510008Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:39.9511342Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:53:39.9511930Z   )
2026-01-14T08:53:39.9512219Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:39.9513348Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:39.9514691Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:53:39.9515280Z   )
2026-01-14T08:53:39.9515460Z )
2026-01-14T08:53:39.9515562Z 
2026-01-14T08:53:39.9515566Z 
2026-01-14T08:53:39.9515570Z 
2026-01-14T08:53:39.9515657Z def forward(self, x):
2026-01-14T08:53:39.9515966Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:39.9516435Z     conv1_weight = self.conv1.weight
2026-01-14T08:53:39.9516739Z     bn1_weight = self.bn1.weight
2026-01-14T08:53:39.9517021Z     bn1_bias = self.bn1.bias
2026-01-14T08:53:39.9517288Z     conv2_weight = self.conv2.weight
2026-01-14T08:53:39.9517589Z     conv2_bias = self.conv2.bias
2026-01-14T08:53:39.9517864Z     bn2_weight = self.bn2.weight
2026-01-14T08:53:39.9518142Z     bn2_bias = self.bn2.bias
2026-01-14T08:53:39.9518508Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:53:39.9518869Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:53:39.9519235Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:53:39.9519629Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:53:39.9519954Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:53:39.9528593Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:53:39.9529116Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:39.9529873Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:53:39.9530682Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:53:39.9531317Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:53:39.9531770Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:39.9532251Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:53:39.9532749Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:39.9533334Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:53:39.9533990Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:53:39.9534712Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:39.9535352Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:53:39.9535830Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:53:39.9536330Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:53:39.9536843Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:53:39.9537453Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:53:39.9538141Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:53:39.9539152Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:39.9540140Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:53:39.9540765Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:53:39.9541911Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:53:39.9543096Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:53:39.9544249Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:53:39.9545311Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:39.9545922Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:53:39.9546592Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:53:39.9547237Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:39.9548465Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:53:39.9549726Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:53:39.9550414Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:53:39.9550961Z     
2026-01-14T08:53:39.9551265Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:39.9551678Z model fx: GraphModule(
2026-01-14T08:53:39.9552025Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7803896Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7805668Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:58.7806397Z   )
2026-01-14T08:53:58.7806627Z   (conv1): ConvBn1d(
2026-01-14T08:53:58.7806957Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:58.7807547Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:58.7808195Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7809624Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:58.7811612Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:53:58.7812522Z     )
2026-01-14T08:53:58.7812745Z   )
2026-01-14T08:53:58.7813118Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7814485Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7816079Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:53:58.7816800Z   )
2026-01-14T08:53:58.7817024Z   (conv2): ConvBn1d(
2026-01-14T08:53:58.7817321Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:53:58.7817859Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:58.7818504Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7819920Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:58.7821816Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:53:58.7822728Z     )
2026-01-14T08:53:58.7822944Z   )
2026-01-14T08:53:58.7823302Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7824696Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7826335Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:53:58.7827058Z   )
2026-01-14T08:53:58.7827274Z )
2026-01-14T08:53:58.7827408Z 
2026-01-14T08:53:58.7827413Z 
2026-01-14T08:53:58.7827419Z 
2026-01-14T08:53:58.7827914Z def forward(self, x):
2026-01-14T08:53:58.7828390Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:58.7829126Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:58.7829896Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:53:58.7830826Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:53:58.7831595Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:53:58.7832178Z     return activation_post_process_2
2026-01-14T08:53:58.7832534Z     
2026-01-14T08:53:58.7832907Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:58.7833383Z diff: tensor([[[0.],
2026-01-14T08:53:58.7833656Z          [0.],
2026-01-14T08:53:58.7833894Z          [0.]],
2026-01-14T08:53:58.7834047Z 
2026-01-14T08:53:58.7834152Z         [[0.],
2026-01-14T08:53:58.7834394Z          [0.],
2026-01-14T08:53:58.7834642Z          [0.]],
2026-01-14T08:53:58.7834791Z 
2026-01-14T08:53:58.7834886Z         [[0.],
2026-01-14T08:53:58.7835125Z          [0.],
2026-01-14T08:53:58.7835391Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:58.7835772Z converted model pt2e: GraphModule(
2026-01-14T08:53:58.7836116Z   (conv1): Module()
2026-01-14T08:53:58.7836405Z   (bn1): Module()
2026-01-14T08:53:58.7836680Z   (conv2): Module()
2026-01-14T08:53:58.7836948Z   (bn2): Module()
2026-01-14T08:53:58.7837215Z )
2026-01-14T08:53:58.7837344Z 
2026-01-14T08:53:58.7837349Z 
2026-01-14T08:53:58.7837354Z 
2026-01-14T08:53:58.7837469Z def forward(self, x):
2026-01-14T08:53:58.7837790Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:58.7838162Z     conv2_bias = self.conv2.bias
2026-01-14T08:53:58.7838506Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:53:58.7838929Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:53:58.7839769Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:58.7841267Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:58.7842528Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:53:58.7843331Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:53:58.7843895Z     _scale_0 = self._scale_0
2026-01-14T08:53:58.7844162Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:53:58.7844461Z     _scale_1 = self._scale_1
2026-01-14T08:53:58.7844732Z     _zero_point_1 = self._zero_point_1
2026-01-14T08:53:58.7845110Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T08:53:58.7846190Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T08:53:58.7847287Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:53:58.7848309Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T08:53:58.7849953Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:53:58.7851552Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:58.7852725Z     quantize_per_channel = self._frozen_param1
2026-01-14T08:53:58.7853774Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:53:58.7855491Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T08:53:58.7857056Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010241499170660973, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:53:58.7858628Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:58.7859852Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:58.7860324Z     
2026-01-14T08:53:58.7860632Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:58.7861067Z onverted model fx: GraphModule(
2026-01-14T08:53:58.7861475Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:58.7862053Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:58.7862471Z )
2026-01-14T08:53:58.7862585Z 
2026-01-14T08:53:58.7862590Z 
2026-01-14T08:53:58.7862594Z 
2026-01-14T08:53:58.7862682Z def forward(self, x):
2026-01-14T08:53:58.7863397Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:58.7864910Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:58.7866181Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:58.7867212Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:53:58.7868777Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:58.7870029Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:53:58.7871067Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010241499170660973, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:53:58.7872628Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:58.7873694Z     return dequantize_per_tensor_default_2
2026-01-14T08:53:58.7873990Z     
2026-01-14T08:53:58.7874296Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:58.7875016Z diff: tensor([[[0.],
2026-01-14T08:53:58.7875257Z          [0.],
2026-01-14T08:53:58.7875452Z          [0.]],
2026-01-14T08:53:58.7875585Z 
2026-01-14T08:53:58.7875661Z         [[0.],
2026-01-14T08:53:58.7875852Z          [0.],
2026-01-14T08:53:58.7876052Z          [0.]],
2026-01-14T08:53:58.7876174Z 
2026-01-14T08:53:58.7876260Z         [[0.],
2026-01-14T08:53:58.7876450Z          [0.],
2026-01-14T08:53:58.7876649Z          [0.]]])
2026-01-14T08:53:58.7876864Z model pt2e: GraphModule(
2026-01-14T08:53:58.7877118Z   (conv1): Module()
2026-01-14T08:53:58.7877329Z   (bn1): Module()
2026-01-14T08:53:58.7877704Z   (conv2): Module()
2026-01-14T08:53:58.7877917Z   (bn2): Module()
2026-01-14T08:53:58.7878245Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7879412Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7880881Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:58.7881482Z   )
2026-01-14T08:53:58.7881786Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7882927Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:58.7884302Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:53:58.7884897Z   )
2026-01-14T08:53:58.7885199Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7886396Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:58.7887749Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:53:58.7888339Z   )
2026-01-14T08:53:58.7888640Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7889849Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7891197Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:53:58.7891789Z   )
2026-01-14T08:53:58.7892078Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7893214Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7894560Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:53:58.7895206Z   )
2026-01-14T08:53:58.7895383Z )
2026-01-14T08:53:58.7895485Z 
2026-01-14T08:53:58.7895489Z 
2026-01-14T08:53:58.7895493Z 
2026-01-14T08:53:58.7895581Z def forward(self, x):
2026-01-14T08:53:58.7895889Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:58.7896264Z     conv1_weight = self.conv1.weight
2026-01-14T08:53:58.7896571Z     bn1_weight = self.bn1.weight
2026-01-14T08:53:58.7896844Z     bn1_bias = self.bn1.bias
2026-01-14T08:53:58.7897121Z     conv2_weight = self.conv2.weight
2026-01-14T08:53:58.7897414Z     conv2_bias = self.conv2.bias
2026-01-14T08:53:58.7897695Z     bn2_weight = self.bn2.weight
2026-01-14T08:53:58.7897972Z     bn2_bias = self.bn2.bias
2026-01-14T08:53:58.7898254Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:53:58.7898595Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:53:58.7898966Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:53:58.7899357Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:53:58.7899686Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:53:58.7900061Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:53:58.7900558Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:58.7901379Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:53:58.7902191Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:53:58.7902829Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:53:58.7903290Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:58.7903755Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:53:58.7904338Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:58.7904912Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:53:58.7905573Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:53:58.7906293Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:58.7906946Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:53:58.7907410Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:53:58.7907907Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:53:58.7908432Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:53:58.7909044Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:53:58.7909740Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:53:58.7910754Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:53:58.7911741Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:53:58.7912372Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:53:58.7913519Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:53:58.7914712Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:53:58.7915854Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:53:58.7916913Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:58.7917531Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:53:58.7918199Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:53:58.7918852Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:58.7919957Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:53:58.7921144Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:53:58.7921835Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:53:58.7922275Z     
2026-01-14T08:53:58.7922578Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:58.7922981Z model fx: GraphModule(
2026-01-14T08:53:58.7923334Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7924475Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7926031Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:53:58.7926635Z   )
2026-01-14T08:53:58.7926823Z   (conv1): ConvBn1d(
2026-01-14T08:53:58.7927094Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:53:58.7927576Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:58.7928114Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7929319Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:58.7930722Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:53:58.7931314Z     )
2026-01-14T08:53:58.7931486Z   )
2026-01-14T08:53:58.7931781Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7932924Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7934269Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:53:58.7934866Z   )
2026-01-14T08:53:58.7935048Z   (conv2): ConvBn1d(
2026-01-14T08:53:58.7935290Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:53:58.7935741Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:58.7936279Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7937398Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:58.7938769Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:53:58.7939375Z     )
2026-01-14T08:53:58.7939550Z   )
2026-01-14T08:53:58.7939847Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:58.7940990Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:58.7942354Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:53:58.7942951Z   )
2026-01-14T08:53:58.7943123Z )
2026-01-14T08:53:58.7943235Z 
2026-01-14T08:53:58.7943240Z 
2026-01-14T08:53:58.7943243Z 
2026-01-14T08:53:58.7943331Z def forward(self, x):
2026-01-14T08:53:58.7943721Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:58.7944342Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:38.0351284Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:54:38.0352103Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:54:38.0352876Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:54:38.0353496Z     return activation_post_process_2
2026-01-14T08:54:38.0353835Z     
2026-01-14T08:54:38.0354196Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:38.0354688Z diff: tensor([[[0.],
2026-01-14T08:54:38.0354951Z          [0.],
2026-01-14T08:54:38.0355195Z          [0.]],
2026-01-14T08:54:38.0355344Z 
2026-01-14T08:54:38.0355436Z         [[0.],
2026-01-14T08:54:38.0355672Z          [0.],
2026-01-14T08:54:38.0355903Z          [0.]],
2026-01-14T08:54:38.0356057Z 
2026-01-14T08:54:38.0357594Z         [[0.],
2026-01-14T08:54:38.0357856Z          [0.],
2026-01-14T08:54:38.0358120Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:54:38.0358506Z converted model pt2e: GraphModule(
2026-01-14T08:54:38.0358843Z   (conv1): Module()
2026-01-14T08:54:38.0359102Z   (bn1): Module()
2026-01-14T08:54:38.0359348Z   (conv2): Module()
2026-01-14T08:54:38.0359610Z   (bn2): Module()
2026-01-14T08:54:38.0360027Z )
2026-01-14T08:54:38.0360158Z 
2026-01-14T08:54:38.0360163Z 
2026-01-14T08:54:38.0360168Z 
2026-01-14T08:54:38.0360284Z def forward(self, x):
2026-01-14T08:54:38.0360660Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:38.0361108Z     conv2_bias = self.conv2.bias
2026-01-14T08:54:38.0361522Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:54:38.0362033Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:54:38.0363056Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:38.0364824Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:38.0366331Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:54:38.0367295Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:54:38.0367998Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T08:54:38.0369144Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.0025454412680119276, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T08:54:38.0370408Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:54:38.0371623Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T08:54:38.0373453Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:54:38.0375598Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:54:38.0376884Z     quantize_per_tensor = self._frozen_param1
2026-01-14T08:54:38.0377996Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0026105986908078194, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:54:38.0379820Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T08:54:38.0381554Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.01024628710001707, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:54:38.0383415Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T08:54:38.0384842Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T08:54:38.0385406Z     
2026-01-14T08:54:38.0385760Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:38.0386307Z onverted model fx: GraphModule(
2026-01-14T08:54:38.0386829Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:38.0387622Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:38.0388042Z )
2026-01-14T08:54:38.0388144Z 
2026-01-14T08:54:38.0388149Z 
2026-01-14T08:54:38.0388153Z 
2026-01-14T08:54:38.0388240Z def forward(self, x):
2026-01-14T08:54:38.0388951Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:54:38.0390572Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:38.0391785Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:38.0392810Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:54:38.0394363Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:38.0395601Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:54:38.0396669Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.01024628710001707, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:54:38.0398225Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:54:38.0399273Z     return dequantize_per_tensor_default_2
2026-01-14T08:54:38.0399573Z     
2026-01-14T08:54:38.0399869Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:38.0400275Z diff: tensor([[[0.],
2026-01-14T08:54:38.0400495Z          [0.],
2026-01-14T08:54:38.0400694Z          [0.]],
2026-01-14T08:54:38.0400816Z 
2026-01-14T08:54:38.0400891Z         [[0.],
2026-01-14T08:54:38.0401086Z          [0.],
2026-01-14T08:54:38.0401281Z          [0.]],
2026-01-14T08:54:38.0401403Z 
2026-01-14T08:54:38.0401477Z         [[0.],
2026-01-14T08:54:38.0401676Z          [0.],
2026-01-14T08:54:38.0401864Z          [0.]]])
2026-01-14T08:54:38.0402294Z [32mPASSED[0m
2026-01-14T08:54:38.0403067Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T08:54:38.0404208Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T08:54:38.0404916Z   (conv): Module()
2026-01-14T08:54:38.0405124Z   (bn): Module()
2026-01-14T08:54:38.0405444Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:38.0406578Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:38.0407933Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:38.0408523Z   )
2026-01-14T08:54:38.0408811Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:38.0410079Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:38.0411658Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:54:38.0412414Z   )
2026-01-14T08:54:38.0412797Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:38.0413929Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:38.0415210Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:54:38.0415818Z   )
2026-01-14T08:54:38.0415996Z )
2026-01-14T08:54:38.0416095Z 
2026-01-14T08:54:38.0416099Z 
2026-01-14T08:54:38.0416103Z 
2026-01-14T08:54:38.0416194Z def forward(self, x):
2026-01-14T08:54:38.0416494Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:38.0416872Z     conv_weight = self.conv.weight
2026-01-14T08:54:38.0417159Z     conv_bias = self.conv.bias
2026-01-14T08:54:38.0417433Z     bn_weight = self.bn.weight
2026-01-14T08:54:38.0417692Z     bn_bias = self.bn.bias
2026-01-14T08:54:38.0417963Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:38.0418289Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:38.0418647Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:38.0419148Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:38.0419822Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:38.0420446Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:38.0420872Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:38.0421331Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:38.0421814Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:38.0422380Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:38.0423031Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:38.0423745Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:54:38.0424919Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:54:38.0425971Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:38.0426621Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:54:54.6347749Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:54:54.6348684Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:54:54.6349859Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:54:54.6350990Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:54:54.6351653Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:54:54.6352271Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:54:54.6352714Z     
2026-01-14T08:54:54.6353019Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:54.6353444Z model fx: GraphModule(
2026-01-14T08:54:54.6353910Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6355206Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:54.6356569Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:54.6357191Z   )
2026-01-14T08:54:54.6358742Z   (conv): ConvBnReLU1d(
2026-01-14T08:54:54.6359014Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:54:54.6359471Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:54.6360016Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6361197Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:54.6362968Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:54:54.6363731Z     )
2026-01-14T08:54:54.6363909Z   )
2026-01-14T08:54:54.6364204Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6365357Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:54.6366646Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:54:54.6367186Z   )
2026-01-14T08:54:54.6367364Z )
2026-01-14T08:54:54.6367471Z 
2026-01-14T08:54:54.6367483Z 
2026-01-14T08:54:54.6367487Z 
2026-01-14T08:54:54.6367575Z def forward(self, x):
2026-01-14T08:54:54.6367953Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:54.6368565Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:54.6369189Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:54:54.6369667Z     return activation_post_process_1
2026-01-14T08:54:54.6370051Z     
2026-01-14T08:54:54.6370354Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:54.6370770Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:54.6371015Z          [0., 0., 0.],
2026-01-14T08:54:54.6371271Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:54:54.6371598Z converted model pt2e: GraphModule(
2026-01-14T08:54:54.6371880Z   (conv): Module()
2026-01-14T08:54:54.6372088Z   (bn): Module()
2026-01-14T08:54:54.6372296Z )
2026-01-14T08:54:54.6372398Z 
2026-01-14T08:54:54.6372403Z 
2026-01-14T08:54:54.6372407Z 
2026-01-14T08:54:54.6372501Z def forward(self, x):
2026-01-14T08:54:54.6372803Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:54.6373174Z     conv_bias = self.conv.bias
2026-01-14T08:54:54.6373492Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:54.6374318Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:54:54.6376007Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:54.6377251Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:54.6377803Z     _scale_0 = self._scale_0
2026-01-14T08:54:54.6378075Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:54:54.6378409Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:54:54.6379561Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:54:54.6381214Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:54:54.6382383Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:54:54.6383296Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:54:54.6384852Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:54.6386190Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:54:54.6386658Z     
2026-01-14T08:54:54.6386968Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:54.6387389Z onverted model fx: GraphModule(
2026-01-14T08:54:54.6387667Z   (conv): ConvReLU1d(
2026-01-14T08:54:54.6388016Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:54.6388424Z     (1): ReLU()
2026-01-14T08:54:54.6388632Z   )
2026-01-14T08:54:54.6388810Z )
2026-01-14T08:54:54.6388912Z 
2026-01-14T08:54:54.6388916Z 
2026-01-14T08:54:54.6388920Z 
2026-01-14T08:54:54.6389019Z def forward(self, x):
2026-01-14T08:54:54.6389721Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:54:54.6391209Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:54.6392416Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:54.6393430Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:54:54.6394996Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:54.6396065Z     return dequantize_per_tensor_default_1
2026-01-14T08:54:54.6396358Z     
2026-01-14T08:54:54.6396666Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:54.6397074Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:54.6397330Z          [0., 0., 0.],
2026-01-14T08:54:54.6397549Z          [0., 0., 0.]]])
2026-01-14T08:54:54.6397795Z model pt2e: GraphModule(
2026-01-14T08:54:54.6398035Z   (conv): Module()
2026-01-14T08:54:54.6398250Z   (bn): Module()
2026-01-14T08:54:54.6398566Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6399706Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:54.6401048Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:54.6401636Z   )
2026-01-14T08:54:54.6401935Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6403065Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:54.6404428Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:54:54.6405030Z   )
2026-01-14T08:54:54.6405319Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:54.6406542Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:54.6407821Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:54:54.6408357Z   )
2026-01-14T08:54:54.6408532Z )
2026-01-14T08:54:54.6408632Z 
2026-01-14T08:54:54.6408636Z 
2026-01-14T08:54:54.6408640Z 
2026-01-14T08:54:54.6408727Z def forward(self, x):
2026-01-14T08:54:54.6409111Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:54.6409481Z     conv_weight = self.conv.weight
2026-01-14T08:54:54.6409844Z     conv_bias = self.conv.bias
2026-01-14T08:54:54.6410111Z     bn_weight = self.bn.weight
2026-01-14T08:54:54.6410384Z     bn_bias = self.bn.bias
2026-01-14T08:54:54.6410659Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:54.6410990Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:54.6411358Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:54.6411885Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:54.6412602Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:54.6413213Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:54.6413653Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:54.6414107Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:54.6414605Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:54.6415176Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:54.6415818Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:54.6416533Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:55:19.0430269Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:55:19.0431507Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:55:19.0432342Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:55:19.0433026Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:55:19.0433732Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:55:19.0435171Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:19.0436232Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:19.0436832Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:19.0437471Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:19.0437911Z     
2026-01-14T08:55:19.0438221Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.0438637Z model fx: GraphModule(
2026-01-14T08:55:19.0438988Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0440171Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.0441561Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:19.0442166Z   )
2026-01-14T08:55:19.0442369Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:19.0442620Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:55:19.0443087Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:19.0443871Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0445015Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:19.0446406Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:55:19.0447189Z     )
2026-01-14T08:55:19.0447379Z   )
2026-01-14T08:55:19.0447674Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0448834Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.0450266Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:55:19.0450808Z   )
2026-01-14T08:55:19.0450997Z )
2026-01-14T08:55:19.0451102Z 
2026-01-14T08:55:19.0451106Z 
2026-01-14T08:55:19.0451110Z 
2026-01-14T08:55:19.0451199Z def forward(self, x):
2026-01-14T08:55:19.0451598Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:19.0452215Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:19.0452848Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:19.0453343Z     return activation_post_process_1
2026-01-14T08:55:19.0453627Z     
2026-01-14T08:55:19.0453939Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.0454354Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:19.0454612Z          [0., 0., 0.],
2026-01-14T08:55:19.0454861Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:19.0455203Z converted model pt2e: GraphModule(
2026-01-14T08:55:19.0455485Z   (conv): Module()
2026-01-14T08:55:19.0455703Z   (bn): Module()
2026-01-14T08:55:19.0455909Z )
2026-01-14T08:55:19.0456011Z 
2026-01-14T08:55:19.0456015Z 
2026-01-14T08:55:19.0456020Z 
2026-01-14T08:55:19.0456107Z def forward(self, x):
2026-01-14T08:55:19.0456417Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:19.0456794Z     conv_bias = self.conv.bias
2026-01-14T08:55:19.0457128Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:19.0457957Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:19.0459458Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:19.0460717Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:19.0461393Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:55:19.0462473Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002590105403214693, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:55:19.0463998Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:55:19.0465018Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:19.0466116Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:19.0467797Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:55:19.0469032Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:55:19.0469499Z     
2026-01-14T08:55:19.0469809Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.0470236Z onverted model fx: GraphModule(
2026-01-14T08:55:19.0470509Z   (conv): ConvReLU1d(
2026-01-14T08:55:19.0470949Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:19.0471355Z     (1): ReLU()
2026-01-14T08:55:19.0471557Z   )
2026-01-14T08:55:19.0471731Z )
2026-01-14T08:55:19.0471838Z 
2026-01-14T08:55:19.0471842Z 
2026-01-14T08:55:19.0471847Z 
2026-01-14T08:55:19.0471937Z def forward(self, x):
2026-01-14T08:55:19.0472646Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:19.0474152Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:19.0475648Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:19.0476673Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:19.0478251Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:19.0479331Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:19.0479653Z     
2026-01-14T08:55:19.0479951Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.0480368Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:19.0480622Z          [0., 0., 0.],
2026-01-14T08:55:19.0480847Z          [0., 0., 0.]]])
2026-01-14T08:55:19.0481295Z [32mPASSED[0m
2026-01-14T08:55:19.0481982Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:55:19.0482725Z   (conv): Module()
2026-01-14T08:55:19.0482939Z   (bn): Module()
2026-01-14T08:55:19.0483273Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0484662Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.0486257Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:19.0486859Z   )
2026-01-14T08:55:19.0487159Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0488630Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:19.0490668Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:55:19.0491550Z   )
2026-01-14T08:55:19.0491854Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.0493402Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.0494955Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123179912567139)
2026-01-14T08:55:19.0495499Z   )
2026-01-14T08:55:19.0495674Z )
2026-01-14T08:55:19.0495774Z 
2026-01-14T08:55:19.0495778Z 
2026-01-14T08:55:19.0495782Z 
2026-01-14T08:55:19.0495875Z def forward(self, x):
2026-01-14T08:55:19.0496299Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:19.0496683Z     conv_weight = self.conv.weight
2026-01-14T08:55:19.0496973Z     conv_bias = self.conv.bias
2026-01-14T08:55:19.0497246Z     bn_weight = self.bn.weight
2026-01-14T08:55:19.0497518Z     bn_bias = self.bn.bias
2026-01-14T08:55:19.0497791Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:55:19.0498124Z     bn_running_var = self.bn.running_var
2026-01-14T08:55:19.0498486Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:19.0498995Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:19.0499683Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:35.7486830Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:55:35.7487507Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:55:35.7488098Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:55:35.7488637Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:55:35.7489208Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:55:35.7489942Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:55:35.7490661Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:55:35.7491848Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:55:35.7492899Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:55:35.7493514Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:55:35.7494176Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:55:35.7494819Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:55:35.7495897Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:35.7496939Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:35.7497540Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:35.7498165Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:35.7498611Z     
2026-01-14T08:55:35.7498914Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:35.7499327Z model fx: GraphModule(
2026-01-14T08:55:35.7499679Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:35.7501066Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:35.7502677Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:35.7503271Z   )
2026-01-14T08:55:35.7503465Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:35.7503728Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:55:35.7504438Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:35.7504988Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:35.7506419Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:35.7508540Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:55:35.7509537Z     )
2026-01-14T08:55:35.7509713Z   )
2026-01-14T08:55:35.7510010Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:35.7511416Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:35.7513047Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123179912567139)
2026-01-14T08:55:35.7513596Z   )
2026-01-14T08:55:35.7513772Z )
2026-01-14T08:55:35.7513879Z 
2026-01-14T08:55:35.7513883Z 
2026-01-14T08:55:35.7513887Z 
2026-01-14T08:55:35.7513979Z def forward(self, x):
2026-01-14T08:55:35.7514360Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:35.7514967Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:35.7515587Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:35.7516072Z     return activation_post_process_1
2026-01-14T08:55:35.7516347Z     
2026-01-14T08:55:35.7516648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:35.7517059Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:35.7517303Z          [0., 0., 0.],
2026-01-14T08:55:35.7517594Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:55:35.7517965Z converted model pt2e: GraphModule(
2026-01-14T08:55:35.7518246Z   (conv): Module()
2026-01-14T08:55:35.7518451Z   (bn): Module()
2026-01-14T08:55:35.7518654Z )
2026-01-14T08:55:35.7518754Z 
2026-01-14T08:55:35.7518758Z 
2026-01-14T08:55:35.7518762Z 
2026-01-14T08:55:35.7518854Z def forward(self, x):
2026-01-14T08:55:35.7519150Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:35.7519521Z     conv_bias = self.conv.bias
2026-01-14T08:55:35.7519843Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:35.7520672Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:35.7522170Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:35.7523422Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:35.7523967Z     _scale_0 = self._scale_0
2026-01-14T08:55:35.7524237Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:55:35.7524566Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:55:35.7525622Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:55:35.7527274Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:55:35.7528430Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:35.7529349Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538502242416143, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:35.7530973Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538502242416143, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:35.7532286Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:55:35.7532752Z     
2026-01-14T08:55:35.7533059Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:35.7533475Z onverted model fx: GraphModule(
2026-01-14T08:55:35.7533753Z   (conv): ConvReLU1d(
2026-01-14T08:55:35.7534153Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:35.7534571Z     (1): ReLU()
2026-01-14T08:55:35.7534768Z   )
2026-01-14T08:55:35.7534937Z )
2026-01-14T08:55:35.7535038Z 
2026-01-14T08:55:35.7535042Z 
2026-01-14T08:55:35.7535046Z 
2026-01-14T08:55:35.7535146Z def forward(self, x):
2026-01-14T08:55:35.7535853Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:35.7537350Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:35.7538566Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:35.7539581Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538502242416143, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:35.7541153Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538502242416143, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:35.7542222Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:35.7542519Z     
2026-01-14T08:55:35.7542818Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:35.7543229Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:35.7543477Z          [0., 0., 0.],
2026-01-14T08:55:35.7543707Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:55:35.7544002Z model pt2e: GraphModule(
2026-01-14T08:55:35.7544243Z   (conv): Module()
2026-01-14T08:55:35.7544451Z   (bn): Module()
2026-01-14T08:55:35.7544762Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:35.7546157Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:35.7547743Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:35.7548331Z   )
2026-01-14T08:55:35.7548623Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:35.7550017Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:35.7551626Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:55:35.7552229Z   )
2026-01-14T08:55:35.7552519Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:00.1204882Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:00.1206845Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123179912567139)
2026-01-14T08:56:00.1207808Z   )
2026-01-14T08:56:00.1208038Z )
2026-01-14T08:56:00.1208163Z 
2026-01-14T08:56:00.1208168Z 
2026-01-14T08:56:00.1208173Z 
2026-01-14T08:56:00.1208290Z def forward(self, x):
2026-01-14T08:56:00.1208661Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:00.1209119Z     conv_weight = self.conv.weight
2026-01-14T08:56:00.1209473Z     conv_bias = self.conv.bias
2026-01-14T08:56:00.1209902Z     bn_weight = self.bn.weight
2026-01-14T08:56:00.1210229Z     bn_bias = self.bn.bias
2026-01-14T08:56:00.1210573Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:00.1210983Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:00.1211451Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:00.1212043Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:00.1212856Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:00.1213605Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:00.1214114Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:00.1214663Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:00.1215241Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:00.1215907Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:00.1216674Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:00.1217521Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:56:00.1218912Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:56:00.1220161Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:00.1220896Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:00.1221732Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:56:00.1222481Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:56:00.1223759Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:00.1225001Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:00.1225712Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:00.1226450Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:00.1226970Z     
2026-01-14T08:56:00.1227339Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:00.1227828Z model fx: GraphModule(
2026-01-14T08:56:00.1228243Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:00.1229875Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:00.1231902Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:00.1232615Z   )
2026-01-14T08:56:00.1232846Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:00.1233154Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:56:00.1233706Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:00.1234343Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:00.1244693Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:00.1246403Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:56:00.1247012Z     )
2026-01-14T08:56:00.1247191Z   )
2026-01-14T08:56:00.1247498Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:00.1248896Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:00.1250484Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123179912567139)
2026-01-14T08:56:00.1251033Z   )
2026-01-14T08:56:00.1251205Z )
2026-01-14T08:56:00.1251312Z 
2026-01-14T08:56:00.1251316Z 
2026-01-14T08:56:00.1251320Z 
2026-01-14T08:56:00.1251408Z def forward(self, x):
2026-01-14T08:56:00.1251798Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:00.1252399Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:00.1253026Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:00.1253515Z     return activation_post_process_1
2026-01-14T08:56:00.1253797Z     
2026-01-14T08:56:00.1254095Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:00.1254513Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:00.1254758Z          [0., 0., 0.],
2026-01-14T08:56:00.1255052Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:56:00.1255434Z converted model pt2e: GraphModule(
2026-01-14T08:56:00.1255710Z   (conv): Module()
2026-01-14T08:56:00.1255928Z   (bn): Module()
2026-01-14T08:56:00.1256129Z )
2026-01-14T08:56:00.1256231Z 
2026-01-14T08:56:00.1256244Z 
2026-01-14T08:56:00.1256249Z 
2026-01-14T08:56:00.1256337Z def forward(self, x):
2026-01-14T08:56:00.1256639Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:00.1257015Z     conv_bias = self.conv.bias
2026-01-14T08:56:00.1257347Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:00.1258171Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:00.1259655Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:00.1260898Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:00.1261479Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:56:00.1262406Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:56:00.1263914Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:56:00.1265037Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:00.1265949Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538502242416143, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:00.1267501Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005538502242416143, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:00.1268795Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:00.1269258Z     
2026-01-14T08:56:00.1269566Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:00.1269984Z onverted model fx: GraphModule(
2026-01-14T08:56:00.1270263Z   (conv): ConvReLU1d(
2026-01-14T08:56:00.1270618Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:00.1271048Z     (1): ReLU()
2026-01-14T08:56:00.1271276Z   )
2026-01-14T08:56:00.1271445Z )
2026-01-14T08:56:00.1271544Z 
2026-01-14T08:56:00.1271548Z 
2026-01-14T08:56:00.1271558Z 
2026-01-14T08:56:00.1271643Z def forward(self, x):
2026-01-14T08:56:00.1272341Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:00.1273820Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:00.1275352Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:00.1276365Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538502242416143, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:00.1277921Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538502242416143, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:00.1278988Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:00.1279276Z     
2026-01-14T08:56:00.1279584Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:00.1279993Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:00.1280250Z          [0., 0., 0.],
2026-01-14T08:56:00.1280480Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:56:00.1280983Z [32mPASSED[0m
2026-01-14T08:56:00.1281691Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:56:00.1282452Z   (conv): Module()
2026-01-14T08:56:00.1282669Z   (bn): Module()
2026-01-14T08:56:00.1282984Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:00.1284127Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:19.2365711Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:19.2366478Z   )
2026-01-14T08:56:19.2366845Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:19.2368354Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:19.2370449Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:56:19.2371373Z   )
2026-01-14T08:56:19.2372012Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:19.2373422Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:19.2375328Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:56:19.2376182Z   )
2026-01-14T08:56:19.2376396Z )
2026-01-14T08:56:19.2376533Z 
2026-01-14T08:56:19.2376539Z 
2026-01-14T08:56:19.2376544Z 
2026-01-14T08:56:19.2376654Z def forward(self, x):
2026-01-14T08:56:19.2377044Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:19.2377508Z     conv_weight = self.conv.weight
2026-01-14T08:56:19.2377875Z     bn_weight = self.bn.weight
2026-01-14T08:56:19.2378200Z     bn_bias = self.bn.bias
2026-01-14T08:56:19.2378540Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:19.2378942Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:19.2379423Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:19.2380031Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:19.2380854Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:19.2381603Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:19.2382130Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:19.2382680Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:19.2383272Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:19.2383945Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:19.2384723Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:19.2385915Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:19.2387085Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:19.2387816Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:19.2389131Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:19.2390398Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:19.2391105Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:19.2391854Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:19.2392389Z     
2026-01-14T08:56:19.2392757Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:19.2393250Z model fx: GraphModule(
2026-01-14T08:56:19.2393658Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:19.2395021Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:19.2396637Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:19.2397352Z   )
2026-01-14T08:56:19.2397586Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:19.2397912Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:19.2398502Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:19.2399144Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:19.2400717Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:19.2402650Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:56:19.2403642Z     )
2026-01-14T08:56:19.2403876Z   )
2026-01-14T08:56:19.2404230Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:19.2405607Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:19.2407240Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:56:19.2407890Z   )
2026-01-14T08:56:19.2408071Z )
2026-01-14T08:56:19.2408179Z 
2026-01-14T08:56:19.2408184Z 
2026-01-14T08:56:19.2408188Z 
2026-01-14T08:56:19.2408279Z def forward(self, x):
2026-01-14T08:56:19.2408663Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:19.2409266Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:19.2409964Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:19.2410460Z     return activation_post_process_1
2026-01-14T08:56:19.2410740Z     
2026-01-14T08:56:19.2411046Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:19.2411456Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:19.2411713Z          [0., 0., 0.],
2026-01-14T08:56:19.2411963Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:19.2412306Z converted model pt2e: GraphModule(
2026-01-14T08:56:19.2412586Z   (conv): Module()
2026-01-14T08:56:19.2412808Z   (bn): Module()
2026-01-14T08:56:19.2413009Z )
2026-01-14T08:56:19.2413121Z 
2026-01-14T08:56:19.2413125Z 
2026-01-14T08:56:19.2413129Z 
2026-01-14T08:56:19.2413216Z def forward(self, x):
2026-01-14T08:56:19.2413527Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:19.2413945Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:19.2414779Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:19.2416271Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:19.2417578Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:19.2418126Z     _scale_0 = self._scale_0
2026-01-14T08:56:19.2418395Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:19.2418732Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:56:19.2419783Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:19.2420851Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:56:19.2421852Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:56:19.2422927Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:19.2423852Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0054035005159676075, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:19.2425511Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:19.2426742Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:19.2427212Z     
2026-01-14T08:56:19.2427511Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:19.2427937Z onverted model fx: GraphModule(
2026-01-14T08:56:19.2428295Z   (conv): ConvReLU1d(
2026-01-14T08:56:19.2428651Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:19.2429053Z     (1): ReLU()
2026-01-14T08:56:19.2429255Z   )
2026-01-14T08:56:19.2429433Z )
2026-01-14T08:56:19.2429536Z 
2026-01-14T08:56:19.2429540Z 
2026-01-14T08:56:19.2429544Z 
2026-01-14T08:56:19.2429640Z def forward(self, x):
2026-01-14T08:56:19.2430351Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:19.2431837Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:19.2433048Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:19.2434068Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0054035005159676075, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:19.2435642Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:19.2436712Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:19.2437005Z     
2026-01-14T08:56:19.2437308Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:19.2437717Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:19.2437965Z          [0., 0., 0.],
2026-01-14T08:56:19.2438179Z          [0., 0., 0.]]])
2026-01-14T08:56:19.2438423Z model pt2e: GraphModule(
2026-01-14T08:56:19.2438667Z   (conv): Module()
2026-01-14T08:56:19.2438874Z   (bn): Module()
2026-01-14T08:56:19.2439198Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3471256Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:34.3472928Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:34.3473646Z   )
2026-01-14T08:56:34.3473999Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3475609Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:34.3477252Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:56:34.3477968Z   )
2026-01-14T08:56:34.3478332Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3479705Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:34.3481309Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:56:34.3481977Z   )
2026-01-14T08:56:34.3482200Z )
2026-01-14T08:56:34.3482336Z 
2026-01-14T08:56:34.3482341Z 
2026-01-14T08:56:34.3482346Z 
2026-01-14T08:56:34.3482827Z def forward(self, x):
2026-01-14T08:56:34.3483206Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:34.3483661Z     conv_weight = self.conv.weight
2026-01-14T08:56:34.3484050Z     bn_weight = self.bn.weight
2026-01-14T08:56:34.3484375Z     bn_bias = self.bn.bias
2026-01-14T08:56:34.3484710Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:56:34.3485098Z     bn_running_var = self.bn.running_var
2026-01-14T08:56:34.3485722Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:34.3486315Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:34.3487127Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:34.3487866Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:56:34.3488379Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:56:34.3488932Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:56:34.3489523Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:56:34.3490308Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:56:34.3491090Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:56:34.3492277Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:34.3493453Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:56:34.3494180Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:56:34.3495503Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:56:34.3496770Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:56:34.3497477Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:34.3498226Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:34.3498749Z     
2026-01-14T08:56:34.3499117Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:34.3499621Z model fx: GraphModule(
2026-01-14T08:56:34.3500027Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3501387Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:34.3502993Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:34.3503708Z   )
2026-01-14T08:56:34.3503944Z   (conv): ConvBnReLU1d(
2026-01-14T08:56:34.3504275Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:34.3504859Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:56:34.3505495Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3506827Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:34.3508475Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:56:34.3509200Z     )
2026-01-14T08:56:34.3509451Z   )
2026-01-14T08:56:34.3509823Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:34.3511266Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:34.3512569Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:56:34.3513113Z   )
2026-01-14T08:56:34.3513286Z )
2026-01-14T08:56:34.3513397Z 
2026-01-14T08:56:34.3513401Z 
2026-01-14T08:56:34.3513405Z 
2026-01-14T08:56:34.3513580Z def forward(self, x):
2026-01-14T08:56:34.3513966Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:34.3514565Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:34.3515193Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:34.3515674Z     return activation_post_process_1
2026-01-14T08:56:34.3515956Z     
2026-01-14T08:56:34.3516253Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:34.3516676Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:34.3516926Z          [0., 0., 0.],
2026-01-14T08:56:34.3517176Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:34.3517512Z converted model pt2e: GraphModule(
2026-01-14T08:56:34.3517790Z   (conv): Module()
2026-01-14T08:56:34.3518005Z   (bn): Module()
2026-01-14T08:56:34.3518200Z )
2026-01-14T08:56:34.3518307Z 
2026-01-14T08:56:34.3518311Z 
2026-01-14T08:56:34.3518321Z 
2026-01-14T08:56:34.3518408Z def forward(self, x):
2026-01-14T08:56:34.3518710Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:34.3519135Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:56:34.3519958Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:34.3521442Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:34.3522700Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:56:34.3523274Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:56:34.3524205Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:56:34.3525157Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:56:34.3526139Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:56:34.3527216Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:56:34.3528146Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0053919292986392975, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:34.3529709Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:34.3530978Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:34.3531449Z     
2026-01-14T08:56:34.3531751Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:34.3532177Z onverted model fx: GraphModule(
2026-01-14T08:56:34.3532445Z   (conv): ConvReLU1d(
2026-01-14T08:56:34.3532798Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:56:34.3533198Z     (1): ReLU()
2026-01-14T08:56:34.3533396Z   )
2026-01-14T08:56:34.3533566Z )
2026-01-14T08:56:34.3533673Z 
2026-01-14T08:56:34.3533677Z 
2026-01-14T08:56:34.3533680Z 
2026-01-14T08:56:34.3533766Z def forward(self, x):
2026-01-14T08:56:34.3534604Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:34.3536092Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:34.3537389Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:34.3538409Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0053919292986392975, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:34.3539977Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:34.3541058Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:34.3541396Z     
2026-01-14T08:56:34.3541707Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:34.3542119Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:34.3542368Z          [0., 0., 0.],
2026-01-14T08:56:34.3542587Z          [0., 0., 0.]]])
2026-01-14T08:56:34.3543025Z [32mPASSED[0m
2026-01-14T08:56:34.3543654Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T08:56:34.3544348Z   (conv): Module()
2026-01-14T08:56:34.3544682Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7859169Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:35.7861149Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:56:35.7862065Z   )
2026-01-14T08:56:35.7862422Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7863790Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7865408Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:35.7866110Z   )
2026-01-14T08:56:35.7866467Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7867858Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7869407Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:56:35.7870053Z   )
2026-01-14T08:56:35.7870268Z )
2026-01-14T08:56:35.7870398Z 
2026-01-14T08:56:35.7870404Z 
2026-01-14T08:56:35.7870409Z 
2026-01-14T08:56:35.7870520Z def forward(self, x):
2026-01-14T08:56:35.7870895Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:35.7871355Z     conv_weight = self.conv.weight
2026-01-14T08:56:35.7872027Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:35.7872831Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:35.7873977Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:35.7875232Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:35.7876162Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:35.7876926Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:35.7877452Z     
2026-01-14T08:56:35.7877826Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:35.7878320Z model fx: GraphModule(
2026-01-14T08:56:35.7878921Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7880288Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7881897Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:35.7882615Z   )
2026-01-14T08:56:35.7882841Z   (conv): ConvReLU1d(
2026-01-14T08:56:35.7883176Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:35.7883649Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7885070Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:35.7886998Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:56:35.7887908Z     )
2026-01-14T08:56:35.7888133Z   )
2026-01-14T08:56:35.7888478Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7889950Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7891516Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:56:35.7892157Z   )
2026-01-14T08:56:35.7892372Z )
2026-01-14T08:56:35.7892495Z 
2026-01-14T08:56:35.7892500Z 
2026-01-14T08:56:35.7892505Z 
2026-01-14T08:56:35.7892613Z def forward(self, x):
2026-01-14T08:56:35.7893083Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:35.7893823Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:35.7894575Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:35.7895168Z     return activation_post_process_1
2026-01-14T08:56:35.7895507Z     
2026-01-14T08:56:35.7895872Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:35.7896371Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:35.7896681Z          [0., 0., 0.],
2026-01-14T08:56:35.7896992Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:35.7897397Z converted model pt2e: GraphModule(
2026-01-14T08:56:35.7897742Z   (conv): Module()
2026-01-14T08:56:35.7897994Z )
2026-01-14T08:56:35.7898119Z 
2026-01-14T08:56:35.7898124Z 
2026-01-14T08:56:35.7898129Z 
2026-01-14T08:56:35.7898243Z def forward(self, x):
2026-01-14T08:56:35.7898612Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:35.7899060Z     _scale_0 = self._scale_0
2026-01-14T08:56:35.7899396Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:35.7899864Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:56:35.7901258Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:35.7903022Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:35.7904513Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:35.7906115Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:56:35.7907171Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:35.7908078Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0037561955396085978, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:35.7909643Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:35.7910876Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:35.7911351Z     
2026-01-14T08:56:35.7911654Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:35.7912083Z onverted model fx: GraphModule(
2026-01-14T08:56:35.7912359Z   (conv): ConvReLU1d(
2026-01-14T08:56:35.7912761Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:35.7913219Z     (1): ReLU()
2026-01-14T08:56:35.7913419Z   )
2026-01-14T08:56:35.7913591Z )
2026-01-14T08:56:35.7913699Z 
2026-01-14T08:56:35.7913702Z 
2026-01-14T08:56:35.7913706Z 
2026-01-14T08:56:35.7913794Z def forward(self, x):
2026-01-14T08:56:35.7914505Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:35.7915990Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:35.7917208Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:35.7918236Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0037561955396085978, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:35.7919806Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:35.7920878Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:35.7921177Z     
2026-01-14T08:56:35.7921490Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:35.7921900Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:35.7922157Z          [0., 0., 0.],
2026-01-14T08:56:35.7922395Z          [0., 0., 0.]]])
2026-01-14T08:56:35.7922643Z model pt2e: GraphModule(
2026-01-14T08:56:35.7922881Z   (conv): Module()
2026-01-14T08:56:35.7931573Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7932845Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:35.7934237Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:56:35.7934843Z   )
2026-01-14T08:56:35.7935155Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7936286Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7937739Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:35.7938339Z   )
2026-01-14T08:56:35.7938637Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:35.7939784Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:35.7941156Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:56:35.7941696Z   )
2026-01-14T08:56:35.7941873Z )
2026-01-14T08:56:35.7941984Z 
2026-01-14T08:56:35.7941988Z 
2026-01-14T08:56:35.7941992Z 
2026-01-14T08:56:35.7942080Z def forward(self, x):
2026-01-14T08:56:35.7942401Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:35.7942772Z     conv_weight = self.conv.weight
2026-01-14T08:56:37.2178966Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:37.2179844Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:37.2181084Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:37.2181991Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:37.2182553Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:37.2183175Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:37.2183628Z     
2026-01-14T08:56:37.2183943Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:37.2184358Z model fx: GraphModule(
2026-01-14T08:56:37.2184705Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2185857Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:37.2187228Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:37.2187827Z   )
2026-01-14T08:56:37.2188026Z   (conv): ConvReLU1d(
2026-01-14T08:56:37.2188305Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:37.2188705Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2189824Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:37.2191195Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:56:37.2191804Z     )
2026-01-14T08:56:37.2191999Z   )
2026-01-14T08:56:37.2192348Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2193500Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:37.2194791Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:56:37.2195332Z   )
2026-01-14T08:56:37.2195515Z )
2026-01-14T08:56:37.2195633Z 
2026-01-14T08:56:37.2195637Z 
2026-01-14T08:56:37.2195641Z 
2026-01-14T08:56:37.2195733Z def forward(self, x):
2026-01-14T08:56:37.2196121Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:37.2196728Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:37.2197573Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:37.2198065Z     return activation_post_process_1
2026-01-14T08:56:37.2198349Z     
2026-01-14T08:56:37.2198648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:37.2199063Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:37.2199315Z          [0., 0., 0.],
2026-01-14T08:56:37.2199696Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:37.2200033Z converted model pt2e: GraphModule(
2026-01-14T08:56:37.2200313Z   (conv): Module()
2026-01-14T08:56:37.2200528Z )
2026-01-14T08:56:37.2200631Z 
2026-01-14T08:56:37.2200635Z 
2026-01-14T08:56:37.2200639Z 
2026-01-14T08:56:37.2200727Z def forward(self, x):
2026-01-14T08:56:37.2201038Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:37.2201456Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:56:37.2202549Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0024561325553804636, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:37.2204047Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:37.2205551Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:37.2207176Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:56:37.2208162Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:56:37.2209065Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003747650422155857, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:37.2210709Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:37.2211933Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:37.2212412Z     
2026-01-14T08:56:37.2212727Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:37.2213151Z onverted model fx: GraphModule(
2026-01-14T08:56:37.2213434Z   (conv): ConvReLU1d(
2026-01-14T08:56:37.2213828Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:37.2214289Z     (1): ReLU()
2026-01-14T08:56:37.2214490Z   )
2026-01-14T08:56:37.2214675Z )
2026-01-14T08:56:37.2214781Z 
2026-01-14T08:56:37.2214785Z 
2026-01-14T08:56:37.2214789Z 
2026-01-14T08:56:37.2214898Z def forward(self, x):
2026-01-14T08:56:37.2215603Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:37.2217092Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:37.2218294Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:37.2219316Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003747650422155857, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:37.2220870Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:37.2222031Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:37.2222393Z     
2026-01-14T08:56:37.2222693Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:37.2223112Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:37.2223365Z          [0., 0., 0.],
2026-01-14T08:56:37.2223583Z          [0., 0., 0.]]])
2026-01-14T08:56:37.2223828Z model pt2e: GraphModule(
2026-01-14T08:56:37.2224155Z   (conv): Module()
2026-01-14T08:56:37.2224485Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2225696Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:37.2227294Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:56:37.2228061Z   )
2026-01-14T08:56:37.2228358Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2229501Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:37.2230833Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:37.2231431Z   )
2026-01-14T08:56:37.2231736Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2232863Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:37.2234213Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:56:37.2234803Z   )
2026-01-14T08:56:37.2234987Z )
2026-01-14T08:56:37.2235087Z 
2026-01-14T08:56:37.2235091Z 
2026-01-14T08:56:37.2235095Z 
2026-01-14T08:56:37.2235190Z def forward(self, x):
2026-01-14T08:56:37.2235497Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:37.2235882Z     conv_weight = self.conv.weight
2026-01-14T08:56:37.2236398Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:37.2237079Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:37.2238023Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:37.2239004Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:56:37.2239652Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:37.2240089Z     
2026-01-14T08:56:37.2240400Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:37.2240808Z model fx: GraphModule(
2026-01-14T08:56:37.2241159Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2242321Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:37.2243698Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:37.2244302Z   )
2026-01-14T08:56:37.2244490Z   (conv): Conv1d(
2026-01-14T08:56:37.2244752Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:37.2245150Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:37.2246434Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:38.8264766Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:56:38.8266112Z     )
2026-01-14T08:56:38.8266357Z   )
2026-01-14T08:56:38.8266764Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8268097Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:38.8269465Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:56:38.8270061Z   )
2026-01-14T08:56:38.8270275Z )
2026-01-14T08:56:38.8270386Z 
2026-01-14T08:56:38.8270391Z 
2026-01-14T08:56:38.8270394Z 
2026-01-14T08:56:38.8270483Z def forward(self, x):
2026-01-14T08:56:38.8270874Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:38.8271480Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:38.8272111Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:38.8272604Z     return activation_post_process_1
2026-01-14T08:56:38.8272885Z     
2026-01-14T08:56:38.8273193Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:38.8273603Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:38.8273860Z          [0., 0., 0.],
2026-01-14T08:56:38.8274112Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:38.8274454Z converted model pt2e: GraphModule(
2026-01-14T08:56:38.8274921Z   (conv): Module()
2026-01-14T08:56:38.8275132Z )
2026-01-14T08:56:38.8275239Z 
2026-01-14T08:56:38.8275243Z 
2026-01-14T08:56:38.8275247Z 
2026-01-14T08:56:38.8275335Z def forward(self, x):
2026-01-14T08:56:38.8275644Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:38.8276021Z     _scale_0 = self._scale_0
2026-01-14T08:56:38.8276291Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:38.8276648Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:56:38.8277851Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:38.8279471Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:38.8280963Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:38.8282556Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:56:38.8283986Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008684427477419376, -25, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:56:38.8285571Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:38.8286783Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:56:38.8287264Z     
2026-01-14T08:56:38.8287566Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:38.8288318Z onverted model fx: GraphModule(
2026-01-14T08:56:38.8288942Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:38.8289481Z )
2026-01-14T08:56:38.8289586Z 
2026-01-14T08:56:38.8289591Z 
2026-01-14T08:56:38.8289595Z 
2026-01-14T08:56:38.8289688Z def forward(self, x):
2026-01-14T08:56:38.8290480Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:38.8293652Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:38.8294868Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:38.8295892Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008684427477419376, -25, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:38.8297459Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:38.8298524Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:38.8298823Z     
2026-01-14T08:56:38.8299137Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:38.8299551Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:38.8299801Z          [0., 0., 0.],
2026-01-14T08:56:38.8300019Z          [0., 0., 0.]]])
2026-01-14T08:56:38.8300266Z model pt2e: GraphModule(
2026-01-14T08:56:38.8300508Z   (conv): Module()
2026-01-14T08:56:38.8300841Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8301995Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:38.8303377Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:56:38.8303990Z   )
2026-01-14T08:56:38.8304281Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8305414Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:38.8306767Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:38.8307363Z   )
2026-01-14T08:56:38.8307659Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8308813Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:38.8310167Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:56:38.8310782Z   )
2026-01-14T08:56:38.8310967Z )
2026-01-14T08:56:38.8311069Z 
2026-01-14T08:56:38.8311074Z 
2026-01-14T08:56:38.8311082Z 
2026-01-14T08:56:38.8311172Z def forward(self, x):
2026-01-14T08:56:38.8311488Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:38.8311868Z     conv_weight = self.conv.weight
2026-01-14T08:56:38.8312394Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:38.8313071Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:38.8314127Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:56:38.8315128Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:56:38.8315764Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:56:38.8316213Z     
2026-01-14T08:56:38.8316516Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:38.8317017Z model fx: GraphModule(
2026-01-14T08:56:38.8317363Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8318517Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:38.8319877Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:56:38.8320471Z   )
2026-01-14T08:56:38.8320665Z   (conv): Conv1d(
2026-01-14T08:56:38.8320923Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:38.8321331Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8322459Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:38.8323844Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:56:38.8324455Z     )
2026-01-14T08:56:38.8324633Z   )
2026-01-14T08:56:38.8324934Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:38.8326085Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:38.8327447Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:56:38.8328053Z   )
2026-01-14T08:56:38.8328227Z )
2026-01-14T08:56:38.8328339Z 
2026-01-14T08:56:38.8328343Z 
2026-01-14T08:56:38.8328347Z 
2026-01-14T08:56:38.8328435Z def forward(self, x):
2026-01-14T08:56:38.8328819Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:38.8329447Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:38.8330136Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:38.8330621Z     return activation_post_process_1
2026-01-14T08:56:38.8330911Z     
2026-01-14T08:56:38.8331214Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:38.8331636Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:38.8331882Z          [0., 0., 0.],
2026-01-14T08:56:38.8332150Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:38.8332485Z converted model pt2e: GraphModule(
2026-01-14T08:56:38.8332779Z   (conv): Module()
2026-01-14T08:56:38.8332991Z )
2026-01-14T08:56:38.8333093Z 
2026-01-14T08:56:38.8333097Z 
2026-01-14T08:56:38.8333101Z 
2026-01-14T08:56:38.8333189Z def forward(self, x):
2026-01-14T08:56:38.8333506Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:38.8333930Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:56:38.8335016Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002545453840866685, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:51.2285413Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:57:51.2287262Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:51.2288896Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:57:51.2290406Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008662103675305843, -26, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:57:51.2292148Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:51.2293357Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:57:51.2293830Z     
2026-01-14T08:57:51.2294135Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:51.2294572Z onverted model fx: GraphModule(
2026-01-14T08:57:51.2295021Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:57:51.2295493Z )
2026-01-14T08:57:51.2295597Z 
2026-01-14T08:57:51.2295601Z 
2026-01-14T08:57:51.2295605Z 
2026-01-14T08:57:51.2295700Z def forward(self, x):
2026-01-14T08:57:51.2296404Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:57:51.2297890Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:51.2299088Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:57:51.2300132Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008662103675305843, -26, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:51.2301677Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:51.2302743Z     return dequantize_per_tensor_default_1
2026-01-14T08:57:51.2303040Z     
2026-01-14T08:57:51.2303347Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:51.2303761Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:51.2304013Z          [0., 0., 0.],
2026-01-14T08:57:51.2304230Z          [0., 0., 0.]]])
2026-01-14T08:57:51.2304680Z [32mPASSED[0m
2026-01-14T08:57:51.2305400Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T08:57:51.2306560Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:57:51.2307655Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T08:57:51.2308344Z   (conv): Module()
2026-01-14T08:57:51.2308680Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2309843Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:51.2311295Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:57:51.2311950Z   )
2026-01-14T08:57:51.2312242Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2313476Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2314819Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:57:51.2315407Z   )
2026-01-14T08:57:51.2315701Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2316821Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2318250Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:57:51.2318855Z   )
2026-01-14T08:57:51.2319147Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2320293Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2321575Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:57:51.2322109Z   )
2026-01-14T08:57:51.2322275Z )
2026-01-14T08:57:51.2322379Z 
2026-01-14T08:57:51.2322384Z 
2026-01-14T08:57:51.2322393Z 
2026-01-14T08:57:51.2322483Z def forward(self, x):
2026-01-14T08:57:51.2322787Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:51.2323156Z     conv_weight = self.conv.weight
2026-01-14T08:57:51.2323666Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:57:51.2324201Z     conv_bias = self.conv.bias
2026-01-14T08:57:51.2324609Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:51.2325527Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:57:51.2326478Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:57:51.2327424Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:57:51.2328265Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:57:51.2328803Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:57:51.2329421Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:57:51.2329915Z     
2026-01-14T08:57:51.2330217Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:51.2330617Z model fx: GraphModule(
2026-01-14T08:57:51.2330961Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2332094Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2333433Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:57:51.2334019Z   )
2026-01-14T08:57:51.2334201Z   (conv): Conv1d(
2026-01-14T08:57:51.2334428Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:57:51.2334783Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2335910Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:51.2337339Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:57:51.2338094Z     )
2026-01-14T08:57:51.2338274Z   )
2026-01-14T08:57:51.2338564Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2339695Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2341122Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:57:51.2341724Z   )
2026-01-14T08:57:51.2341915Z   (relu): ReLU(inplace=True)
2026-01-14T08:57:51.2342279Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:51.2343426Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:51.2344715Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:57:51.2345254Z   )
2026-01-14T08:57:51.2345423Z )
2026-01-14T08:57:51.2345530Z 
2026-01-14T08:57:51.2345535Z 
2026-01-14T08:57:51.2345539Z 
2026-01-14T08:57:51.2345627Z def forward(self, x):
2026-01-14T08:57:51.2346017Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:51.2346500Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:57:51.2346989Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:57:51.2347792Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:57:51.2348458Z     relu = self.relu(add);  add = None
2026-01-14T08:57:51.2348916Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:57:51.2349394Z     return activation_post_process_2
2026-01-14T08:57:51.2349684Z     
2026-01-14T08:57:51.2349976Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:51.2350436Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:57:51.2350803Z converted model pt2e: GraphModule(
2026-01-14T08:57:51.2351090Z   (conv): Module()
2026-01-14T08:57:51.2351287Z )
2026-01-14T08:57:51.2351397Z 
2026-01-14T08:57:51.2351407Z 
2026-01-14T08:57:51.2351411Z 
2026-01-14T08:57:51.2351496Z def forward(self, x):
2026-01-14T08:57:51.2351805Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:51.2352162Z     _scale_0 = self._scale_0
2026-01-14T08:57:51.2352431Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:57:51.2352772Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:57:52.5183748Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:57:52.5184955Z     conv_bias = self.conv.bias
2026-01-14T08:57:52.5185711Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:57:52.5187061Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:57:52.5188664Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:52.5190373Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T08:57:52.5192076Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:57:52.5193643Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:52.5195360Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T08:57:52.5196309Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:57:52.5197203Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:57:52.5198784Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:52.5200002Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:57:52.5200476Z     
2026-01-14T08:57:52.5200787Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:52.5201207Z onverted model fx: GraphModule(
2026-01-14T08:57:52.5201636Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:57:52.5202084Z   (relu): ReLU(inplace=True)
2026-01-14T08:57:52.5202339Z )
2026-01-14T08:57:52.5202445Z 
2026-01-14T08:57:52.5202449Z 
2026-01-14T08:57:52.5202460Z 
2026-01-14T08:57:52.5202549Z def forward(self, x):
2026-01-14T08:57:52.5210817Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:57:52.5212332Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:52.5213399Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:57:52.5214251Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:52.5215802Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:52.5217275Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:57:52.5218019Z     relu = self.relu(add);  add = None
2026-01-14T08:57:52.5218835Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:57:52.5220389Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:52.5221452Z     return dequantize_per_tensor_default_2
2026-01-14T08:57:52.5221755Z     
2026-01-14T08:57:52.5222049Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:52.5222465Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:57:52.5222728Z model pt2e: GraphModule(
2026-01-14T08:57:52.5222977Z   (conv): Module()
2026-01-14T08:57:52.5223294Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5224580Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:52.5226011Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:57:52.5226611Z   )
2026-01-14T08:57:52.5226910Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5228035Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:52.5229457Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:57:52.5230047Z   )
2026-01-14T08:57:52.5230334Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5231465Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:52.5232808Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:57:52.5233407Z   )
2026-01-14T08:57:52.5233702Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5234856Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:52.5236175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:57:52.5236703Z   )
2026-01-14T08:57:52.5236882Z )
2026-01-14T08:57:52.5236984Z 
2026-01-14T08:57:52.5236988Z 
2026-01-14T08:57:52.5236992Z 
2026-01-14T08:57:52.5237086Z def forward(self, x):
2026-01-14T08:57:52.5237394Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:52.5237773Z     conv_weight = self.conv.weight
2026-01-14T08:57:52.5238282Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:57:52.5238825Z     conv_bias = self.conv.bias
2026-01-14T08:57:52.5239228Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:52.5240158Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:57:52.5241112Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:57:52.5242056Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:57:52.5242897Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:57:52.5243434Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:57:52.5244063Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:57:52.5244506Z     
2026-01-14T08:57:52.5244804Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:52.5245214Z model fx: GraphModule(
2026-01-14T08:57:52.5245554Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5246698Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:52.5248036Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:57:52.5248627Z   )
2026-01-14T08:57:52.5248813Z   (conv): Conv1d(
2026-01-14T08:57:52.5249037Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:57:52.5249491Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5250660Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:52.5252049Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:57:52.5252747Z     )
2026-01-14T08:57:52.5252922Z   )
2026-01-14T08:57:52.5253218Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:52.5254347Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:52.5255706Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:57:52.5256296Z   )
2026-01-14T08:57:52.5256495Z   (relu): ReLU(inplace=True)
2026-01-14T08:57:52.5256859Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:30.2767176Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:30.2768689Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:58:30.2769511Z   )
2026-01-14T08:58:30.2769871Z )
2026-01-14T08:58:30.2770010Z 
2026-01-14T08:58:30.2770016Z 
2026-01-14T08:58:30.2770021Z 
2026-01-14T08:58:30.2770137Z def forward(self, x):
2026-01-14T08:58:30.2770672Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:30.2771362Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:58:30.2772053Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:58:30.2773099Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:58:30.2774018Z     relu = self.relu(add);  add = None
2026-01-14T08:58:30.2774601Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:58:30.2775376Z     return activation_post_process_2
2026-01-14T08:58:30.2775667Z     
2026-01-14T08:58:30.2776022Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:30.2776494Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:58:30.2776868Z converted model pt2e: GraphModule(
2026-01-14T08:58:30.2777168Z   (conv): Module()
2026-01-14T08:58:30.2777388Z )
2026-01-14T08:58:30.2777493Z 
2026-01-14T08:58:30.2777497Z 
2026-01-14T08:58:30.2777502Z 
2026-01-14T08:58:30.2777590Z def forward(self, x):
2026-01-14T08:58:30.2777913Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:30.2778340Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:58:30.2779427Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0019342823652550578, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:30.2780627Z     conv_bias = self.conv.bias
2026-01-14T08:58:30.2781380Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:30.2782838Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:58:30.2784700Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:30.2786430Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T08:58:30.2787951Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:58:30.2789660Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:30.2791269Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T08:58:30.2792213Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:58:30.2793117Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:58:30.2794686Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:58:30.2795915Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:58:30.2796379Z     
2026-01-14T08:58:30.2796686Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:30.2797108Z onverted model fx: GraphModule(
2026-01-14T08:58:30.2797520Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:58:30.2797956Z   (relu): ReLU(inplace=True)
2026-01-14T08:58:30.2798205Z )
2026-01-14T08:58:30.2798308Z 
2026-01-14T08:58:30.2798313Z 
2026-01-14T08:58:30.2798322Z 
2026-01-14T08:58:30.2798418Z def forward(self, x):
2026-01-14T08:58:30.2799129Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:58:30.2800621Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:30.2801681Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:58:30.2802544Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:30.2804089Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:30.2805555Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:58:30.2806313Z     relu = self.relu(add);  add = None
2026-01-14T08:58:30.2807131Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:58:30.2808692Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:30.2809844Z     return dequantize_per_tensor_default_2
2026-01-14T08:58:30.2810139Z     
2026-01-14T08:58:30.2810450Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:30.2810876Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:58:30.2811344Z [32mPASSED[0m
2026-01-14T08:58:30.2812242Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T08:58:30.2813471Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T08:58:30.2814586Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T08:58:30.2815415Z   (conv): Module()
2026-01-14T08:58:30.2815639Z   (bn): Module()
2026-01-14T08:58:30.2816006Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:30.2817161Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:30.2818518Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:58:30.2819116Z   )
2026-01-14T08:58:30.2819422Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:30.2820649Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:30.2822248Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:58:30.2823014Z   )
2026-01-14T08:58:30.2823307Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:30.2824449Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:30.2825803Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:30.2826391Z   )
2026-01-14T08:58:30.2826691Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:30.2827820Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:30.2829175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:30.2829769Z   )
2026-01-14T08:58:30.2829945Z )
2026-01-14T08:58:30.2830048Z 
2026-01-14T08:58:30.2830052Z 
2026-01-14T08:58:30.2830063Z 
2026-01-14T08:58:30.2830152Z def forward(self, x):
2026-01-14T08:58:30.2830458Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:30.2830841Z     conv_weight = self.conv.weight
2026-01-14T08:58:30.2831138Z     conv_bias = self.conv.bias
2026-01-14T08:58:30.2831415Z     bn_weight = self.bn.weight
2026-01-14T08:58:30.2831688Z     bn_bias = self.bn.bias
2026-01-14T08:58:30.2831963Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:58:30.2832290Z     bn_running_var = self.bn.running_var
2026-01-14T08:58:30.2832682Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:58:30.2833186Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:30.2833870Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:58:30.2834493Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:58:30.2834925Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:58:30.2835393Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:58:30.2835885Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:58:30.2836543Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:58:30.2837199Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:58:49.8658757Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:58:49.8661771Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:58:49.8663112Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:58:49.8663727Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:58:49.8664407Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:58:49.8665043Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:58:49.8666132Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:58:49.8667297Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:58:49.8668178Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:58:49.8669024Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:58:49.8669673Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:58:49.8670115Z     
2026-01-14T08:58:49.8670416Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:49.8670828Z model fx: GraphModule(
2026-01-14T08:58:49.8671174Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:49.8672380Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:49.8673735Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:58:49.8674326Z   )
2026-01-14T08:58:49.8674515Z   (conv): ConvBn1d(
2026-01-14T08:58:49.8674928Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:58:49.8675386Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:58:49.8675923Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:49.8677112Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:58:49.8678721Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:58:49.8679473Z     )
2026-01-14T08:58:49.8679657Z   )
2026-01-14T08:58:49.8679948Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:49.8681085Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:49.8682433Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:49.8683014Z   )
2026-01-14T08:58:49.8683247Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:58:49.8683679Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:58:49.8684975Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:58:49.8686319Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:58:49.8686898Z   )
2026-01-14T08:58:49.8687195Z )
2026-01-14T08:58:49.8687301Z 
2026-01-14T08:58:49.8687305Z 
2026-01-14T08:58:49.8687309Z 
2026-01-14T08:58:49.8687395Z def forward(self, x):
2026-01-14T08:58:49.8687782Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:58:49.8688388Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:58:49.8689010Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:58:49.8689676Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:58:49.8690454Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:58:49.8690977Z     return activation_post_process_2
2026-01-14T08:58:49.8691249Z     
2026-01-14T08:58:49.8691549Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:49.8691960Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:58:49.8692210Z          [0., 0., 0.],
2026-01-14T08:58:49.8692469Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:58:49.8692796Z converted model pt2e: GraphModule(
2026-01-14T08:58:49.8693077Z   (conv): Module()
2026-01-14T08:58:49.8693292Z   (bn): Module()
2026-01-14T08:58:49.8693494Z )
2026-01-14T08:58:49.8693594Z 
2026-01-14T08:58:49.8693598Z 
2026-01-14T08:58:49.8693602Z 
2026-01-14T08:58:49.8693689Z def forward(self, x):
2026-01-14T08:58:49.8693995Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:58:49.8694366Z     conv_bias = self.conv.bias
2026-01-14T08:58:49.8694690Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:58:49.8695515Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:58:49.8696988Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:49.8698243Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:58:49.8698789Z     _scale_0 = self._scale_0
2026-01-14T08:58:49.8699055Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:58:49.8699386Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:58:49.8700441Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:58:49.8702080Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:58:49.8703532Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010604282841086388, -5, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:58:49.8705106Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:49.8706517Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T08:58:49.8707834Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:58:49.8709404Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:49.8710608Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:58:49.8711072Z     
2026-01-14T08:58:49.8711456Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:49.8711932Z onverted model fx: GraphModule(
2026-01-14T08:58:49.8712339Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:58:49.8712809Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:58:49.8713118Z )
2026-01-14T08:58:49.8713228Z 
2026-01-14T08:58:49.8713232Z 
2026-01-14T08:58:49.8713236Z 
2026-01-14T08:58:49.8713322Z def forward(self, x):
2026-01-14T08:58:49.8714029Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:58:49.8715501Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:58:49.8716700Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:58:49.8717706Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010604282841086388, -5, -128, 127, torch.int8);  conv = None
2026-01-14T08:58:49.8719240Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:58:49.8720515Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:58:49.8721611Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:58:49.8723181Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:58:49.8724242Z     return dequantize_per_tensor_default_2
2026-01-14T08:58:49.8724533Z     
2026-01-14T08:58:49.8724835Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:58:49.8725241Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:58:49.8725489Z          [0., 0., 0.],
2026-01-14T08:58:49.8725703Z          [0., 0., 0.]]])
2026-01-14T08:58:49.8725945Z model pt2e: GraphModule(
2026-01-14T08:58:49.8726182Z   (conv): Module()
2026-01-14T08:58:49.8726394Z   (bn): Module()
2026-01-14T08:58:49.8726718Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7515248Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7517249Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:59:03.7517899Z   )
2026-01-14T08:59:03.7518195Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7519702Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:03.7521345Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:59:03.7521938Z   )
2026-01-14T08:59:03.7522560Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7523711Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7525058Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:03.7525883Z   )
2026-01-14T08:59:03.7526212Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7527339Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7528685Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:03.7529286Z   )
2026-01-14T08:59:03.7529460Z )
2026-01-14T08:59:03.7529570Z 
2026-01-14T08:59:03.7529574Z 
2026-01-14T08:59:03.7529578Z 
2026-01-14T08:59:03.7529666Z def forward(self, x):
2026-01-14T08:59:03.7530077Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:03.7530462Z     conv_weight = self.conv.weight
2026-01-14T08:59:03.7530765Z     conv_bias = self.conv.bias
2026-01-14T08:59:03.7531045Z     bn_weight = self.bn.weight
2026-01-14T08:59:03.7531314Z     bn_bias = self.bn.bias
2026-01-14T08:59:03.7531587Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:03.7531913Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:03.7532274Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:03.7532770Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:03.7533449Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:03.7534074Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:03.7534510Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:59:03.7534963Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:59:03.7535455Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:59:03.7536017Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:59:03.7536671Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:59:03.7537384Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:59:03.7538561Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:59:03.7539616Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:59:03.7540234Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:59:03.7540903Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:59:03.7541540Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:03.7542615Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:03.7543784Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:03.7544654Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:59:03.7545492Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:59:03.7546245Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:59:03.7546682Z     
2026-01-14T08:59:03.7546985Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:03.7547388Z model fx: GraphModule(
2026-01-14T08:59:03.7547732Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7548872Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7550309Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:59:03.7550902Z   )
2026-01-14T08:59:03.7551081Z   (conv): ConvBn1d(
2026-01-14T08:59:03.7551314Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:59:03.7551763Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:03.7552307Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7553419Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:03.7554792Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:59:03.7555393Z     )
2026-01-14T08:59:03.7555568Z   )
2026-01-14T08:59:03.7555864Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7556998Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7558351Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:03.7558941Z   )
2026-01-14T08:59:03.7559166Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:03.7559602Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:03.7560732Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:03.7562084Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:59:03.7562673Z   )
2026-01-14T08:59:03.7562843Z )
2026-01-14T08:59:03.7562943Z 
2026-01-14T08:59:03.7562948Z 
2026-01-14T08:59:03.7562952Z 
2026-01-14T08:59:03.7563043Z def forward(self, x):
2026-01-14T08:59:03.7563422Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:03.7564040Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:03.7564658Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:03.7565320Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:59:03.7566018Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:59:03.7566535Z     return activation_post_process_2
2026-01-14T08:59:03.7566813Z     
2026-01-14T08:59:03.7567109Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:03.7567518Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:03.7567760Z          [0., 0., 0.],
2026-01-14T08:59:03.7568016Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:03.7568342Z converted model pt2e: GraphModule(
2026-01-14T08:59:03.7568629Z   (conv): Module()
2026-01-14T08:59:03.7568842Z   (bn): Module()
2026-01-14T08:59:03.7569035Z )
2026-01-14T08:59:03.7569134Z 
2026-01-14T08:59:03.7569138Z 
2026-01-14T08:59:03.7569234Z 
2026-01-14T08:59:03.7569331Z def forward(self, x):
2026-01-14T08:59:03.7569628Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:03.7570081Z     conv_bias = self.conv.bias
2026-01-14T08:59:03.7570403Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:03.7571227Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:59:03.7572799Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:03.7574046Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:03.7574622Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:59:03.7575870Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002568009542301297, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:59:03.7577385Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:59:03.7578830Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010644976049661636, -4, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:03.7580406Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:03.7581822Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:00:00.8233675Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:00:00.8235501Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:00:00.8236931Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:00:00.8237545Z     
2026-01-14T09:00:00.8237864Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:00.8238369Z onverted model fx: GraphModule(
2026-01-14T09:00:00.8238895Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T09:00:00.8239411Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:00:00.8239808Z )
2026-01-14T09:00:00.8239917Z 
2026-01-14T09:00:00.8239921Z 
2026-01-14T09:00:00.8239926Z 
2026-01-14T09:00:00.8240028Z def forward(self, x):
2026-01-14T09:00:00.8240751Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T09:00:00.8242247Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:00.8243516Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:00.8244549Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010644976049661636, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:00.8246296Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:00.8248181Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:00:00.8249477Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:00:00.8251315Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:00.8252843Z     return dequantize_per_tensor_default_2
2026-01-14T09:00:00.8253245Z     
2026-01-14T09:00:00.8253555Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:00.8254063Z diff: tensor([[[0., 0., 0.],
2026-01-14T09:00:00.8254315Z          [0., 0., 0.],
2026-01-14T09:00:00.8254568Z          [0., 0., 0.]]])
2026-01-14T09:00:00.8255087Z [32mPASSED[0m
2026-01-14T09:00:00.8255911Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T09:00:00.8257211Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T09:00:00.8258463Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T09:00:00.8259250Z   (conv): Module()
2026-01-14T09:00:00.8259466Z   (bn): Module()
2026-01-14T09:00:00.8259807Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8261105Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:00.8262594Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:00.8263241Z   )
2026-01-14T09:00:00.8263629Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8264948Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:00.8266741Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:00:00.8267596Z   )
2026-01-14T09:00:00.8267977Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8269226Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:00.8270764Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:00:00.8271445Z   )
2026-01-14T09:00:00.8271637Z )
2026-01-14T09:00:00.8271748Z 
2026-01-14T09:00:00.8271780Z 
2026-01-14T09:00:00.8271783Z 
2026-01-14T09:00:00.8271874Z def forward(self, x):
2026-01-14T09:00:00.8272236Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:00.8272665Z     conv_weight = self.conv.weight
2026-01-14T09:00:00.8272997Z     conv_bias = self.conv.bias
2026-01-14T09:00:00.8273368Z     bn_weight = self.bn.weight
2026-01-14T09:00:00.8273643Z     bn_bias = self.bn.bias
2026-01-14T09:00:00.8273941Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:00.8274333Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:00.8274963Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:00.8275517Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:00.8276466Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:00.8277186Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:00.8277633Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:00.8278100Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:00.8278677Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:00.8279417Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:00.8280068Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:00.8280873Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:00.8282066Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:00.8283209Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:00.8283846Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:00.8284553Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:00.8285281Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:00.8286373Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:00.8287543Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:00.8288244Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:00.8288685Z     
2026-01-14T09:00:00.8289003Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:00.8289421Z model fx: GraphModule(
2026-01-14T09:00:00.8289777Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8291004Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:00.8292436Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:00.8293068Z   )
2026-01-14T09:00:00.8293280Z   (conv): ConvBn2d(
2026-01-14T09:00:00.8293532Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:00.8294000Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:00.8294556Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8295768Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:00.8297391Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T09:00:00.8298180Z     )
2026-01-14T09:00:00.8298361Z   )
2026-01-14T09:00:00.8298665Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:00.8299820Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:00.8301175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T09:00:00.8301781Z   )
2026-01-14T09:00:00.8301957Z )
2026-01-14T09:00:00.8302175Z 
2026-01-14T09:00:00.8302181Z 
2026-01-14T09:00:00.8302185Z 
2026-01-14T09:00:00.8302278Z def forward(self, x):
2026-01-14T09:00:00.8302676Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:00.8303287Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:00.8303926Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:00.8304497Z     return activation_post_process_1
2026-01-14T09:00:00.8304787Z     
2026-01-14T09:00:00.8305091Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:00.8305615Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:00.8305873Z           [0., 0., 0.],
2026-01-14T09:00:00.8306101Z           [0., 0., 0.]],
2026-01-14T09:00:00.8306251Z 
2026-01-14T09:00:00.8306338Z          [[0., 0., 0.],
2026-01-14T09:00:00.8306563Z           [0., 0., 0.],
2026-01-14T09:00:00.8306797Z           [0., 0., 0.]],
2026-01-14T09:00:00.8306947Z 
2026-01-14T09:00:00.8307026Z          [[0., 0., 0.],
2026-01-14T09:00:00.8307251Z           [0., 0., 0.],
2026-01-14T09:00:00.8307505Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:06.8034481Z converted model pt2e: GraphModule(
2026-01-14T09:00:06.8034920Z   (conv): Module()
2026-01-14T09:00:06.8035748Z   (bn): Module()
2026-01-14T09:00:06.8036069Z )
2026-01-14T09:00:06.8036222Z 
2026-01-14T09:00:06.8036227Z 
2026-01-14T09:00:06.8036263Z 
2026-01-14T09:00:06.8036374Z def forward(self, x):
2026-01-14T09:00:06.8036776Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:06.8037244Z     conv_bias = self.conv.bias
2026-01-14T09:00:06.8038141Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:06.8039936Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:06.8041151Z     _scale_0 = self._scale_0
2026-01-14T09:00:06.8041492Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:00:06.8041886Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:00:06.8043159Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:00:06.8045182Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:00:06.8046899Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01609589159488678, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:06.8048768Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:06.8050283Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:00:06.8050840Z     
2026-01-14T09:00:06.8051211Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:06.8051718Z onverted model fx: GraphModule(
2026-01-14T09:00:06.8052227Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:06.8052746Z )
2026-01-14T09:00:06.8052872Z 
2026-01-14T09:00:06.8052877Z 
2026-01-14T09:00:06.8052882Z 
2026-01-14T09:00:06.8052990Z def forward(self, x):
2026-01-14T09:00:06.8053850Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:06.8056008Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:06.8057461Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:06.8058661Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01609589159488678, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:06.8060614Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:06.8061870Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:06.8062220Z     
2026-01-14T09:00:06.8062591Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:06.8063088Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:06.8063396Z           [0., 0., 0.],
2026-01-14T09:00:06.8063679Z           [0., 0., 0.]],
2026-01-14T09:00:06.8063865Z 
2026-01-14T09:00:06.8063961Z          [[0., 0., 0.],
2026-01-14T09:00:06.8064245Z           [0., 0., 0.],
2026-01-14T09:00:06.8064557Z           [0., 0., 0.]],
2026-01-14T09:00:06.8064778Z 
2026-01-14T09:00:06.8064897Z          [[0., 0., 0.],
2026-01-14T09:00:06.8065169Z           [0., 0., 0.],
2026-01-14T09:00:06.8065460Z           [0., 0., 0.]]]])
2026-01-14T09:00:06.8065744Z model pt2e: GraphModule(
2026-01-14T09:00:06.8065986Z   (conv): Module()
2026-01-14T09:00:06.8066190Z   (bn): Module()
2026-01-14T09:00:06.8066511Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8067642Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:06.8069034Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:06.8069621Z   )
2026-01-14T09:00:06.8069909Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8071238Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:06.8072612Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:00:06.8073203Z   )
2026-01-14T09:00:06.8073496Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8074618Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:06.8076263Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:00:06.8076858Z   )
2026-01-14T09:00:06.8077026Z )
2026-01-14T09:00:06.8077127Z 
2026-01-14T09:00:06.8077131Z 
2026-01-14T09:00:06.8077142Z 
2026-01-14T09:00:06.8077228Z def forward(self, x):
2026-01-14T09:00:06.8077528Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:06.8077908Z     conv_weight = self.conv.weight
2026-01-14T09:00:06.8078195Z     conv_bias = self.conv.bias
2026-01-14T09:00:06.8078463Z     bn_weight = self.bn.weight
2026-01-14T09:00:06.8078735Z     bn_bias = self.bn.bias
2026-01-14T09:00:06.8079022Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:06.8079342Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:06.8079708Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:06.8080195Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:06.8081023Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:06.8081645Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:06.8082088Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:06.8082551Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:06.8083157Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:06.8083734Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:06.8084394Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:06.8085160Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:06.8086338Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:06.8087391Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:06.8088021Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:06.8088693Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:06.8089360Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:06.8090502Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:06.8091645Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:06.8092331Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:06.8092762Z     
2026-01-14T09:00:06.8093067Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:06.8093474Z model fx: GraphModule(
2026-01-14T09:00:06.8093812Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8094956Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:06.8096303Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:06.8096892Z   )
2026-01-14T09:00:06.8097081Z   (conv): ConvBn2d(
2026-01-14T09:00:06.8097316Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:06.8097775Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:06.8098307Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8099434Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:06.8100808Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T09:00:06.8101418Z     )
2026-01-14T09:00:06.8101603Z   )
2026-01-14T09:00:06.8101890Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:06.8103027Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:06.8104373Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T09:00:06.8104967Z   )
2026-01-14T09:00:06.8105136Z )
2026-01-14T09:00:06.8105350Z 
2026-01-14T09:00:06.8105356Z 
2026-01-14T09:00:06.8105361Z 
2026-01-14T09:00:06.8105462Z def forward(self, x):
2026-01-14T09:00:06.8105872Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:06.8106474Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:06.8107105Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:06.8107667Z     return activation_post_process_1
2026-01-14T09:00:06.8107948Z     
2026-01-14T09:00:06.8108252Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:06.8108654Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:06.8108910Z           [0., 0., 0.],
2026-01-14T09:00:28.8322532Z           [0., 0., 0.]],
2026-01-14T09:00:28.8322727Z 
2026-01-14T09:00:28.8322807Z          [[0., 0., 0.],
2026-01-14T09:00:28.8323038Z           [0., 0., 0.],
2026-01-14T09:00:28.8323263Z           [0., 0., 0.]],
2026-01-14T09:00:28.8323441Z 
2026-01-14T09:00:28.8323520Z          [[0., 0., 0.],
2026-01-14T09:00:28.8323740Z           [0., 0., 0.],
2026-01-14T09:00:28.8323992Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:00:28.8324342Z converted model pt2e: GraphModule(
2026-01-14T09:00:28.8324621Z   (conv): Module()
2026-01-14T09:00:28.8324832Z   (bn): Module()
2026-01-14T09:00:28.8325030Z )
2026-01-14T09:00:28.8325147Z 
2026-01-14T09:00:28.8325152Z 
2026-01-14T09:00:28.8325156Z 
2026-01-14T09:00:28.8325243Z def forward(self, x):
2026-01-14T09:00:28.8325553Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:28.8326053Z     conv_bias = self.conv.bias
2026-01-14T09:00:28.8327067Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:28.8328725Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:28.8329905Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:00:28.8330849Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014918133383616805, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:00:28.8332404Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:00:28.8333851Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01611170545220375, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:28.8335430Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:28.8336640Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:00:28.8337114Z     
2026-01-14T09:00:28.8337422Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.8337843Z onverted model fx: GraphModule(
2026-01-14T09:00:28.8338269Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:28.8338702Z )
2026-01-14T09:00:28.8338813Z 
2026-01-14T09:00:28.8338817Z 
2026-01-14T09:00:28.8338821Z 
2026-01-14T09:00:28.8338908Z def forward(self, x):
2026-01-14T09:00:28.8339624Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:28.8341462Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:28.8342697Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:28.8343707Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01611170545220375, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:28.8345257Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:28.8346494Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:28.8346790Z     
2026-01-14T09:00:28.8347101Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.8347518Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:28.8347776Z           [0., 0., 0.],
2026-01-14T09:00:28.8347995Z           [0., 0., 0.]],
2026-01-14T09:00:28.8348155Z 
2026-01-14T09:00:28.8348233Z          [[0., 0., 0.],
2026-01-14T09:00:28.8348467Z           [0., 0., 0.],
2026-01-14T09:00:28.8348682Z           [0., 0., 0.]],
2026-01-14T09:00:28.8348831Z 
2026-01-14T09:00:28.8348914Z          [[0., 0., 0.],
2026-01-14T09:00:28.8349127Z           [0., 0., 0.],
2026-01-14T09:00:28.8349351Z           [0., 0., 0.]]]])
2026-01-14T09:00:28.8349789Z [32mPASSED[0m
2026-01-14T09:00:28.8350455Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:00:28.8351180Z   (conv): Module()
2026-01-14T09:00:28.8351416Z   (bn): Module()
2026-01-14T09:00:28.8351764Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.8353149Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.8354754Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:28.8355342Z   )
2026-01-14T09:00:28.8355639Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.8357100Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:28.8359058Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:00:28.8359947Z   )
2026-01-14T09:00:28.8360239Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.8361627Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.8363219Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:00:28.8363820Z   )
2026-01-14T09:00:28.8363997Z )
2026-01-14T09:00:28.8364097Z 
2026-01-14T09:00:28.8364102Z 
2026-01-14T09:00:28.8364106Z 
2026-01-14T09:00:28.8364203Z def forward(self, x):
2026-01-14T09:00:28.8364506Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:28.8364884Z     conv_weight = self.conv.weight
2026-01-14T09:00:28.8365172Z     conv_bias = self.conv.bias
2026-01-14T09:00:28.8365443Z     bn_weight = self.bn.weight
2026-01-14T09:00:28.8365702Z     bn_bias = self.bn.bias
2026-01-14T09:00:28.8365986Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:28.8366406Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:28.8366772Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:28.8367274Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:28.8367955Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:28.8368659Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:28.8369094Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:28.8369562Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:28.8370106Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:28.8370686Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:28.8371337Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:28.8372108Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:28.8373288Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:28.8374347Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:28.8375185Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:28.8375875Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:28.8376527Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:28.8377609Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:28.8378766Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:28.8379465Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:28.8379913Z     
2026-01-14T09:00:28.8380213Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:28.8380626Z model fx: GraphModule(
2026-01-14T09:00:28.8380979Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.8382430Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:28.8384043Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:28.8384632Z   )
2026-01-14T09:00:28.8384822Z   (conv): ConvBn2d(
2026-01-14T09:00:28.8385058Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:28.8385524Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:28.8386057Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:28.8387505Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:28.8389501Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:00:28.8390384Z     )
2026-01-14T09:00:28.8390567Z   )
2026-01-14T09:00:28.8390992Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:48.6855593Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:48.6857276Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:00:48.6858222Z   )
2026-01-14T09:00:48.6858474Z )
2026-01-14T09:00:48.6858626Z 
2026-01-14T09:00:48.6858632Z 
2026-01-14T09:00:48.6858637Z 
2026-01-14T09:00:48.6858740Z def forward(self, x):
2026-01-14T09:00:48.6859135Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:48.6859753Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:48.6860404Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:48.6860890Z     return activation_post_process_1
2026-01-14T09:00:48.6861173Z     
2026-01-14T09:00:48.6861479Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:48.6861893Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:48.6862151Z           [0., 0., 0.],
2026-01-14T09:00:48.6862375Z           [0., 0., 0.]],
2026-01-14T09:00:48.6862526Z 
2026-01-14T09:00:48.6862617Z          [[0., 0., 0.],
2026-01-14T09:00:48.6862832Z           [0., 0., 0.],
2026-01-14T09:00:48.6863054Z           [0., 0., 0.]],
2026-01-14T09:00:48.6863205Z 
2026-01-14T09:00:48.6863283Z          [[0., 0., 0.],
2026-01-14T09:00:48.6863503Z           [0., 0., 0.],
2026-01-14T09:00:48.6863798Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:00:48.6864177Z converted model pt2e: GraphModule(
2026-01-14T09:00:48.6864481Z   (conv): Module()
2026-01-14T09:00:48.6864689Z   (bn): Module()
2026-01-14T09:00:48.6864896Z )
2026-01-14T09:00:48.6864998Z 
2026-01-14T09:00:48.6865007Z 
2026-01-14T09:00:48.6865011Z 
2026-01-14T09:00:48.6865096Z def forward(self, x):
2026-01-14T09:00:48.6873589Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:48.6873974Z     conv_bias = self.conv.bias
2026-01-14T09:00:48.6875096Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:48.6876602Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:48.6877670Z     _scale_0 = self._scale_0
2026-01-14T09:00:48.6877952Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:00:48.6878292Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:00:48.6879354Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:00:48.6881002Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:00:48.6882447Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016454609110951424, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:48.6884022Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:48.6885229Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:00:48.6885696Z     
2026-01-14T09:00:48.6886008Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:48.6886612Z onverted model fx: GraphModule(
2026-01-14T09:00:48.6887042Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:48.6887476Z )
2026-01-14T09:00:48.6887581Z 
2026-01-14T09:00:48.6887585Z 
2026-01-14T09:00:48.6887589Z 
2026-01-14T09:00:48.6887677Z def forward(self, x):
2026-01-14T09:00:48.6888395Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:48.6890082Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:48.6891306Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:48.6892327Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016454609110951424, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:48.6893856Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:48.6894915Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:48.6895217Z     
2026-01-14T09:00:48.6895525Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:48.6895950Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:48.6896202Z           [0., 0., 0.],
2026-01-14T09:00:48.6896439Z           [0., 0., 0.]],
2026-01-14T09:00:48.6896590Z 
2026-01-14T09:00:48.6896671Z          [[0., 0., 0.],
2026-01-14T09:00:48.6896902Z           [0., 0., 0.],
2026-01-14T09:00:48.6897123Z           [0., 0., 0.]],
2026-01-14T09:00:48.6897280Z 
2026-01-14T09:00:48.6897358Z          [[0., 0., 0.],
2026-01-14T09:00:48.6897574Z           [0., 0., 0.],
2026-01-14T09:00:48.6897824Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:00:48.6898131Z model pt2e: GraphModule(
2026-01-14T09:00:48.6898374Z   (conv): Module()
2026-01-14T09:00:48.6898593Z   (bn): Module()
2026-01-14T09:00:48.6898912Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:48.6900302Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:48.6901901Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:48.6902489Z   )
2026-01-14T09:00:48.6902793Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:48.6904184Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:48.6905798Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:00:48.6906406Z   )
2026-01-14T09:00:48.6906697Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:48.6908078Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:48.6909654Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:00:48.6910249Z   )
2026-01-14T09:00:48.6910427Z )
2026-01-14T09:00:48.6910529Z 
2026-01-14T09:00:48.6910623Z 
2026-01-14T09:00:48.6910628Z 
2026-01-14T09:00:48.6910717Z def forward(self, x):
2026-01-14T09:00:48.6911029Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:48.6911402Z     conv_weight = self.conv.weight
2026-01-14T09:00:48.6911706Z     conv_bias = self.conv.bias
2026-01-14T09:00:48.6911979Z     bn_weight = self.bn.weight
2026-01-14T09:00:48.6912975Z     bn_bias = self.bn.bias
2026-01-14T09:00:48.6913246Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:48.6913577Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:48.6913941Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:48.6914437Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:48.6915131Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:48.6915747Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:48.6916197Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:48.6916657Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:48.6917169Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:48.6917749Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:48.6918395Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:48.6919125Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:48.6920294Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:48.6921361Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:48.6922000Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:48.6922682Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:48.6923347Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:48.6924415Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:48.6925577Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:48.6926276Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:48.6926715Z     
2026-01-14T09:00:48.6927024Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:48.6927437Z model fx: GraphModule(
2026-01-14T09:00:48.6927791Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:48.6929185Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:48.6930827Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:48.6931435Z   )
2026-01-14T09:00:48.6931620Z   (conv): ConvBn2d(
2026-01-14T09:00:48.6931865Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:01:10.6885246Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:10.6886033Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:10.6888199Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:10.6890357Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:01:10.6891205Z     )
2026-01-14T09:01:10.6891449Z   )
2026-01-14T09:01:10.6891745Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:10.6893327Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:10.6894957Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:01:10.6895551Z   )
2026-01-14T09:01:10.6895736Z )
2026-01-14T09:01:10.6895840Z 
2026-01-14T09:01:10.6895850Z 
2026-01-14T09:01:10.6895854Z 
2026-01-14T09:01:10.6895944Z def forward(self, x):
2026-01-14T09:01:10.6896337Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:10.6896939Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:10.6897571Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:10.6898062Z     return activation_post_process_1
2026-01-14T09:01:10.6898344Z     
2026-01-14T09:01:10.6898650Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:10.6899062Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:10.6899322Z           [0., 0., 0.],
2026-01-14T09:01:10.6899545Z           [0., 0., 0.]],
2026-01-14T09:01:10.6899701Z 
2026-01-14T09:01:10.6899782Z          [[0., 0., 0.],
2026-01-14T09:01:10.6899999Z           [0., 0., 0.],
2026-01-14T09:01:10.6900227Z           [0., 0., 0.]],
2026-01-14T09:01:10.6900376Z 
2026-01-14T09:01:10.6900461Z          [[0., 0., 0.],
2026-01-14T09:01:10.6900683Z           [0., 0., 0.],
2026-01-14T09:01:10.6900986Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:01:10.6901364Z converted model pt2e: GraphModule(
2026-01-14T09:01:10.6901655Z   (conv): Module()
2026-01-14T09:01:10.6901866Z   (bn): Module()
2026-01-14T09:01:10.6902072Z )
2026-01-14T09:01:10.6902179Z 
2026-01-14T09:01:10.6902183Z 
2026-01-14T09:01:10.6902187Z 
2026-01-14T09:01:10.6902275Z def forward(self, x):
2026-01-14T09:01:10.6902611Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:10.6902989Z     conv_bias = self.conv.bias
2026-01-14T09:01:10.6903739Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:10.6905244Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:10.6906299Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:01:10.6907230Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:01:10.6908752Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:01:10.6910200Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016429806128144264, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:10.6911849Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:10.6913068Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:01:10.6913533Z     
2026-01-14T09:01:10.6913865Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:10.6914317Z onverted model fx: GraphModule(
2026-01-14T09:01:10.6914730Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:01:10.6915249Z )
2026-01-14T09:01:10.6915352Z 
2026-01-14T09:01:10.6915356Z 
2026-01-14T09:01:10.6915360Z 
2026-01-14T09:01:10.6915446Z def forward(self, x):
2026-01-14T09:01:10.6916160Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:01:10.6917651Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:10.6918866Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:10.6919875Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016429806128144264, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:10.6921397Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:10.6922457Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:10.6922755Z     
2026-01-14T09:01:10.6923052Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:10.6923469Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:10.6923744Z           [0., 0., 0.],
2026-01-14T09:01:10.6924000Z           [0., 0., 0.]],
2026-01-14T09:01:10.6924152Z 
2026-01-14T09:01:10.6924230Z          [[0., 0., 0.],
2026-01-14T09:01:10.6924459Z           [0., 0., 0.],
2026-01-14T09:01:10.6924680Z           [0., 0., 0.]],
2026-01-14T09:01:10.6924835Z 
2026-01-14T09:01:10.6924915Z          [[0., 0., 0.],
2026-01-14T09:01:10.6925138Z           [0., 0., 0.],
2026-01-14T09:01:10.6925382Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:01:10.6925880Z [32mPASSED[0m
2026-01-14T09:01:10.6926568Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T09:01:10.6927325Z   (conv): Module()
2026-01-14T09:01:10.6927534Z   (bn): Module()
2026-01-14T09:01:10.6927867Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:10.6929007Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:10.6930435Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:10.6931029Z   )
2026-01-14T09:01:10.6931319Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:10.6932536Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:10.6934127Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:10.6934886Z   )
2026-01-14T09:01:10.6935183Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:10.6936413Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:10.6937759Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:10.6938342Z   )
2026-01-14T09:01:10.6938519Z )
2026-01-14T09:01:10.6938620Z 
2026-01-14T09:01:10.6938625Z 
2026-01-14T09:01:10.6938628Z 
2026-01-14T09:01:10.6938720Z def forward(self, x):
2026-01-14T09:01:10.6939108Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:10.6939489Z     conv_weight = self.conv.weight
2026-01-14T09:01:10.6939780Z     conv_bias = self.conv.bias
2026-01-14T09:01:10.6940052Z     bn_weight = self.bn.weight
2026-01-14T09:01:10.6940313Z     bn_bias = self.bn.bias
2026-01-14T09:01:10.6940589Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:10.6940920Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:10.6941279Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:10.6941780Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:10.6942462Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:10.6943084Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:10.6943514Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:10.6943977Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:10.6944493Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:10.6945075Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:10.6945718Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:10.6946439Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:10.6947645Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:10.6948733Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:10.6949359Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:10.6950035Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:10.6950698Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:10.6951769Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:10.6952920Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:10.6953615Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:10.6954050Z     
2026-01-14T09:01:10.6954359Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:10.6954766Z model fx: GraphModule(
2026-01-14T09:01:30.5778742Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5780341Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:30.5781999Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:30.5782714Z   )
2026-01-14T09:01:30.5782938Z   (conv): ConvBn2d(
2026-01-14T09:01:30.5783285Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:01:30.5783902Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:30.5784790Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5786206Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:30.5788117Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:30.5789186Z     )
2026-01-14T09:01:30.5789399Z   )
2026-01-14T09:01:30.5789755Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5791111Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:30.5792739Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:30.5793445Z   )
2026-01-14T09:01:30.5793654Z )
2026-01-14T09:01:30.5793788Z 
2026-01-14T09:01:30.5793793Z 
2026-01-14T09:01:30.5793798Z 
2026-01-14T09:01:30.5793905Z def forward(self, x):
2026-01-14T09:01:30.5794368Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:30.5795094Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:30.5795842Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:30.5796419Z     return activation_post_process_1
2026-01-14T09:01:30.5796758Z     
2026-01-14T09:01:30.5797125Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:30.5797620Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5797976Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5798290Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5798614Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5798931Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5799250Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:30.5799468Z 
2026-01-14T09:01:30.5799575Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5799932Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5800252Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5800566Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5800880Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5801190Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:30.5801411Z 
2026-01-14T09:01:30.5801518Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5801827Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5802141Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5802447Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5802759Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5803141Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:30.5803574Z converted model pt2e: GraphModule(
2026-01-14T09:01:30.5803909Z   (conv): Module()
2026-01-14T09:01:30.5804160Z   (bn): Module()
2026-01-14T09:01:30.5804404Z )
2026-01-14T09:01:30.5804527Z 
2026-01-14T09:01:30.5804532Z 
2026-01-14T09:01:30.5804537Z 
2026-01-14T09:01:30.5804642Z def forward(self, x):
2026-01-14T09:01:30.5805010Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:30.5805458Z     conv_bias = self.conv.bias
2026-01-14T09:01:30.5806355Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:30.5808138Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:30.5809352Z     _scale_0 = self._scale_0
2026-01-14T09:01:30.5809900Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:30.5810304Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:01:30.5811565Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:30.5813556Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:01:30.5815408Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.027857238426804543, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:30.5817289Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:30.5818725Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:01:30.5819284Z     
2026-01-14T09:01:30.5819648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:30.5820150Z onverted model fx: GraphModule(
2026-01-14T09:01:30.5820723Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:01:30.5821368Z )
2026-01-14T09:01:30.5821503Z 
2026-01-14T09:01:30.5821509Z 
2026-01-14T09:01:30.5821514Z 
2026-01-14T09:01:30.5821626Z def forward(self, x):
2026-01-14T09:01:30.5822455Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:30.5823948Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:30.5825166Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:30.5826182Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.027857238426804543, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:30.5827713Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:30.5828784Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:30.5829074Z     
2026-01-14T09:01:30.5829371Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:30.5829786Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5830069Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5830329Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5830590Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5830853Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5831103Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:30.5831289Z 
2026-01-14T09:01:30.5831369Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5831619Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5831872Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5832129Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5832384Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5832641Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:30.5832821Z 
2026-01-14T09:01:30.5832903Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5833159Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5833408Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5833664Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5833915Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:30.5834173Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:01:30.5834602Z model pt2e: GraphModule(
2026-01-14T09:01:30.5834852Z   (conv): Module()
2026-01-14T09:01:30.5835064Z   (bn): Module()
2026-01-14T09:01:30.5835376Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5836519Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:30.5837971Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:30.5838560Z   )
2026-01-14T09:01:30.5838847Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5839989Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:30.5841352Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:01:30.5841948Z   )
2026-01-14T09:01:30.5842242Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:30.5843364Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:30.5844708Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:01:30.5845298Z   )
2026-01-14T09:01:30.5845465Z )
2026-01-14T09:01:30.5845570Z 
2026-01-14T09:01:30.5845574Z 
2026-01-14T09:01:30.5845578Z 
2026-01-14T09:01:30.5845663Z def forward(self, x):
2026-01-14T09:01:30.5845966Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:30.5846340Z     conv_weight = self.conv.weight
2026-01-14T09:01:30.5846634Z     conv_bias = self.conv.bias
2026-01-14T09:01:30.5846901Z     bn_weight = self.bn.weight
2026-01-14T09:01:30.5847170Z     bn_bias = self.bn.bias
2026-01-14T09:01:30.5847441Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:30.5847765Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:30.5848126Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:30.5848627Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:30.5849303Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:30.5849967Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:30.5850403Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:30.5850851Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:30.5851343Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:30.5851913Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:52.6614309Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:52.6615207Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:52.6616653Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:52.6617971Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:52.6618710Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:52.6619512Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:52.6620599Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:52.6621896Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:52.6623267Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:52.6625993Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:52.6626514Z     
2026-01-14T09:01:52.6626884Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:52.6627375Z model fx: GraphModule(
2026-01-14T09:01:52.6627782Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:52.6629155Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:52.6630764Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:52.6631473Z   )
2026-01-14T09:01:52.6631695Z   (conv): ConvBn2d(
2026-01-14T09:01:52.6632037Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:01:52.6632649Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:52.6633288Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:52.6634617Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:52.6636244Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:01:52.6636971Z     )
2026-01-14T09:01:52.6637194Z   )
2026-01-14T09:01:52.6637547Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:52.6638916Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:52.6640508Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:01:52.6641213Z   )
2026-01-14T09:01:52.6641432Z )
2026-01-14T09:01:52.6641559Z 
2026-01-14T09:01:52.6641564Z 
2026-01-14T09:01:52.6641569Z 
2026-01-14T09:01:52.6641679Z def forward(self, x):
2026-01-14T09:01:52.6642141Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:52.6642861Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:52.6643601Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:52.6644183Z     return activation_post_process_1
2026-01-14T09:01:52.6644515Z     
2026-01-14T09:01:52.6644877Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:52.6653961Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6654266Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6654536Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6654804Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6655066Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6655328Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:52.6655512Z 
2026-01-14T09:01:52.6655596Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6655854Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6656105Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6656365Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6656618Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6656883Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:52.6657189Z 
2026-01-14T09:01:52.6657283Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6657544Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6657806Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6658059Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6658321Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6658632Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:52.6659084Z converted model pt2e: GraphModule(
2026-01-14T09:01:52.6659359Z   (conv): Module()
2026-01-14T09:01:52.6659574Z   (bn): Module()
2026-01-14T09:01:52.6659771Z )
2026-01-14T09:01:52.6659883Z 
2026-01-14T09:01:52.6659887Z 
2026-01-14T09:01:52.6659891Z 
2026-01-14T09:01:52.6659980Z def forward(self, x):
2026-01-14T09:01:52.6660289Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:52.6660662Z     conv_bias = self.conv.bias
2026-01-14T09:01:52.6661423Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:52.6662930Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:52.6663989Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:01:52.6664933Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:01:52.6666476Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:01:52.6667955Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.02784322015941143, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:52.6669513Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:52.6670707Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:01:52.6671180Z     
2026-01-14T09:01:52.6671480Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:52.6671909Z onverted model fx: GraphModule(
2026-01-14T09:01:52.6672387Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:01:52.6672867Z )
2026-01-14T09:01:52.6672968Z 
2026-01-14T09:01:52.6672973Z 
2026-01-14T09:01:52.6672977Z 
2026-01-14T09:01:52.6673072Z def forward(self, x):
2026-01-14T09:01:52.6673793Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:52.6675757Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:52.6677024Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:52.6678033Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.02784322015941143, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:52.6679561Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:52.6680605Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:52.6680906Z     
2026-01-14T09:01:52.6681371Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:52.6681821Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6682131Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6682406Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6682684Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6682952Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6683228Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:52.6683551Z 
2026-01-14T09:01:52.6683634Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6683909Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6684185Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6684452Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6684727Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6684997Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:52.6685199Z 
2026-01-14T09:01:52.6685284Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6685551Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6685833Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6686101Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6686378Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:52.6686708Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:01:52.6687206Z [32mPASSED[0m
2026-01-14T09:01:52.6687960Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:01:52.6688779Z   (conv): Module()
2026-01-14T09:01:52.6689004Z   (bn): Module()
2026-01-14T09:01:52.6689347Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:52.6690603Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:52.6691964Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:01:52.6692557Z   )
2026-01-14T09:01:52.6692861Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:52.6694064Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:52.6695660Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:01:52.6696421Z   )
2026-01-14T09:01:52.6696734Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:12.4886024Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:12.4887706Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:02:12.4888423Z   )
2026-01-14T09:02:12.4888655Z )
2026-01-14T09:02:12.4888778Z 
2026-01-14T09:02:12.4888783Z 
2026-01-14T09:02:12.4888788Z 
2026-01-14T09:02:12.4888898Z def forward(self, x):
2026-01-14T09:02:12.4889278Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:12.4889748Z     conv_weight = self.conv.weight
2026-01-14T09:02:12.4890213Z     bn_weight = self.bn.weight
2026-01-14T09:02:12.4890536Z     bn_bias = self.bn.bias
2026-01-14T09:02:12.4890874Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:02:12.4891273Z     bn_running_var = self.bn.running_var
2026-01-14T09:02:12.4891703Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:02:12.4892324Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:12.4893470Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:02:12.4894228Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:02:12.4894750Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:12.4895305Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:02:12.4895895Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:12.4896745Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:02:12.4897529Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:02:12.4898717Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:12.4899901Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:12.4900645Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:02:12.4901974Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:02:12.4903362Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:02:12.4904192Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:02:12.4904725Z     
2026-01-14T09:02:12.4905084Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:12.4905579Z model fx: GraphModule(
2026-01-14T09:02:12.4905998Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:12.4907371Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:12.4908999Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:12.4909709Z   )
2026-01-14T09:02:12.4909940Z   (conv): ConvBn2d(
2026-01-14T09:02:12.4910257Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:12.4910852Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:12.4911504Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:12.4912965Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:12.4914889Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:02:12.4915810Z     )
2026-01-14T09:02:12.4916025Z   )
2026-01-14T09:02:12.4916380Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:12.4917736Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:12.4919364Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:02:12.4920068Z   )
2026-01-14T09:02:12.4920284Z )
2026-01-14T09:02:12.4920406Z 
2026-01-14T09:02:12.4920412Z 
2026-01-14T09:02:12.4920417Z 
2026-01-14T09:02:12.4920532Z def forward(self, x):
2026-01-14T09:02:12.4920984Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:12.4921710Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:12.4922604Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:12.4923196Z     return activation_post_process_1
2026-01-14T09:02:12.4923532Z     
2026-01-14T09:02:12.4923897Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:12.4924395Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:12.4924696Z           [0., 0., 0.],
2026-01-14T09:02:12.4925057Z           [0., 0., 0.]],
2026-01-14T09:02:12.4925239Z 
2026-01-14T09:02:12.4925335Z          [[0., 0., 0.],
2026-01-14T09:02:12.4925605Z           [0., 0., 0.],
2026-01-14T09:02:12.4925869Z           [0., 0., 0.]],
2026-01-14T09:02:12.4926058Z 
2026-01-14T09:02:12.4926155Z          [[0., 0., 0.],
2026-01-14T09:02:12.4926417Z           [0., 0., 0.],
2026-01-14T09:02:12.4926694Z           [0., 0., 0.]]],
2026-01-14T09:02:12.4926878Z 
2026-01-14T09:02:12.4926883Z 
2026-01-14T09:02:12.4926986Z         [[[0., 0., 0.],
2026-01-14T09:02:12.4927250Z           [0., 0., 0.],
2026-01-14T09:02:12.4927554Z           [0., 0., 0.]],
2026-01-14T09:02:12.4927747Z 
2026-01-14T09:02:12.4927846Z          [[0., 0., 0.],
2026-01-14T09:02:12.4928127Z           [0., 0., 0.],
2026-01-14T09:02:12.4928405Z           [0., 0., 0.]],
2026-01-14T09:02:12.4928605Z 
2026-01-14T09:02:12.4928702Z          [[0., 0., 0.],
2026-01-14T09:02:12.4928916Z           [0., 0., 0.],
2026-01-14T09:02:12.4929141Z           [0., 0., 0.]]],
2026-01-14T09:02:12.4929298Z 
2026-01-14T09:02:12.4929302Z 
2026-01-14T09:02:12.4929388Z         [[[0., 0., 0.],
2026-01-14T09:02:12.4929601Z           [0., 0., 0.],
2026-01-14T09:02:12.4929893Z           [0., 0., 0.]],
2026-01-14T09:02:12.4930046Z 
2026-01-14T09:02:12.4930126Z          [[0., 0., 0.],
2026-01-14T09:02:12.4930348Z           [0., 0., 0.],
2026-01-14T09:02:12.4930564Z           [0., 0., 0.]],
2026-01-14T09:02:12.4930724Z 
2026-01-14T09:02:12.4930800Z          [[0., 0., 0.],
2026-01-14T09:02:12.4931015Z           [0., 0., 0.],
2026-01-14T09:02:12.4931277Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:12.4931627Z converted model pt2e: GraphModule(
2026-01-14T09:02:12.4931902Z   (conv): Module()
2026-01-14T09:02:12.4932114Z   (bn): Module()
2026-01-14T09:02:12.4932307Z )
2026-01-14T09:02:12.4932414Z 
2026-01-14T09:02:12.4932418Z 
2026-01-14T09:02:12.4932422Z 
2026-01-14T09:02:12.4932508Z def forward(self, x):
2026-01-14T09:02:12.4932807Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:12.4933655Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:12.4935147Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:12.4936162Z     _scale_0 = self._scale_0
2026-01-14T09:02:12.4936439Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:02:12.4936766Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:02:12.4937822Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:02:12.4938885Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:02:12.4939873Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:02:12.4941393Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01773674599826336, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:12.4943006Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:12.4944301Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:02:12.4944775Z     
2026-01-14T09:02:12.4945072Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:12.4945494Z onverted model fx: GraphModule(
2026-01-14T09:02:12.4945909Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:12.4946423Z )
2026-01-14T09:02:12.4946525Z 
2026-01-14T09:02:12.4946529Z 
2026-01-14T09:02:12.4946532Z 
2026-01-14T09:02:12.4946624Z def forward(self, x):
2026-01-14T09:02:12.4947334Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:12.4948822Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:12.4950041Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:12.4951042Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01773674599826336, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:12.4952576Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:12.4953695Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:12.4953989Z     
2026-01-14T09:02:12.4954297Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:12.4954713Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:12.4954960Z           [0., 0., 0.],
2026-01-14T09:02:12.4955186Z           [0., 0., 0.]],
2026-01-14T09:02:12.4955335Z 
2026-01-14T09:02:12.4955415Z          [[0., 0., 0.],
2026-01-14T09:02:12.4955638Z           [0., 0., 0.],
2026-01-14T09:02:12.4955853Z           [0., 0., 0.]],
2026-01-14T09:02:12.4956008Z 
2026-01-14T09:02:12.4956086Z          [[0., 0., 0.],
2026-01-14T09:02:12.4956298Z           [0., 0., 0.],
2026-01-14T09:02:12.4956518Z           [0., 0., 0.]]],
2026-01-14T09:02:12.4956669Z 
2026-01-14T09:02:12.4956673Z 
2026-01-14T09:02:12.4956761Z         [[[0., 0., 0.],
2026-01-14T09:02:12.4956979Z           [0., 0., 0.],
2026-01-14T09:02:12.4957202Z           [0., 0., 0.]],
2026-01-14T09:02:12.4957348Z 
2026-01-14T09:02:12.4957427Z          [[0., 0., 0.],
2026-01-14T09:02:12.4957646Z           [0., 0., 0.],
2026-01-14T09:02:12.4957860Z           [0., 0., 0.]],
2026-01-14T09:02:12.4958013Z 
2026-01-14T09:02:12.4958090Z          [[0., 0., 0.],
2026-01-14T09:02:12.4958299Z           [0., 0., 0.],
2026-01-14T09:02:12.4958517Z           [0., 0., 0.]]],
2026-01-14T09:02:12.4958668Z 
2026-01-14T09:02:12.4958672Z 
2026-01-14T09:02:12.4958756Z         [[[0., 0., 0.],
2026-01-14T09:02:12.4958974Z           [0., 0., 0.],
2026-01-14T09:02:12.4959192Z           [0., 0., 0.]],
2026-01-14T09:02:12.4959337Z 
2026-01-14T09:02:12.4959412Z          [[0., 0., 0.],
2026-01-14T09:02:12.4959630Z           [0., 0., 0.],
2026-01-14T09:02:12.4959845Z           [0., 0., 0.]],
2026-01-14T09:02:12.4959996Z 
2026-01-14T09:02:12.4960072Z          [[0., 0., 0.],
2026-01-14T09:02:12.4960284Z           [0., 0., 0.],
2026-01-14T09:02:12.4960512Z           [0., 0., 0.]]]])
2026-01-14T09:02:12.4960759Z model pt2e: GraphModule(
2026-01-14T09:02:12.4960997Z   (conv): Module()
2026-01-14T09:02:12.4961208Z   (bn): Module()
2026-01-14T09:02:26.4045054Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4046301Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:26.4047913Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:26.4048515Z   )
2026-01-14T09:02:26.4048811Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4050008Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:26.4051512Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:02:26.4052111Z   )
2026-01-14T09:02:26.4052402Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4053533Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:26.4054868Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:02:26.4055460Z   )
2026-01-14T09:02:26.4055643Z )
2026-01-14T09:02:26.4055745Z 
2026-01-14T09:02:26.4055749Z 
2026-01-14T09:02:26.4055753Z 
2026-01-14T09:02:26.4055842Z def forward(self, x):
2026-01-14T09:02:26.4056155Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:26.4056531Z     conv_weight = self.conv.weight
2026-01-14T09:02:26.4056829Z     bn_weight = self.bn.weight
2026-01-14T09:02:26.4057094Z     bn_bias = self.bn.bias
2026-01-14T09:02:26.4057372Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:02:26.4057702Z     bn_running_var = self.bn.running_var
2026-01-14T09:02:26.4058062Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:02:26.4058556Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:26.4059243Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:02:26.4059861Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:02:26.4060291Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:26.4060748Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:02:26.4061246Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:26.4061822Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:02:26.4062472Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:02:26.4063464Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:26.4064452Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:26.4065079Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:02:26.4066172Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:02:26.4067371Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:02:26.4068057Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:02:26.4068496Z     
2026-01-14T09:02:26.4068794Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:26.4069202Z model fx: GraphModule(
2026-01-14T09:02:26.4069554Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4070783Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:26.4072142Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:26.4072730Z   )
2026-01-14T09:02:26.4072920Z   (conv): ConvBn2d(
2026-01-14T09:02:26.4073183Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:26.4073678Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:26.4074294Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4075859Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:26.4077392Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:02:26.4077993Z     )
2026-01-14T09:02:26.4078166Z   )
2026-01-14T09:02:26.4078470Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:26.4079595Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:26.4080928Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:02:26.4081515Z   )
2026-01-14T09:02:26.4081688Z )
2026-01-14T09:02:26.4081787Z 
2026-01-14T09:02:26.4081791Z 
2026-01-14T09:02:26.4081795Z 
2026-01-14T09:02:26.4081887Z def forward(self, x):
2026-01-14T09:02:26.4082262Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:26.4082863Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:26.4083485Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:26.4083966Z     return activation_post_process_1
2026-01-14T09:02:26.4084241Z     
2026-01-14T09:02:26.4084538Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:26.4084949Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:26.4085193Z           [0., 0., 0.],
2026-01-14T09:02:26.4085418Z           [0., 0., 0.]],
2026-01-14T09:02:26.4085564Z 
2026-01-14T09:02:26.4085646Z          [[0., 0., 0.],
2026-01-14T09:02:26.4085864Z           [0., 0., 0.],
2026-01-14T09:02:26.4086075Z           [0., 0., 0.]],
2026-01-14T09:02:26.4086228Z 
2026-01-14T09:02:26.4086304Z          [[0., 0., 0.],
2026-01-14T09:02:26.4086541Z           [0., 0., 0.],
2026-01-14T09:02:26.4086783Z           [0., 0., 0.]]],
2026-01-14T09:02:26.4086932Z 
2026-01-14T09:02:26.4086936Z 
2026-01-14T09:02:26.4087018Z         [[[0., 0., 0.],
2026-01-14T09:02:26.4087230Z           [0., 0., 0.],
2026-01-14T09:02:26.4087447Z           [0., 0., 0.]],
2026-01-14T09:02:26.4087596Z 
2026-01-14T09:02:26.4087679Z          [[0., 0., 0.],
2026-01-14T09:02:26.4087893Z           [0., 0., 0.],
2026-01-14T09:02:26.4088107Z           [0., 0., 0.]],
2026-01-14T09:02:26.4088260Z 
2026-01-14T09:02:26.4088336Z          [[0., 0., 0.],
2026-01-14T09:02:26.4088546Z           [0., 0., 0.],
2026-01-14T09:02:26.4088770Z           [0., 0., 0.]]],
2026-01-14T09:02:26.4088920Z 
2026-01-14T09:02:26.4088924Z 
2026-01-14T09:02:26.4089012Z         [[[0., 0., 0.],
2026-01-14T09:02:26.4089224Z           [0., 0., 0.],
2026-01-14T09:02:26.4089442Z           [0., 0., 0.]],
2026-01-14T09:02:26.4089587Z 
2026-01-14T09:02:26.4089664Z          [[0., 0., 0.],
2026-01-14T09:02:26.4089943Z           [0., 0., 0.],
2026-01-14T09:02:26.4090154Z           [0., 0., 0.]],
2026-01-14T09:02:26.4090307Z 
2026-01-14T09:02:26.4090383Z          [[0., 0., 0.],
2026-01-14T09:02:26.4090596Z           [0., 0., 0.],
2026-01-14T09:02:26.4090853Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:26.4091192Z converted model pt2e: GraphModule(
2026-01-14T09:02:26.4091607Z   (conv): Module()
2026-01-14T09:02:26.4091826Z   (bn): Module()
2026-01-14T09:02:26.4092021Z )
2026-01-14T09:02:26.4092121Z 
2026-01-14T09:02:26.4092125Z 
2026-01-14T09:02:26.4092135Z 
2026-01-14T09:02:26.4092221Z def forward(self, x):
2026-01-14T09:02:26.4092522Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:26.4093370Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:26.4094972Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:26.4096016Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:02:26.4097006Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:02:26.4097942Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:02:26.4098930Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:02:26.4100432Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01770818792283535, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:26.4101987Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:26.4103192Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:26.4103660Z     
2026-01-14T09:02:26.4103960Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:26.4104378Z onverted model fx: GraphModule(
2026-01-14T09:02:26.4104787Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:26.4105217Z )
2026-01-14T09:02:26.4105317Z 
2026-01-14T09:02:26.4105321Z 
2026-01-14T09:02:26.4105325Z 
2026-01-14T09:02:26.4105414Z def forward(self, x):
2026-01-14T09:02:26.4106130Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:26.4107668Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:26.4108867Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:26.4109874Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01770818792283535, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:26.4111397Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:26.4112439Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:26.4112737Z     
2026-01-14T09:02:26.4113031Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:26.4113440Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:29.2435081Z           [0., 0., 0.],
2026-01-14T09:02:29.2435343Z           [0., 0., 0.]],
2026-01-14T09:02:29.2435521Z 
2026-01-14T09:02:29.2435615Z          [[0., 0., 0.],
2026-01-14T09:02:29.2435837Z           [0., 0., 0.],
2026-01-14T09:02:29.2436081Z           [0., 0., 0.]],
2026-01-14T09:02:29.2436231Z 
2026-01-14T09:02:29.2436308Z          [[0., 0., 0.],
2026-01-14T09:02:29.2436523Z           [0., 0., 0.],
2026-01-14T09:02:29.2436931Z           [0., 0., 0.]]],
2026-01-14T09:02:29.2437092Z 
2026-01-14T09:02:29.2437096Z 
2026-01-14T09:02:29.2437172Z         [[[0., 0., 0.],
2026-01-14T09:02:29.2437387Z           [0., 0., 0.],
2026-01-14T09:02:29.2437598Z           [0., 0., 0.]],
2026-01-14T09:02:29.2437743Z 
2026-01-14T09:02:29.2437825Z          [[0., 0., 0.],
2026-01-14T09:02:29.2438034Z           [0., 0., 0.],
2026-01-14T09:02:29.2438388Z           [0., 0., 0.]],
2026-01-14T09:02:29.2438531Z 
2026-01-14T09:02:29.2438607Z          [[0., 0., 0.],
2026-01-14T09:02:29.2438822Z           [0., 0., 0.],
2026-01-14T09:02:29.2439035Z           [0., 0., 0.]]],
2026-01-14T09:02:29.2439190Z 
2026-01-14T09:02:29.2439194Z 
2026-01-14T09:02:29.2439275Z         [[[0., 0., 0.],
2026-01-14T09:02:29.2439494Z           [0., 0., 0.],
2026-01-14T09:02:29.2439707Z           [0., 0., 0.]],
2026-01-14T09:02:29.2439859Z 
2026-01-14T09:02:29.2439935Z          [[0., 0., 0.],
2026-01-14T09:02:29.2440145Z           [0., 0., 0.],
2026-01-14T09:02:29.2440374Z           [0., 0., 0.]],
2026-01-14T09:02:29.2440522Z 
2026-01-14T09:02:29.2440602Z          [[0., 0., 0.],
2026-01-14T09:02:29.2440824Z           [0., 0., 0.],
2026-01-14T09:02:29.2441043Z           [0., 0., 0.]]]])
2026-01-14T09:02:29.2441290Z model pt2e: GraphModule(
2026-01-14T09:02:29.2441533Z   (conv1): Module()
2026-01-14T09:02:29.2441742Z   (bn1): Module()
2026-01-14T09:02:29.2441964Z   (conv2): Module()
2026-01-14T09:02:29.2442166Z   (bn2): Module()
2026-01-14T09:02:29.2449771Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2451008Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:29.2452366Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:29.2452964Z   )
2026-01-14T09:02:29.2453267Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2454479Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:29.2456070Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:02:29.2456826Z   )
2026-01-14T09:02:29.2457121Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2458323Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:29.2459916Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:29.2460674Z   )
2026-01-14T09:02:29.2460961Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2462103Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:29.2463446Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:29.2464045Z   )
2026-01-14T09:02:29.2464339Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2465582Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:29.2466930Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:02:29.2467514Z   )
2026-01-14T09:02:29.2467719Z )
2026-01-14T09:02:29.2467834Z 
2026-01-14T09:02:29.2467839Z 
2026-01-14T09:02:29.2467844Z 
2026-01-14T09:02:29.2467949Z def forward(self, x):
2026-01-14T09:02:29.2468268Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:29.2468730Z     conv1_weight = self.conv1.weight
2026-01-14T09:02:29.2469037Z     bn1_weight = self.bn1.weight
2026-01-14T09:02:29.2469310Z     bn1_bias = self.bn1.bias
2026-01-14T09:02:29.2469584Z     conv2_weight = self.conv2.weight
2026-01-14T09:02:29.2469876Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:29.2470154Z     bn2_weight = self.bn2.weight
2026-01-14T09:02:29.2470421Z     bn2_bias = self.bn2.bias
2026-01-14T09:02:29.2470713Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:02:29.2471052Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:02:29.2471428Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:02:29.2471821Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:02:29.2472150Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:02:29.2472523Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:02:29.2473017Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:29.2473719Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:02:29.2474514Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:02:29.2475334Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:02:29.2475777Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:29.2476235Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:02:29.2476751Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:29.2477333Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:02:29.2478038Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:02:29.2478754Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:02:29.2479409Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:02:29.2479869Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:02:29.2480357Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:02:29.2480882Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:02:29.2481492Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:02:29.2482178Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:02:29.2483184Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:29.2484174Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:02:29.2484807Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:02:29.2485939Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:02:29.2487125Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:02:29.2488398Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:02:29.2489451Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:29.2490110Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:02:29.2490789Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:02:29.2491446Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:02:29.2492667Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:02:29.2493838Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:02:29.2494530Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:02:29.2494962Z     
2026-01-14T09:02:29.2495274Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:29.2495681Z model fx: GraphModule(
2026-01-14T09:02:29.2496021Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2497172Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:29.2498573Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:29.2499168Z   )
2026-01-14T09:02:29.2499352Z   (conv1): ConvBn2d(
2026-01-14T09:02:29.2499630Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:29.2500128Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:29.2500658Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2501847Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:29.2503438Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:29.2504205Z     )
2026-01-14T09:02:29.2504387Z   )
2026-01-14T09:02:29.2504682Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:29.2505831Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:29.2507175Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:29.2507784Z   )
2026-01-14T09:02:29.2508003Z   (conv2): ConvBn2d(
2026-01-14T09:02:29.2508258Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:02:29.2508714Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:46.0435858Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0437419Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:46.0439425Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:02:46.0440350Z     )
2026-01-14T09:02:46.0440597Z   )
2026-01-14T09:02:46.0440954Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0442715Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:46.0444351Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:02:46.0445243Z   )
2026-01-14T09:02:46.0445482Z )
2026-01-14T09:02:46.0445611Z 
2026-01-14T09:02:46.0445616Z 
2026-01-14T09:02:46.0445621Z 
2026-01-14T09:02:46.0445735Z def forward(self, x):
2026-01-14T09:02:46.0446224Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:46.0446978Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:46.0447743Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:02:46.0448523Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:02:46.0449281Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:02:46.0449988Z     return activation_post_process_2
2026-01-14T09:02:46.0450329Z     
2026-01-14T09:02:46.0450699Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:46.0451185Z diff: tensor([[[[0.]],
2026-01-14T09:02:46.0451378Z 
2026-01-14T09:02:46.0451486Z          [[0.]],
2026-01-14T09:02:46.0451643Z 
2026-01-14T09:02:46.0451752Z          [[0.]]],
2026-01-14T09:02:46.0451907Z 
2026-01-14T09:02:46.0451913Z 
2026-01-14T09:02:46.0452007Z         [[[0.]],
2026-01-14T09:02:46.0452193Z 
2026-01-14T09:02:46.0452300Z          [[0.]],
2026-01-14T09:02:46.0452460Z 
2026-01-14T09:02:46.0452554Z          [[0.]]],
2026-01-14T09:02:46.0452718Z 
2026-01-14T09:02:46.0452723Z 
2026-01-14T09:02:46.0452817Z         [[[0.]],
2026-01-14T09:02:46.0452966Z 
2026-01-14T09:02:46.0453065Z          [[0.]],
2026-01-14T09:02:46.0453224Z 
2026-01-14T09:02:46.0453363Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:46.0453760Z converted model pt2e: GraphModule(
2026-01-14T09:02:46.0454109Z   (conv1): Module()
2026-01-14T09:02:46.0454378Z   (bn1): Module()
2026-01-14T09:02:46.0454636Z   (conv2): Module()
2026-01-14T09:02:46.0454908Z   (bn2): Module()
2026-01-14T09:02:46.0455157Z )
2026-01-14T09:02:46.0455293Z 
2026-01-14T09:02:46.0455298Z 
2026-01-14T09:02:46.0455310Z 
2026-01-14T09:02:46.0455420Z def forward(self, x):
2026-01-14T09:02:46.0455800Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:46.0456256Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:46.0457167Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:46.0458951Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:46.0460176Z     _scale_0 = self._scale_0
2026-01-14T09:02:46.0460518Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:02:46.0460878Z     _scale_1 = self._scale_1
2026-01-14T09:02:46.0461219Z     _zero_point_1 = self._zero_point_1
2026-01-14T09:02:46.0461615Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T09:02:46.0462974Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T09:02:46.0464286Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:02:46.0465518Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T09:02:46.0467457Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.01743602752685547, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:02:46.0469260Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:46.0470349Z     quantize_per_channel = self._frozen_param1
2026-01-14T09:02:46.0471510Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:02:46.0473234Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T09:02:46.0475220Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:02:46.0476814Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:46.0478023Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:46.0478507Z     
2026-01-14T09:02:46.0478811Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:46.0479245Z onverted model fx: GraphModule(
2026-01-14T09:02:46.0479676Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:46.0480265Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:46.0480707Z )
2026-01-14T09:02:46.0480813Z 
2026-01-14T09:02:46.0480817Z 
2026-01-14T09:02:46.0480821Z 
2026-01-14T09:02:46.0480912Z def forward(self, x):
2026-01-14T09:02:46.0481641Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:46.0483135Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:46.0484358Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:46.0485394Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.01743602752685547, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:02:46.0486931Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:46.0488189Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:02:46.0489229Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:02:46.0490876Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:46.0491944Z     return dequantize_per_tensor_default_2
2026-01-14T09:02:46.0492253Z     
2026-01-14T09:02:46.0492566Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:46.0492971Z diff: tensor([[[[0.]],
2026-01-14T09:02:46.0493135Z 
2026-01-14T09:02:46.0493215Z          [[0.]],
2026-01-14T09:02:46.0493342Z 
2026-01-14T09:02:46.0493427Z          [[0.]]],
2026-01-14T09:02:46.0493553Z 
2026-01-14T09:02:46.0493557Z 
2026-01-14T09:02:46.0493791Z         [[[0.]],
2026-01-14T09:02:46.0493922Z 
2026-01-14T09:02:46.0494004Z          [[0.]],
2026-01-14T09:02:46.0494130Z 
2026-01-14T09:02:46.0494206Z          [[0.]]],
2026-01-14T09:02:46.0494336Z 
2026-01-14T09:02:46.0494340Z 
2026-01-14T09:02:46.0494417Z         [[[0.]],
2026-01-14T09:02:46.0494542Z 
2026-01-14T09:02:46.0494618Z          [[0.]],
2026-01-14T09:02:46.0494748Z 
2026-01-14T09:02:46.0494950Z          [[0.]]]])
2026-01-14T09:02:46.0495182Z model pt2e: GraphModule(
2026-01-14T09:02:46.0495428Z   (conv1): Module()
2026-01-14T09:02:46.0495648Z   (bn1): Module()
2026-01-14T09:02:46.0495851Z   (conv2): Module()
2026-01-14T09:02:46.0496073Z   (bn2): Module()
2026-01-14T09:02:46.0496393Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0497549Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:46.0498911Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:46.0499506Z   )
2026-01-14T09:02:46.0499810Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0500956Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:46.0502335Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:02:46.0502962Z   )
2026-01-14T09:02:46.0503283Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0504434Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:46.0505795Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:02:46.0506403Z   )
2026-01-14T09:02:46.0506725Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:46.0507871Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:46.0509220Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:02:46.0509826Z   )
2026-01-14T09:02:46.0510120Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3072725Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:03.3074301Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:03:03.3075141Z   )
2026-01-14T09:03:03.3075333Z )
2026-01-14T09:03:03.3075435Z 
2026-01-14T09:03:03.3075439Z 
2026-01-14T09:03:03.3075443Z 
2026-01-14T09:03:03.3075551Z def forward(self, x):
2026-01-14T09:03:03.3075864Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:03.3076263Z     conv1_weight = self.conv1.weight
2026-01-14T09:03:03.3076565Z     bn1_weight = self.bn1.weight
2026-01-14T09:03:03.3076851Z     bn1_bias = self.bn1.bias
2026-01-14T09:03:03.3077124Z     conv2_weight = self.conv2.weight
2026-01-14T09:03:03.3077425Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:03.3077700Z     bn2_weight = self.bn2.weight
2026-01-14T09:03:03.3077982Z     bn2_bias = self.bn2.bias
2026-01-14T09:03:03.3078650Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:03:03.3079157Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:03:03.3079611Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:03:03.3080000Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:03:03.3080338Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:03:03.3080706Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:03:03.3081419Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:03.3082108Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:03:03.3082917Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:03:03.3083554Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:03:03.3084083Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:03.3084700Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:03:03.3085252Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:03:03.3085953Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:03:03.3086608Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:03:03.3087338Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:03.3088000Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:03:03.3088455Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:03:03.3088952Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:03:03.3089477Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:03:03.3090176Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:03:03.3090871Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:03:03.3091877Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:03:03.3092880Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:03:03.3093520Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:03:03.3094666Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:03:03.3095862Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:03:03.3097014Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:03:03.3098140Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:03:03.3098756Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:03:03.3099450Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:03:03.3100112Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:03.3101209Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:03:03.3102399Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:03:03.3103194Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:03:03.3103641Z     
2026-01-14T09:03:03.3103950Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:03.3104353Z model fx: GraphModule(
2026-01-14T09:03:03.3104710Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3105864Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:03.3107321Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:03:03.3107928Z   )
2026-01-14T09:03:03.3108117Z   (conv1): ConvBn2d(
2026-01-14T09:03:03.3108399Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:03:03.3108888Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:03.3109434Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3110550Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:03.3111936Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:03:03.3112561Z     )
2026-01-14T09:03:03.3112738Z   )
2026-01-14T09:03:03.3113036Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3114176Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:03.3115552Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:03:03.3116153Z   )
2026-01-14T09:03:03.3116335Z   (conv2): ConvBn2d(
2026-01-14T09:03:03.3116582Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:03:03.3117041Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:03.3117583Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3118705Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:03.3120088Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:03:03.3120693Z     )
2026-01-14T09:03:03.3120868Z   )
2026-01-14T09:03:03.3121169Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:03.3122310Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:03.3123667Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:03:03.3124270Z   )
2026-01-14T09:03:03.3124444Z )
2026-01-14T09:03:03.3124549Z 
2026-01-14T09:03:03.3124554Z 
2026-01-14T09:03:03.3124558Z 
2026-01-14T09:03:03.3124652Z def forward(self, x):
2026-01-14T09:03:03.3125035Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:03.3125656Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:03.3126293Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:03:03.3126941Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:03:03.3127671Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:03:03.3128160Z     return activation_post_process_2
2026-01-14T09:03:03.3128444Z     
2026-01-14T09:03:03.3128740Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:03.3129144Z diff: tensor([[[[0.]],
2026-01-14T09:03:03.3129294Z 
2026-01-14T09:03:03.3129372Z          [[0.]],
2026-01-14T09:03:03.3129589Z 
2026-01-14T09:03:03.3129664Z          [[0.]]],
2026-01-14T09:03:03.3129791Z 
2026-01-14T09:03:03.3129795Z 
2026-01-14T09:03:03.3129922Z         [[[0.]],
2026-01-14T09:03:03.3130047Z 
2026-01-14T09:03:03.3130125Z          [[0.]],
2026-01-14T09:03:03.3130247Z 
2026-01-14T09:03:03.3130328Z          [[0.]]],
2026-01-14T09:03:03.3130451Z 
2026-01-14T09:03:03.3130455Z 
2026-01-14T09:03:03.3130529Z         [[[0.]],
2026-01-14T09:03:03.3130656Z 
2026-01-14T09:03:03.3130729Z          [[0.]],
2026-01-14T09:03:03.3130849Z 
2026-01-14T09:03:03.3130965Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:03.3131282Z converted model pt2e: GraphModule(
2026-01-14T09:03:03.3131569Z   (conv1): Module()
2026-01-14T09:03:03.3131783Z   (bn1): Module()
2026-01-14T09:03:03.3131999Z   (conv2): Module()
2026-01-14T09:03:03.3132204Z   (bn2): Module()
2026-01-14T09:03:03.3132408Z )
2026-01-14T09:03:03.3132509Z 
2026-01-14T09:03:03.3132512Z 
2026-01-14T09:03:03.3132516Z 
2026-01-14T09:03:03.3132612Z def forward(self, x):
2026-01-14T09:03:03.3132919Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:03.3133300Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:03.3134063Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:03.3135577Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:03.3136644Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T09:03:03.3137664Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.001512790797278285, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T09:03:03.3138646Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:03:26.9907069Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T09:03:26.9908980Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.017422160133719444, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:03:26.9910893Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:03:26.9912177Z     quantize_per_tensor = self._frozen_param1
2026-01-14T09:03:26.9913285Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001512868795543909, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:03:26.9915121Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T09:03:26.9916877Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:03:26.9918741Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T09:03:26.9920479Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T09:03:26.9921061Z     
2026-01-14T09:03:26.9921428Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:26.9921942Z onverted model fx: GraphModule(
2026-01-14T09:03:26.9922449Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:26.9923150Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:26.9923842Z )
2026-01-14T09:03:26.9923978Z 
2026-01-14T09:03:26.9924004Z 
2026-01-14T09:03:26.9924009Z 
2026-01-14T09:03:26.9924121Z def forward(self, x):
2026-01-14T09:03:26.9924982Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:26.9926774Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:26.9928000Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:26.9929031Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.017422160133719444, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:03:26.9930642Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:26.9931903Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:03:26.9932938Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:03:26.9934481Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:03:26.9935543Z     return dequantize_per_tensor_default_2
2026-01-14T09:03:26.9935846Z     
2026-01-14T09:03:26.9936146Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:26.9936555Z diff: tensor([[[[0.]],
2026-01-14T09:03:26.9936712Z 
2026-01-14T09:03:26.9936791Z          [[0.]],
2026-01-14T09:03:26.9936924Z 
2026-01-14T09:03:26.9937000Z          [[0.]]],
2026-01-14T09:03:26.9937127Z 
2026-01-14T09:03:26.9937131Z 
2026-01-14T09:03:26.9937205Z         [[[0.]],
2026-01-14T09:03:26.9937335Z 
2026-01-14T09:03:26.9937410Z          [[0.]],
2026-01-14T09:03:26.9937535Z 
2026-01-14T09:03:26.9937616Z          [[0.]]],
2026-01-14T09:03:26.9937740Z 
2026-01-14T09:03:26.9937743Z 
2026-01-14T09:03:26.9937817Z         [[[0.]],
2026-01-14T09:03:26.9937941Z 
2026-01-14T09:03:26.9938022Z          [[0.]],
2026-01-14T09:03:26.9938146Z 
2026-01-14T09:03:26.9938222Z          [[0.]]]])
2026-01-14T09:03:26.9938648Z [32mPASSED[0m
2026-01-14T09:03:26.9939424Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T09:03:26.9940573Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T09:03:26.9941296Z   (conv): Module()
2026-01-14T09:03:26.9941508Z   (bn): Module()
2026-01-14T09:03:26.9941833Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:26.9942969Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:26.9944433Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:26.9945033Z   )
2026-01-14T09:03:26.9945323Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:26.9946537Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:26.9948211Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:03:26.9948961Z   )
2026-01-14T09:03:26.9949256Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:26.9950393Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:26.9951685Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:03:26.9952224Z   )
2026-01-14T09:03:26.9952393Z )
2026-01-14T09:03:26.9952493Z 
2026-01-14T09:03:26.9952497Z 
2026-01-14T09:03:26.9952501Z 
2026-01-14T09:03:26.9952595Z def forward(self, x):
2026-01-14T09:03:26.9952913Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:26.9961071Z     conv_weight = self.conv.weight
2026-01-14T09:03:26.9961381Z     conv_bias = self.conv.bias
2026-01-14T09:03:26.9961657Z     bn_weight = self.bn.weight
2026-01-14T09:03:26.9961916Z     bn_bias = self.bn.bias
2026-01-14T09:03:26.9962191Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:03:26.9962516Z     bn_running_var = self.bn.running_var
2026-01-14T09:03:26.9962880Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:26.9963375Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:26.9964064Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:26.9964682Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:03:26.9965133Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:26.9965626Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:03:26.9966116Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:03:26.9966704Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:03:26.9967357Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:03:26.9968063Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:26.9969232Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:03:26.9970349Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:03:26.9970974Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:03:26.9971663Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:03:26.9972306Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:26.9973382Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:03:26.9974447Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:03:26.9975486Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:03:26.9976247Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:03:26.9976877Z     
2026-01-14T09:03:26.9977193Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:26.9977604Z model fx: GraphModule(
2026-01-14T09:03:26.9977957Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:26.9979107Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:26.9980602Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:26.9981201Z   )
2026-01-14T09:03:26.9981396Z   (conv): ConvBnReLU2d(
2026-01-14T09:03:26.9981662Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:03:26.9982121Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:26.9982673Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:26.9983871Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:47.1545276Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:03:47.1546278Z     )
2026-01-14T09:03:47.1546509Z   )
2026-01-14T09:03:47.1546870Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:47.1548263Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:47.1549846Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:03:47.1550535Z   )
2026-01-14T09:03:47.1550775Z )
2026-01-14T09:03:47.1550910Z 
2026-01-14T09:03:47.1550915Z 
2026-01-14T09:03:47.1550920Z 
2026-01-14T09:03:47.1551034Z def forward(self, x):
2026-01-14T09:03:47.1551514Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:47.1552234Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:47.1552995Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:03:47.1553573Z     return activation_post_process_1
2026-01-14T09:03:47.1553918Z     
2026-01-14T09:03:47.1554282Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:47.1554797Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:03:47.1555117Z           [0., 0., 0.],
2026-01-14T09:03:47.1555389Z           [0., 0., 0.]],
2026-01-14T09:03:47.1555573Z 
2026-01-14T09:03:47.1555682Z          [[0., 0., 0.],
2026-01-14T09:03:47.1555954Z           [0., 0., 0.],
2026-01-14T09:03:47.1556228Z           [0., 0., 0.]],
2026-01-14T09:03:47.1556408Z 
2026-01-14T09:03:47.1556507Z          [[0., 0., 0.],
2026-01-14T09:03:47.1556790Z           [0., 0., 0.],
2026-01-14T09:03:47.1557096Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:47.1557512Z converted model pt2e: GraphModule(
2026-01-14T09:03:47.1557862Z   (conv): Module()
2026-01-14T09:03:47.1558117Z   (bn): Module()
2026-01-14T09:03:47.1558366Z )
2026-01-14T09:03:47.1558494Z 
2026-01-14T09:03:47.1558499Z 
2026-01-14T09:03:47.1558504Z 
2026-01-14T09:03:47.1558613Z def forward(self, x):
2026-01-14T09:03:47.1558990Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:47.1559432Z     conv_bias = self.conv.bias
2026-01-14T09:03:47.1560327Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:03:47.1562455Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:47.1563671Z     _scale_0 = self._scale_0
2026-01-14T09:03:47.1564004Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:03:47.1564393Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:03:47.1565864Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:03:47.1567820Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:03:47.1569031Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:03:47.1570225Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004903945606201887, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:03:47.1572087Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:47.1573539Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:03:47.1574106Z     
2026-01-14T09:03:47.1574515Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:47.1575366Z onverted model fx: GraphModule(
2026-01-14T09:03:47.1575708Z   (conv): ConvReLU2d(
2026-01-14T09:03:47.1576067Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:47.1576491Z     (1): ReLU()
2026-01-14T09:03:47.1576691Z   )
2026-01-14T09:03:47.1576872Z )
2026-01-14T09:03:47.1576976Z 
2026-01-14T09:03:47.1576980Z 
2026-01-14T09:03:47.1576992Z 
2026-01-14T09:03:47.1577081Z def forward(self, x):
2026-01-14T09:03:47.1577797Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:03:47.1579284Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:47.1580497Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:47.1581520Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004903945606201887, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:03:47.1583080Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:47.1584142Z     return dequantize_per_tensor_default_1
2026-01-14T09:03:47.1584444Z     
2026-01-14T09:03:47.1584741Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:47.1585160Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:03:47.1585411Z           [0., 0., 0.],
2026-01-14T09:03:47.1585646Z           [0., 0., 0.]],
2026-01-14T09:03:47.1585800Z 
2026-01-14T09:03:47.1585887Z          [[0., 0., 0.],
2026-01-14T09:03:47.1586104Z           [0., 0., 0.],
2026-01-14T09:03:47.1586328Z           [0., 0., 0.]],
2026-01-14T09:03:47.1586475Z 
2026-01-14T09:03:47.1586552Z          [[0., 0., 0.],
2026-01-14T09:03:47.1586775Z           [0., 0., 0.],
2026-01-14T09:03:47.1586994Z           [0., 0., 0.]]]])
2026-01-14T09:03:47.1587246Z model pt2e: GraphModule(
2026-01-14T09:03:47.1587486Z   (conv): Module()
2026-01-14T09:03:47.1587700Z   (bn): Module()
2026-01-14T09:03:47.1588016Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:47.1589311Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:47.1590658Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:47.1591368Z   )
2026-01-14T09:03:47.1591672Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:47.1592817Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:47.1594177Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:03:47.1594773Z   )
2026-01-14T09:03:47.1595066Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:47.1596204Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:47.1597491Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:03:47.1598026Z   )
2026-01-14T09:03:47.1598203Z )
2026-01-14T09:03:47.1598303Z 
2026-01-14T09:03:47.1598307Z 
2026-01-14T09:03:47.1598311Z 
2026-01-14T09:03:47.1598397Z def forward(self, x):
2026-01-14T09:03:47.1598706Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:47.1599076Z     conv_weight = self.conv.weight
2026-01-14T09:03:47.1599373Z     conv_bias = self.conv.bias
2026-01-14T09:03:47.1599640Z     bn_weight = self.bn.weight
2026-01-14T09:03:47.1599908Z     bn_bias = self.bn.bias
2026-01-14T09:03:47.1600193Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:03:47.1600515Z     bn_running_var = self.bn.running_var
2026-01-14T09:03:47.1600881Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:47.1601370Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:47.1602054Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:47.1602676Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:03:47.1603116Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:47.1603579Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:03:47.1604072Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:03:47.1604653Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:03:47.1605301Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:03:47.1606025Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:47.1607187Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:03:47.1608253Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:03:47.1608885Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:03:47.1609557Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:03:47.1610286Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:47.1611447Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:03:47.1612499Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:03:47.1613099Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:03:47.1613714Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:03:47.1614162Z     
2026-01-14T09:03:47.1614465Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:47.1614962Z model fx: GraphModule(
2026-01-14T09:03:47.1615310Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:47.1616453Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:47.1617793Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:47.1618385Z   )
2026-01-14T09:03:47.1618583Z   (conv): ConvBnReLU2d(
2026-01-14T09:03:47.1618837Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:09.4899230Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:09.4899809Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:09.4900945Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:09.4902361Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:04:09.4902957Z     )
2026-01-14T09:04:09.4903138Z   )
2026-01-14T09:04:09.4903428Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:09.4904599Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:09.4905898Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:04:09.4906433Z   )
2026-01-14T09:04:09.4906620Z )
2026-01-14T09:04:09.4906724Z 
2026-01-14T09:04:09.4906734Z 
2026-01-14T09:04:09.4906738Z 
2026-01-14T09:04:09.4906828Z def forward(self, x):
2026-01-14T09:04:09.4907264Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:09.4907871Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:09.4908488Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:09.4908984Z     return activation_post_process_1
2026-01-14T09:04:09.4909258Z     
2026-01-14T09:04:09.4909574Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:09.4909990Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:09.4910249Z           [0., 0., 0.],
2026-01-14T09:04:09.4910472Z           [0., 0., 0.]],
2026-01-14T09:04:09.4910631Z 
2026-01-14T09:04:09.4910712Z          [[0., 0., 0.],
2026-01-14T09:04:09.4910933Z           [0., 0., 0.],
2026-01-14T09:04:09.4911154Z           [0., 0., 0.]],
2026-01-14T09:04:09.4911307Z 
2026-01-14T09:04:09.4911403Z          [[0., 0., 0.],
2026-01-14T09:04:09.4911618Z           [0., 0., 0.],
2026-01-14T09:04:09.4911888Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:04:09.4912229Z converted model pt2e: GraphModule(
2026-01-14T09:04:09.4912516Z   (conv): Module()
2026-01-14T09:04:09.4912726Z   (bn): Module()
2026-01-14T09:04:09.4912930Z )
2026-01-14T09:04:09.4913056Z 
2026-01-14T09:04:09.4913066Z 
2026-01-14T09:04:09.4913070Z 
2026-01-14T09:04:09.4913156Z def forward(self, x):
2026-01-14T09:04:09.4913465Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:09.4914143Z     conv_bias = self.conv.bias
2026-01-14T09:04:09.4914917Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:09.4916413Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:09.4917623Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:04:09.4918559Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014826410915702581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:09.4920080Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:04:09.4921089Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:09.4922006Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004861548542976379, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:09.4923566Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:09.4924797Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:04:09.4925266Z     
2026-01-14T09:04:09.4925577Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:09.4925990Z onverted model fx: GraphModule(
2026-01-14T09:04:09.4926264Z   (conv): ConvReLU2d(
2026-01-14T09:04:09.4926625Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:09.4927048Z     (1): ReLU()
2026-01-14T09:04:09.4927252Z   )
2026-01-14T09:04:09.4927430Z )
2026-01-14T09:04:09.4927529Z 
2026-01-14T09:04:09.4927533Z 
2026-01-14T09:04:09.4927537Z 
2026-01-14T09:04:09.4927652Z def forward(self, x):
2026-01-14T09:04:09.4928388Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:09.4929938Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:09.4931321Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:09.4932640Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004861548542976379, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:09.4934412Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:09.4935484Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:09.4935789Z     
2026-01-14T09:04:09.4936088Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:09.4936504Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:09.4936763Z           [0., 0., 0.],
2026-01-14T09:04:09.4937015Z           [0., 0., 0.]],
2026-01-14T09:04:09.4937223Z 
2026-01-14T09:04:09.4937339Z          [[0., 0., 0.],
2026-01-14T09:04:09.4937557Z           [0., 0., 0.],
2026-01-14T09:04:09.4937811Z           [0., 0., 0.]],
2026-01-14T09:04:09.4937975Z 
2026-01-14T09:04:09.4938054Z          [[0., 0., 0.],
2026-01-14T09:04:09.4938275Z           [0., 0., 0.],
2026-01-14T09:04:09.4938492Z           [0., 0., 0.]]]])
2026-01-14T09:04:09.4938945Z [32mPASSED[0m
2026-01-14T09:04:09.4939744Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:04:09.4940485Z   (conv): Module()
2026-01-14T09:04:09.4940704Z   (bn): Module()
2026-01-14T09:04:09.4941026Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:09.4942428Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:09.4945191Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:09.4945782Z   )
2026-01-14T09:04:09.4946085Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:09.4947550Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:09.4949516Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:04:09.4950406Z   )
2026-01-14T09:04:09.4950696Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:09.4952095Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:09.4953632Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:04:09.4954171Z   )
2026-01-14T09:04:09.4954348Z )
2026-01-14T09:04:09.4954451Z 
2026-01-14T09:04:09.4954455Z 
2026-01-14T09:04:09.4954459Z 
2026-01-14T09:04:09.4954546Z def forward(self, x):
2026-01-14T09:04:09.4954852Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:09.4955222Z     conv_weight = self.conv.weight
2026-01-14T09:04:09.4955514Z     conv_bias = self.conv.bias
2026-01-14T09:04:09.4955791Z     bn_weight = self.bn.weight
2026-01-14T09:04:09.4956058Z     bn_bias = self.bn.bias
2026-01-14T09:04:09.4956332Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:09.4956654Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:09.4957023Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:09.4957516Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:09.4958203Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:09.4958819Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:09.4959258Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:09.4959720Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:09.4960213Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:09.4960790Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:09.4961439Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:09.4962156Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:09.4963323Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:09.4964388Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:09.4965110Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:09.4965789Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:09.4966444Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:09.4967560Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:09.4968693Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:29.8065475Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:29.8068628Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:29.8069170Z     
2026-01-14T09:04:29.8069509Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:29.8069931Z model fx: GraphModule(
2026-01-14T09:04:29.8070279Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8071694Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:29.8073324Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:29.8073916Z   )
2026-01-14T09:04:29.8074115Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:29.8074373Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:29.8075028Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:29.8075571Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8077160Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:29.8079133Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:04:29.8080020Z     )
2026-01-14T09:04:29.8080204Z   )
2026-01-14T09:04:29.8080498Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8081892Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:29.8083430Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:04:29.8083962Z   )
2026-01-14T09:04:29.8084148Z )
2026-01-14T09:04:29.8084250Z 
2026-01-14T09:04:29.8084255Z 
2026-01-14T09:04:29.8084258Z 
2026-01-14T09:04:29.8084353Z def forward(self, x):
2026-01-14T09:04:29.8084741Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:29.8085358Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:29.8085983Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:29.8086472Z     return activation_post_process_1
2026-01-14T09:04:29.8086749Z     
2026-01-14T09:04:29.8087053Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:29.8087468Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:29.8087727Z           [0., 0., 0.],
2026-01-14T09:04:29.8088342Z           [0., 0., 0.]],
2026-01-14T09:04:29.8088503Z 
2026-01-14T09:04:29.8088582Z          [[0., 0., 0.],
2026-01-14T09:04:29.8088806Z           [0., 0., 0.],
2026-01-14T09:04:29.8089028Z           [0., 0., 0.]],
2026-01-14T09:04:29.8089181Z 
2026-01-14T09:04:29.8089260Z          [[0., 0., 0.],
2026-01-14T09:04:29.8089478Z           [0., 0., 0.],
2026-01-14T09:04:29.8089774Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:04:29.8090446Z converted model pt2e: GraphModule(
2026-01-14T09:04:29.8090731Z   (conv): Module()
2026-01-14T09:04:29.8090948Z   (bn): Module()
2026-01-14T09:04:29.8091149Z )
2026-01-14T09:04:29.8091251Z 
2026-01-14T09:04:29.8091254Z 
2026-01-14T09:04:29.8091258Z 
2026-01-14T09:04:29.8091352Z def forward(self, x):
2026-01-14T09:04:29.8091657Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:29.8092033Z     conv_bias = self.conv.bias
2026-01-14T09:04:29.8092781Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:29.8094278Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:29.8095303Z     _scale_0 = self._scale_0
2026-01-14T09:04:29.8095586Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:04:29.8095922Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:04:29.8096980Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:04:29.8098631Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:04:29.8099654Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:29.8100567Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.008064487017691135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:29.8102153Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:29.8103437Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:04:29.8103905Z     
2026-01-14T09:04:29.8104212Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:29.8104643Z onverted model fx: GraphModule(
2026-01-14T09:04:29.8104915Z   (conv): ConvReLU2d(
2026-01-14T09:04:29.8105285Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:29.8105713Z     (1): ReLU()
2026-01-14T09:04:29.8105926Z   )
2026-01-14T09:04:29.8106104Z )
2026-01-14T09:04:29.8106211Z 
2026-01-14T09:04:29.8106215Z 
2026-01-14T09:04:29.8106219Z 
2026-01-14T09:04:29.8106305Z def forward(self, x):
2026-01-14T09:04:29.8107014Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:29.8108509Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:29.8109719Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:29.8110735Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008064487017691135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:29.8112392Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:29.8113468Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:29.8113762Z     
2026-01-14T09:04:29.8114066Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:29.8114560Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:29.8114825Z           [0., 0., 0.],
2026-01-14T09:04:29.8115047Z           [0., 0., 0.]],
2026-01-14T09:04:29.8115204Z 
2026-01-14T09:04:29.8115284Z          [[0., 0., 0.],
2026-01-14T09:04:29.8115510Z           [0., 0., 0.],
2026-01-14T09:04:29.8115725Z           [0., 0., 0.]],
2026-01-14T09:04:29.8115874Z 
2026-01-14T09:04:29.8115959Z          [[0., 0., 0.],
2026-01-14T09:04:29.8116178Z           [0., 0., 0.],
2026-01-14T09:04:29.8116419Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:04:29.8116716Z model pt2e: GraphModule(
2026-01-14T09:04:29.8116967Z   (conv): Module()
2026-01-14T09:04:29.8117177Z   (bn): Module()
2026-01-14T09:04:29.8117501Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8118888Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:29.8120484Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:29.8129641Z   )
2026-01-14T09:04:29.8130070Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8131501Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:29.8133115Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:04:29.8133720Z   )
2026-01-14T09:04:29.8134013Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:29.8135400Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:29.8136942Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:04:29.8137475Z   )
2026-01-14T09:04:29.8137655Z )
2026-01-14T09:04:29.8137758Z 
2026-01-14T09:04:29.8137762Z 
2026-01-14T09:04:29.8137766Z 
2026-01-14T09:04:29.8137855Z def forward(self, x):
2026-01-14T09:04:29.8138173Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:29.8138552Z     conv_weight = self.conv.weight
2026-01-14T09:04:29.8138842Z     conv_bias = self.conv.bias
2026-01-14T09:04:29.8139120Z     bn_weight = self.bn.weight
2026-01-14T09:04:29.8139383Z     bn_bias = self.bn.bias
2026-01-14T09:04:29.8139665Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:29.8139992Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:29.8140364Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:29.8140857Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:29.8141547Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:29.8142171Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:29.8142610Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:29.8145056Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:29.8145578Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:29.8146166Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:29.8146814Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:51.9702778Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:51.9704656Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:51.9705935Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:51.9706696Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:51.9707537Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:51.9708314Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:51.9709598Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:51.9710841Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:51.9711567Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:51.9712323Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:51.9712846Z     
2026-01-14T09:04:51.9713234Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:51.9713728Z model fx: GraphModule(
2026-01-14T09:04:51.9714158Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9715823Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:51.9717785Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:51.9718503Z   )
2026-01-14T09:04:51.9718741Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:51.9719061Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:51.9719611Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:51.9720259Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9721892Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:51.9723815Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:04:51.9724543Z     )
2026-01-14T09:04:51.9724772Z   )
2026-01-14T09:04:51.9725137Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9726791Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:51.9728599Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:04:51.9729246Z   )
2026-01-14T09:04:51.9729464Z )
2026-01-14T09:04:51.9729598Z 
2026-01-14T09:04:51.9729603Z 
2026-01-14T09:04:51.9729608Z 
2026-01-14T09:04:51.9730025Z def forward(self, x):
2026-01-14T09:04:51.9730513Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:51.9731230Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:51.9731981Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:51.9732639Z     return activation_post_process_1
2026-01-14T09:04:51.9732979Z     
2026-01-14T09:04:51.9733333Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:51.9733830Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:51.9734141Z           [0., 0., 0.],
2026-01-14T09:04:51.9734407Z           [0., 0., 0.]],
2026-01-14T09:04:51.9734586Z 
2026-01-14T09:04:51.9734693Z          [[0., 0., 0.],
2026-01-14T09:04:51.9734957Z           [0., 0., 0.],
2026-01-14T09:04:51.9735232Z           [0., 0., 0.]],
2026-01-14T09:04:51.9735411Z 
2026-01-14T09:04:51.9735507Z          [[0., 0., 0.],
2026-01-14T09:04:51.9735786Z           [0., 0., 0.],
2026-01-14T09:04:51.9736139Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:04:51.9736618Z converted model pt2e: GraphModule(
2026-01-14T09:04:51.9736964Z   (conv): Module()
2026-01-14T09:04:51.9737222Z   (bn): Module()
2026-01-14T09:04:51.9737472Z )
2026-01-14T09:04:51.9737605Z 
2026-01-14T09:04:51.9737610Z 
2026-01-14T09:04:51.9737626Z 
2026-01-14T09:04:51.9737758Z def forward(self, x):
2026-01-14T09:04:51.9738156Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:51.9738632Z     conv_bias = self.conv.bias
2026-01-14T09:04:51.9739434Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:51.9740934Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:51.9741986Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:04:51.9742914Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:51.9744437Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:04:51.9745447Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:51.9746359Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00804795604199171, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:51.9747911Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:51.9749118Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:04:51.9749590Z     
2026-01-14T09:04:51.9749888Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:51.9750315Z onverted model fx: GraphModule(
2026-01-14T09:04:51.9750596Z   (conv): ConvReLU2d(
2026-01-14T09:04:51.9750962Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:51.9751388Z     (1): ReLU()
2026-01-14T09:04:51.9751584Z   )
2026-01-14T09:04:51.9751772Z )
2026-01-14T09:04:51.9751873Z 
2026-01-14T09:04:51.9751877Z 
2026-01-14T09:04:51.9751881Z 
2026-01-14T09:04:51.9751968Z def forward(self, x):
2026-01-14T09:04:51.9752684Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:51.9754274Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:51.9755484Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:51.9756501Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00804795604199171, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:51.9758119Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:51.9759189Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:51.9759493Z     
2026-01-14T09:04:51.9759820Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:51.9760263Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:51.9760518Z           [0., 0., 0.],
2026-01-14T09:04:51.9760747Z           [0., 0., 0.]],
2026-01-14T09:04:51.9760899Z 
2026-01-14T09:04:51.9760977Z          [[0., 0., 0.],
2026-01-14T09:04:51.9761195Z           [0., 0., 0.],
2026-01-14T09:04:51.9761420Z           [0., 0., 0.]],
2026-01-14T09:04:51.9761567Z 
2026-01-14T09:04:51.9761646Z          [[0., 0., 0.],
2026-01-14T09:04:51.9761870Z           [0., 0., 0.],
2026-01-14T09:04:51.9762113Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:04:51.9762616Z [32mPASSED[0m
2026-01-14T09:04:51.9763326Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:04:51.9764089Z   (conv): Module()
2026-01-14T09:04:51.9764296Z   (bn): Module()
2026-01-14T09:04:51.9764621Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9765771Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:51.9767107Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:51.9767699Z   )
2026-01-14T09:04:51.9767991Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9769210Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:51.9770927Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:04:51.9771679Z   )
2026-01-14T09:04:51.9771976Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:51.9773120Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:51.9774412Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:04:51.9775180Z   )
2026-01-14T09:04:51.9775497Z )
2026-01-14T09:04:51.9775600Z 
2026-01-14T09:04:51.9775612Z 
2026-01-14T09:04:51.9775616Z 
2026-01-14T09:04:51.9775704Z def forward(self, x):
2026-01-14T09:04:51.9776029Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:51.9776525Z     conv_weight = self.conv.weight
2026-01-14T09:04:51.9776824Z     bn_weight = self.bn.weight
2026-01-14T09:04:51.9777099Z     bn_bias = self.bn.bias
2026-01-14T09:04:51.9777380Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:51.9777710Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:08.8719170Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:08.8719870Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:08.8720731Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:08.8721468Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:08.8721994Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:08.8722739Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:08.8723350Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:08.8724041Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:08.8724818Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:08.8726017Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:08.8727192Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:08.8727921Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:08.8729232Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:08.8730585Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:08.8731289Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:08.8732028Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:08.8732547Z     
2026-01-14T09:05:08.8732917Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:08.8733401Z model fx: GraphModule(
2026-01-14T09:05:08.8733825Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8735187Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:08.8736808Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:08.8737525Z   )
2026-01-14T09:05:08.8737754Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:08.8738097Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:08.8738680Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:08.8739323Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8740736Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:08.8742630Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:05:08.8743538Z     )
2026-01-14T09:05:08.8743757Z   )
2026-01-14T09:05:08.8744124Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8745493Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:08.8747017Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:05:08.8747650Z   )
2026-01-14T09:05:08.8747888Z )
2026-01-14T09:05:08.8748012Z 
2026-01-14T09:05:08.8748017Z 
2026-01-14T09:05:08.8748022Z 
2026-01-14T09:05:08.8748234Z def forward(self, x):
2026-01-14T09:05:08.8748705Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:08.8749427Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:08.8750167Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:08.8750834Z     return activation_post_process_1
2026-01-14T09:05:08.8751166Z     
2026-01-14T09:05:08.8751531Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:08.8752016Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:08.8752321Z           [0., 0., 0.],
2026-01-14T09:05:08.8752586Z           [0., 0., 0.]],
2026-01-14T09:05:08.8752773Z 
2026-01-14T09:05:08.8752869Z          [[0., 0., 0.],
2026-01-14T09:05:08.8753136Z           [0., 0., 0.],
2026-01-14T09:05:08.8753398Z           [0., 0., 0.]],
2026-01-14T09:05:08.8753577Z 
2026-01-14T09:05:08.8753678Z          [[0., 0., 0.],
2026-01-14T09:05:08.8753949Z           [0., 0., 0.],
2026-01-14T09:05:08.8754261Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:08.8754660Z converted model pt2e: GraphModule(
2026-01-14T09:05:08.8754999Z   (conv): Module()
2026-01-14T09:05:08.8755252Z   (bn): Module()
2026-01-14T09:05:08.8755500Z )
2026-01-14T09:05:08.8755622Z 
2026-01-14T09:05:08.8755627Z 
2026-01-14T09:05:08.8755632Z 
2026-01-14T09:05:08.8755756Z def forward(self, x):
2026-01-14T09:05:08.8756119Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:08.8757125Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:08.8758913Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:08.8760140Z     _scale_0 = self._scale_0
2026-01-14T09:05:08.8760472Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:08.8760859Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:05:08.8762197Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:08.8763399Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:08.8764391Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:05:08.8765466Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:08.8766375Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007783781737089157, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:08.8767933Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:08.8769148Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:08.8769609Z     
2026-01-14T09:05:08.8769957Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:08.8770382Z onverted model fx: GraphModule(
2026-01-14T09:05:08.8770659Z   (conv): ConvReLU2d(
2026-01-14T09:05:08.8771016Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:08.8771437Z     (1): ReLU()
2026-01-14T09:05:08.8771629Z   )
2026-01-14T09:05:08.8771808Z )
2026-01-14T09:05:08.8771907Z 
2026-01-14T09:05:08.8771911Z 
2026-01-14T09:05:08.8771915Z 
2026-01-14T09:05:08.8772007Z def forward(self, x):
2026-01-14T09:05:08.8772807Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:08.8774291Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:08.8775676Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:08.8776821Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007783781737089157, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:08.8778376Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:08.8779437Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:08.8779733Z     
2026-01-14T09:05:08.8780035Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:08.8780449Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:08.8780703Z           [0., 0., 0.],
2026-01-14T09:05:08.8780921Z           [0., 0., 0.]],
2026-01-14T09:05:08.8781070Z 
2026-01-14T09:05:08.8781155Z          [[0., 0., 0.],
2026-01-14T09:05:08.8781375Z           [0., 0., 0.],
2026-01-14T09:05:08.8781604Z           [0., 0., 0.]],
2026-01-14T09:05:08.8781752Z 
2026-01-14T09:05:08.8781829Z          [[0., 0., 0.],
2026-01-14T09:05:08.8782050Z           [0., 0., 0.],
2026-01-14T09:05:08.8782267Z           [0., 0., 0.]]]])
2026-01-14T09:05:08.8782522Z model pt2e: GraphModule(
2026-01-14T09:05:08.8782762Z   (conv): Module()
2026-01-14T09:05:08.8782979Z   (bn): Module()
2026-01-14T09:05:08.8783303Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8784439Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:08.8785830Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:08.8786412Z   )
2026-01-14T09:05:08.8786707Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8787856Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:08.8789211Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:05:08.8789815Z   )
2026-01-14T09:05:08.8790106Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:08.8791247Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:08.8792530Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:05:08.8793062Z   )
2026-01-14T09:05:08.8793238Z )
2026-01-14T09:05:08.8793338Z 
2026-01-14T09:05:08.8793349Z 
2026-01-14T09:05:08.8793353Z 
2026-01-14T09:05:08.8793439Z def forward(self, x):
2026-01-14T09:05:08.8793747Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:08.8794119Z     conv_weight = self.conv.weight
2026-01-14T09:05:27.7911010Z     bn_weight = self.bn.weight
2026-01-14T09:05:27.7911893Z     bn_bias = self.bn.bias
2026-01-14T09:05:27.7912643Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:27.7913370Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:27.7914092Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:27.7915686Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:27.7917080Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:27.7918307Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:27.7919178Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:27.7920271Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:27.7920813Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:27.7921393Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:27.7922038Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:27.7923032Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:27.7924023Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:27.7924650Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:27.7925748Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:27.7926792Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:27.7927388Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:27.7928004Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:27.7928441Z     
2026-01-14T09:05:27.7928747Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:27.7929154Z model fx: GraphModule(
2026-01-14T09:05:27.7929507Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7930730Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:27.7932187Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:27.7932781Z   )
2026-01-14T09:05:27.7932977Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:27.7933255Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:27.7933752Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:27.7934280Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7935402Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:27.7936784Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:05:27.7937384Z     )
2026-01-14T09:05:27.7937570Z   )
2026-01-14T09:05:27.7937862Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7939009Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:27.7940305Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:05:27.7940840Z   )
2026-01-14T09:05:27.7941020Z )
2026-01-14T09:05:27.7941123Z 
2026-01-14T09:05:27.7941127Z 
2026-01-14T09:05:27.7941131Z 
2026-01-14T09:05:27.7941219Z def forward(self, x):
2026-01-14T09:05:27.7941698Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:27.7942309Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:27.7942942Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:27.7943422Z     return activation_post_process_1
2026-01-14T09:05:27.7943703Z     
2026-01-14T09:05:27.7944007Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:27.7944498Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:27.7944754Z           [0., 0., 0.],
2026-01-14T09:05:27.7944975Z           [0., 0., 0.]],
2026-01-14T09:05:27.7945127Z 
2026-01-14T09:05:27.7945213Z          [[0., 0., 0.],
2026-01-14T09:05:27.7945427Z           [0., 0., 0.],
2026-01-14T09:05:27.7945647Z           [0., 0., 0.]],
2026-01-14T09:05:27.7945794Z 
2026-01-14T09:05:27.7945871Z          [[0., 0., 0.],
2026-01-14T09:05:27.7946089Z           [0., 0., 0.],
2026-01-14T09:05:27.7946345Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:27.7946687Z converted model pt2e: GraphModule(
2026-01-14T09:05:27.7946974Z   (conv): Module()
2026-01-14T09:05:27.7947181Z   (bn): Module()
2026-01-14T09:05:27.7947379Z )
2026-01-14T09:05:27.7947479Z 
2026-01-14T09:05:27.7947483Z 
2026-01-14T09:05:27.7947488Z 
2026-01-14T09:05:27.7947574Z def forward(self, x):
2026-01-14T09:05:27.7947880Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:27.7948722Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:27.7950214Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:27.7951264Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:05:27.7952190Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:05:27.7953130Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:27.7954119Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:05:27.7955188Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:27.7956102Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007779817562550306, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:27.7957648Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:27.7958869Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:27.7959335Z     
2026-01-14T09:05:27.7959636Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:27.7960061Z onverted model fx: GraphModule(
2026-01-14T09:05:27.7960329Z   (conv): ConvReLU2d(
2026-01-14T09:05:27.7960696Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:27.7961117Z     (1): ReLU()
2026-01-14T09:05:27.7961315Z   )
2026-01-14T09:05:27.7961484Z )
2026-01-14T09:05:27.7961589Z 
2026-01-14T09:05:27.7961594Z 
2026-01-14T09:05:27.7961598Z 
2026-01-14T09:05:27.7961687Z def forward(self, x):
2026-01-14T09:05:27.7962399Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:27.7963966Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:27.7965179Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:27.7966196Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007779817562550306, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:27.7967746Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:27.7968941Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:27.7969230Z     
2026-01-14T09:05:27.7969538Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:27.7969994Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:27.7970243Z           [0., 0., 0.],
2026-01-14T09:05:27.7970470Z           [0., 0., 0.]],
2026-01-14T09:05:27.7970620Z 
2026-01-14T09:05:27.7970705Z          [[0., 0., 0.],
2026-01-14T09:05:27.7970927Z           [0., 0., 0.],
2026-01-14T09:05:27.7971144Z           [0., 0., 0.]],
2026-01-14T09:05:27.7971298Z 
2026-01-14T09:05:27.7971375Z          [[0., 0., 0.],
2026-01-14T09:05:27.7971587Z           [0., 0., 0.],
2026-01-14T09:05:27.7971811Z           [0., 0., 0.]]]])
2026-01-14T09:05:27.7972269Z [32mPASSED[0m
2026-01-14T09:05:27.7972906Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T09:05:27.7973587Z   (conv): Module()
2026-01-14T09:05:27.7973907Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7975370Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:27.7977109Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:05:27.7977861Z   )
2026-01-14T09:05:27.7978156Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7979287Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:27.7989077Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:27.7989703Z   )
2026-01-14T09:05:27.7990006Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:27.7991171Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:27.7992462Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:05:27.7992999Z   )
2026-01-14T09:05:27.7993170Z )
2026-01-14T09:05:27.7993277Z 
2026-01-14T09:05:27.7993282Z 
2026-01-14T09:05:27.7993286Z 
2026-01-14T09:05:29.2468829Z def forward(self, x):
2026-01-14T09:05:29.2469356Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:29.2469896Z     conv_weight = self.conv.weight
2026-01-14T09:05:29.2470525Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:29.2471344Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:29.2472474Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:29.2473544Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:29.2474564Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:29.2475645Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:29.2476187Z     
2026-01-14T09:05:29.2476551Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:29.2477050Z model fx: GraphModule(
2026-01-14T09:05:29.2477669Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2479042Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:29.2480722Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:29.2481423Z   )
2026-01-14T09:05:29.2481663Z   (conv): ConvReLU2d(
2026-01-14T09:05:29.2482018Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:29.2482530Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2483940Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:29.2485853Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:05:29.2486768Z     )
2026-01-14T09:05:29.2486987Z   )
2026-01-14T09:05:29.2487343Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2488724Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:29.2490348Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:05:29.2491070Z   )
2026-01-14T09:05:29.2491289Z )
2026-01-14T09:05:29.2491422Z 
2026-01-14T09:05:29.2491427Z 
2026-01-14T09:05:29.2491432Z 
2026-01-14T09:05:29.2491540Z def forward(self, x):
2026-01-14T09:05:29.2492002Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:29.2492731Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:29.2493479Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:29.2494054Z     return activation_post_process_1
2026-01-14T09:05:29.2494396Z     
2026-01-14T09:05:29.2494756Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:29.2495255Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:29.2495566Z           [0., 0., 0.],
2026-01-14T09:05:29.2495855Z           [0., 0., 0.]],
2026-01-14T09:05:29.2496037Z 
2026-01-14T09:05:29.2496147Z          [[0., 0., 0.],
2026-01-14T09:05:29.2496413Z           [0., 0., 0.],
2026-01-14T09:05:29.2496685Z           [0., 0., 0.]],
2026-01-14T09:05:29.2496865Z 
2026-01-14T09:05:29.2496961Z          [[0., 0., 0.],
2026-01-14T09:05:29.2497237Z           [0., 0., 0.],
2026-01-14T09:05:29.2497548Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:29.2497967Z converted model pt2e: GraphModule(
2026-01-14T09:05:29.2498303Z   (conv): Module()
2026-01-14T09:05:29.2498561Z )
2026-01-14T09:05:29.2498687Z 
2026-01-14T09:05:29.2498692Z 
2026-01-14T09:05:29.2498696Z 
2026-01-14T09:05:29.2498814Z def forward(self, x):
2026-01-14T09:05:29.2499205Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:29.2499589Z     _scale_0 = self._scale_0
2026-01-14T09:05:29.2499859Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:29.2500216Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:05:29.2501559Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:29.2503200Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:29.2504799Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:29.2506412Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:05:29.2507403Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:29.2508321Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006228470243513584, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:29.2509888Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:29.2511125Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:29.2511604Z     
2026-01-14T09:05:29.2511907Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:29.2512333Z onverted model fx: GraphModule(
2026-01-14T09:05:29.2512607Z   (conv): ConvReLU2d(
2026-01-14T09:05:29.2513018Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:29.2513484Z     (1): ReLU()
2026-01-14T09:05:29.2513686Z   )
2026-01-14T09:05:29.2513858Z )
2026-01-14T09:05:29.2513966Z 
2026-01-14T09:05:29.2513976Z 
2026-01-14T09:05:29.2513980Z 
2026-01-14T09:05:29.2514071Z def forward(self, x):
2026-01-14T09:05:29.2514793Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:29.2516290Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:29.2517518Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:29.2518537Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006228470243513584, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:29.2520110Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:29.2521189Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:29.2521488Z     
2026-01-14T09:05:29.2521793Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:29.2522203Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:29.2522463Z           [0., 0., 0.],
2026-01-14T09:05:29.2522699Z           [0., 0., 0.]],
2026-01-14T09:05:29.2522848Z 
2026-01-14T09:05:29.2522927Z          [[0., 0., 0.],
2026-01-14T09:05:29.2523151Z           [0., 0., 0.],
2026-01-14T09:05:29.2523366Z           [0., 0., 0.]],
2026-01-14T09:05:29.2523515Z 
2026-01-14T09:05:29.2523600Z          [[0., 0., 0.],
2026-01-14T09:05:29.2523820Z           [0., 0., 0.],
2026-01-14T09:05:29.2524054Z           [0., 0., 0.]]]])
2026-01-14T09:05:29.2524299Z model pt2e: GraphModule(
2026-01-14T09:05:29.2524547Z   (conv): Module()
2026-01-14T09:05:29.2524875Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2526132Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:29.2527521Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:05:29.2528238Z   )
2026-01-14T09:05:29.2528537Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2529673Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:29.2531129Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:29.2531757Z   )
2026-01-14T09:05:29.2532058Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:29.2533209Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:29.2534510Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:05:29.2535057Z   )
2026-01-14T09:05:29.2535236Z )
2026-01-14T09:05:29.2535339Z 
2026-01-14T09:05:29.2535342Z 
2026-01-14T09:05:29.2535346Z 
2026-01-14T09:05:29.2535434Z def forward(self, x):
2026-01-14T09:05:29.2535752Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:29.2536130Z     conv_weight = self.conv.weight
2026-01-14T09:05:29.2536649Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:29.2537341Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:29.2538297Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:29.2539200Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:29.2539744Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:29.2540376Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:29.2540816Z     
2026-01-14T09:05:29.2541122Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:29.2541586Z model fx: GraphModule(
2026-01-14T09:05:29.2541926Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7115071Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:30.7116762Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:30.7117486Z   )
2026-01-14T09:05:30.7117725Z   (conv): ConvReLU2d(
2026-01-14T09:05:30.7118075Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:30.7118563Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7119928Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:30.7121592Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:05:30.7122322Z     )
2026-01-14T09:05:30.7122549Z   )
2026-01-14T09:05:30.7122903Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7124519Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:30.7126097Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:05:30.7126742Z   )
2026-01-14T09:05:30.7127121Z )
2026-01-14T09:05:30.7127250Z 
2026-01-14T09:05:30.7127255Z 
2026-01-14T09:05:30.7127260Z 
2026-01-14T09:05:30.7127373Z def forward(self, x):
2026-01-14T09:05:30.7127846Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:30.7128591Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:30.7129341Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:30.7130009Z     return activation_post_process_1
2026-01-14T09:05:30.7130348Z     
2026-01-14T09:05:30.7130731Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:30.7131229Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:30.7131540Z           [0., 0., 0.],
2026-01-14T09:05:30.7131810Z           [0., 0., 0.]],
2026-01-14T09:05:30.7132001Z 
2026-01-14T09:05:30.7132099Z          [[0., 0., 0.],
2026-01-14T09:05:30.7132376Z           [0., 0., 0.],
2026-01-14T09:05:30.7132656Z           [0., 0., 0.]],
2026-01-14T09:05:30.7132837Z 
2026-01-14T09:05:30.7132950Z          [[0., 0., 0.],
2026-01-14T09:05:30.7133214Z           [0., 0., 0.],
2026-01-14T09:05:30.7133531Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:30.7133936Z converted model pt2e: GraphModule(
2026-01-14T09:05:30.7134281Z   (conv): Module()
2026-01-14T09:05:30.7134531Z )
2026-01-14T09:05:30.7134665Z 
2026-01-14T09:05:30.7134670Z 
2026-01-14T09:05:30.7134675Z 
2026-01-14T09:05:30.7134783Z def forward(self, x):
2026-01-14T09:05:30.7135160Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:30.7135670Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:05:30.7137033Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0014933162601664662, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:30.7138646Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:30.7140163Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:30.7141786Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:05:30.7142774Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:30.7143670Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006232379004359245, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:30.7145230Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:30.7146453Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:30.7146918Z     
2026-01-14T09:05:30.7147223Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:30.7147643Z onverted model fx: GraphModule(
2026-01-14T09:05:30.7147920Z   (conv): ConvReLU2d(
2026-01-14T09:05:30.7148328Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:30.7148798Z     (1): ReLU()
2026-01-14T09:05:30.7149107Z   )
2026-01-14T09:05:30.7149280Z )
2026-01-14T09:05:30.7149385Z 
2026-01-14T09:05:30.7149389Z 
2026-01-14T09:05:30.7149393Z 
2026-01-14T09:05:30.7149487Z def forward(self, x):
2026-01-14T09:05:30.7150197Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:30.7151693Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:30.7152993Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:30.7154015Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006232379004359245, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:30.7155581Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:30.7156655Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:30.7156949Z     
2026-01-14T09:05:30.7157251Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:30.7157677Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:30.7157934Z           [0., 0., 0.],
2026-01-14T09:05:30.7158158Z           [0., 0., 0.]],
2026-01-14T09:05:30.7158309Z 
2026-01-14T09:05:30.7158387Z          [[0., 0., 0.],
2026-01-14T09:05:30.7158616Z           [0., 0., 0.],
2026-01-14T09:05:30.7158830Z           [0., 0., 0.]],
2026-01-14T09:05:30.7158985Z 
2026-01-14T09:05:30.7159062Z          [[0., 0., 0.],
2026-01-14T09:05:30.7159284Z           [0., 0., 0.],
2026-01-14T09:05:30.7159505Z           [0., 0., 0.]]]])
2026-01-14T09:05:30.7159756Z model pt2e: GraphModule(
2026-01-14T09:05:30.7159995Z   (conv): Module()
2026-01-14T09:05:30.7160336Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7161555Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:30.7163162Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:05:30.7163929Z   )
2026-01-14T09:05:30.7164223Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7165366Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:30.7166716Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:30.7167313Z   )
2026-01-14T09:05:30.7167612Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7168741Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:30.7170152Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:05:30.7170747Z   )
2026-01-14T09:05:30.7170927Z )
2026-01-14T09:05:30.7171027Z 
2026-01-14T09:05:30.7171031Z 
2026-01-14T09:05:30.7171035Z 
2026-01-14T09:05:30.7171129Z def forward(self, x):
2026-01-14T09:05:30.7171432Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:30.7171814Z     conv_weight = self.conv.weight
2026-01-14T09:05:30.7172414Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:30.7173094Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:30.7174045Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:30.7175274Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:05:30.7176050Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:30.7176489Z     
2026-01-14T09:05:30.7176795Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:30.7177203Z model fx: GraphModule(
2026-01-14T09:05:30.7177552Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7178700Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:30.7180047Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:30.7180638Z   )
2026-01-14T09:05:30.7180816Z   (conv): Conv2d(
2026-01-14T09:05:30.7181081Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:30.7181493Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:30.7182682Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:30.7184293Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:05:30.7185051Z     )
2026-01-14T09:05:30.7185239Z   )
2026-01-14T09:05:30.7185534Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3562293Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:32.3564034Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:05:32.3564656Z   )
2026-01-14T09:05:32.3564839Z )
2026-01-14T09:05:32.3564945Z 
2026-01-14T09:05:32.3564950Z 
2026-01-14T09:05:32.3564954Z 
2026-01-14T09:05:32.3565050Z def forward(self, x):
2026-01-14T09:05:32.3565434Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:32.3566047Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:32.3566679Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:32.3567175Z     return activation_post_process_1
2026-01-14T09:05:32.3567458Z     
2026-01-14T09:05:32.3567759Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:32.3568178Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:32.3568501Z           [0., 0., 0.],
2026-01-14T09:05:32.3568755Z           [0., 0., 0.]],
2026-01-14T09:05:32.3568908Z 
2026-01-14T09:05:32.3568996Z          [[0., 0., 0.],
2026-01-14T09:05:32.3569243Z           [0., 0., 0.],
2026-01-14T09:05:32.3569531Z           [0., 0., 0.]],
2026-01-14T09:05:32.3569694Z 
2026-01-14T09:05:32.3569777Z          [[0., 0., 0.],
2026-01-14T09:05:32.3570102Z           [0., 0., 0.],
2026-01-14T09:05:32.3570360Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:32.3570708Z converted model pt2e: GraphModule(
2026-01-14T09:05:32.3570992Z   (conv): Module()
2026-01-14T09:05:32.3571202Z )
2026-01-14T09:05:32.3571305Z 
2026-01-14T09:05:32.3571310Z 
2026-01-14T09:05:32.3571314Z 
2026-01-14T09:05:32.3571584Z def forward(self, x):
2026-01-14T09:05:32.3571901Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:32.3572265Z     _scale_0 = self._scale_0
2026-01-14T09:05:32.3572541Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:32.3572896Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:05:32.3574278Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:32.3576278Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:32.3577804Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:32.3579423Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:05:32.3580860Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007977825589478016, -4, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:05:32.3582445Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:32.3583673Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:32.3584156Z     
2026-01-14T09:05:32.3584466Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:32.3584887Z onverted model fx: GraphModule(
2026-01-14T09:05:32.3585351Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:32.3585833Z )
2026-01-14T09:05:32.3585937Z 
2026-01-14T09:05:32.3585941Z 
2026-01-14T09:05:32.3585945Z 
2026-01-14T09:05:32.3586040Z def forward(self, x):
2026-01-14T09:05:32.3586754Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:32.3588267Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:32.3589482Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:32.3590502Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007977825589478016, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:32.3592061Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:32.3593125Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:32.3593425Z     
2026-01-14T09:05:32.3593718Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:32.3594136Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:32.3594389Z           [0., 0., 0.],
2026-01-14T09:05:32.3594608Z           [0., 0., 0.]],
2026-01-14T09:05:32.3594763Z 
2026-01-14T09:05:32.3594845Z          [[0., 0., 0.],
2026-01-14T09:05:32.3595060Z           [0., 0., 0.],
2026-01-14T09:05:32.3595281Z           [0., 0., 0.]],
2026-01-14T09:05:32.3595429Z 
2026-01-14T09:05:32.3595505Z          [[0., 0., 0.],
2026-01-14T09:05:32.3595728Z           [0., 0., 0.],
2026-01-14T09:05:32.3595943Z           [0., 0., 0.]]]])
2026-01-14T09:05:32.3596192Z model pt2e: GraphModule(
2026-01-14T09:05:32.3596547Z   (conv): Module()
2026-01-14T09:05:32.3596875Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3598030Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:32.3599524Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:05:32.3600132Z   )
2026-01-14T09:05:32.3600421Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3601561Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:32.3602918Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:32.3603504Z   )
2026-01-14T09:05:32.3603802Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3604933Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:32.3606297Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:05:32.3606895Z   )
2026-01-14T09:05:32.3607063Z )
2026-01-14T09:05:32.3607174Z 
2026-01-14T09:05:32.3607177Z 
2026-01-14T09:05:32.3607182Z 
2026-01-14T09:05:32.3607269Z def forward(self, x):
2026-01-14T09:05:32.3607574Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:32.3607950Z     conv_weight = self.conv.weight
2026-01-14T09:05:32.3608468Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:32.3609142Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:32.3610179Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:32.3611166Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:05:32.3611819Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:32.3612257Z     
2026-01-14T09:05:32.3612560Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:32.3612969Z model fx: GraphModule(
2026-01-14T09:05:32.3613311Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3614465Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:32.3615822Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:32.3616414Z   )
2026-01-14T09:05:32.3616601Z   (conv): Conv2d(
2026-01-14T09:05:32.3616861Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:32.3617266Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3618385Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:32.3619776Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:05:32.3620382Z     )
2026-01-14T09:05:32.3620562Z   )
2026-01-14T09:05:32.3621032Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:32.3622172Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:32.3623532Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:05:32.3624203Z   )
2026-01-14T09:05:32.3624380Z )
2026-01-14T09:05:32.3624483Z 
2026-01-14T09:05:32.3624487Z 
2026-01-14T09:05:32.3624491Z 
2026-01-14T09:05:32.3624584Z def forward(self, x):
2026-01-14T09:05:32.3624966Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:32.3625576Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:32.3626207Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:32.3626702Z     return activation_post_process_1
2026-01-14T09:05:32.3626977Z     
2026-01-14T09:05:32.3627279Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:32.3627695Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:32.3627941Z           [0., 0., 0.],
2026-01-14T09:05:32.3628160Z           [0., 0., 0.]],
2026-01-14T09:05:32.3628309Z 
2026-01-14T09:05:32.3628387Z          [[0., 0., 0.],
2026-01-14T09:05:32.3628616Z           [0., 0., 0.],
2026-01-14T09:05:32.3628832Z           [0., 0., 0.]],
2026-01-14T09:05:32.3628984Z 
2026-01-14T09:05:32.3629061Z          [[0., 0., 0.],
2026-01-14T09:05:32.3629277Z           [0., 0., 0.],
2026-01-14T09:05:32.3629531Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:32.3629868Z converted model pt2e: GraphModule(
2026-01-14T09:05:32.3630150Z   (conv): Module()
2026-01-14T09:05:32.3630355Z )
2026-01-14T09:05:32.3630454Z 
2026-01-14T09:05:32.3630458Z 
2026-01-14T09:05:32.3630462Z 
2026-01-14T09:05:32.3630548Z def forward(self, x):
2026-01-14T09:05:32.3630856Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:32.3631268Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:06:43.9489324Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015127983642742038, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:43.9499526Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:43.9501096Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:43.9502737Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:43.9504165Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007949408143758774, -5, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:06:43.9505725Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:43.9506939Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:43.9507410Z     
2026-01-14T09:06:43.9507721Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:43.9508146Z onverted model fx: GraphModule(
2026-01-14T09:06:43.9508620Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:06:43.9509101Z )
2026-01-14T09:06:43.9509207Z 
2026-01-14T09:06:43.9509218Z 
2026-01-14T09:06:43.9509222Z 
2026-01-14T09:06:43.9509637Z def forward(self, x):
2026-01-14T09:06:43.9510357Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:06:43.9511850Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:43.9513275Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:06:43.9514280Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007949408143758774, -5, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:43.9515820Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:43.9516892Z     return dequantize_per_tensor_default_1
2026-01-14T09:06:43.9517186Z     
2026-01-14T09:06:43.9517494Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:43.9517906Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:43.9518166Z           [0., 0., 0.],
2026-01-14T09:06:43.9518386Z           [0., 0., 0.]],
2026-01-14T09:06:43.9518541Z 
2026-01-14T09:06:43.9518626Z          [[0., 0., 0.],
2026-01-14T09:06:43.9518838Z           [0., 0., 0.],
2026-01-14T09:06:43.9519063Z           [0., 0., 0.]],
2026-01-14T09:06:43.9519210Z 
2026-01-14T09:06:43.9519294Z          [[0., 0., 0.],
2026-01-14T09:06:43.9519507Z           [0., 0., 0.],
2026-01-14T09:06:43.9519732Z           [0., 0., 0.]]]])
2026-01-14T09:06:43.9520181Z [32mPASSED[0m
2026-01-14T09:06:43.9520891Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T09:06:43.9522050Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T09:06:43.9523141Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T09:06:43.9523836Z   (conv): Module()
2026-01-14T09:06:43.9524161Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9525333Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:43.9526776Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:06:43.9527432Z   )
2026-01-14T09:06:43.9527728Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9528853Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9530290Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:06:43.9530881Z   )
2026-01-14T09:06:43.9531176Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9532307Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9533645Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:06:43.9534249Z   )
2026-01-14T09:06:43.9534540Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9535776Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9537066Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:06:43.9537595Z   )
2026-01-14T09:06:43.9537774Z )
2026-01-14T09:06:43.9537960Z 
2026-01-14T09:06:43.9537964Z 
2026-01-14T09:06:43.9537968Z 
2026-01-14T09:06:43.9538057Z def forward(self, x):
2026-01-14T09:06:43.9538369Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:43.9538741Z     conv_weight = self.conv.weight
2026-01-14T09:06:43.9539261Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:43.9539805Z     conv_bias = self.conv.bias
2026-01-14T09:06:43.9540212Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:43.9541149Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:06:43.9542100Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:06:43.9543078Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:06:43.9543952Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:06:43.9544483Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:06:43.9545111Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:06:43.9545549Z     
2026-01-14T09:06:43.9545854Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:43.9546258Z model fx: GraphModule(
2026-01-14T09:06:43.9546616Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9547765Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9549107Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:06:43.9549712Z   )
2026-01-14T09:06:43.9549892Z   (conv): Conv2d(
2026-01-14T09:06:43.9550135Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:06:43.9550504Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9551634Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:06:43.9553076Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:06:43.9553732Z     )
2026-01-14T09:06:43.9553919Z   )
2026-01-14T09:06:43.9554209Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9555345Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9556703Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:06:43.9557298Z   )
2026-01-14T09:06:43.9557507Z   (relu): ReLU(inplace=True)
2026-01-14T09:06:43.9557869Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:43.9559102Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:43.9560399Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:06:43.9560928Z   )
2026-01-14T09:06:43.9561107Z )
2026-01-14T09:06:43.9561208Z 
2026-01-14T09:06:43.9561212Z 
2026-01-14T09:06:43.9561216Z 
2026-01-14T09:06:43.9561303Z def forward(self, x):
2026-01-14T09:06:43.9561761Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:43.9562241Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:06:43.9562735Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:06:43.9563596Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:06:43.9564249Z     relu = self.relu(add);  add = None
2026-01-14T09:06:43.9564707Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:06:43.9565196Z     return activation_post_process_2
2026-01-14T09:06:43.9565481Z     
2026-01-14T09:06:43.9565777Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:43.9566195Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:45.4688565Z           [0., 0., 0.],
2026-01-14T09:06:45.4689158Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:06:45.4690276Z converted model pt2e: GraphModule(
2026-01-14T09:06:45.4691018Z   (conv): Module()
2026-01-14T09:06:45.4691561Z )
2026-01-14T09:06:45.4691769Z 
2026-01-14T09:06:45.4691778Z 
2026-01-14T09:06:45.4691785Z 
2026-01-14T09:06:45.4691972Z def forward(self, x):
2026-01-14T09:06:45.4692577Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:45.4693319Z     _scale_0 = self._scale_0
2026-01-14T09:06:45.4693654Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:06:45.4694019Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:06:45.4695230Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:06:45.4696420Z     conv_bias = self.conv.bias
2026-01-14T09:06:45.4697159Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:06:45.4698485Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:06:45.4700069Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:45.4701779Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T09:06:45.4703291Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:06:45.4704850Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:45.4706450Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T09:06:45.4707384Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:06:45.4708472Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:06:45.4710037Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:45.4711246Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:06:45.4711834Z     
2026-01-14T09:06:45.4712136Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:45.4712561Z onverted model fx: GraphModule(
2026-01-14T09:06:45.4712984Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:06:45.4713433Z   (relu): ReLU(inplace=True)
2026-01-14T09:06:45.4713684Z )
2026-01-14T09:06:45.4713787Z 
2026-01-14T09:06:45.4713791Z 
2026-01-14T09:06:45.4713795Z 
2026-01-14T09:06:45.4713882Z def forward(self, x):
2026-01-14T09:06:45.4714600Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:06:45.4716082Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:06:45.4717138Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:06:45.4718011Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:06:45.4719546Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:06:45.4721003Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:06:45.4721759Z     relu = self.relu(add);  add = None
2026-01-14T09:06:45.4722566Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:06:45.4724121Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:06:45.4725191Z     return dequantize_per_tensor_default_2
2026-01-14T09:06:45.4725486Z     
2026-01-14T09:06:45.4725792Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:45.4726203Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:06:45.4726463Z           [0., 0., 0.],
2026-01-14T09:06:45.4726686Z           [0., 0., 0.]]]])
2026-01-14T09:06:45.4726944Z model pt2e: GraphModule(
2026-01-14T09:06:45.4727197Z   (conv): Module()
2026-01-14T09:06:45.4727524Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4728687Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:45.4730123Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:06:45.4730740Z   )
2026-01-14T09:06:45.4731035Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4732166Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:45.4733508Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:06:45.4734100Z   )
2026-01-14T09:06:45.4734495Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4735621Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:45.4736969Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:06:45.4737650Z   )
2026-01-14T09:06:45.4737942Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4739086Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:45.4740376Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:06:45.4740914Z   )
2026-01-14T09:06:45.4741095Z )
2026-01-14T09:06:45.4741195Z 
2026-01-14T09:06:45.4741200Z 
2026-01-14T09:06:45.4741204Z 
2026-01-14T09:06:45.4741295Z def forward(self, x):
2026-01-14T09:06:45.4741599Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:06:45.4741969Z     conv_weight = self.conv.weight
2026-01-14T09:06:45.4742481Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:06:45.4743026Z     conv_bias = self.conv.bias
2026-01-14T09:06:45.4743462Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:06:45.4744409Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:06:45.4745355Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:06:45.4746316Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:06:45.4747157Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:06:45.4747692Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:06:45.4748318Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:06:45.4748757Z     
2026-01-14T09:06:45.4749057Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:06:45.4749461Z model fx: GraphModule(
2026-01-14T09:06:45.4749804Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4750946Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:06:45.4752288Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:06:45.4752884Z   )
2026-01-14T09:06:45.4753064Z   (conv): Conv2d(
2026-01-14T09:06:45.4753301Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:06:45.4753666Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:06:45.4754798Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:06:45.4756186Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:06:45.4756786Z     )
2026-01-14T09:06:45.4756976Z   )
2026-01-14T09:06:45.4757277Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1078623Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:26.1080408Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:26.1081161Z   )
2026-01-14T09:07:26.1081454Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:26.1082117Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1083525Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:26.1085102Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:26.1085774Z   )
2026-01-14T09:07:26.1086027Z )
2026-01-14T09:07:26.1086156Z 
2026-01-14T09:07:26.1086161Z 
2026-01-14T09:07:26.1086166Z 
2026-01-14T09:07:26.1086306Z def forward(self, x):
2026-01-14T09:07:26.1086791Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:26.1087413Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:07:26.1088020Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:07:26.1089024Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:07:26.1089934Z     relu = self.relu(add);  add = None
2026-01-14T09:07:26.1090523Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:07:26.1091137Z     return activation_post_process_2
2026-01-14T09:07:26.1091477Z     
2026-01-14T09:07:26.1091879Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:26.1092393Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:26.1092722Z           [0., 0., 0.],
2026-01-14T09:07:26.1093057Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:07:26.1093478Z converted model pt2e: GraphModule(
2026-01-14T09:07:26.1093832Z   (conv): Module()
2026-01-14T09:07:26.1094098Z )
2026-01-14T09:07:26.1094223Z 
2026-01-14T09:07:26.1094228Z 
2026-01-14T09:07:26.1094233Z 
2026-01-14T09:07:26.1094363Z def forward(self, x):
2026-01-14T09:07:26.1094742Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:26.1095288Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:07:26.1096651Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002265168819576502, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:26.1097919Z     conv_bias = self.conv.bias
2026-01-14T09:07:26.1098818Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:07:26.1100459Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:07:26.1102402Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:26.1104469Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T09:07:26.1106365Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:07:26.1108449Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:26.1110134Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T09:07:26.1111100Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:26.1112027Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:07:26.1113766Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:07:26.1115016Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:07:26.1115510Z     
2026-01-14T09:07:26.1115831Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:26.1116269Z onverted model fx: GraphModule(
2026-01-14T09:07:26.1116696Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:07:26.1117167Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:26.1117421Z )
2026-01-14T09:07:26.1117538Z 
2026-01-14T09:07:26.1117541Z 
2026-01-14T09:07:26.1117546Z 
2026-01-14T09:07:26.1117646Z def forward(self, x):
2026-01-14T09:07:26.1118365Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:07:26.1119851Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:26.1120936Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:07:26.1121802Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:07:26.1123361Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:26.1124855Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:07:26.1125621Z     relu = self.relu(add);  add = None
2026-01-14T09:07:26.1126498Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:07:26.1128101Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:26.1129186Z     return dequantize_per_tensor_default_2
2026-01-14T09:07:26.1129500Z     
2026-01-14T09:07:26.1129870Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:26.1130300Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:26.1130552Z           [0., 0., 0.],
2026-01-14T09:07:26.1130794Z           [0., 0., 0.]]]])
2026-01-14T09:07:26.1131268Z [32mPASSED[0m
2026-01-14T09:07:26.1132069Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T09:07:26.1133317Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T09:07:26.1134472Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec [32mPASSED[0m
2026-01-14T09:07:26.1135638Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T09:07:26.1136408Z   (conv): Module()
2026-01-14T09:07:26.1136629Z   (bn): Module()
2026-01-14T09:07:26.1136973Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1138132Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:26.1139576Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:07:26.1140171Z   )
2026-01-14T09:07:26.1140478Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1141719Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:26.1143319Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:07:26.1144094Z   )
2026-01-14T09:07:26.1144398Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1145555Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:26.1146927Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:07:26.1147521Z   )
2026-01-14T09:07:26.1147842Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:26.1149002Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:26.1150373Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:07:26.1150977Z   )
2026-01-14T09:07:26.1151158Z )
2026-01-14T09:07:26.1151267Z 
2026-01-14T09:07:26.1151271Z 
2026-01-14T09:07:26.1151288Z 
2026-01-14T09:07:26.1151382Z def forward(self, x):
2026-01-14T09:07:26.1151696Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:26.1152095Z     conv_weight = self.conv.weight
2026-01-14T09:07:26.1152400Z     conv_bias = self.conv.bias
2026-01-14T09:07:26.1152681Z     bn_weight = self.bn.weight
2026-01-14T09:07:26.1152968Z     bn_bias = self.bn.bias
2026-01-14T09:07:26.1153246Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:07:26.1153585Z     bn_running_var = self.bn.running_var
2026-01-14T09:07:40.2595678Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:07:40.2596386Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:40.2597215Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:07:40.2597975Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:07:40.2598511Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:07:40.2599102Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:07:40.2599703Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:07:40.2600406Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:07:40.2601200Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:07:40.2602056Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:07:40.2603770Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:07:40.2605056Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:07:40.2605811Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:07:40.2606638Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:07:40.2607593Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:07:40.2608892Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:07:40.2610424Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:07:40.2611478Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:07:40.2612475Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:07:40.2613252Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:07:40.2613796Z     
2026-01-14T09:07:40.2614167Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:40.2614698Z model fx: GraphModule(
2026-01-14T09:07:40.2615139Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:40.2616504Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:40.2618138Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:07:40.2618856Z   )
2026-01-14T09:07:40.2619096Z   (conv): ConvBn2d(
2026-01-14T09:07:40.2619402Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:07:40.2619962Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:07:40.2620636Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:40.2622053Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:40.2623982Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:07:40.2624905Z     )
2026-01-14T09:07:40.2625133Z   )
2026-01-14T09:07:40.2625507Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:40.2626876Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:40.2628493Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:07:40.2629211Z   )
2026-01-14T09:07:40.2629513Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:07:40.2630058Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:40.2631421Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:40.2633032Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:07:40.2633745Z   )
2026-01-14T09:07:40.2634076Z )
2026-01-14T09:07:40.2634204Z 
2026-01-14T09:07:40.2634209Z 
2026-01-14T09:07:40.2634214Z 
2026-01-14T09:07:40.2634335Z def forward(self, x):
2026-01-14T09:07:40.2634805Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:40.2635548Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:07:40.2636497Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:07:40.2637302Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:07:40.2638152Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:07:40.2638784Z     return activation_post_process_2
2026-01-14T09:07:40.2639136Z     
2026-01-14T09:07:40.2639505Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:40.2640015Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:40.2640360Z           [0., 0., 0.],
2026-01-14T09:07:40.2640631Z           [0., 0., 0.]],
2026-01-14T09:07:40.2640821Z 
2026-01-14T09:07:40.2640938Z          [[0., 0., 0.],
2026-01-14T09:07:40.2641221Z           [0., 0., 0.],
2026-01-14T09:07:40.2641486Z           [0., 0., 0.]],
2026-01-14T09:07:40.2641678Z 
2026-01-14T09:07:40.2641783Z          [[0., 0., 0.],
2026-01-14T09:07:40.2642039Z           [0., 0., 0.],
2026-01-14T09:07:40.2642374Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:07:40.2642792Z converted model pt2e: GraphModule(
2026-01-14T09:07:40.2643161Z   (conv): Module()
2026-01-14T09:07:40.2643426Z   (bn): Module()
2026-01-14T09:07:40.2643694Z )
2026-01-14T09:07:40.2643833Z 
2026-01-14T09:07:40.2643838Z 
2026-01-14T09:07:40.2643843Z 
2026-01-14T09:07:40.2643952Z def forward(self, x):
2026-01-14T09:07:40.2644316Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:40.2644766Z     conv_bias = self.conv.bias
2026-01-14T09:07:40.2653379Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:07:40.2654947Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:40.2655969Z     _scale_0 = self._scale_0
2026-01-14T09:07:40.2656264Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:07:40.2656604Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:07:40.2657668Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:07:40.2659324Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:07:40.2660781Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014923675917088985, -46, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:07:40.2662361Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:40.2663790Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T09:07:40.2665013Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:07:40.2666718Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:40.2667937Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:07:40.2668404Z     
2026-01-14T09:07:40.2668713Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:40.2669134Z onverted model fx: GraphModule(
2026-01-14T09:07:40.2669558Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:07:40.2670131Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:07:40.2670450Z )
2026-01-14T09:07:40.2670553Z 
2026-01-14T09:07:40.2670558Z 
2026-01-14T09:07:40.2670561Z 
2026-01-14T09:07:40.2670659Z def forward(self, x):
2026-01-14T09:07:40.2671373Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:07:40.2672875Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:40.2674087Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:07:40.2675360Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014923675917088985, -46, -128, 127, torch.int8);  conv = None
2026-01-14T09:07:40.2676914Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:40.2678198Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:01.0893610Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:01.0896490Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:01.0897836Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:01.0898206Z     
2026-01-14T09:08:01.0898581Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:01.0899109Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:01.0899413Z           [0., 0., 0.],
2026-01-14T09:08:01.0899692Z           [0., 0., 0.]],
2026-01-14T09:08:01.0899875Z 
2026-01-14T09:08:01.0899975Z          [[0., 0., 0.],
2026-01-14T09:08:01.0900251Z           [0., 0., 0.],
2026-01-14T09:08:01.0900518Z           [0., 0., 0.]],
2026-01-14T09:08:01.0900707Z 
2026-01-14T09:08:01.0900805Z          [[0., 0., 0.],
2026-01-14T09:08:01.0901070Z           [0., 0., 0.],
2026-01-14T09:08:01.0901343Z           [0., 0., 0.]]]])
2026-01-14T09:08:01.0901646Z model pt2e: GraphModule(
2026-01-14T09:08:01.0901950Z   (conv): Module()
2026-01-14T09:08:01.0902212Z   (bn): Module()
2026-01-14T09:08:01.0902594Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0903959Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0905567Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:01.0906274Z   )
2026-01-14T09:08:01.0906627Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0907983Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:01.0909902Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:01.0910625Z   )
2026-01-14T09:08:01.0910979Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0912317Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0914107Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:01.0914812Z   )
2026-01-14T09:08:01.0915156Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0916509Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0918098Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:01.0918794Z   )
2026-01-14T09:08:01.0919018Z )
2026-01-14T09:08:01.0919139Z 
2026-01-14T09:08:01.0919144Z 
2026-01-14T09:08:01.0919150Z 
2026-01-14T09:08:01.0919258Z def forward(self, x):
2026-01-14T09:08:01.0919631Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:01.0920085Z     conv_weight = self.conv.weight
2026-01-14T09:08:01.0920436Z     conv_bias = self.conv.bias
2026-01-14T09:08:01.0920757Z     bn_weight = self.bn.weight
2026-01-14T09:08:01.0921079Z     bn_bias = self.bn.bias
2026-01-14T09:08:01.0921414Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:08:01.0921801Z     bn_running_var = self.bn.running_var
2026-01-14T09:08:01.0922235Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:08:01.0922824Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:01.0923657Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:08:01.0924386Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:08:01.0924909Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:08:01.0925457Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:08:01.0926055Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:08:01.0926740Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:08:01.0927504Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:08:01.0928358Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:08:01.0929852Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:08:01.0931111Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:08:01.0931856Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:08:01.0932653Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:08:01.0933434Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:08:01.0934715Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:08:01.0936084Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:08:01.0937129Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:08:01.0938216Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:08:01.0939005Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:01.0939535Z     
2026-01-14T09:08:01.0939895Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:01.0940388Z model fx: GraphModule(
2026-01-14T09:08:01.0942728Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0944083Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0945670Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:01.0946411Z   )
2026-01-14T09:08:01.0946655Z   (conv): ConvBn2d(
2026-01-14T09:08:01.0946964Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:08:01.0947544Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:08:01.0948080Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0949205Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:01.0950579Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:01.0951188Z     )
2026-01-14T09:08:01.0951379Z   )
2026-01-14T09:08:01.0951666Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0952808Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0954140Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:01.0954729Z   )
2026-01-14T09:08:01.0954961Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:01.0955385Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:01.0956532Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:01.0957858Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:01.0958443Z   )
2026-01-14T09:08:01.0958613Z )
2026-01-14T09:08:01.0958721Z 
2026-01-14T09:08:01.0958726Z 
2026-01-14T09:08:01.0958730Z 
2026-01-14T09:08:01.0958819Z def forward(self, x):
2026-01-14T09:08:01.0959208Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:01.0959805Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:08:01.0960426Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:01.0961083Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:08:01.0961791Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:08:01.0962310Z     return activation_post_process_2
2026-01-14T09:08:01.0962589Z     
2026-01-14T09:08:01.0962893Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:01.0963301Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:01.0963560Z           [0., 0., 0.],
2026-01-14T09:08:01.0963782Z           [0., 0., 0.]],
2026-01-14T09:08:01.0963939Z 
2026-01-14T09:08:01.0964018Z          [[0., 0., 0.],
2026-01-14T09:08:01.0964331Z           [0., 0., 0.],
2026-01-14T09:08:01.0964558Z           [0., 0., 0.]],
2026-01-14T09:08:01.0964705Z 
2026-01-14T09:08:01.0964791Z          [[0., 0., 0.],
2026-01-14T09:08:01.0965003Z           [0., 0., 0.],
2026-01-14T09:08:01.0965261Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:01.0965627Z converted model pt2e: GraphModule(
2026-01-14T09:08:01.0966082Z   (conv): Module()
2026-01-14T09:08:01.0966340Z   (bn): Module()
2026-01-14T09:08:01.0966590Z )
2026-01-14T09:08:01.0966715Z 
2026-01-14T09:08:01.0966720Z 
2026-01-14T09:08:01.0966725Z 
2026-01-14T09:08:01.0966833Z def forward(self, x):
2026-01-14T09:08:01.0967211Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:01.0967676Z     conv_bias = self.conv.bias
2026-01-14T09:08:01.0968540Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:01.0970097Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:01.0971143Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:08:27.3705960Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014815704198554158, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:08:27.3707544Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:08:27.3709022Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014958353713154793, -45, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:08:27.3710634Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:27.3712056Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:08:27.3713301Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:27.3714964Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:08:27.3716195Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:08:27.3716672Z     
2026-01-14T09:08:27.3716990Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:27.3717420Z onverted model fx: GraphModule(
2026-01-14T09:08:27.3717855Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:08:27.3718367Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:27.3718689Z )
2026-01-14T09:08:27.3718797Z 
2026-01-14T09:08:27.3718801Z 
2026-01-14T09:08:27.3718805Z 
2026-01-14T09:08:27.3718901Z def forward(self, x):
2026-01-14T09:08:27.3719622Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:27.3721116Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:27.3722330Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:08:27.3723689Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014958353713154793, -45, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:27.3725303Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:27.3726596Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:27.3727905Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:27.3729493Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:27.3730649Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:27.3730959Z     
2026-01-14T09:08:27.3731269Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:27.3731684Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:27.3731944Z           [0., 0., 0.],
2026-01-14T09:08:27.3732175Z           [0., 0., 0.]],
2026-01-14T09:08:27.3732328Z 
2026-01-14T09:08:27.3732418Z          [[0., 0., 0.],
2026-01-14T09:08:27.3732635Z           [0., 0., 0.],
2026-01-14T09:08:27.3732865Z           [0., 0., 0.]],
2026-01-14T09:08:27.3733019Z 
2026-01-14T09:08:27.3733118Z          [[0., 0., 0.],
2026-01-14T09:08:27.3733338Z           [0., 0., 0.],
2026-01-14T09:08:27.3733566Z           [0., 0., 0.]]]])
2026-01-14T09:08:27.3734025Z [32mPASSED[0m
2026-01-14T09:08:27.3734704Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_mobilenet_v2 [33mSKIPPED[0m
2026-01-14T09:08:27.3735774Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_resnet18 [33mSKIPPED[0m
2026-01-14T09:08:27.3736818Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizeMixQATAndPTQ::test_mixing_qat_ptq [33mSKIPPED[0m
2026-01-14T09:08:27.3737792Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add [32mPASSED[0m
2026-01-14T09:08:27.3738717Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add_relu [32mPASSED[0m
2026-01-14T09:08:27.3739649Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_conv2d [32mPASSED[0m
2026-01-14T09:08:27.3740623Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_dynamic_linear [32mPASSED[0m
2026-01-14T09:08:27.3741601Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_maxpool2d [32mPASSED[0m
2026-01-14T09:08:27.3742525Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq [32mPASSED[0m
2026-01-14T09:08:27.3743474Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq_per_channel [32mPASSED[0m
2026-01-14T09:08:27.3744482Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_static_linear [32mPASSED[0m
2026-01-14T09:08:27.3746029Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3748049Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3750056Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3752166Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3754167Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3756178Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3758267Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3760266Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3762258Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3764247Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3766242Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3768224Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3770286Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3772287Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3774280Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3776475Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3955479Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3957505Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3959493Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3961645Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3963654Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3965708Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3967868Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3969928Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3971908Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3973888Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3976256Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3978226Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3980212Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3982195Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3984180Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3986160Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3988154Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3990145Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3992129Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3994115Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.3996238Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.3998238Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4000351Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4002345Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4004325Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4006304Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4008283Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4010303Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4012293Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4014327Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4016312Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4018290Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4020272Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4022248Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4024226Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4026197Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4202824Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4206010Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4210780Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4214263Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4216243Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4218224Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4220206Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4222177Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4224216Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4226205Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4228186Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4230156Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4232148Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4234205Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4236194Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4238192Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4240284Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4242284Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4244293Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4246385Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4248378Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4250424Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4252414Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4254397Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4256401Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4258421Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4260423Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4262412Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4264449Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4266441Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4268411Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4270401Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4272381Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4274503Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4276659Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4278774Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4458633Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4460662Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4462630Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4464614Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4466592Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4468577Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4470563Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4472541Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4474580Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4476786Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4478782Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4480767Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4482769Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4484903Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4486900Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4488883Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4491094Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4493070Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4495034Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4496989Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4498957Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4500936Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4502901Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4504905Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4506881Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4508853Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4510805Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4512762Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4514789Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4516880Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4518849Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4520817Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4522852Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4524814Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4526779Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4528719Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4530741Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4895772Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4897764Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [33mSKIPPED[0m
2026-01-14T09:08:27.4899714Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [33mSKIPPED[0m
2026-01-14T09:08:27.4901195Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4902322Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4903454Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_qat_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4904677Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:08:27.4905994Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:08:27.4907296Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:08:27.4908617Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:08:27.4909757Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4910850Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4912275Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4913567Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4914907Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4916126Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4917354Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4918490Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4919732Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:08:27.4920952Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4922131Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4923476Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:08:27.4924767Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mul_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4925808Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4926941Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4928118Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4929332Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4930580Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_dynamic_fp16 [33mSKIPPED[0m
2026-01-14T09:08:27.4931644Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_relu_dynamic_fp16 [33mSKIPPED[0m
2026-01-14T09:08:27.4932677Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d [33mSKIPPED[0m
2026-01-14T09:08:27.4933669Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add [33mSKIPPED[0m
2026-01-14T09:08:27.4934745Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add_relu [33mSKIPPED[0m
2026-01-14T09:08:27.4935821Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardswish [33mSKIPPED[0m
2026-01-14T09:08:27.4936880Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardtanh [33mSKIPPED[0m
2026-01-14T09:08:27.4937914Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu [33mSKIPPED[0m
2026-01-14T09:08:27.4938943Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu6 [33mSKIPPED[0m
2026-01-14T09:08:27.4939961Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_silu [33mSKIPPED[0m
2026-01-14T09:08:27.4940925Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qcat [33mSKIPPED[0m
2026-01-14T09:08:27.4941916Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv1d_relu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4942910Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_2 [33mSKIPPED[0m
2026-01-14T09:08:27.4944012Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3 [33mSKIPPED[0m
2026-01-14T09:08:27.4945090Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_broadcast_shapes_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4946184Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4947313Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4948390Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4949512Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4950589Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4951682Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4960796Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4961970Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4963032Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4964091Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4965148Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4966184Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4967253Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4968321Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4969477Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4970739Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4971851Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4972926Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4974054Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4975494Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4976625Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.4977660Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.4978709Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5264917Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5265994Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5267121Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_int8_mixed_bf16_xpu [33mSKIPPED[0m
2026-01-14T09:08:27.5268412Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5269457Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5270566Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5271854Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5272966Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_with_concat_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5274024Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qflatten [33mSKIPPED[0m
2026-01-14T09:08:27.5275456Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5276859Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5278259Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5279630Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5281023Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5282404Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5283783Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5285193Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5286627Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5288120Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5289611Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5291153Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5292643Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5294178Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5295646Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5297120Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5298322Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5299502Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5300756Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5302020Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_dynamic_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5303213Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.5304672Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5305852Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5306902Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.5308005Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5309204Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:08:27.5310354Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.5311480Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5312790Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:08:27.5313970Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mul_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5314969Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_cpu [33mSKIPPED[0m
2026-01-14T09:08:27.5316054Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5317158Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:08:27.5318326Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:08:27.5319439Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qmaxpool2d [33mSKIPPED[0m
2026-01-14T09:08:27.5320746Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5322371Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5323988Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5325590Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5327207Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5328815Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5330540Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5332141Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5333744Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5335470Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T09:08:27.5337068Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T09:08:27.5338670Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T09:13:22.5481417Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_False [33mSKIPPED[0m
2026-01-14T09:13:22.5483580Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_True [33mSKIPPED[0m
2026-01-14T09:13:22.5486918Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_False [33mSKIPPED[0m
2026-01-14T09:13:22.5488871Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_True [33mSKIPPED[0m
2026-01-14T09:13:22.5490587Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_q_attention_block [33mSKIPPED[0m
2026-01-14T09:13:22.5491988Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:13:22.5493384Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:13:22.5494892Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag_with_output_quant [33mSKIPPED[0m
2026-01-14T09:13:22.5496351Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block [33mSKIPPED[0m
2026-01-14T09:13:22.5497636Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qat_bn_conv2d [33mSKIPPED[0m
2026-01-14T09:13:22.5499035Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu [33mSKIPPED[0m
2026-01-14T09:13:22.5500539Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_adaptive_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:13:22.5501970Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_annotate_mul_tensor [32mPASSED[0m
2026-01-14T09:13:22.5503364Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_attention_block [32mPASSED[0m
2026-01-14T09:13:22.5504747Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:13:22.5506094Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe [32mPASSED[0m
2026-01-14T09:13:22.5507227Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_same_inputs [32mPASSED[0m
2026-01-14T09:13:22.5508428Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_single_input [32mPASSED[0m
2026-01-14T09:13:22.5509903Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d [32mPASSED[0m
2026-01-14T09:13:22.5510990Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary [32mPASSED[0m
2026-01-14T09:13:22.5512122Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:13:22.5513475Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:13:22.5514677Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_serials_binary_unary [32mPASSED[0m
2026-01-14T09:13:22.5515837Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_unary [32mPASSED[0m
2026-01-14T09:13:22.5516958Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:13:22.5518131Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe [32mPASSED[0m
2026-01-14T09:13:22.5519292Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_linear_recipe [32mPASSED[0m
2026-01-14T09:13:22.5520480Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:13:22.5521639Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe [32mPASSED[0m
2026-01-14T09:13:22.5522748Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2 [32mPASSED[0m
2026-01-14T09:13:22.5523823Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear [32mPASSED[0m
2026-01-14T09:13:22.5524880Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary [32mPASSED[0m
2026-01-14T09:13:22.5525998Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary2 [32mPASSED[0m
2026-01-14T09:13:22.5527142Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic [32mPASSED[0m
2026-01-14T09:13:22.5528332Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic_qat [32mPASSED[0m
2026-01-14T09:13:22.5529513Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_qat [32mPASSED[0m
2026-01-14T09:13:22.5530720Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary [32mPASSED[0m
2026-01-14T09:13:22.5531916Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic [32mPASSED[0m
2026-01-14T09:13:22.5533177Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:13:22.5534402Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_qat [32mPASSED[0m
2026-01-14T09:13:22.5535619Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_serials [32mPASSED[0m
2026-01-14T09:13:22.5536817Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_dynamic_fp16 [32mPASSED[0m
2026-01-14T09:13:22.5537933Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary [32mPASSED[0m
2026-01-14T09:13:22.5539060Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic [32mPASSED[0m
2026-01-14T09:13:22.5540239Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:13:22.5541494Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_qat [32mPASSED[0m
2026-01-14T09:13:22.5542631Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_lowering_to_x86 [33mSKIPPED[0m
2026-01-14T09:13:22.5543752Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:13:22.5544934Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d [32mPASSED[0m
2026-01-14T09:13:22.5546030Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary [32mPASSED[0m
2026-01-14T09:13:22.5547178Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:13:22.5548351Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:13:22.5549511Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_unary [32mPASSED[0m
2026-01-14T09:13:22.5550678Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:13:22.5551951Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case1 [32mPASSED[0m
2026-01-14T09:13:22.5553273Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case2 [32mPASSED[0m
2026-01-14T09:13:22.5554657Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs [32mPASSED[0m
2026-01-14T09:13:22.5555967Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig [32mPASSED[0m
2026-01-14T09:13:22.5557263Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_for_dynamic_quant [32mPASSED[0m
2026-01-14T09:13:22.5558622Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_with_underscores [32mPASSED[0m
2026-01-14T09:13:22.5559935Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_with_mixed_configs [32mPASSED[0m
2026-01-14T09:13:22.5561101Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:13:22.5562281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm_weight_in_bkn_layout [33mSKIPPED[0m
2026-01-14T09:13:22.5796907Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5798168Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5799570Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.5800820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5802250Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5803479Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.5804657Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-1 [33mSKIPPED[0m
2026-01-14T09:13:22.5805982Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-2 [33mSKIPPED[0m
2026-01-14T09:13:22.5807252Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_create_tensor_out_of_inference_mode [33mSKIPPED[0m
2026-01-14T09:13:22.5808619Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_expected_gpu_kernel_fbgemm [33mSKIPPED[0m
2026-01-14T09:13:22.5810165Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5811903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5813641Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5815264Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5816909Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5818484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5820142Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5821715Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5823242Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5824564Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5825883Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.5827303Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes3 [33mSKIPPED[0m
2026-01-14T09:13:22.5828620Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.5830006Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.5831314Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.5832616Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes3 [33mSKIPPED[0m
2026-01-14T09:13:22.5834491Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5836822Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5839098Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5841362Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5843622Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5845940Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5848210Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5850458Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5852718Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5854881Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5857130Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5859367Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5861518Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5863761Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5866016Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5868157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.5870405Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.5872627Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6045091Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6047426Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6049964Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6052122Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6054369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6056621Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6058779Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6060997Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6063234Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6065367Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6067594Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6069792Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6071930Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6074114Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6076574Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6078790Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6081160Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6083387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6085868Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6088314Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6090681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6092826Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6095069Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6097291Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6099412Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6101593Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6103733Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6105849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6107961Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6110076Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6112335Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6114878Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6117127Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6119343Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6121586Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6289322Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6291545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6293721Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6295834Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6297946Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6300052Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6302157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6304260Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6306373Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6308468Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:13:22.6310575Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:13:22.6312717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6315047Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6317232Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6319515Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6321698Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6323959Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6326159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6328368Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6330617Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6332818Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6335011Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6337199Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6339387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6341562Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6343737Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6345919Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6349880Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6352117Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6354314Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6356605Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6358806Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6360982Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6363172Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6523562Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6525781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6527947Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6530186Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6532418Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6534597Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6536798Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6538999Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6541183Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6543538Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6545736Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6548034Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6550214Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6552456Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6554619Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6556782Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6558944Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6561124Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6563304Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6565493Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6567682Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6569900Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6572073Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6574257Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6576731Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6578904Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6581090Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6583424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6585602Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6587782Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6589984Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6600521Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6602800Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6604993Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6757883Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6760091Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6762266Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6764433Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6766609Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6768769Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6771159Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6773355Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6775819Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6778009Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6780219Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6782410Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6784601Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6786787Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6788974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6791192Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6793423Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6795659Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6797883Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6800111Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6802356Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6804733Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6806975Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6809215Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6811627Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6813865Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6816099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6818346Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6820565Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6822794Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6825019Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6827265Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6829503Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6831763Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6989462Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6991732Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6994006Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.6996393Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.6998644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7000975Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7003258Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7005483Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7007696Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7010002Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7012256Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7014502Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7016738Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7018976Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7021217Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7023444Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7025681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7027903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7030195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7032468Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7034793Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7037018Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7039254Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7041494Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7043741Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7045971Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7048191Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7050483Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7052710Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7054930Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7057148Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7059363Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7061586Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7063964Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7225215Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7227471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7229853Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7232090Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7234310Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7236529Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7238759Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7240990Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7243195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7245414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7247629Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7249906Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7252137Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7254387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7256747Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7258974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7261195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7263503Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7265731Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7267926Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7270106Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7272277Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7274455Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7276810Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7279005Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7281207Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7283411Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7285612Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7287796Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7290029Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7292334Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7294507Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7296786Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7298958Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7459616Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7462169Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7464709Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7467240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7469746Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7472280Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7474950Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7477160Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7479350Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7481540Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7483793Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7486136Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7488313Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7490560Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7492874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7495087Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7497293Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7499473Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7501671Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7503930Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7506124Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7508288Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7510455Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7512627Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7514780Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7516953Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7519156Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7521424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7523612Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7525878Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7528051Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7530291Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7532527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7534706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7692204Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7694414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7696569Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7698747Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7700921Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7703112Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7705292Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7707461Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7709628Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7711945Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7714117Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7716393Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7718555Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7720717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7722929Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7725102Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7727283Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7729456Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7731689Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7733885Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7736063Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7738230Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7740397Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7742602Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7744907Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7747127Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7749338Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7751644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7753911Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7756160Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7758418Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7760651Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7762943Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7765185Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7920324Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7922580Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7924816Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7927042Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7929282Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7931578Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7933984Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7936247Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7938607Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7940840Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7943127Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7945368Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7947592Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7949830Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7952064Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7954282Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7956522Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7958758Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7961004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7963253Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7965492Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7967816Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7970099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7972409Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7974636Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7977067Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7979274Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7981489Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7983740Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7985955Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7988179Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7990410Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.7992634Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.7994850Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8155787Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8158025Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8160373Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8162634Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8164834Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8167145Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8169359Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8171626Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8173900Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8176262Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8178496Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8180717Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8182938Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8185157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8187374Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8189574Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8191782Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8194032Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8196354Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8198577Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8200946Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8203177Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8205397Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8207625Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8209905Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8212124Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:13:22.8214347Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:13:22.8216516Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8218635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8220776Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8222968Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8225099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8227240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8229450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8392871Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8395321Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8397608Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8399751Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8401881Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8403998Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8406102Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8408224Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8410403Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8412587Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8414701Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8416817Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8418923Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8421049Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8423169Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8425407Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8427527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8429742Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8431911Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8434096Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8436288Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8438469Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8440653Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8442832Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8444988Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8447171Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8449356Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8451606Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8453789Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8455957Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8458106Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8460365Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8462545Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8464800Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8466971Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8632463Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8634638Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8636817Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8638992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8641163Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8643386Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8645525Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8647646Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8649763Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8651953Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8654138Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8656398Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8658511Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8660623Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8662931Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8665064Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8667180Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8669292Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8671400Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8673496Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8675776Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8677895Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8680016Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8682136Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8684282Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8686378Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8688490Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8690781Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8692893Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8695002Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8697246Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8699414Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8701574Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8703809Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8705986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8921619Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8923814Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8925973Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8928139Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8930379Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8932551Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8934730Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8936891Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8939196Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8941373Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8943648Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8945813Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8947991Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8950147Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8952298Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8954459Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8956635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8958797Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8960966Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8962669Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_has_compatible_shallow_copy_type [33mSKIPPED[0m
2026-01-14T09:13:22.8963868Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_index_select [33mSKIPPED[0m
2026-01-14T09:13:22.8965227Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8966802Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8968363Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.8969963Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.8971331Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:13:22.8972644Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_per_row_config_before_dim [33mSKIPPED[0m
2026-01-14T09:13:22.8973844Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.8975150Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.8976508Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T09:13:22.8978042Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8979759Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8981484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8983203Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8984924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8986652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8988368Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8990091Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8991808Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8993524Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8995249Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:13:22.8996975Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:13:22.8998615Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity0 [33mSKIPPED[0m
2026-01-14T09:13:22.9312498Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity1 [33mSKIPPED[0m
2026-01-14T09:13:22.9313945Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity0 [33mSKIPPED[0m
2026-01-14T09:13:22.9315405Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity1 [33mSKIPPED[0m
2026-01-14T09:13:22.9316719Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity0 [33mSKIPPED[0m
2026-01-14T09:13:22.9318081Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity1 [33mSKIPPED[0m
2026-01-14T09:13:22.9319763Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9321069Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9322340Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.9323813Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9326690Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9327977Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.9329187Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_dtype_layout [33mSKIPPED[0m
2026-01-14T09:13:22.9330613Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_transpose [33mSKIPPED[0m
2026-01-14T09:13:22.9331777Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_conv2d_weight [33mSKIPPED[0m
2026-01-14T09:13:22.9341192Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9342681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9344284Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9345839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9347339Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:13:22.9348903Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:13:22.9350702Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:13:22.9352433Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:13:22.9353979Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9355316Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9356923Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_from_int4_tensor [33mSKIPPED[0m
2026-01-14T09:13:22.9358284Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9359796Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9361145Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9362519Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9364193Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9365672Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9367028Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_activation_prescaling [33mSKIPPED[0m
2026-01-14T09:13:22.9368206Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:13:22.9369220Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9370548Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9371586Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.9372661Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_linear [33mSKIPPED[0m
2026-01-14T09:13:22.9373912Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:13:22.9375180Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice [33mSKIPPED[0m
2026-01-14T09:13:22.9376296Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_and_copy_similar_to_vllm [33mSKIPPED[0m
2026-01-14T09:13:22.9377494Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_preserves_aliasing [33mSKIPPED[0m
2026-01-14T09:13:22.9378634Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes0 [33mSKIPPED[0m
2026-01-14T09:13:22.9379714Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes1 [33mSKIPPED[0m
2026-01-14T09:13:22.9380802Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes2 [33mSKIPPED[0m
2026-01-14T09:13:22.9382133Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9383670Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9385183Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_cant_initialize_in_cpu [33mSKIPPED[0m
2026-01-14T09:13:22.9386731Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_128 [33mSKIPPED[0m
2026-01-14T09:13:22.9388329Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_32 [33mSKIPPED[0m
2026-01-14T09:13:22.9389921Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_64 [33mSKIPPED[0m
2026-01-14T09:13:22.9391417Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_error_conditions [33mSKIPPED[0m
2026-01-14T09:13:22.9392855Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9394311Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9395762Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9397376Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config1 [33mSKIPPED[0m
2026-01-14T09:13:22.9398851Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config0 [33mSKIPPED[0m
2026-01-14T09:13:22.9400315Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config1 [33mSKIPPED[0m
2026-01-14T09:14:33.8327878Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_mm_int4wo_device_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T09:14:33.8329421Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:14:33.8330951Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:14:33.8332478Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config0 [33mSKIPPED[0m
2026-01-14T09:14:33.8334129Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config1 [33mSKIPPED[0m
2026-01-14T09:14:33.8335629Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config0 [33mSKIPPED[0m
2026-01-14T09:14:33.8336998Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config1 [33mSKIPPED[0m
2026-01-14T09:14:33.8338454Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config0 [33mSKIPPED[0m
2026-01-14T09:14:33.8340012Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config1 [33mSKIPPED[0m
2026-01-14T09:14:33.8341443Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_to_device [33mSKIPPED[0m
2026-01-14T09:14:33.8342661Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_available_gpu_kernels [32mPASSED[0m
2026-01-14T09:14:33.8343846Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config0 [32mPASSED[0m
2026-01-14T09:14:33.8345063Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config1 [32mPASSED[0m
2026-01-14T09:14:33.8346269Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config2 [32mPASSED[0m
2026-01-14T09:14:33.8347484Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config3 [32mPASSED[0m
2026-01-14T09:14:33.8348693Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config0 [32mPASSED[0m
2026-01-14T09:14:33.8349908Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config1 [32mPASSED[0m
2026-01-14T09:14:33.8351129Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config2 [32mPASSED[0m
2026-01-14T09:14:33.8352336Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config3 [32mPASSED[0m
2026-01-14T09:14:33.8353503Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config0 [32mPASSED[0m
2026-01-14T09:14:33.8355063Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config1 [32mPASSED[0m
2026-01-14T09:14:33.8356189Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config2 [32mPASSED[0m
2026-01-14T09:14:33.8357300Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config3 [32mPASSED[0m
2026-01-14T09:14:33.8358586Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8361065Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8362521Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8363986Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8365483Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8366947Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8368402Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8369904Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8371351Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8372803Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8374246Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8375866Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8377311Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8378757Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8380198Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8381640Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8383084Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8384526Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8385970Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8387543Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8388985Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8390426Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8391974Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8393418Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8394861Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8396299Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8397724Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8399154Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:14:33.8400589Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:14:33.8402013Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:14:41.7330999Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:14:41.7332509Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:14:41.7333773Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config0 [32mPASSED[0m
2026-01-14T09:14:41.7334892Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config1 [32mPASSED[0m
2026-01-14T09:14:41.7335979Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config2 [32mPASSED[0m
2026-01-14T09:14:41.7337059Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config3 [32mPASSED[0m
2026-01-14T09:14:41.7338202Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7339372Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_float16 [32mPASSED[0m
2026-01-14T09:14:41.7340579Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7341800Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:14:41.7342996Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7344165Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_float16 [32mPASSED[0m
2026-01-14T09:14:41.7345358Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7346997Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:14:41.7348203Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7349374Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_float16 [32mPASSED[0m
2026-01-14T09:14:41.7350737Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7351961Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:14:41.7353151Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7354323Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_float16 [32mPASSED[0m
2026-01-14T09:14:41.7355529Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7356801Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:14:41.7358191Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7359725Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity1_bfloat16 [32mPASSED[0m
2026-01-14T09:14:41.7362197Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7365531Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7368881Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7372235Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7375935Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7379255Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7382677Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7385963Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7389430Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7392845Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7396192Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7399489Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7402760Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7518633Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7521993Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7525417Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7528902Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7532270Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7535660Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7538991Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7542338Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7545757Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7549151Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7552448Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7555723Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7559004Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7562441Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7565858Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7569321Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7572667Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7576173Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7579471Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7582811Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7586232Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7589572Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7690855Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7694168Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7697610Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7700978Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7704510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7707857Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7711159Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7714444Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7717721Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7721083Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7724504Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7727942Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7731458Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7734890Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7738491Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7741902Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7745250Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7748630Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7751951Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7755272Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7758611Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7761925Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7853177Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7856646Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7860221Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7863612Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7866941Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7870269Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7873575Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7877170Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7880635Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7884019Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7887353Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7892252Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7895715Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7899116Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7902579Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7905975Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7909303Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7912616Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7915942Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7919373Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.7922835Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.7926310Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8014798Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8018355Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8021685Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8025079Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8028535Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8031914Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8035258Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8038572Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8041891Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8045390Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8048860Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8052421Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8055749Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8059064Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8062379Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8065763Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8069216Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8072541Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8075932Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8079275Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8082496Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8085807Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8170902Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8174131Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8177491Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8180773Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8184126Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8187413Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8190640Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8193847Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8197221Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8200510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8203966Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8207241Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8210554Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8213779Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8217049Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8220333Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8223685Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8226967Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8230288Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8233510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8236801Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8240079Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8338720Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8342010Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8345255Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8348465Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8351677Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8354953Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8358358Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8361779Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8365007Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8368366Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8371669Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8375097Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8378512Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8381777Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8385008Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8388220Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8391426Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8394703Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8398168Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8401711Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8404982Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8408238Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8501564Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8504848Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8508123Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8511393Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8514651Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8517989Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8521557Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8524895Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8528345Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8531699Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8534956Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8538339Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8541736Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8545067Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8548342Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8551607Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8554954Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8558285Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8561770Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8565098Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8568361Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8571699Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8662861Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8666239Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8669670Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8672997Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8676402Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
﻿2026-01-14T09:14:41.8684198Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8687491Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8690989Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8694926Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8698810Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8702577Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8714719Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8718375Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8721759Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8725188Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8728695Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8732150Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8735457Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8738715Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8742033Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8745439Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8748802Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8827282Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8831041Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8834527Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8838151Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8841561Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8844934Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8848237Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8851627Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8854945Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8858321Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8861630Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8865005Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8868439Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8871816Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8875407Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8878789Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8882161Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8885533Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8889030Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8892481Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8895795Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8899106Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8983996Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8987433Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8991047Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.8994528Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.8997925Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9001242Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9004557Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9007943Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9011492Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9014879Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9018209Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9021525Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9024939Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9028371Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9031866Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9035239Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9038578Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9041896Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9045215Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9048598Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9052109Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9055489Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9138183Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9141784Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9145108Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9148547Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9152002Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9155327Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9158552Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9161761Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9164970Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9168173Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9171484Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9174966Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9178239Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9181561Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9184908Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9188178Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9191413Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9194615Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9197828Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9201116Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9204473Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9207800Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9295484Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9298758Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9302044Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9305321Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9308681Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9311957Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9315183Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9318391Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9321611Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9324887Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9328379Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9331832Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9335111Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9338335Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9341547Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9344829Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9348187Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9351461Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9354686Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9357937Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:41.9361153Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:41.9364513Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:49.7156535Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:49.7160797Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:49.7164686Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:49.7168515Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:49.7172420Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:49.7176518Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:14:49.7180529Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:14:49.7183219Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T09:14:49.7185201Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_ATEN_KLEIDIAI: 'opaque_aten_kleidiai'>} [33mSKIPPED[0m
2026-01-14T09:14:49.7187582Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>} [33mSKIPPED[0m
2026-01-14T09:14:49.7189519Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_conv2d [32mPASSED[0m
2026-01-14T09:14:49.7191070Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_embedding [32mPASSED[0m
2026-01-14T09:14:49.7193034Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:14:49.7195134Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config_with_unwrap [32mPASSED[0m
2026-01-14T09:14:49.7197050Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:14:49.7199018Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:14:49.7200839Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:14:49.7202516Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_linear [32mPASSED[0m
2026-01-14T09:14:49.7205096Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.7208618Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.7212181Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.7215625Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.7219200Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.7222646Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.7226065Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.7229505Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.7233062Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.7236572Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.7240058Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9927770Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9931451Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9934927Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9938392Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9941856Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9945326Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9948784Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9952256Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9955727Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9959439Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9963025Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9966555Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9970087Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9973645Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9977318Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9980814Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9984337Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9987805Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:49.9991256Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:49.9994695Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:49.9998127Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.0001777Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.0005220Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.0008867Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.0012415Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2762950Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2766470Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2769981Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2773424Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2777064Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2780559Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2783995Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2787631Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2791151Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2794661Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2798106Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2801529Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2805056Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2808575Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2812059Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2815464Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2818971Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2822480Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2825910Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2829436Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2832914Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2836388Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.2840232Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.2843725Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.2847277Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5539517Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5543017Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5546470Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5549942Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5553384Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5556826Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5560480Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5564028Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5567550Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5571061Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5574486Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5578170Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5581642Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5585049Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5588492Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5592005Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5595435Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5598857Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5602526Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5605962Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5609471Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5613011Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.5616488Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.5619994Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.5623483Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8397347Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8400857Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8404294Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8407725Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8411510Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8415016Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8420652Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8424058Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8427468Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8430849Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8434240Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8437651Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8441106Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8444519Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8447959Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8451442Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8454982Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8458411Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8461849Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8465249Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8468734Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8472123Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:50.8475784Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:50.8479220Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:50.8482664Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1225438Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1228962Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1232418Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1236091Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1239593Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1243101Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1246542Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1250057Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1253503Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1256938Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1260461Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1263920Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1267511Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1271035Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1274463Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1278342Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1281803Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1297407Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1301053Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1304470Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1307920Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1311395Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.1314787Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.1318178Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.1321598Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4004021Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4007854Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4011466Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4015002Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4018446Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4021907Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4025356Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4028818Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4032276Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4035724Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4039139Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4042567Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4046006Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4049549Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4053288Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4056792Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4060400Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4063905Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4067366Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4070855Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4074302Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4077940Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.4081386Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.4084810Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.4088364Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6852616Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6856240Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6859908Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6863364Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6866808Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6870270Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6873740Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6877397Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6880850Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6884293Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6887718Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6891262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6894932Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6898385Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6902056Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6905563Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6909099Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6912721Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6916164Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6919606Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6923065Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6926531Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.6930057Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.6933624Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.6937560Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9671348Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9675017Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9678441Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9681912Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9685358Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9688815Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9692320Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9695740Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9699192Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9702627Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9706283Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9709754Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9713255Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9717058Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9720620Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9724054Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9727653Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9731163Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9734603Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9738031Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9741471Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9744916Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:51.9748766Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:51.9752262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:51.9755916Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:52.0784924Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:52.0787847Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:52.0790719Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:14:52.0793595Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:14:52.0796454Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:14:52.0798713Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:14:52.0800356Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:14:52.0801801Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice [32mPASSED[0m
2026-01-14T09:14:52.0803154Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice_and_copy_ [32mPASSED[0m
2026-01-14T09:14:52.0804498Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_to_dtype [32mPASSED[0m
2026-01-14T09:14:52.0805689Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_False [33mSKIPPED[0m
2026-01-14T09:14:52.0806724Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_True [33mSKIPPED[0m
2026-01-14T09:14:52.0807751Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_False [33mSKIPPED[0m
2026-01-14T09:14:52.0809060Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_True [33mSKIPPED[0m
2026-01-14T09:14:52.0810234Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0811420Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0812667Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0813827Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0815000Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0816182Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0817349Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0818514Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0819689Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0820867Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0822044Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0823217Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0824390Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0825559Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0826728Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0827899Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0829066Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0830234Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0831391Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0832549Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0833704Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0834859Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0836017Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0837161Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0838455Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0839629Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0840783Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0841980Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0843137Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0844287Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0845454Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0846608Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0847765Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0848932Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0850143Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0851290Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0852438Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0853601Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:14:52.0854740Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:14:52.0855877Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:15:07.4125895Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:15:07.4127151Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:15:07.4128316Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:15:07.4129511Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:15:07.4130753Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:15:07.4131909Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:15:07.4133073Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:15:07.4134277Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:15:07.4135281Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_add_tensors [32mPASSED[0m
2026-01-14T09:15:07.4136225Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_inplace_operation [32mPASSED[0m
2026-01-14T09:15:07.4137547Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_pad_unpad [32mPASSED[0m
2026-01-14T09:15:07.4138537Z test/quantization/test_gptq.py::TestMultiTensorInputRecorder::test_multitensor_input_recorder [32mPASSED[0m
2026-01-14T09:15:07.4139483Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_calc_success [32mPASSED[0m
2026-01-14T09:15:07.4140341Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_row_errors [32mPASSED[0m
2026-01-14T09:15:07.4141285Z test/quantization/test_observer.py::TestQuantFlow::test_fixed_qparams_observer [32mPASSED[0m
2026-01-14T09:15:07.4142162Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_channel_affine [32mPASSED[0m
2026-01-14T09:15:07.4143052Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_tensor_affine [32mPASSED[0m
2026-01-14T09:15:07.4143877Z test/quantization/test_observer.py::TestQuantFlow::test_mse_observer [32mPASSED[0m
2026-01-14T09:15:07.4144887Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_False [32mPASSED[0m
2026-01-14T09:15:07.4145987Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_True [32mPASSED[0m
2026-01-14T09:15:07.4146913Z test/quantization/test_qat.py::TestQAT::test_composable_qat_quantizer [32mPASSED[0m
2026-01-14T09:15:07.4147680Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dtype [32mPASSED[0m
2026-01-14T09:15:07.4148558Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dynamic_and_range_learning [32mPASSED[0m
2026-01-14T09:15:07.4149408Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_eps [32mPASSED[0m
2026-01-14T09:15:07.4150194Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity [32mPASSED[0m
2026-01-14T09:15:07.4151081Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity_error_cases [32mPASSED[0m
2026-01-14T09:15:07.4151977Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_mapping_type [32mPASSED[0m
2026-01-14T09:15:07.4152795Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_torch_intx [32mPASSED[0m
2026-01-14T09:15:07.4153614Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_channel_group [32mPASSED[0m
2026-01-14T09:15:07.4154434Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token [32mPASSED[0m
2026-01-14T09:15:07.4155280Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:15:07.4156197Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:15:07.4157106Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:15:07.4157946Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_embedding_4w [32mPASSED[0m
2026-01-14T09:15:07.4158714Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_4w [32mPASSED[0m
2026-01-14T09:15:07.4159479Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_8da4w [32mPASSED[0m
2026-01-14T09:15:07.4160368Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:15:07.4161332Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:15:07.4162168Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_repr [32mPASSED[0m
2026-01-14T09:15:07.4162973Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_int4_preshuffled_primitives [33mSKIPPED[0m
2026-01-14T09:15:07.4163790Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_primitives [33mSKIPPED[0m
2026-01-14T09:15:07.4164580Z test/quantization/test_qat.py::TestQAT::test_fbgemm_int4_weight_only_primitives [33mSKIPPED[0m
2026-01-14T09:15:07.4165548Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_config [32mPASSED[0m
2026-01-14T09:15:07.4166358Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity0 [32mPASSED[0m
2026-01-14T09:15:07.4167175Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity1 [32mPASSED[0m
2026-01-14T09:15:07.4167956Z test/quantization/test_qat.py::TestQAT::test_infer_fp8_int4_config [32mPASSED[0m
2026-01-14T09:15:07.4168750Z test/quantization/test_qat.py::TestQAT::test_infer_int4_weight_only_config [32mPASSED[0m
2026-01-14T09:15:07.4169517Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:15:07.4170416Z test/quantization/test_qat.py::TestQAT::test_nvfp4_fake_quanitzed_linear_mixed_precision [33mSKIPPED[0m
2026-01-14T09:15:07.4171219Z test/quantization/test_qat.py::TestQAT::test_qat_4w_embedding [32mPASSED[0m
2026-01-14T09:15:07.4171990Z test/quantization/test_qat.py::TestQAT::test_qat_4w_linear tensor(5.9366e-05, device='cuda:0', dtype=torch.bfloat16,
2026-01-14T09:15:07.4172622Z        grad_fn=<AbsBackward0>)
2026-01-14T09:15:07.4172925Z [32mPASSED[0m
2026-01-14T09:15:07.4173457Z test/quantization/test_qat.py::TestQAT::test_qat_4w_primitives tensor(0.0005, device='cuda:0', dtype=torch.bfloat16)
2026-01-14T09:15:07.4174151Z [32mPASSED[0m
2026-01-14T09:15:07.4174974Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer tensor(0.0038, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AbsBackward0>)
2026-01-14T09:15:07.4175714Z [32mPASSED[0m
2026-01-14T09:15:07.4176207Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:15:07.4176924Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_eps [32mPASSED[0m
2026-01-14T09:15:07.4177599Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_linear [32mPASSED[0m
2026-01-14T09:15:07.4178440Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:15:07.4179519Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:15:07.4180556Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:15:07.4181474Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:15:07.4182423Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant [32mPASSED[0m
2026-01-14T09:15:07.4183511Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant_backward [32mPASSED[0m
2026-01-14T09:15:07.4184542Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:15:07.4185504Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_meta_weights [32mPASSED[0m
2026-01-14T09:15:07.4186467Z test/quantization/test_qat.py::TestQAT::test_qat_api_convert_no_quantization [32mPASSED[0m
2026-01-14T09:15:07.4187380Z test/quantization/test_qat.py::TestQAT::test_qat_api_deprecation [32mPASSED[0m
2026-01-14T09:15:07.4188200Z test/quantization/test_qat.py::TestQAT::test_qat_config_init [32mPASSED[0m
2026-01-14T09:15:07.4189035Z test/quantization/test_qat.py::TestQAT::test_qat_fp8a4w_quantizer [32mPASSED[0m
2026-01-14T09:15:07.4189866Z test/quantization/test_qat.py::TestQAT::test_qat_linear_bias [32mPASSED[0m
2026-01-14T09:15:07.4190832Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:15:07.4191953Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:15:07.4193011Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:15:07.4194035Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:15:07.4194946Z test/quantization/test_qat.py::TestQAT::test_qat_prototype_bc [32mPASSED[0m
2026-01-14T09:15:07.4196088Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:15:07.4197113Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:15:07.4198017Z test/quantization/test_qat.py::TestQAT::test_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:15:07.4198857Z test/quantization/test_qat.py::TestQAT::test_quantize_api_errors [32mPASSED[0m
2026-01-14T09:15:07.4199844Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity0 [33mSKIPPED[0m
2026-01-14T09:15:07.4200841Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity1 [33mSKIPPED[0m
2026-01-14T09:15:07.4201770Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_int4 [33mSKIPPED[0m
2026-01-14T09:15:08.1916237Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:15:08.1917754Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:15:08.1919187Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:15:08.1920587Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:15:08.1921734Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_int4 [32mPASSED[0m
2026-01-14T09:15:08.1922819Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1924047Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity1_float32 [32mPASSED[0m
2026-01-14T09:15:08.1925279Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity2_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1926517Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity3_float32 [32mPASSED[0m
2026-01-14T09:15:08.1927757Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity4_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1928989Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity5_float32 [32mPASSED[0m
2026-01-14T09:15:08.1930320Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity6_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1931569Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity7_float32 [32mPASSED[0m
2026-01-14T09:15:08.1932878Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity10_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1934077Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity11_float32 [32mPASSED[0m
2026-01-14T09:15:08.1935115Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity8_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1936137Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity9_float32 [32mPASSED[0m
2026-01-14T09:15:08.1937179Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity12_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1938224Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity13_float32 [32mPASSED[0m
2026-01-14T09:15:08.1939255Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity14_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1940296Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity15_float32 [32mPASSED[0m
2026-01-14T09:15:08.1941330Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity16_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1942644Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity17_float32 [32mPASSED[0m
2026-01-14T09:15:08.1943689Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity18_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1944723Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity19_float32 [32mPASSED[0m
2026-01-14T09:15:08.1945836Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity20_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1946867Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity21_float32 [32mPASSED[0m
2026-01-14T09:15:08.1947908Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity22_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1948949Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity23_float32 [32mPASSED[0m
2026-01-14T09:15:08.1949992Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity24_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1951038Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity25_float32 [32mPASSED[0m
2026-01-14T09:15:08.1952070Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity26_bfloat16 [32mPASSED[0m
2026-01-14T09:15:08.1953109Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity27_float32 [32mPASSED[0m
2026-01-14T09:15:08.1954214Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity0_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1955363Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity1_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1956486Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity2_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1957607Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity3_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1958718Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity4_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1959841Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity5_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1960954Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity6_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1962067Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity7_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1963185Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity10_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1964400Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity11_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1965594Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity12_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1966729Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity13_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1967859Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity14_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1968984Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity15_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1970145Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity8_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1971269Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity9_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1972542Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity16_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1973681Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity17_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1975141Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity18_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1976342Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity19_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1977472Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity20_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1978603Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity21_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1979722Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity22_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1980837Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity23_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1981949Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity24_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1983075Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity25_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1984200Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity26_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1985308Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity27_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1986432Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity28_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1987573Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity29_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1988688Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity30_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:08.1989802Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity31_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:08.1990919Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity32_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5464763Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity33_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5465945Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity34_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5467056Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity35_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5468207Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity36_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5469338Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity37_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5470454Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity38_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5471574Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity39_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5472685Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity40_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5473812Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity41_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5475533Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity42_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5476655Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity43_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5477785Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity44_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5478994Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity45_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5480116Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity46_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5481234Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity47_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5482348Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity48_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5483491Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity49_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5484614Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity50_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5485990Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity51_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5487121Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity52_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5488381Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity53_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5489507Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity54_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:15:20.5490711Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity55_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:15:20.5491743Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:15:20.5492688Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:15:20.5493513Z test/quantization/test_qat.py::TestQAT::test_quantize_api_prepare [32mPASSED[0m
2026-01-14T09:15:20.5494386Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls0 [32mPASSED[0m
2026-01-14T09:15:20.5495487Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls1 [32mPASSED[0m
2026-01-14T09:15:20.5496516Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls2 [32mPASSED[0m
2026-01-14T09:15:20.5497363Z test/quantization/test_qat.py::TestQAT::test_replace_linear_8da4w [32mPASSED[0m
2026-01-14T09:15:20.5498202Z test/quantization/test_qat.py::TestQAT::test_replace_linear_int4 [32mPASSED[0m
2026-01-14T09:15:20.5498955Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:15:20.5499800Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer_linear_bias [32mPASSED[0m
2026-01-14T09:15:20.5500656Z test/quantization/test_quant_api.py::TestQuantFlow::test_config_deprecation [32mPASSED[0m
2026-01-14T09:15:20.5501524Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_singleline [32mPASSED[0m
2026-01-14T09:15:20.5502518Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_eager_mode_impl [33mSKIPPED[0m
2026-01-14T09:15:20.5503580Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_unified_impl [33mSKIPPED[0m
2026-01-14T09:15:20.5504534Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T09:15:20.5505664Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5506676Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5507681Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5509984Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5510987Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5511985Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5512981Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5513986Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5514975Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5515971Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5516967Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:15:20.5517957Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:15:20.5518891Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cuda_serialization [32mPASSED[0m
2026-01-14T09:15:20.5519760Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8_wo_quant_save_load [32mPASSED[0m
2026-01-14T09:15:20.5520669Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8wo_quantized_model_to_device [32mPASSED[0m
2026-01-14T09:15:20.5521596Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_default [32mPASSED[0m
2026-01-14T09:15:20.5522539Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_embedding_linear [32mPASSED[0m
2026-01-14T09:15:20.5523503Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_module_name [32mPASSED[0m
2026-01-14T09:15:20.5524434Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_basic [32mPASSED[0m
2026-01-14T09:15:20.5525390Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_fullmatch [32mPASSED[0m
2026-01-14T09:15:20.5526371Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence [32mPASSED[0m
2026-01-14T09:15:20.5536431Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence2 [32mPASSED[0m
2026-01-14T09:15:20.5537566Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_skip [32mPASSED[0m
2026-01-14T09:15:20.5538662Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_model_streaming [32mPASSED[0m
2026-01-14T09:15:20.5539633Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type0 [32mPASSED[0m
2026-01-14T09:15:20.5540713Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type1 [32mPASSED[0m
2026-01-14T09:15:20.5541725Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load [32mPASSED[0m
2026-01-14T09:15:20.5542890Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load_map_location [32mPASSED[0m
2026-01-14T09:15:20.5543891Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config0 [32mPASSED[0m
2026-01-14T09:15:20.5545039Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config1 [32mPASSED[0m
2026-01-14T09:15:20.5546014Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config2 [32mPASSED[0m
2026-01-14T09:15:20.5546918Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config3 [32mPASSED[0m
2026-01-14T09:15:20.5547826Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config4 [32mPASSED[0m
2026-01-14T09:15:20.5548776Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config5 [32mPASSED[0m
2026-01-14T09:15:34.6552591Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config6 [32mPASSED[0m
2026-01-14T09:15:34.6553560Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config7 [32mPASSED[0m
2026-01-14T09:15:34.6554471Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config8 [32mPASSED[0m
2026-01-14T09:15:34.6555413Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config9 [32mPASSED[0m
2026-01-14T09:15:34.6556364Z test/quantization/test_quant_api.py::TestFqnToConfig::test_filter_fn_and_fqn_to_config_error [33mSKIPPED[0m
2026-01-14T09:15:34.6557447Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_module_config_and_fqn_config_both_specified [33mSKIPPED[0m
2026-01-14T09:15:34.6558526Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module [33mSKIPPED[0m
2026-01-14T09:15:34.6559583Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_module_swap [33mSKIPPED[0m
2026-01-14T09:15:34.6560674Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_param [33mSKIPPED[0m
2026-01-14T09:15:34.6561652Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_custom [33mSKIPPED[0m
2026-01-14T09:15:34.6562569Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_linear [33mSKIPPED[0m
2026-01-14T09:15:34.6563494Z test/quantization/test_quant_api.py::TestFqnToConfig::test_non_fqn_config_filter_fn_none [33mSKIPPED[0m
2026-01-14T09:15:34.6564525Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_module_over_param_regex [33mSKIPPED[0m
2026-01-14T09:15:34.6565616Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_default [33mSKIPPED[0m
2026-01-14T09:15:34.6566682Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module [33mSKIPPED[0m
2026-01-14T09:15:34.6567763Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module_regex [33mSKIPPED[0m
2026-01-14T09:15:34.6568884Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_default [33mSKIPPED[0m
2026-01-14T09:15:34.6570128Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_module_regex [33mSKIPPED[0m
2026-01-14T09:15:34.6571250Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param [33mSKIPPED[0m
2026-01-14T09:15:34.6572346Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param_regex [33mSKIPPED[0m
2026-01-14T09:15:34.6573347Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_exact [33mSKIPPED[0m
2026-01-14T09:15:34.6574540Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_regex [33mSKIPPED[0m
2026-01-14T09:15:34.6575863Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantized_model_streaming_fqn_config [33mSKIPPED[0m
2026-01-14T09:15:34.6576992Z test/quantization/test_quant_api.py::TestFqnToConfig::test_top_level_param [33mSKIPPED[0m
2026-01-14T09:15:34.6578412Z test/quantization/test_quant_api.py::TestFqnToConfig::test_unsupported_param_config_raises_not_implemented_error [33mSKIPPED[0m
2026-01-14T09:15:34.6579710Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_and_quantize_scale_only_sinq [32mPASSED[0m
2026-01-14T09:15:34.6580830Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym [32mPASSED[0m
2026-01-14T09:15:34.6581944Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym_no_clipping_err [32mPASSED[0m
2026-01-14T09:15:34.6583143Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym [32mPASSED[0m
2026-01-14T09:15:34.6584214Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym_eps [32mPASSED[0m
2026-01-14T09:15:34.6585270Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_sym [32mPASSED[0m
2026-01-14T09:15:34.6586323Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_token_asym [32mPASSED[0m
2026-01-14T09:15:34.6587340Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine [32mPASSED[0m
2026-01-14T09:15:34.6588374Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine_cachemask [32mPASSED[0m
2026-01-14T09:15:34.6589431Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_blockwise_scaling [32mPASSED[0m
2026-01-14T09:15:34.6590533Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_rowwise_scaling_3d_weight_axis_1 [32mPASSED[0m
2026-01-14T09:15:34.6591691Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric [32mPASSED[0m
2026-01-14T09:15:34.6592794Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric_memory [32mPASSED[0m
2026-01-14T09:15:34.6593882Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_groupwise_affine_qparams [32mPASSED[0m
2026-01-14T09:15:34.6595054Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_dequantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:15:34.6596416Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_quantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:15:34.6597594Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_maybe_expand_scale_to_tensor_shape [32mPASSED[0m
2026-01-14T09:15:34.6598879Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max [32mPASSED[0m
2026-01-14T09:15:34.6600061Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_dtype [32mPASSED[0m
2026-01-14T09:15:34.6601303Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_zero_input [32mPASSED[0m
2026-01-14T09:15:34.6602495Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym [32mPASSED[0m
2026-01-14T09:15:34.6603604Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d [32mPASSED[0m
2026-01-14T09:15:34.6604836Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d_multi_dim_reduction [32mPASSED[0m
2026-01-14T09:15:34.6606027Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_group_sym [32mPASSED[0m
2026-01-14T09:15:34.6607115Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_tensor_asym [32mPASSED[0m
2026-01-14T09:15:34.6608084Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_raises [32mPASSED[0m
2026-01-14T09:15:34.6608920Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity [33mSKIPPED[0m
2026-01-14T09:15:34.6609998Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity_scaled [33mSKIPPED[0m
2026-01-14T09:15:34.6610824Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_srelu [33mSKIPPED[0m
2026-01-14T09:15:34.6611665Z test/sparsity/test_activation24.py::test_srelu_fp8_semi_sparse_activation_linear [33mSKIPPED[0m
2026-01-14T09:15:34.6612522Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_eye [33mSKIPPED[0m
2026-01-14T09:15:34.6613441Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_random_tensor [33mSKIPPED[0m
2026-01-14T09:15:34.6614546Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification [33mSKIPPED[0m
2026-01-14T09:15:34.6615848Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification_compile [33mSKIPPED[0m
2026-01-14T09:15:34.6616913Z test/sparsity/test_sparse_api.py::TestSemiStructuredSparse::test_sparse [33mSKIPPED[0m
2026-01-14T09:15:34.6617953Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:15:34.6618967Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:15:34.6619989Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:15:34.6621164Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:15:34.6622194Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_quant_semi_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:15:34.6623239Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1 [32mPASSED[0m
2026-01-14T09:15:34.6624288Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024 [32mPASSED[0m
2026-01-14T09:15:34.6625344Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1 [32mPASSED[0m
2026-01-14T09:15:34.6626379Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1024 [32mPASSED[0m
2026-01-14T09:15:34.6627393Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False [32mPASSED[0m
2026-01-14T09:15:34.6628361Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_True [32mPASSED[0m
2026-01-14T09:15:34.6629206Z test/sparsity/test_supermask.py::TestSupermask::test_from_linear [32mPASSED[0m
2026-01-14T09:20:32.8461456Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_2 [32mPASSED[0m
2026-01-14T09:20:32.8463920Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_4 [32mPASSED[0m
2026-01-14T09:20:32.8465162Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_8 [32mPASSED[0m
2026-01-14T09:20:32.8466390Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_2 [32mPASSED[0m
2026-01-14T09:20:32.8467561Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_4 [32mPASSED[0m
2026-01-14T09:20:32.8468737Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_8 [32mPASSED[0m
2026-01-14T09:20:32.8469794Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4 [32mPASSED[0m
2026-01-14T09:20:32.8470805Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:20:32.8471751Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare [32mPASSED[0m
2026-01-14T09:20:32.8472602Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask [32mPASSED[0m
2026-01-14T09:20:32.8473577Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:20:32.8475631Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config [32mPASSED[0m
2026-01-14T09:20:32.8476852Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_False [32mPASSED[0m
2026-01-14T09:20:32.8478007Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_True [32mPASSED[0m
2026-01-14T09:20:32.8479277Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_False [32mPASSED[0m
2026-01-14T09:20:32.8480449Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_True [32mPASSED[0m
2026-01-14T09:20:32.8481672Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_False [32mPASSED[0m
2026-01-14T09:20:32.8482901Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_True [32mPASSED[0m
2026-01-14T09:20:32.8484156Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_False [32mPASSED[0m
2026-01-14T09:20:32.8485392Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_True [32mPASSED[0m
2026-01-14T09:20:32.8486557Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8487660Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8488792Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8490042Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8491277Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8492394Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8493524Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8494673Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8495788Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_Adam4bit [33mSKIPPED[0m
2026-01-14T09:20:32.8496872Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_AdamW4bit [33mSKIPPED[0m
2026-01-14T09:20:32.8497952Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_Adam8bit [33mSKIPPED[0m
2026-01-14T09:20:32.8499024Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_AdamW8bit [33mSKIPPED[0m
2026-01-14T09:20:32.8500195Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8501361Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8502582Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_1 [32mPASSED[0m
2026-01-14T09:20:32.8503861Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_2 [32mPASSED[0m
2026-01-14T09:20:32.8505132Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_True_grad_accum_1 [32mPASSED[0m
2026-01-14T09:20:32.8506201Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_save_load [32mPASSED[0m
2026-01-14T09:20:32.8507260Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8508456Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8509849Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8511054Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8512252Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8513457Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:20:32.8514678Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8515841Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8516984Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8518148Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8519307Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8520480Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8521663Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8522804Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8523955Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8525115Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:20:32.8526259Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8527408Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:20:32.8528558Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8529726Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8530995Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8532146Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8533309Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8534487Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8535657Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8536817Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8537967Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8539135Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:20:32.8540302Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8541453Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:20:32.8542564Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8543781Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8544860Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8545939Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:20:32.8547001Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:20:32.8548122Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:22:06.8483891Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8484839Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:22:06.8485734Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8486662Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:22:06.8487559Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8488447Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:22:06.8489399Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8490386Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:22:06.8491268Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8492170Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cuda [33mSKIPPED[0m
2026-01-14T09:22:06.8493066Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:22:06.8493961Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cuda [33mSKIPPED[0m
2026-01-14T09:22:06.8494654Z test/test_low_bit_optim.py::TestFSDP2::test_fsdp2 dist init r=0, world=2
2026-01-14T09:22:06.8495077Z dist init r=1, world=2
2026-01-14T09:22:06.8495351Z [32mPASSED[0m
2026-01-14T09:22:06.8495723Z test/test_low_bit_optim.py::TestFSDP2::test_uneven_shard dist init r=0, world=2
2026-01-14T09:22:06.8496189Z dist init r=1, world=2
2026-01-14T09:22:06.8496448Z [32mPASSED[0m
2026-01-14T09:22:06.8497000Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_0_cpu [32mPASSED[0m
2026-01-14T09:22:06.8497884Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_1_cuda [32mPASSED[0m
2026-01-14T09:22:06.8498764Z test/test_model_architecture.py::TestModels::test_toy_linear_model_0_cpu [32mPASSED[0m
2026-01-14T09:22:06.8499557Z test/test_model_architecture.py::TestModels::test_toy_linear_model_1_cuda [32mPASSED[0m
2026-01-14T09:22:06.8500345Z test/test_model_architecture.py::TestModels::test_transformer_block_0_cpu [32mPASSED[0m
2026-01-14T09:22:06.8501145Z test/test_model_architecture.py::TestModels::test_transformer_block_1_cuda [32mPASSED[0m
2026-01-14T09:22:06.8502296Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8503728Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8505170Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8507034Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8508552Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8509988Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8511515Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8512935Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8514375Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8515807Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8517224Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8518657Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8520088Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8521509Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8522940Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8524375Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8525795Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8527226Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8528665Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8530147Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8531578Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8533015Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8534436Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8535863Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8537436Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8538849Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8540269Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8541739Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8543142Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8544577Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8546013Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8547415Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8548847Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8550274Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8551685Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8553109Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8706589Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8708409Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8710006Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8711539Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8712957Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8714477Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8716026Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8717446Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8718980Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8720788Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8722287Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8723755Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8725390Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8726885Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8728345Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8729922Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8731484Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8732966Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8734432Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8741672Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8743333Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8744877Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8746341Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8747821Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8749391Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8750894Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8752367Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8753920Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8755393Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8756953Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8758550Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8760050Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8761554Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8763114Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8764637Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8766094Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8767650Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8769167Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8770719Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8772241Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8773878Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8775678Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8785773Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8787433Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8788972Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8790414Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8791938Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8793443Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8938420Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8939843Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8941381Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8942877Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8944265Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8945730Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8947143Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8948529Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8949944Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8951350Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8952750Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8954151Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8955536Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8956978Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8958349Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8959705Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8961063Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8962433Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8963800Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8965147Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8966510Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8967874Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8969220Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8970676Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8972088Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8973432Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8975001Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8976366Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8977703Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8979075Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8980439Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8981784Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8983138Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8984501Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8985845Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8987295Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8988664Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8990002Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8991356Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8992717Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8994055Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8995406Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.8996768Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.8998103Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.8999463Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9000951Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9002292Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9003645Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9005053Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9006396Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9173591Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9175198Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9176530Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9177879Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9179221Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9180556Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9182026Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9183374Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9184705Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9186058Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9187398Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9188735Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9190085Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9191425Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9192761Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9194109Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9195446Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9196909Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9198244Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9199726Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9201053Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9202389Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9203741Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9205068Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9206399Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9207748Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9209078Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9210500Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9211912Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9213240Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9214590Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9215951Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9217284Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9218651Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9220006Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9221355Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9222696Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9224040Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9225409Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9228762Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9230123Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9231506Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9232865Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9234213Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9235574Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9236928Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9238278Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9239622Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:06.9240984Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:06.9242398Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:06.9243743Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:09.1595840Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:09.1597538Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:09.1599043Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:22:09.1600577Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:09.1602115Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:22:09.1603608Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:22:09.1605127Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:22:09.1606393Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1607431Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1608458Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1609645Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1610680Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1611611Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1612629Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1613556Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1614481Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1615413Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1616339Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1617271Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1618202Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1619125Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1620055Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1620926Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1621759Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1622592Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1623513Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1624359Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1625188Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1626023Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1626858Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1627682Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1628521Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1629347Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1630188Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1631017Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:22:09.1631843Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:22:09.1632680Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:22:09.1633622Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:09.1634670Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:09.1635720Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:09.1636860Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:09.1637914Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:09.1638948Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:09.1640054Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:09.1641156Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:09.1642187Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:09.1643227Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:09.1644273Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:09.1645325Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:09.1646361Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:22:09.1647398Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:22:09.1648451Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:22:09.1649565Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:22:09.1650676Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:22:09.1651808Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:22:09.1652848Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:22:09.1653907Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:22:09.1654957Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:22:09.1656000Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:22:09.1657052Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:22:09.1658101Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:22:09.1659164Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:09.1660211Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:09.1661252Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:09.1662308Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:09.1663348Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:09.1664388Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:09.1665478Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:09.1666578Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.3991497Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.3992586Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.3993792Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.3994838Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.3995877Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:22:13.3996920Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:22:13.3997965Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:22:13.3999015Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:22:13.4000052Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:22:13.4001098Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:22:13.4002147Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:22:13.4003191Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.4004244Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.4005379Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.4006422Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.4007471Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.4008504Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:13.4009538Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:13.4010672Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:13.4011720Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:13.4012756Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:13.4013784Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:13.4014831Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:13.4015887Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.4016923Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.4017968Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.4019167Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.4020216Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.4021283Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:13.4022436Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:13.4023521Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:13.4024610Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:13.4025692Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:13.4026790Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:13.4027868Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:13.4028961Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.4030048Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.4031122Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.4032210Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.4033360Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.4034454Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:22:13.4035547Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:22:13.4036639Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:22:13.4037737Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:22:13.4038819Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:22:13.4039904Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:22:13.4041004Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:22:13.4042097Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.4043190Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.4044280Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.4045363Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.4046456Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.4047633Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:13.4048723Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:13.4049857Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:13.4051048Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:13.4052137Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:13.4053213Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:13.4054311Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:13.4055416Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:13.4056504Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:13.4057590Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:13.4058686Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:13.4059782Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:13.4060883Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6003453Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6004779Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6005895Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6006979Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6008066Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6009143Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6010331Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6011423Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6012499Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6013589Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6014683Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6015765Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6016851Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6018023Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6019189Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6020282Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6021358Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6022575Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6023662Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6024756Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6025847Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6026929Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6028026Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6028977Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6029782Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6030599Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6031406Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6032242Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6033129Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6033949Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6034760Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6035570Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6036377Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6037180Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6037989Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6038806Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6039621Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6040439Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6041264Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6042083Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6042966Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6043788Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6044613Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6045448Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6046367Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6047213Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6048070Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6058593Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6059519Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6060345Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6061177Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6061991Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6062817Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6063631Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6064461Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6065282Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6066094Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6066916Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6067738Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6068566Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6069443Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6070261Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6071092Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6071906Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:22:18.6072730Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:22:18.6073543Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:22:18.6074372Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:22:18.6075605Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:22:18.6076425Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:22:18.6077244Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:22:18.6078064Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:22:18.6078886Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:22:18.6079707Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:22:18.6080520Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:22:18.6081356Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:22:18.6082216Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:22:19.0006978Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:22:19.0007963Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:22:19.0008888Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:22:19.0009791Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:22:19.0010877Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:22:19.0011712Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:22:19.0012663Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:22:19.0013391Z test/test_ops.py::test_swizzle_mm [33mSKIPPED[0m (ROCm not available)
2026-01-14T09:22:19.0014108Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0014991Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0015768Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0016561Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0017456Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0018235Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0019106Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0019881Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0020656Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0021650Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0022444Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0023277Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0024125Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0024904Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0025814Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0026623Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0027417Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0028341Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0029134Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0030011Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0030844Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0031653Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0032522Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0033323Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0034221Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0034989Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0036010Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0036844Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0037618Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0038505Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0039346Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0040132Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0041007Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0041782Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0042692Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0043476Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0044257Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0045147Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0045937Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0046833Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0047644Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0048445Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0049341Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0050313Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0051220Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0052057Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0052865Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0053778Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0054556Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0055363Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0056217Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0057009Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0057895Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0058692Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0059465Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0060341Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0061115Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0061924Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0062794Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0063572Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0064594Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0065392Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0066209Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0067125Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0068070Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0068999Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0069799Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0070624Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0071516Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0072331Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0073248Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0074059Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0075186Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0076025Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0076807Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0077700Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0078497Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0079426Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0080291Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0081068Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0081858Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0412586Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0413612Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0414509Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0415384Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0416277Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0417131Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0418038Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0418901Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0419792Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0420677Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0421536Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0422435Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0423421Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0424437Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0425330Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0426198Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0427160Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0428005Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0428878Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0429653Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0430511Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0431367Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0432200Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0433036Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0433842Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0434698Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0435556Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0436365Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0437224Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0438079Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0439126Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0440034Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0440906Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0441785Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0442592Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0443477Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0444367Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0445251Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0446149Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0446935Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0447772Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0448619Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0449445Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0450417Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0451232Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0451994Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0452746Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0453779Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0454660Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0455444Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0456289Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0457232Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0458089Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0458964Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0459778Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0460659Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0461546Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0462416Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0463301Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0464084Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0464972Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0465874Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0466756Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0467625Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0468460Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0469335Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0470214Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0471076Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0471948Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0472791Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0473633Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0474497Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0475733Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0476614Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0477430Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0478280Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0479120Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0479982Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0480859Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0481683Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0482562Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0483789Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0484998Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0486054Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0487275Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0488681Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0490006Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0491194Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0492154Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0749956Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0751104Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0751955Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0752733Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0753505Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0754262Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0755038Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0755809Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0756585Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0757363Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0758261Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0759044Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0759826Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0760624Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0761411Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0762207Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0763008Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0763789Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0764599Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0765399Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0766202Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:22:19.0767007Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:22:19.0767926Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0768955Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0770089Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0771279Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0772325Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0773342Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0774378Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0775652Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0776688Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0777711Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0778749Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0779794Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0780834Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0781877Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0782993Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0784043Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0785090Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0786121Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0787245Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0788304Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0789346Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0790390Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0791444Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0792497Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0793589Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0794617Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0795655Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0796696Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0797730Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0798754Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0799782Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0800896Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0801988Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0803061Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0804094Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0805222Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0806259Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0807293Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0808338Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0809408Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0810502Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0811538Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0812595Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0813646Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0814695Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0815725Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0816831Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0817899Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0818942Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0819971Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0821011Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.0822051Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.0823138Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1066991Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1068308Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1069347Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1070370Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1071389Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1072414Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1073450Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1075669Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1076703Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1077736Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1078854Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1079888Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1080915Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1081955Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1083014Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1084051Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1085069Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1086116Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1087167Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1088195Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1089215Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1090318Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1091428Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1092508Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1093520Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1094550Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1095583Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1096609Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1097633Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1098662Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1099698Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1100728Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1101764Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1102869Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1103919Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1105068Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1106093Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1107137Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1108186Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1109266Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1110289Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1111335Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1112385Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1113424Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1114436Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1115469Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1116514Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1117536Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1118559Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1119588Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1120676Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1121707Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1122721Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1123754Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1124791Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1125826Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1126855Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1127895Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1128946Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1130031Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1131061Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1132102Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1133198Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1134286Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1135349Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1136392Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1137438Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1138509Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1139521Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1140551Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1381850Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1383174Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1384190Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1385211Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1386256Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1387271Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1388294Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1389324Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1390469Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1391506Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1392585Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1393632Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1394686Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1395728Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1396765Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1397810Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1398864Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1399916Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1400947Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1401993Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1403038Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1404075Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1405264Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1415382Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1416433Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1417562Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1418572Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1419587Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1420621Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1421654Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1422683Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1423732Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1424756Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1425784Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1426812Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1427836Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1428882Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1429953Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1430977Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1432014Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1433055Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1434089Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1435101Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1436138Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1437184Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1438202Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1439207Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1440217Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1441233Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1442254Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1443351Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1444375Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1445400Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1446409Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1447460Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1448470Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1449495Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1450586Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1451602Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1452658Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1453728Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1454763Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1455781Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1456812Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1457858Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1458929Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1459947Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1460980Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1462018Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1463040Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1671743Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1673231Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1674283Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1675487Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1676495Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1677512Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1678536Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1679549Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1680548Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1681743Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1682824Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1683842Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1684920Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1685961Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1686997Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1688026Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1689052Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1690151Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1691191Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1692217Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1693285Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1694314Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:22:19.1695355Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:22:19.1696533Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1697673Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1698818Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1699958Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1701100Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1702233Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1703423Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1704560Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1705702Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1706827Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1707984Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1709133Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1710345Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1711553Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1712727Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1713911Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1715101Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1716258Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1717418Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1718577Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1719731Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1720886Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1722043Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1723193Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1724339Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1725501Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1726706Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1727859Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1729023Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1730220Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1731363Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1732520Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1733725Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1734874Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1736026Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1737179Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1738339Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1739518Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1740815Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1741992Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1743154Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1944827Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1946285Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1947662Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1948958Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1950298Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1951553Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1952812Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1954008Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1955310Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1956520Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1957913Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1959117Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1960453Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1961714Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1962919Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1964195Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1965399Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1966661Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1967873Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1969171Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1970561Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1971752Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1973309Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1974515Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1976030Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1977443Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1978638Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1979906Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1981095Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1982410Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1983664Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1984844Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1986158Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1987335Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1988589Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1989876Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1991170Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1992474Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1993657Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1994958Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1996130Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1997381Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:22:19.1998577Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:22:19.1999861Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2001118Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2002301Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2003463Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2004728Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2005956Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2007275Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2008521Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2009870Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2011188Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2012372Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2013647Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2014822Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2016109Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2017322Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2018560Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2019859Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2021064Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2221496Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2222906Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2224198Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2225383Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2226678Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2227868Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2229191Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2230511Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2231726Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2233017Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2234226Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2235640Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2237002Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2238213Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2239536Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2240845Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2242151Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2243525Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2244747Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2246026Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2247222Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2248556Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2249907Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2251122Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2252556Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2253772Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2255072Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2256359Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2257600Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2258892Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2260104Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2261414Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2262608Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2263914Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2265112Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2266330Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2267726Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2269076Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2270283Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2271592Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2272965Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2274224Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2275749Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2276925Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2278172Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2279321Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2280612Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2281812Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2283056Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2284333Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2285618Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2286865Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2288046Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2289346Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2290693Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2291877Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2293242Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2294422Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2295674Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2296888Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2298156Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2493948Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2495476Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2496650Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2497809Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2499034Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2500199Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2501365Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2502537Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2503697Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2504870Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2506037Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2507200Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2508368Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2509529Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2510759Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2511927Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2513083Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2514258Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2515426Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2516603Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2517783Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2518950Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2520131Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2521302Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2522494Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2523690Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2524952Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2526129Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2527309Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2528532Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2529702Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2530967Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2532141Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2533376Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2534543Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2535722Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2536903Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2538076Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2539258Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2540493Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2541671Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2542849Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2544020Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2545203Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2546385Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2547565Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2548750Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2549918Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2551095Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2552301Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2553493Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2554715Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2555930Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2557094Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2558256Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2559489Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2560653Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2561811Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2563029Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2564194Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2565357Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2763617Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2764960Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2766119Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2767376Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2768547Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2769695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2770940Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2772093Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2773292Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2774445Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2775779Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2776927Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2778080Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2779236Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2780398Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2781549Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2782889Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2784052Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2785205Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2786422Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2787597Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2788772Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2789958Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2791138Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2792304Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2793489Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2794659Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2795836Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2797021Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2798269Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2799452Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2800642Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2801822Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2803012Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2804191Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2805382Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2806572Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2807749Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2808945Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2810172Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2811355Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2812690Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2813868Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2815046Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2816265Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2817448Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2818631Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2819822Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2821005Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2822210Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2823422Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2824604Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2825783Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2826970Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2828194Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2829378Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2830569Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2831747Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2832978Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2834161Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2995311Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2996613Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:22:19.2997808Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:22:19.2999005Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3000313Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype0-Xq_Wq_dtypes0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3001840Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype1-Xq_Wq_dtypes1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3003378Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype2-Xq_Wq_dtypes2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3004782Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype3-Xq_Wq_dtypes3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3006251Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype4-Xq_Wq_dtypes4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3007654Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype5-Xq_Wq_dtypes5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3009063Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype6-Xq_Wq_dtypes6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3010561Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype7-Xq_Wq_dtypes7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3011961Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype8-Xq_Wq_dtypes8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3013364Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype9-Xq_Wq_dtypes9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3014789Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype10-Xq_Wq_dtypes10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3016221Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype11-Xq_Wq_dtypes11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3017663Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype12-Xq_Wq_dtypes12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3019170Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype13-Xq_Wq_dtypes13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3020610Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype14-Xq_Wq_dtypes14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3022065Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype15-Xq_Wq_dtypes15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3023504Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype16-Xq_Wq_dtypes16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3024942Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype17-Xq_Wq_dtypes17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3026383Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype18-Xq_Wq_dtypes18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3027818Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype19-Xq_Wq_dtypes19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3029262Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype20-Xq_Wq_dtypes20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3030709Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype21-Xq_Wq_dtypes21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3032146Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype22-Xq_Wq_dtypes22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3033815Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype23-Xq_Wq_dtypes23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3044783Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype24-Xq_Wq_dtypes24-1-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3046217Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype25-Xq_Wq_dtypes25-1-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3047717Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype26-Xq_Wq_dtypes26-1-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3049126Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype27-Xq_Wq_dtypes27-1-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3050610Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype28-Xq_Wq_dtypes28-1-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3052032Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype29-Xq_Wq_dtypes29-1-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3053494Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype30-Xq_Wq_dtypes30-1-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3054907Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype31-Xq_Wq_dtypes31-1-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3056320Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype32-Xq_Wq_dtypes32-1-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3057730Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype33-Xq_Wq_dtypes33-1-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3059201Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype34-Xq_Wq_dtypes34-1-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3060612Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype35-Xq_Wq_dtypes35-1-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3062020Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype36-Xq_Wq_dtypes36-4-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3063485Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype37-Xq_Wq_dtypes37-4-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3064890Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype38-Xq_Wq_dtypes38-4-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3066300Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype39-Xq_Wq_dtypes39-4-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3067707Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype40-Xq_Wq_dtypes40-4-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3069109Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype41-Xq_Wq_dtypes41-4-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3070519Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype42-Xq_Wq_dtypes42-4-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3071923Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype43-Xq_Wq_dtypes43-4-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3073380Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype44-Xq_Wq_dtypes44-4-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3075005Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype45-Xq_Wq_dtypes45-4-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3076422Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype46-Xq_Wq_dtypes46-4-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3220579Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype47-Xq_Wq_dtypes47-4-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3222019Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype48-Xq_Wq_dtypes48-1-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3223444Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype49-Xq_Wq_dtypes49-1-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3224878Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype50-Xq_Wq_dtypes50-1-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3226297Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype51-Xq_Wq_dtypes51-1-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3227723Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype52-Xq_Wq_dtypes52-1-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3229141Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype53-Xq_Wq_dtypes53-1-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3230557Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype54-Xq_Wq_dtypes54-1-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3231970Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype55-Xq_Wq_dtypes55-1-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3233484Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype56-Xq_Wq_dtypes56-1-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3234912Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype57-Xq_Wq_dtypes57-1-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3236331Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype58-Xq_Wq_dtypes58-1-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3237750Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype59-Xq_Wq_dtypes59-1-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3239172Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype60-Xq_Wq_dtypes60-4-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3240595Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype61-Xq_Wq_dtypes61-4-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3242013Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype62-Xq_Wq_dtypes62-4-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3243438Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype63-Xq_Wq_dtypes63-4-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3244848Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype64-Xq_Wq_dtypes64-4-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3246262Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype65-Xq_Wq_dtypes65-4-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3247801Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype66-Xq_Wq_dtypes66-4-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3249221Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype67-Xq_Wq_dtypes67-4-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3250692Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype68-Xq_Wq_dtypes68-4-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3252169Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype69-Xq_Wq_dtypes69-4-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3253591Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype70-Xq_Wq_dtypes70-4-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3255015Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype71-Xq_Wq_dtypes71-4-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3256436Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype72-Xq_Wq_dtypes72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3257853Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype73-Xq_Wq_dtypes73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3259275Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype74-Xq_Wq_dtypes74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3260687Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype75-Xq_Wq_dtypes75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3262110Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype76-Xq_Wq_dtypes76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3263585Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype77-Xq_Wq_dtypes77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3265000Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype78-Xq_Wq_dtypes78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3266423Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype79-Xq_Wq_dtypes79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3267839Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype80-Xq_Wq_dtypes80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3269262Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype81-Xq_Wq_dtypes81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3270700Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype82-Xq_Wq_dtypes82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3272116Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype83-Xq_Wq_dtypes83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3273535Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype84-Xq_Wq_dtypes84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3275153Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype85-Xq_Wq_dtypes85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3276576Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype86-Xq_Wq_dtypes86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3278069Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype87-Xq_Wq_dtypes87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3279553Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype88-Xq_Wq_dtypes88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3280966Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype89-Xq_Wq_dtypes89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3282454Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype90-Xq_Wq_dtypes90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3283875Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype91-Xq_Wq_dtypes91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3285296Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype92-Xq_Wq_dtypes92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3286714Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype93-Xq_Wq_dtypes93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3288132Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype94-Xq_Wq_dtypes94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3289555Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype95-Xq_Wq_dtypes95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3291035Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype96-Xq_Wq_dtypes96-1-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3442856Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype97-Xq_Wq_dtypes97-1-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3444308Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype98-Xq_Wq_dtypes98-1-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3445816Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype99-Xq_Wq_dtypes99-1-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3447251Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype100-Xq_Wq_dtypes100-1-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3448712Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype101-Xq_Wq_dtypes101-1-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3450241Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype102-Xq_Wq_dtypes102-1-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3451706Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype103-Xq_Wq_dtypes103-1-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3453174Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype104-Xq_Wq_dtypes104-1-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3454639Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype105-Xq_Wq_dtypes105-1-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3456096Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype106-Xq_Wq_dtypes106-1-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3457554Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype107-Xq_Wq_dtypes107-1-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3459013Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype108-Xq_Wq_dtypes108-4-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3460618Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype109-Xq_Wq_dtypes109-4-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3462083Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype110-Xq_Wq_dtypes110-4-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3463547Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype111-Xq_Wq_dtypes111-4-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3465059Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype112-Xq_Wq_dtypes112-4-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3466517Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype113-Xq_Wq_dtypes113-4-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3467970Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype114-Xq_Wq_dtypes114-4-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3469428Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype115-Xq_Wq_dtypes115-4-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3470878Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype116-Xq_Wq_dtypes116-4-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3472341Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype117-Xq_Wq_dtypes117-4-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3473847Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype118-Xq_Wq_dtypes118-4-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3475464Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype119-Xq_Wq_dtypes119-4-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3476994Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype120-Xq_Wq_dtypes120-1-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3478459Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype121-Xq_Wq_dtypes121-1-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3479919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype122-Xq_Wq_dtypes122-1-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3481376Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype123-Xq_Wq_dtypes123-1-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3482837Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype124-Xq_Wq_dtypes124-1-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3484305Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype125-Xq_Wq_dtypes125-1-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3485758Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype126-Xq_Wq_dtypes126-1-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3487216Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype127-Xq_Wq_dtypes127-1-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3488671Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype128-Xq_Wq_dtypes128-1-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3490191Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype129-Xq_Wq_dtypes129-1-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3491781Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype130-Xq_Wq_dtypes130-1-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3493234Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype131-Xq_Wq_dtypes131-1-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3494697Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype132-Xq_Wq_dtypes132-4-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3496218Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype133-Xq_Wq_dtypes133-4-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3497677Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype134-Xq_Wq_dtypes134-4-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3499144Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype135-Xq_Wq_dtypes135-4-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3500606Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype136-Xq_Wq_dtypes136-4-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3502058Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype137-Xq_Wq_dtypes137-4-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3503572Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype138-Xq_Wq_dtypes138-4-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3505028Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype139-Xq_Wq_dtypes139-4-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3506499Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype140-Xq_Wq_dtypes140-4-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3508015Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype141-Xq_Wq_dtypes141-4-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3509469Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype142-Xq_Wq_dtypes142-4-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3510929Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype143-Xq_Wq_dtypes143-4-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3512391Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype144-Xq_Wq_dtypes144-1-size_mnk144-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3513843Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype145-Xq_Wq_dtypes145-1-size_mnk145-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3862969Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype146-Xq_Wq_dtypes146-1-size_mnk146-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3864645Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype147-Xq_Wq_dtypes147-1-size_mnk147-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3866115Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype148-Xq_Wq_dtypes148-1-size_mnk148-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3867590Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype149-Xq_Wq_dtypes149-1-size_mnk149-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3869051Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype150-Xq_Wq_dtypes150-1-size_mnk150-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3870643Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype151-Xq_Wq_dtypes151-1-size_mnk151-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3872181Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype152-Xq_Wq_dtypes152-1-size_mnk152-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3873651Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype153-Xq_Wq_dtypes153-1-size_mnk153-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3875544Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype154-Xq_Wq_dtypes154-1-size_mnk154-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3877329Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype155-Xq_Wq_dtypes155-1-size_mnk155-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3878991Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype156-Xq_Wq_dtypes156-4-size_mnk156-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3880940Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype157-Xq_Wq_dtypes157-4-size_mnk157-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3882676Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype158-Xq_Wq_dtypes158-4-size_mnk158-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3884188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype159-Xq_Wq_dtypes159-4-size_mnk159-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3885673Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype160-Xq_Wq_dtypes160-4-size_mnk160-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3887154Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype161-Xq_Wq_dtypes161-4-size_mnk161-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3888751Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype162-Xq_Wq_dtypes162-4-size_mnk162-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3890348Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype163-Xq_Wq_dtypes163-4-size_mnk163-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3891828Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype164-Xq_Wq_dtypes164-4-size_mnk164-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3893358Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype165-Xq_Wq_dtypes165-4-size_mnk165-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3894842Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype166-Xq_Wq_dtypes166-4-size_mnk166-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3896344Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype167-Xq_Wq_dtypes167-4-size_mnk167-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3897825Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype168-Xq_Wq_dtypes168-1-size_mnk168-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3899308Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype169-Xq_Wq_dtypes169-1-size_mnk169-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3900797Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype170-Xq_Wq_dtypes170-1-size_mnk170-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3902270Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype171-Xq_Wq_dtypes171-1-size_mnk171-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3903826Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype172-Xq_Wq_dtypes172-1-size_mnk172-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3905366Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype173-Xq_Wq_dtypes173-1-size_mnk173-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3906841Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype174-Xq_Wq_dtypes174-1-size_mnk174-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3908378Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype175-Xq_Wq_dtypes175-1-size_mnk175-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3909854Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype176-Xq_Wq_dtypes176-1-size_mnk176-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3911331Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype177-Xq_Wq_dtypes177-1-size_mnk177-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3912870Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype178-Xq_Wq_dtypes178-1-size_mnk178-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3914342Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype179-Xq_Wq_dtypes179-1-size_mnk179-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3915829Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype180-Xq_Wq_dtypes180-4-size_mnk180-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3917312Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype181-Xq_Wq_dtypes181-4-size_mnk181-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3918790Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype182-Xq_Wq_dtypes182-4-size_mnk182-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3921227Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype183-Xq_Wq_dtypes183-4-size_mnk183-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3922754Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype184-Xq_Wq_dtypes184-4-size_mnk184-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3924254Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype185-Xq_Wq_dtypes185-4-size_mnk185-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3925738Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype186-Xq_Wq_dtypes186-4-size_mnk186-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3927216Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype187-Xq_Wq_dtypes187-4-size_mnk187-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3928693Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype188-Xq_Wq_dtypes188-4-size_mnk188-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3930227Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype189-Xq_Wq_dtypes189-4-size_mnk189-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3931703Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype190-Xq_Wq_dtypes190-4-size_mnk190-False] [33mSKIPPED[0m
2026-01-14T09:22:19.3933185Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype191-Xq_Wq_dtypes191-4-size_mnk191-True] [33mSKIPPED[0m
2026-01-14T09:22:19.3934268Z test/test_utils.py::TestTorchVersion::test_torch_version_at_least [32mPASSED[0m
2026-01-14T09:22:19.3934978Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls [32mPASSED[0m
2026-01-14T09:22:19.3935775Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_attr [32mPASSED[0m
2026-01-14T09:22:19.3936744Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_data [32mPASSED[0m
2026-01-14T09:22:19.3937660Z test/test_utils.py::TestTorchAOBaseTensor::test_implements_and_torch_function_together [32mPASSED[0m
2026-01-14T09:22:19.3938492Z test/test_utils.py::TestTorchAOBaseTensor::test_print_arg_types [32mPASSED[0m
2026-01-14T09:22:19.3938881Z 
2026-01-14T09:22:19.3939188Z [33m=============================== warnings summary ===============================[0m
2026-01-14T09:22:19.3939841Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1
2026-01-14T09:22:19.3942046Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1: DeprecationWarning: Importing from torchao.dtypes.uintx.dyn_int8_act_int4_wei_cpu_layout is deprecated. Please use 'from torchao.prototype.dtypes import Int8DynamicActInt4WeightCPULayout' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3944073Z     from .dyn_int8_act_int4_wei_cpu_layout import (
2026-01-14T09:22:19.3944335Z 
2026-01-14T09:22:19.3944625Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22
2026-01-14T09:22:19.3946661Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22: DeprecationWarning: Importing from torchao.dtypes.uintx.uintx_layout is deprecated. Please use 'from torchao.prototype.dtypes import UintxLayout, UintxTensor' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3948488Z     from .uintx_layout import (
2026-01-14T09:22:19.3948676Z 
2026-01-14T09:22:19.3948942Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23
2026-01-14T09:22:19.3951008Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23: DeprecationWarning: Importing BlockSparseLayout from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import BlockSparseLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:22:19.3952973Z     from .uintx.block_sparse_layout import BlockSparseLayout
2026-01-14T09:22:19.3953271Z 
2026-01-14T09:22:19.3953538Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24
2026-01-14T09:22:19.3955489Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24: DeprecationWarning: Importing from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import CutlassInt4PackedLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:22:19.3957398Z     from .uintx.cutlass_int4_packed_layout import CutlassInt4PackedLayout
2026-01-14T09:22:19.3957755Z 
2026-01-14T09:22:19.3958167Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: 2 warnings
2026-01-14T09:22:19.3958816Z test/core/test_config.py: 2 warnings
2026-01-14T09:22:19.3959127Z test/dtypes/test_uintx.py: 84 warnings
2026-01-14T09:22:19.3959440Z test/hqq/test_hqq_affine.py: 6 warnings
2026-01-14T09:22:19.3960704Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: UserWarning: `UIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3961956Z     warnings.warn(
2026-01-14T09:22:19.3962102Z 
2026-01-14T09:22:19.3962459Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:22:19.3963354Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:22:19.3964166Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7]
2026-01-14T09:22:19.3964837Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module
2026-01-14T09:22:19.3965506Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only
2026-01-14T09:22:19.3966276Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16
2026-01-14T09:22:19.3967978Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209: UserWarning: `Int4DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3969314Z     warnings.warn(
2026-01-14T09:22:19.3969458Z 
2026-01-14T09:22:19.3969921Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: 3 warnings
2026-01-14T09:22:19.3970563Z test/core/test_config.py: 2 warnings
2026-01-14T09:22:19.3970902Z test/dtypes/test_affine_quantized.py: 4 warnings
2026-01-14T09:22:19.3971288Z test/integration/test_integration.py: 6 warnings
2026-01-14T09:22:19.3971645Z test/quantization/test_qat.py: 6 warnings
2026-01-14T09:22:19.3971997Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:22:19.3973367Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: UserWarning: `Int8DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3974944Z     warnings.warn(
2026-01-14T09:22:19.3975083Z 
2026-01-14T09:22:19.3975442Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:22:19.3976285Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:22:19.3977025Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14]
2026-01-14T09:22:19.3978560Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272: UserWarning: `GemliteUIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3979854Z     warnings.warn(
2026-01-14T09:22:19.3979990Z 
2026-01-14T09:22:19.3980356Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: 1 warning
2026-01-14T09:22:19.3980939Z test/core/test_config.py: 1 warning
2026-01-14T09:22:19.3981251Z test/prototype/test_parq.py: 25 warnings
2026-01-14T09:22:19.3981597Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:22:19.3982936Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: UserWarning: Config Deprecation: _default is deprecated and will no longer be supported in a future release. Please see https://github.com/pytorch/ao/issues/3229 for more details.
2026-01-14T09:22:19.3984242Z     warnings.warn(
2026-01-14T09:22:19.3984381Z 
2026-01-14T09:22:19.3984738Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360
2026-01-14T09:22:19.3986622Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360: UserWarning: `Float8StaticActivationFloat8WeightConfig` version 1 will be deleted in a future release of torchao. Please migrate to version 2 by setting version=2. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:22:19.3988220Z     warnings.warn(
2026-01-14T09:22:19.3988358Z 
2026-01-14T09:22:19.3988489Z test/dtypes/test_affine_quantized.py: 7 warnings
2026-01-14T09:22:19.3988876Z test/integration/test_integration.py: 52 warnings
2026-01-14T09:22:19.3989257Z test/quantization/test_quant_api.py: 8 warnings
2026-01-14T09:22:19.3990825Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T09:22:19.3992337Z     warnings.warn(
2026-01-14T09:22:19.3992481Z 
2026-01-14T09:22:19.3992616Z test/dtypes/test_affine_quantized.py: 10 warnings
2026-01-14T09:22:19.3993032Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:22:19.3993374Z test/integration/test_integration.py: 18 warnings
2026-01-14T09:22:19.3993756Z test/quantization/test_quant_api.py: 17 warnings
2026-01-14T09:22:19.3995243Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:827: UserWarning: Config Deprecation: version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:22:19.3996868Z     warnings.warn(
2026-01-14T09:22:19.3997005Z 
2026-01-14T09:22:19.3997146Z test/dtypes/test_affine_quantized.py: 9 warnings
2026-01-14T09:22:19.3997500Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:22:19.3997846Z test/integration/test_integration.py: 96 warnings
2026-01-14T09:22:19.3998224Z test/quantization/test_quant_api.py: 5 warnings
2026-01-14T09:22:19.4000067Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:241: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:22:19.4001873Z     warnings.warn(
2026-01-14T09:22:19.4002009Z 
2026-01-14T09:22:19.4002143Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T09:22:19.4002556Z test/integration/test_integration.py: 31 warnings
2026-01-14T09:22:19.4002967Z test/quantization/test_quant_api.py: 108 warnings
2026-01-14T09:22:19.4004811Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/int4_cpu_layout.py:82: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:22:19.4006570Z     warnings.warn(
2026-01-14T09:22:19.4006704Z 
2026-01-14T09:22:19.4006897Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:22:19.4007383Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:22:19.4007853Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:22:19.4009359Z   /pytorch/ao/test/dtypes/test_nf4.py:224: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:22:19.4010995Z     torch.testing.assert_allclose(input_tensor, nf4_to_dtype, atol=0.13, rtol=0.13)
2026-01-14T09:22:19.4011391Z 
2026-01-14T09:22:19.4011580Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:22:19.4012064Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:22:19.4012575Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:22:19.4014085Z   /pytorch/ao/test/dtypes/test_nf4.py:230: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:22:19.4015516Z     torch.testing.assert_allclose(
2026-01-14T09:22:19.4015716Z 
2026-01-14T09:22:19.4015821Z test/float8/test_base.py: 36 warnings
2026-01-14T09:22:19.4017250Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/float8/float8_linear.py:261: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:826.)
2026-01-14T09:22:19.4018642Z     autocast_dtype = torch.get_autocast_gpu_dtype()
2026-01-14T09:22:19.4018898Z 
2026-01-14T09:22:19.4019169Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda
2026-01-14T09:22:19.4019694Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda
2026-01-14T09:22:19.4021244Z   /pytorch/ao/test/kernel/test_autotuner.py:50: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:22:19.4022738Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:22:19.4022998Z 
2026-01-14T09:22:19.4023236Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda
2026-01-14T09:22:19.4023811Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu
2026-01-14T09:22:19.4024382Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda
2026-01-14T09:22:19.4024944Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu
2026-01-14T09:22:19.4026529Z   /pytorch/ao/test/kernel/test_autotuner.py:96: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:22:19.4028014Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:22:19.4028268Z 
2026-01-14T09:22:19.4028602Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook
2026-01-14T09:22:19.4030146Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py:903: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1531.)
2026-01-14T09:22:19.4031403Z     return callable(*args, **kwargs)
2026-01-14T09:22:19.4031608Z 
2026-01-14T09:22:19.4031850Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T09:22:19.4033749Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/sparsifier/utils.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
2026-01-14T09:22:19.4035454Z     assert self.mask.shape == x.shape
2026-01-14T09:22:19.4035663Z 
2026-01-14T09:22:19.4035891Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler
2026-01-14T09:22:19.4036454Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step
2026-01-14T09:22:19.4037913Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/scheduler/base_scheduler.py:133: UserWarning: Detected call of `scheduler.step()` before `sparsifier.step()`. You have to make sure you run the sparsifier.step() BEFORE any calls to the scheduler.step().
2026-01-14T09:22:19.4039266Z     warnings.warn(
2026-01-14T09:22:19.4039401Z 
2026-01-14T09:22:19.4039686Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu
2026-01-14T09:22:19.4041227Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:42: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:22:19.4042679Z     m, guards = torchdynamo.export(  # noqa: F841©
2026-01-14T09:22:19.4043064Z 
2026-01-14T09:22:19.4043345Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu
2026-01-14T09:22:19.4044863Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:86: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:22:19.4046300Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:22:19.4046546Z 
2026-01-14T09:22:19.4046892Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict
2026-01-14T09:22:19.4048497Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:118: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:22:19.4049956Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:22:19.4050203Z 
2026-01-14T09:22:19.4050379Z test/quantization/pt2e/test_quantize_pt2e.py: 18 warnings
2026-01-14T09:22:19.4050861Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 88 warnings
2026-01-14T09:22:19.4051341Z test/quantization/pt2e/test_representation.py: 8 warnings
2026-01-14T09:22:19.4052181Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/_xnnpack_quantizer.py:289: UserWarning: XNNPACKQuantizer is deprecated!
2026-01-14T09:22:19.4053043Z     warnings.warn(f"{self.__class__.__name__} is deprecated!")
2026-01-14T09:22:19.4053339Z 
2026-01-14T09:22:19.4053681Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize
2026-01-14T09:22:19.4054538Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2
2026-01-14T09:22:19.4056592Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/export/_unlift.py:81: UserWarning: Attempted to insert a get_attr Node with no underlying reference in the owning GraphModule! Call GraphModule.add_submodule to add the necessary submodule, GraphModule.add_parameter to add the necessary Parameter, or nn.Module.register_buffer to add the necessary buffer
2026-01-14T09:22:19.4058327Z     getattr_node = gm.graph.get_attr(lifted_node)
2026-01-14T09:22:19.4058578Z 
2026-01-14T09:22:19.4058925Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize
2026-01-14T09:22:19.4060292Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/graph.py:1772: UserWarning: Node weight target weight weight of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
2026-01-14T09:22:19.4061386Z     warnings.warn(
2026-01-14T09:22:19.4061525Z 
2026-01-14T09:22:19.4061823Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported
2026-01-14T09:22:19.4063406Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:910: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.
2026-01-14T09:22:19.4064714Z     warnings.warn(
2026-01-14T09:22:19.4064848Z 
2026-01-14T09:22:19.4065118Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:22:19.4065892Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node
2026-01-14T09:22:19.4066791Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node
2026-01-14T09:22:19.4068019Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:145: UserWarning: must run observer before calling calculate_qparams. Returning default values.
2026-01-14T09:22:19.4068990Z     warnings.warn(
2026-01-14T09:22:19.4069125Z 
2026-01-14T09:22:19.4069435Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:22:19.4070693Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:1360: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point 
2026-01-14T09:22:19.4071772Z     warnings.warn(
2026-01-14T09:22:19.4071951Z 
2026-01-14T09:22:19.4072389Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:22:19.4073441Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:22:19.4074471Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:22:19.4075619Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:22:19.4076625Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:22:19.4077648Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:22:19.4078571Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec
2026-01-14T09:22:19.4080052Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:263: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
2026-01-14T09:22:19.4081260Z     warnings.warn(
2026-01-14T09:22:19.4081395Z 
2026-01-14T09:22:19.4081802Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe
2026-01-14T09:22:19.4087169Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:1325: UserWarning: The input of maxpool2d is not quantized, skip annotate maxpool2d with config QuantizationConfig(input_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), output_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), weight=QuantizationSpec(dtype=torch.int8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.PerChannelMinMaxObserver'>, eps=0.000244140625){}, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, ch_axis=0, is_dynamic=False), bias=None, is_qat=False).
2026-01-14T09:22:19.4092365Z     warnings.warn(
2026-01-14T09:22:19.4092524Z 
2026-01-14T09:22:19.4092938Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2
2026-01-14T09:22:19.4094364Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/graph.py:1772: UserWarning: Node cls_token target cls_token cls_token of  does not reference an nn.Module, nn.Parameter, or buffer, which is what 'get_attr' Nodes typically target
2026-01-14T09:22:19.4095498Z     warnings.warn(
2026-01-14T09:22:19.4095632Z 
2026-01-14T09:22:19.4096173Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:22:19.4097621Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:484: UserWarning: Mixed dynamic and static quantization config is not supported.
2026-01-14T09:22:19.4098673Z     warnings.warn(
2026-01-14T09:22:19.4098861Z 
2026-01-14T09:22:19.4099409Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:22:19.4100912Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:383: UserWarning: Skip the quantization config for <class 'torch.nn.modules.linear.Linear'>.
2026-01-14T09:22:19.4102013Z     warnings.warn(
2026-01-14T09:22:19.4102149Z 
2026-01-14T09:22:19.4102372Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:22:19.4103723Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'IntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:22:19.4104883Z   
2026-01-14T09:22:19.4105216Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:22:19.4105750Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:22:19.4106131Z       # train (not shown)
2026-01-14T09:22:19.4106461Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:22:19.4106815Z   
2026-01-14T09:22:19.4107128Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:22:19.4107529Z   
2026-01-14T09:22:19.4107952Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:22:19.4108606Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:22:19.4109032Z       qat_config = QATConfig(
2026-01-14T09:22:19.4109324Z           activation_config=activation_config,
2026-01-14T09:22:19.4109649Z           weight_config=weight_config,
2026-01-14T09:22:19.4109943Z           step="prepare",
2026-01-14T09:22:19.4110174Z       )
2026-01-14T09:22:19.4110381Z       quantize_(model, qat_config)
2026-01-14T09:22:19.4110642Z   
2026-01-14T09:22:19.4110968Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:22:19.4111433Z           
2026-01-14T09:22:19.4111634Z     warnings.warn(
2026-01-14T09:22:19.4111770Z 
2026-01-14T09:22:19.4111998Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:22:19.4113374Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'FromIntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:22:19.4114559Z   
2026-01-14T09:22:19.4114883Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:22:19.4115409Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:22:19.4115781Z       # train (not shown)
2026-01-14T09:22:19.4116107Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:22:19.4116473Z   
2026-01-14T09:22:19.4116783Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:22:19.4117190Z   
2026-01-14T09:22:19.4117605Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:22:19.4118264Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:22:19.4118687Z       qat_config = QATConfig(
2026-01-14T09:22:19.4118981Z           activation_config=activation_config,
2026-01-14T09:22:19.4119307Z           weight_config=weight_config,
2026-01-14T09:22:19.4119601Z           step="prepare",
2026-01-14T09:22:19.4119834Z       )
2026-01-14T09:22:19.4120033Z       quantize_(model, qat_config)
2026-01-14T09:22:19.4120292Z   
2026-01-14T09:22:19.4120604Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:22:19.4121022Z           
2026-01-14T09:22:19.4121218Z     warnings.warn(
2026-01-14T09:22:19.4121364Z 
2026-01-14T09:22:19.4121764Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:22:19.4123795Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/blocksparse.py:198: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)
2026-01-14T09:22:19.4125586Z     bsr_tensor = dense_tensor.to_sparse_bsr(blocksize)
2026-01-14T09:22:19.4125856Z 
2026-01-14T09:22:19.4126199Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:22:19.4127918Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4129371Z     warn_once(
2026-01-14T09:22:19.4140695Z 
2026-01-14T09:22:19.4141098Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:22:19.4142840Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4144346Z     warn_once(
2026-01-14T09:22:19.4144473Z 
2026-01-14T09:22:19.4144834Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:22:19.4146584Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4148041Z     warn_once(
2026-01-14T09:22:19.4148239Z 
2026-01-14T09:22:19.4148600Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:22:19.4150339Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4151795Z     warn_once(
2026-01-14T09:22:19.4151918Z 
2026-01-14T09:22:19.4152221Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:22:19.4153938Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=256 K=128 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4155366Z     warn_once(
2026-01-14T09:22:19.4155487Z 
2026-01-14T09:22:19.4155784Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:22:19.4157439Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=128 K=256 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:22:19.4158869Z     warn_once(
2026-01-14T09:22:19.4158993Z 
2026-01-14T09:23:01.4580376Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T09:23:01.4582079Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:46: UserWarning: WandaSparsifier got semi_structured_bock_size=4, sparsity_level fixed to 50% (2:4) sparsity
2026-01-14T09:23:01.4583122Z     warnings.warn(
2026-01-14T09:23:01.4583281Z 
2026-01-14T09:23:01.4583528Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-14T09:23:01.4584604Z [33m======== [32m1921 passed[0m, [33m[1m4049 skipped[0m, [33m[1m722 warnings[0m[33m in 3025.49s (0:50:25)[0m[33m =========[0m
2026-01-14T09:23:01.4687823Z ##[group]Run pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1
2026-01-14T09:23:01.4688461Z with:
2026-01-14T09:23:01.4688763Z   path: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:01.4689165Z   fail-on-empty: false
2026-01-14T09:23:01.4689393Z env:
2026-01-14T09:23:01.4689645Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:01.4690088Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:01.4690348Z   PR_NUMBER: 3500
2026-01-14T09:23:01.4692018Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:01.4693917Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:01.4694516Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:01.4695094Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:01.4695491Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:01.4695806Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:01.4696168Z ##[endgroup]
2026-01-14T09:23:01.5305473Z Prepare all required actions
2026-01-14T09:23:01.5349801Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:23:01.5350168Z with:
2026-01-14T09:23:01.5350453Z   directory: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:23:01.5350949Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:23:01.5351385Z env:
2026-01-14T09:23:01.5351636Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:01.5351999Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:01.5352251Z   PR_NUMBER: 3500
2026-01-14T09:23:01.5353940Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:01.5355921Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:01.5356526Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:01.5357112Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:01.5357514Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:01.5357837Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:01.5358204Z ##[endgroup]
2026-01-14T09:23:01.5385204Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:23:01.5385936Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:23:01.5400318Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:23:01.5400678Z env:
2026-01-14T09:23:01.5400943Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:01.5401293Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:01.5401555Z   PR_NUMBER: 3500
2026-01-14T09:23:01.5403216Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:01.5405198Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:01.5405852Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:01.5406493Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:01.5406883Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:01.5407187Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:01.5407677Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:23:01.5408181Z   DIRECTORY: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:23:01.5408519Z ##[endgroup]
2026-01-14T09:23:01.5664342Z Unable to find image '308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest' locally
2026-01-14T09:23:01.7809505Z latest: Pulling from tool/alpine
2026-01-14T09:23:01.7810537Z 540db60ca938: Pulling fs layer
2026-01-14T09:23:01.8613253Z 540db60ca938: Download complete
2026-01-14T09:23:01.9774088Z 540db60ca938: Pull complete
2026-01-14T09:23:01.9886470Z Digest: sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:23:01.9928333Z Status: Downloaded newer image for 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:23:03.2011912Z Prepare all required actions
2026-01-14T09:23:03.2043715Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:23:03.2044084Z with:
2026-01-14T09:23:03.2044361Z   directory: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:23:03.2044857Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:23:03.2045299Z env:
2026-01-14T09:23:03.2045549Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:03.2045919Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:03.2046180Z   PR_NUMBER: 3500
2026-01-14T09:23:03.2047865Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:03.2049855Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:03.2050461Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:03.2051037Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:03.2051445Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:03.2051757Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:03.2052123Z ##[endgroup]
2026-01-14T09:23:03.2086384Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:23:03.2087125Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:23:03.2102874Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:23:03.2103239Z env:
2026-01-14T09:23:03.2103483Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:03.2103843Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:03.2104102Z   PR_NUMBER: 3500
2026-01-14T09:23:03.2105766Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:03.2107634Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:03.2108354Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:03.2108915Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:03.2109321Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:03.2109629Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:03.2110136Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:23:03.2110714Z   DIRECTORY: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:23:03.2111057Z ##[endgroup]
2026-01-14T09:23:04.1793971Z ##[group]Run # Only do these steps if we actually want to upload an artifact
2026-01-14T09:23:04.1794595Z [36;1m# Only do these steps if we actually want to upload an artifact[0m
2026-01-14T09:23:04.1795076Z [36;1mif [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then[0m
2026-01-14T09:23:04.1795645Z [36;1m  # If the default execution path is followed then we should get a wheel in the dist/ folder[0m
2026-01-14T09:23:04.1796320Z [36;1m  # attempt to just grab whatever is in there and scoop it all up[0m
2026-01-14T09:23:04.1796852Z [36;1m  if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then[0m
2026-01-14T09:23:04.1797296Z [36;1m    mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:23:04.1797651Z [36;1m  fi[0m
2026-01-14T09:23:04.1797933Z [36;1m  if [[ -d "artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:23:04.1798410Z [36;1m    mv -v artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:23:04.1798828Z [36;1m  fi[0m
2026-01-14T09:23:04.1799167Z [36;1m  if [[ -d "${RUNNER_TEMP}/artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:23:04.1799731Z [36;1m    mv -v "${RUNNER_TEMP}"/artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:23:04.1800217Z [36;1m  fi[0m
2026-01-14T09:23:04.1800418Z [36;1mfi[0m
2026-01-14T09:23:04.1800625Z [36;1m[0m
2026-01-14T09:23:04.1800834Z [36;1mupload_docs=0[0m
2026-01-14T09:23:04.1801239Z [36;1m# Check if there are files in the documentation folder to upload, note that[0m
2026-01-14T09:23:04.1801733Z [36;1m# empty folders do not count[0m
2026-01-14T09:23:04.1802188Z [36;1mif find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 -type f | read -r; then[0m
2026-01-14T09:23:04.1802828Z [36;1m  # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this[0m
2026-01-14T09:23:04.1803350Z [36;1m  # upload will probably not work correctly[0m
2026-01-14T09:23:04.1803712Z [36;1m  upload_docs=1[0m
2026-01-14T09:23:04.1803964Z [36;1mfi[0m
2026-01-14T09:23:04.1804270Z [36;1mecho "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T09:23:04.1813522Z shell: /usr/bin/bash -e {0}
2026-01-14T09:23:04.1813774Z env:
2026-01-14T09:23:04.1814037Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:04.1814392Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:04.1814651Z   PR_NUMBER: 3500
2026-01-14T09:23:04.1816318Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:04.1818204Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:04.1818811Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:04.1819378Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:04.1819790Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:04.1820107Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:04.1820471Z   UPLOAD_ARTIFACT_NAME: 
2026-01-14T09:23:04.1820729Z ##[endgroup]
2026-01-14T09:23:04.1947556Z Prepare all required actions
2026-01-14T09:23:04.1988592Z ##[group]Run ./test-infra/.github/actions/teardown-linux
2026-01-14T09:23:04.1989071Z with:
2026-01-14T09:23:04.1989252Z env:
2026-01-14T09:23:04.1989503Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:04.1989856Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:04.1990105Z   PR_NUMBER: 3500
2026-01-14T09:23:04.1991764Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:04.1993714Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:04.1994340Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:04.1994900Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:04.1995296Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:04.1995610Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:04.1996002Z ##[endgroup]
2026-01-14T09:23:04.2021352Z ##[group]Run set -eou pipefail
2026-01-14T09:23:04.2021651Z [36;1mset -eou pipefail[0m
2026-01-14T09:23:04.2021911Z [36;1m[0m
2026-01-14T09:23:04.2022280Z [36;1mecho "Holding runner for 2 hours until all ssh sessions have logged out"[0m
2026-01-14T09:23:04.2022760Z [36;1mfor _ in $(seq 1440); do[0m
2026-01-14T09:23:04.2023103Z [36;1m    # Break if no ssh session exists anymore[0m
2026-01-14T09:23:04.2023448Z [36;1m    if [ "$(who)" = "" ]; then[0m
2026-01-14T09:23:04.2023741Z [36;1m      break[0m
2026-01-14T09:23:04.2023962Z [36;1m    fi[0m
2026-01-14T09:23:04.2024178Z [36;1m    echo "."[0m
2026-01-14T09:23:04.2024408Z [36;1m    sleep 5[0m
2026-01-14T09:23:04.2024646Z [36;1mdone[0m
2026-01-14T09:23:04.2033646Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:23:04.2034017Z env:
2026-01-14T09:23:04.2034268Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:04.2034627Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:04.2034872Z   PR_NUMBER: 3500
2026-01-14T09:23:04.2036842Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:04.2038845Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:04.2039448Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:04.2040018Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:04.2040419Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:04.2040727Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:04.2041090Z ##[endgroup]
2026-01-14T09:23:04.2071300Z Holding runner for 2 hours until all ssh sessions have logged out
2026-01-14T09:23:04.2167441Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T09:23:04.2168017Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T09:23:04.2168456Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T09:23:04.2168785Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T09:23:04.2169141Z [36;1m# Prune all of the docker images[0m
2026-01-14T09:23:04.2169470Z [36;1mdocker system prune -af[0m
2026-01-14T09:23:04.2179076Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:23:04.2179449Z env:
2026-01-14T09:23:04.2179703Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:04.2180280Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:04.2180544Z   PR_NUMBER: 3500
2026-01-14T09:23:04.2182221Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:04.2184207Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:04.2184806Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:04.2185467Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:04.2185865Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:04.2186179Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:04.2186541Z ##[endgroup]
2026-01-14T09:23:05.7627861Z 0d27adf25a38
2026-01-14T09:23:12.8215389Z Deleted Containers:
2026-01-14T09:23:12.8215799Z 0d27adf25a38e1a64debb637d15a1e61ad304be7eef367fecb8976cebad085fb
2026-01-14T09:23:12.8216145Z 
2026-01-14T09:23:21.1312810Z Deleted Images:
2026-01-14T09:23:21.1313152Z untagged: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:21.1313814Z untagged: pytorch/almalinux-builder@sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T09:23:21.1314612Z deleted: sha256:bb1a1950b861327b13d8893bffd39e26f8e80f9318971babe6b3f9bab8d65d21
2026-01-14T09:23:21.1315270Z deleted: sha256:a54dbc7bc094481efb3d7798f26feac4f04f2c7d3b16372162cacf83ed2388ce
2026-01-14T09:23:21.1315949Z deleted: sha256:645a24a13a583a58c04ea348b38daba4a40b2bbe09eb2012e9d33e823ff99c8e
2026-01-14T09:23:21.1316584Z deleted: sha256:74c5765839aa7e92b734630a11e6a02dc4f9932142efb4becedf62941283e0cd
2026-01-14T09:23:21.1317233Z deleted: sha256:7a626ac79b7f4d3436fb97d7a7ca125845805c133303239c31f4eed62b556453
2026-01-14T09:23:21.1317879Z deleted: sha256:31c03ed8c3f72312100269f048fea1b331a93b53b496ce34be4bac621109f901
2026-01-14T09:23:21.1318527Z deleted: sha256:c32b905bbd58816c78ef90a77285dd4d9b1cdafdbaa7332cd398891b30feee8e
2026-01-14T09:23:21.1319192Z deleted: sha256:4dc58665c3bd3ca188c201fdcfdeb41b0118191cd6843ddeda62495ba0c15986
2026-01-14T09:23:21.1319838Z deleted: sha256:dad808738bccf06931c05520f69d148be75a61afd28065e9aee100d5af6133bd
2026-01-14T09:23:21.1320473Z deleted: sha256:6e036a485561034f6c52610c6a2c7f11e64060ce9e2f10b3d4064a87d091745a
2026-01-14T09:23:21.1321110Z deleted: sha256:ef2ba6b1ca100c37739c13afedd9c52143448d948239c375f611f5bbe19f175d
2026-01-14T09:23:21.1321778Z deleted: sha256:37d850998e8d82d40ffce6b7020d480daecaa091b6fbac01c04a0da1f90f7e8f
2026-01-14T09:23:21.1322426Z deleted: sha256:16a70495db3a28a89c3250c0824d0e3e08c22dced61a31110ef1c7f8c5b127cd
2026-01-14T09:23:21.1323062Z deleted: sha256:b7982627380d2b6bc6a223770c8c18cb45dcc8229c32e1160fcb416a32fc969a
2026-01-14T09:23:21.1323699Z deleted: sha256:a4d99473e3f02923cf34c61996bf5a25863e8ee02801d6634174d671e0ac7367
2026-01-14T09:23:21.1324329Z deleted: sha256:2c683ce33d69b13bbcfe1f405137ff2aea4213c8228876ff55a791116cdcf2e2
2026-01-14T09:23:21.1324980Z deleted: sha256:ffaa389b629375310a946fd02f2f26fcf3678b2c23d94f4aab82a0fc46214892
2026-01-14T09:23:21.1325628Z deleted: sha256:e7ce15ca67e07966f2da85c8d2242c7535a7c9ab1f63b2069834ffba95a5978c
2026-01-14T09:23:21.1326272Z deleted: sha256:63b0fcbf70a9ee9ece0aeb6610359975830e1646da68f5f7722c2e64426bd4c7
2026-01-14T09:23:21.1326921Z deleted: sha256:5c48134bdee035683ad0d4846f19aa135bd7b8735e8c0b6420d13e5779f720e4
2026-01-14T09:23:21.1327561Z deleted: sha256:badca1798f4ace2b0179b607780a5cce32170bedeb23d076335fc973ec72f34c
2026-01-14T09:23:21.1328215Z deleted: sha256:ae88b0e9396996f876f32bf01d80534d3cf5c06c395eba64f7dd66dda56fa55f
2026-01-14T09:23:21.1328858Z deleted: sha256:b52e19c766f22b187f4fcd4e90cfb1e4e3c547dfe7484bf5423db65775cf352f
2026-01-14T09:23:21.1329514Z deleted: sha256:1d80070b73e86e9afa159ca72ee6fc6bcf7f387d21c1d6dcd065fa877e678592
2026-01-14T09:23:21.1330903Z deleted: sha256:ff4f19608a1944c0c2807cd533515673285a9632dc74bf020e83e18630d1ae35
2026-01-14T09:23:21.1331445Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T09:23:21.1332330Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T09:23:21.1333242Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T09:23:21.1333958Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T09:23:21.1334666Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T09:23:21.1335473Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T09:23:21.1336184Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T09:23:21.1336883Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T09:23:21.1337620Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T09:23:21.1338355Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T09:23:21.1339056Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:23:21.1340038Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine@sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:23:21.1341050Z deleted: sha256:6dbb9cc54074106d46d4ccb330f2a40a682d49dda5f4844962b7dce9fe44aaec
2026-01-14T09:23:21.1341781Z deleted: sha256:b2d5eeeaba3a22b9b8aa97261957974a6bd65274ebd43e1d81d0a7b8b752b116
2026-01-14T09:23:21.1342223Z 
2026-01-14T09:23:21.1342337Z Total reclaimed space: 27.66GB
2026-01-14T09:23:21.1431069Z ##[group]Run set +e
2026-01-14T09:23:21.1431346Z [36;1mset +e[0m
2026-01-14T09:23:21.1431600Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T09:23:21.1432013Z [36;1m  sudo rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:23:21.1432385Z [36;1melse[0m
2026-01-14T09:23:21.1432656Z [36;1m  rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:23:21.1433014Z [36;1mfi[0m
2026-01-14T09:23:21.1433210Z [36;1mset -e[0m
2026-01-14T09:23:21.1442881Z shell: /usr/bin/bash -e {0}
2026-01-14T09:23:21.1443132Z env:
2026-01-14T09:23:21.1443380Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:23:21.1443738Z   REPOSITORY: pytorch/ao
2026-01-14T09:23:21.1443983Z   PR_NUMBER: 3500
2026-01-14T09:23:21.1445666Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.7.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:23:21.1447540Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:23:21.1448130Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:23:21.1448689Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:23:21.1449081Z   HAS_NVIDIA_GPU: true
2026-01-14T09:23:21.1449391Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:23:21.1449815Z   NO_SUDO: false
2026-01-14T09:23:21.1450027Z ##[endgroup]
2026-01-14T09:23:21.6907987Z Post job cleanup.
2026-01-14T09:23:21.8016272Z Post job cleanup.
2026-01-14T09:23:21.9009445Z [command]/usr/bin/git version
2026-01-14T09:23:21.9063313Z git version 2.50.1
2026-01-14T09:23:21.9110036Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/bae563ff-1db6-414b-9308-a20e3c1d26e4' before making global git config changes
2026-01-14T09:23:21.9111083Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T09:23:21.9115522Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T09:23:21.9159036Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T09:23:21.9201212Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T09:23:21.9620813Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T09:23:21.9649631Z http.https://github.com/.extraheader
2026-01-14T09:23:21.9662788Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-01-14T09:23:21.9700969Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T09:23:22.0206223Z A job completed hook has been configured by the self-hosted runner administrator
2026-01-14T09:23:22.0248360Z ##[group]Run '/home/ec2-user/runner-scripts/after_job.sh'
2026-01-14T09:23:22.0256743Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:23:22.0257135Z ##[endgroup]
2026-01-14T09:23:22.0378996Z [!ALERT!] Swap in detected! [!ALERT!]
2026-01-14T09:23:33.6086768Z [!ALERT!] Swap out detected [!ALERT!]
2026-01-14T09:23:52.4208137Z Cleaning up orphan processes
