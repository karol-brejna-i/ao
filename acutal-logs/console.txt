2026-01-14T08:15:11.6015856Z Current runner version: '2.331.0'
2026-01-14T08:15:11.6021733Z Runner name: 'i-0e88e327a68214579'
2026-01-14T08:15:11.6022456Z Runner group name: 'default'
2026-01-14T08:15:11.6023277Z Machine name: 'ip-10-0-61-23'
2026-01-14T08:15:11.6026070Z ##[group]GITHUB_TOKEN Permissions
2026-01-14T08:15:11.6028339Z Contents: read
2026-01-14T08:15:11.6028857Z Metadata: read
2026-01-14T08:15:11.6029357Z Packages: read
2026-01-14T08:15:11.6029840Z ##[endgroup]
2026-01-14T08:15:11.6031667Z Secret source: None
2026-01-14T08:15:11.6032274Z Prepare workflow directory
2026-01-14T08:15:11.6580754Z Prepare all required actions
2026-01-14T08:15:11.6617047Z Getting action download info
2026-01-14T08:15:11.9822149Z Download action repository 'actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683' (SHA:11bd71901bbe5b1630ceea73d27597364c9af683)
2026-01-14T08:15:12.2839391Z Download action repository 'pytorch/pytorch@main' (SHA:b321605fc7207c672be72497ceeb20cbb6367319)
2026-01-14T08:15:28.3306895Z Download action repository 'actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093' (SHA:d3f86a106a0bac45b974a628896c90dbdf5c8093)
2026-01-14T08:15:28.6330354Z Download action repository 'pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1' (SHA:a2c1430e2bddadbad9f49a6f9b879f062c6b19b1)
2026-01-14T08:15:28.8421014Z Download action repository 'actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02' (SHA:ea165f8d65b6e75b540449e92b4886f43607fa02)
2026-01-14T08:15:29.3771080Z Getting action download info
2026-01-14T08:15:29.5379616Z Getting action download info
2026-01-14T08:15:29.6726734Z Download action repository 'aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722' (SHA:ececac1a45f3b08a01d2dd070d28d111c5fe6722)
2026-01-14T08:15:29.9504707Z Download action repository 'aws-actions/amazon-ecr-login@062b18b96a7aff071d4dc91bc00c4c1a7945b076' (SHA:062b18b96a7aff071d4dc91bc00c4c1a7945b076)
2026-01-14T08:15:30.2297567Z Uses: pytorch/test-infra/.github/workflows/linux_job_v2.yml@refs/heads/main (479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:30.2301850Z ##[group] Inputs
2026-01-14T08:15:30.2303472Z   script: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:30.2305520Z   timeout: 180
2026-01-14T08:15:30.2305776Z   runner: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:30.2306084Z   upload-artifact: 
2026-01-14T08:15:30.2306603Z   upload-artifact-to-s3: false
2026-01-14T08:15:30.2306900Z   download-artifact: 
2026-01-14T08:15:30.2307130Z   repository: 
2026-01-14T08:15:30.2307359Z   fetch-depth: 1
2026-01-14T08:15:30.2307571Z   submodules: recursive
2026-01-14T08:15:30.2307813Z   ref: 
2026-01-14T08:15:30.2308050Z   test-infra-repository: pytorch/test-infra
2026-01-14T08:15:30.2308365Z   test-infra-ref: 
2026-01-14T08:15:30.2308612Z   use-custom-docker-registry: true
2026-01-14T08:15:30.2308930Z   docker-image: pytorch/almalinux-builder
2026-01-14T08:15:30.2309241Z   docker-build-dir: .ci/docker
2026-01-14T08:15:30.2309512Z   gpu-arch-type: cuda
2026-01-14T08:15:30.2309752Z   gpu-arch-version: 12.6
2026-01-14T08:15:30.2309991Z   job-name: linux-job
2026-01-14T08:15:30.2310250Z   continue-on-error: false
2026-01-14T08:15:30.2310530Z   binary-matrix: 
2026-01-14T08:15:30.2310780Z   run-with-docker: true
2026-01-14T08:15:30.2311032Z   secrets-env: 
2026-01-14T08:15:30.2311243Z   no-sudo: false
2026-01-14T08:15:30.2311465Z ##[endgroup]
2026-01-14T08:15:30.2311964Z Complete job name: test (CUDA 2.9, linux.g5.12xlarge.nvidia.gpu, torch==2.9.1, cuda, 12.6) / linux-job
2026-01-14T08:15:30.3442840Z A job started hook has been configured by the self-hosted runner administrator
2026-01-14T08:15:30.3550075Z ##[group]Run '/home/ec2-user/runner-scripts/before_job.sh'
2026-01-14T08:15:30.3561735Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:30.3562305Z ##[endgroup]
2026-01-14T08:15:31.7800454Z Runner Type: linux.g5.12xlarge.nvidia.gpu
2026-01-14T08:15:31.7800939Z Instance Type: g5.12xlarge
2026-01-14T08:15:31.7801187Z AMI Name: unknown
2026-01-14T08:15:31.7845249Z AMI ID: ami-068c0051b15cdb816
2026-01-14T08:15:37.5674336Z ##[group]Run set -euxo pipefail
2026-01-14T08:15:37.5674714Z [36;1mset -euxo pipefail[0m
2026-01-14T08:15:37.5675024Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T08:15:37.5675418Z [36;1m  echo "::group::Cleanup with-sudo debug output"[0m
2026-01-14T08:15:37.5675805Z [36;1m  sudo rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:37.5676106Z [36;1melse[0m
2026-01-14T08:15:37.5676377Z [36;1m  echo "::group::Cleanup no-sudo debug output"[0m
2026-01-14T08:15:37.5676742Z [36;1m  rm -rfv "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:37.5677023Z [36;1mfi[0m
2026-01-14T08:15:37.5677225Z [36;1m[0m
2026-01-14T08:15:37.5677463Z [36;1mmkdir -p "${GITHUB_WORKSPACE}"[0m
2026-01-14T08:15:37.5677791Z [36;1mecho "::endgroup::"[0m
2026-01-14T08:15:37.5693102Z shell: /usr/bin/bash -e {0}
2026-01-14T08:15:37.5693358Z env:
2026-01-14T08:15:37.5693603Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:37.5693946Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:37.5694230Z   PR_NUMBER: 3500
2026-01-14T08:15:37.5695753Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:37.5697376Z   NO_SUDO: false
2026-01-14T08:15:37.5697594Z ##[endgroup]
2026-01-14T08:15:37.5738054Z + [[ false == \f\a\l\s\e ]]
2026-01-14T08:15:37.5747559Z + echo '::group::Cleanup with-sudo debug output'
2026-01-14T08:15:37.5753452Z ##[group]Cleanup with-sudo debug output
2026-01-14T08:15:37.5753881Z + sudo rm -rfv /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:37.7016374Z removed directory '/home/ec2-user/actions-runner/_work/ao/ao'
2026-01-14T08:15:37.7039447Z + mkdir -p /home/ec2-user/actions-runner/_work/ao/ao
2026-01-14T08:15:37.7058231Z + echo ::endgroup::
2026-01-14T08:15:37.7058721Z ##[endgroup]
2026-01-14T08:15:37.7170992Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:15:37.7171498Z with:
2026-01-14T08:15:37.7171726Z   repository: pytorch/test-infra
2026-01-14T08:15:37.7172008Z   path: test-infra
2026-01-14T08:15:37.7172231Z   submodules: recursive
2026-01-14T08:15:37.7172662Z   token: ***
2026-01-14T08:15:37.7172895Z   ssh-strict: true
2026-01-14T08:15:37.7173099Z   ssh-user: git
2026-01-14T08:15:37.7173326Z   persist-credentials: true
2026-01-14T08:15:37.7173574Z   clean: true
2026-01-14T08:15:37.7173814Z   sparse-checkout-cone-mode: true
2026-01-14T08:15:37.7174104Z   fetch-depth: 1
2026-01-14T08:15:37.7174325Z   fetch-tags: false
2026-01-14T08:15:37.7174547Z   show-progress: true
2026-01-14T08:15:37.7174768Z   lfs: false
2026-01-14T08:15:37.7174989Z   set-safe-directory: true
2026-01-14T08:15:37.7175224Z env:
2026-01-14T08:15:37.7175473Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:37.7175802Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:37.7176077Z   PR_NUMBER: 3500
2026-01-14T08:15:37.7177623Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:37.7179221Z ##[endgroup]
2026-01-14T08:15:37.8628385Z Syncing repository: pytorch/test-infra
2026-01-14T08:15:37.8629335Z ##[group]Getting Git version info
2026-01-14T08:15:37.8629767Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/test-infra'
2026-01-14T08:15:37.8630383Z [command]/usr/bin/git version
2026-01-14T08:15:37.8633828Z git version 2.50.1
2026-01-14T08:15:37.8660772Z ##[endgroup]
2026-01-14T08:15:37.8686739Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/256f5187-8410-408e-a3f1-4c41e9cc5919' before making global git config changes
2026-01-14T08:15:37.8687653Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:15:37.8692602Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:37.8733305Z ##[group]Initializing the repository
2026-01-14T08:15:37.8737728Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T08:15:37.8788456Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:15:37.8789149Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:15:37.8789795Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:15:37.8790283Z hint:
2026-01-14T08:15:37.8790582Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:15:37.8790969Z hint:
2026-01-14T08:15:37.8791324Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:15:37.8791971Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:15:37.8792461Z hint:
2026-01-14T08:15:37.8792698Z hint: 	git branch -m <name>
2026-01-14T08:15:37.8792972Z hint:
2026-01-14T08:15:37.8793366Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:15:37.8794150Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.git/
2026-01-14T08:15:37.8801344Z [command]/usr/bin/git remote add origin https://github.com/pytorch/test-infra
2026-01-14T08:15:37.9072171Z ##[endgroup]
2026-01-14T08:15:37.9072596Z ##[group]Disabling automatic garbage collection
2026-01-14T08:15:37.9076501Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:15:37.9123203Z ##[endgroup]
2026-01-14T08:15:37.9123593Z ##[group]Setting up auth
2026-01-14T08:15:37.9128901Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:15:37.9164279Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:15:37.9613671Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:15:37.9650903Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:15:38.0061122Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:38.0111379Z ##[endgroup]
2026-01-14T08:15:38.0111834Z ##[group]Determining the default branch
2026-01-14T08:15:38.0114575Z Retrieving the default branch name
2026-01-14T08:15:38.2555134Z Default branch 'main'
2026-01-14T08:15:38.2555785Z ##[endgroup]
2026-01-14T08:15:38.2556197Z ##[group]Fetching the repository
2026-01-14T08:15:38.2560273Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/heads/main:refs/remotes/origin/main
2026-01-14T08:15:38.6205471Z From https://github.com/pytorch/test-infra
2026-01-14T08:15:38.6205849Z  * [new branch]      main       -> origin/main
2026-01-14T08:15:38.6238174Z ##[endgroup]
2026-01-14T08:15:38.6238555Z ##[group]Determining the checkout info
2026-01-14T08:15:38.6240206Z ##[endgroup]
2026-01-14T08:15:38.6244890Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:15:38.6292816Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:15:38.6329458Z ##[group]Checking out the ref
2026-01-14T08:15:38.6333349Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2026-01-14T08:15:38.8297265Z Switched to a new branch 'main'
2026-01-14T08:15:38.8299865Z branch 'main' set up to track 'origin/main'.
2026-01-14T08:15:38.8315327Z ##[endgroup]
2026-01-14T08:15:38.8315944Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:15:38.8323885Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:15:38.8379684Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:15:38.8420440Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:15:38.8460400Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:15:38.8496045Z ##[endgroup]
2026-01-14T08:15:38.8496424Z ##[group]Fetching submodules
2026-01-14T08:15:38.8500171Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:15:38.8909087Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:15:38.9327009Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:15:38.9730265Z ##[endgroup]
2026-01-14T08:15:38.9730726Z ##[group]Persisting credentials for submodules
2026-01-14T08:15:38.9735505Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:15:39.0146613Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:15:39.0549308Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:15:39.0950728Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:15:39.1352483Z ##[endgroup]
2026-01-14T08:15:39.1406784Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:15:39.1440059Z 479ee761cd164688ad6fe63fbc0f27d255b35fe1
2026-01-14T08:15:39.1661295Z Prepare all required actions
2026-01-14T08:15:39.1661738Z Getting action download info
2026-01-14T08:15:39.3198586Z Download action repository 'pytorch/test-infra@main' (SHA:479ee761cd164688ad6fe63fbc0f27d255b35fe1)
2026-01-14T08:15:41.7595327Z Getting action download info
2026-01-14T08:15:41.8970407Z Download action repository 'nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482' (SHA:3e91a01664abd3c5cd539100d10d33b9c5b68482)
2026-01-14T08:15:42.1357025Z ##[group]Run ./test-infra/.github/actions/setup-linux
2026-01-14T08:15:42.1357372Z env:
2026-01-14T08:15:42.1357618Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:42.1357940Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:42.1358183Z   PR_NUMBER: 3500
2026-01-14T08:15:42.1359723Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:42.1361276Z ##[endgroup]
2026-01-14T08:15:42.1451298Z ##[group]Run set -euo pipefail
2026-01-14T08:15:42.1451619Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:42.1451885Z [36;1mfunction get_ec2_metadata() {[0m
2026-01-14T08:15:42.1452228Z [36;1m  # Pulled from instance metadata endpoint for EC2[0m
2026-01-14T08:15:42.1452838Z [36;1m  # see https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html[0m
2026-01-14T08:15:42.1453568Z [36;1m  category=$1[0m
2026-01-14T08:15:42.1454442Z [36;1m  curl -H "X-aws-ec2-metadata-token: $(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 30")" -fsSL "http://169.254.169.254/latest/meta-data/${category}"[0m
2026-01-14T08:15:42.1455350Z [36;1m}[0m
2026-01-14T08:15:42.1455599Z [36;1mecho "ami-id: $(get_ec2_metadata ami-id)"[0m
2026-01-14T08:15:42.1456006Z [36;1mecho "instance-id: $(get_ec2_metadata instance-id)"[0m
2026-01-14T08:15:42.1456461Z [36;1mecho "instance-type: $(get_ec2_metadata instance-type)"[0m
2026-01-14T08:15:42.1456852Z [36;1mecho "system info $(uname -a)"[0m
2026-01-14T08:15:42.1466382Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:42.1466733Z env:
2026-01-14T08:15:42.1466982Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:42.1467316Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:42.1467571Z   PR_NUMBER: 3500
2026-01-14T08:15:42.1469068Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:42.1470633Z ##[endgroup]
2026-01-14T08:15:42.1650064Z ami-id: ami-068c0051b15cdb816
2026-01-14T08:15:42.1777983Z instance-id: i-0e88e327a68214579
2026-01-14T08:15:42.1916104Z instance-type: g5.12xlarge
2026-01-14T08:15:42.1932044Z system info Linux ip-10-0-61-23.ec2.internal 6.1.158-180.294.amzn2023.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Dec  1 05:36:50 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
2026-01-14T08:15:42.1981466Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:42.1982452Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:42.1992111Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:42.1992486Z env:
2026-01-14T08:15:42.1992750Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:42.1993113Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:42.1993600Z   PR_NUMBER: 3500
2026-01-14T08:15:42.1995126Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:42.1996685Z ##[endgroup]
2026-01-14T08:15:42.2086924Z ##[group]Run if ! docker version >/dev/null 2>/dev/null; then
2026-01-14T08:15:42.2087418Z [36;1mif ! docker version >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:42.2087835Z [36;1m  if systemctl is-active --quiet docker; then[0m
2026-01-14T08:15:42.2088206Z [36;1m      echo "Docker daemon is running...";[0m
2026-01-14T08:15:42.2088526Z [36;1m  else[0m
2026-01-14T08:15:42.2088864Z [36;1m      echo "Starting docker daemon..." && sudo systemctl start docker;[0m
2026-01-14T08:15:42.2089281Z [36;1m  fi[0m
2026-01-14T08:15:42.2089495Z [36;1mfi[0m
2026-01-14T08:15:42.2098745Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:42.2099095Z env:
2026-01-14T08:15:42.2099354Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:42.2099713Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:42.2099969Z   PR_NUMBER: 3500
2026-01-14T08:15:42.2101491Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:42.2103278Z ##[endgroup]
2026-01-14T08:15:42.2808203Z ##[group]Run AWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")
2026-01-14T08:15:42.2808873Z [36;1mAWS_ACCOUNT_ID=$(aws sts get-caller-identity|grep Account|cut -f4 -d\")[0m
2026-01-14T08:15:42.2809387Z [36;1mretry () { "$@"  || (sleep 1 && "$@") || (sleep 2 && "$@") }[0m
2026-01-14T08:15:42.2809983Z [36;1mretry aws ecr get-login-password --region "$AWS_DEFAULT_REGION" | docker login --username AWS \[0m
2026-01-14T08:15:42.2810694Z [36;1m    --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"[0m
2026-01-14T08:15:42.2820187Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:42.2820543Z env:
2026-01-14T08:15:42.2820819Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:42.2821157Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:42.2821417Z   PR_NUMBER: 3500
2026-01-14T08:15:42.2822936Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:42.2824560Z   AWS_RETRY_MODE: standard
2026-01-14T08:15:42.2824853Z   AWS_MAX_ATTEMPTS: 5
2026-01-14T08:15:42.2825099Z   AWS_DEFAULT_REGION: us-east-1
2026-01-14T08:15:42.2825367Z ##[endgroup]
2026-01-14T08:15:43.3840460Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:15:43.3841036Z Configure a credential helper to remove this warning. See
2026-01-14T08:15:43.3841567Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:15:43.3841952Z 
2026-01-14T08:15:43.3843457Z Login Succeeded
2026-01-14T08:15:43.3925794Z ##[group]Run env | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"
2026-01-14T08:15:43.3926362Z [36;1menv | grep '^GITHUB' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:43.3926862Z [36;1menv | grep '^CI' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:43.3927553Z [36;1menv | grep '^RUNNER' >> "${RUNNER_TEMP}/github_env_${GITHUB_RUN_ID}"[0m
2026-01-14T08:15:43.3937124Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:43.3937469Z env:
2026-01-14T08:15:43.3937718Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:43.3938050Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:43.3938296Z   PR_NUMBER: 3500
2026-01-14T08:15:43.3939801Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:43.3941360Z ##[endgroup]
2026-01-14T08:15:43.4083497Z ##[group]Run RUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"
2026-01-14T08:15:43.4083996Z [36;1mRUNNER_ARTIFACT_DIR="${RUNNER_TEMP}/artifacts"[0m
2026-01-14T08:15:43.4084381Z [36;1msudo rm -rf "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:43.4084717Z [36;1mmkdir -p "${RUNNER_ARTIFACT_DIR}"[0m
2026-01-14T08:15:43.4085135Z [36;1mecho "RUNNER_ARTIFACT_DIR=${RUNNER_ARTIFACT_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:43.4085540Z [36;1m[0m
2026-01-14T08:15:43.4085820Z [36;1mRUNNER_TEST_RESULTS_DIR="${RUNNER_TEMP}/test-results"[0m
2026-01-14T08:15:43.4086222Z [36;1msudo rm -rf "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:43.4086569Z [36;1mmkdir -p "${RUNNER_TEST_RESULTS_DIR}"[0m
2026-01-14T08:15:43.4087202Z [36;1mecho "RUNNER_TEST_RESULTS_DIR=${RUNNER_TEST_RESULTS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:43.4087634Z [36;1m[0m
2026-01-14T08:15:43.4087853Z [36;1mRUNNER_DOCS_DIR="${RUNNER_TEMP}/docs"[0m
2026-01-14T08:15:43.4088179Z [36;1msudo rm -rf "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:43.4088480Z [36;1mmkdir -p "${RUNNER_DOCS_DIR}"[0m
2026-01-14T08:15:43.4088869Z [36;1mecho "RUNNER_DOCS_DIR=${RUNNER_DOCS_DIR}" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:43.4097378Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:43.4097725Z env:
2026-01-14T08:15:43.4097962Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:43.4098298Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:43.4098529Z   PR_NUMBER: 3500
2026-01-14T08:15:43.4100034Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:43.4101590Z ##[endgroup]
2026-01-14T08:15:43.9690428Z ##[group]Run needs=0
2026-01-14T08:15:43.9690665Z [36;1mneeds=0[0m
2026-01-14T08:15:43.9691016Z [36;1mif lspci -v | grep -e 'controller.*NVIDIA' >/dev/null 2>/dev/null; then[0m
2026-01-14T08:15:43.9691510Z [36;1m  needs=1[0m
2026-01-14T08:15:43.9691729Z [36;1mfi[0m
2026-01-14T08:15:43.9691957Z [36;1mecho "does=${needs}" >> $GITHUB_OUTPUT[0m
2026-01-14T08:15:43.9701257Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:43.9701609Z env:
2026-01-14T08:15:43.9701857Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:43.9702197Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:43.9702443Z   PR_NUMBER: 3500
2026-01-14T08:15:43.9703948Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:43.9705649Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:43.9706382Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:43.9706912Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:43.9707285Z ##[endgroup]
2026-01-14T08:15:44.0119995Z ##[group]Run pytorch/test-infra/.github/actions/setup-nvidia@main
2026-01-14T08:15:44.0120363Z with:
2026-01-14T08:15:44.0120563Z   driver-version: 580.65.06
2026-01-14T08:15:44.0120800Z env:
2026-01-14T08:15:44.0121031Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:44.0121359Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:44.0121601Z   PR_NUMBER: 3500
2026-01-14T08:15:44.0123094Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:44.0124825Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:44.0125374Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:44.0125889Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:44.0126242Z ##[endgroup]
2026-01-14T08:15:44.0154513Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:15:44.0155596Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:44.0164329Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:44.0164677Z env:
2026-01-14T08:15:44.0164922Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:44.0165250Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:44.0165497Z   PR_NUMBER: 3500
2026-01-14T08:15:44.0167009Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:44.0168690Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:44.0169256Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:44.0169790Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:44.0170169Z ##[endgroup]
2026-01-14T08:15:44.0276870Z ##[group]Run set -euo pipefail
2026-01-14T08:15:44.0277187Z [36;1mset -euo pipefail[0m
2026-01-14T08:15:44.0277430Z [36;1m[0m
2026-01-14T08:15:44.0277634Z [36;1mhas_gpu=false[0m
2026-01-14T08:15:44.0277866Z [36;1mdevices=""[0m
2026-01-14T08:15:44.0278097Z [36;1m[0m
2026-01-14T08:15:44.0278356Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:15:44.0278785Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:44.0279157Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:44.0279444Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:44.0279731Z [36;1m  fi[0m
2026-01-14T08:15:44.0279926Z [36;1mfi[0m
2026-01-14T08:15:44.0280124Z [36;1m[0m
2026-01-14T08:15:44.0280325Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:15:44.0280700Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:44.0281061Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:44.0281341Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:44.0281634Z [36;1m  fi[0m
2026-01-14T08:15:44.0281831Z [36;1mfi[0m
2026-01-14T08:15:44.0282020Z [36;1m[0m
2026-01-14T08:15:44.0282315Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:15:44.0282985Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:15:44.0283375Z [36;1m    has_gpu=true[0m
2026-01-14T08:15:44.0283651Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:15:44.0283943Z [36;1m  fi[0m
2026-01-14T08:15:44.0284136Z [36;1mfi[0m
2026-01-14T08:15:44.0284319Z [36;1m[0m
2026-01-14T08:15:44.0284598Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:44.0285104Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:15:44.0293751Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:44.0294142Z env:
2026-01-14T08:15:44.0294376Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:44.0294703Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:44.0294939Z   PR_NUMBER: 3500
2026-01-14T08:15:44.0296440Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:44.0298114Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:44.0298655Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:44.0299179Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:44.0299685Z ##[endgroup]
2026-01-14T08:15:47.5466021Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:15:47.5466414Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:15:47.5466782Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:47.5467283Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:47.5467754Z [36;1melse[0m
2026-01-14T08:15:47.5468027Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:15:47.5468363Z [36;1mfi[0m
2026-01-14T08:15:47.5478421Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:15:47.5478775Z env:
2026-01-14T08:15:47.5479024Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:47.5479372Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:47.5479630Z   PR_NUMBER: 3500
2026-01-14T08:15:47.5481133Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:47.5482835Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:47.5483401Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:47.5483921Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:47.5484290Z   HAS_NVIDIA: true
2026-01-14T08:15:47.5484502Z ##[endgroup]
2026-01-14T08:15:47.5591872Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:15:47.5592333Z with:
2026-01-14T08:15:47.5592699Z   timeout_minutes: 10
2026-01-14T08:15:47.5593008Z   max_attempts: 3
2026-01-14T08:15:47.5623494Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:15:47.5654662Z   retry_wait_seconds: 10
2026-01-14T08:15:47.5655039Z   polling_interval_seconds: 1
2026-01-14T08:15:47.5655388Z   warning_on_retry: true
2026-01-14T08:15:47.5655909Z   continue_on_error: false
2026-01-14T08:15:47.5656245Z env:
2026-01-14T08:15:47.5656581Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:15:47.5656957Z   REPOSITORY: pytorch/ao
2026-01-14T08:15:47.5657385Z   PR_NUMBER: 3500
2026-01-14T08:15:47.5658977Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:15:47.5660699Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:15:47.5661528Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:15:47.5662149Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:15:47.5662562Z   HAS_NVIDIA_GPU: true
2026-01-14T08:15:47.5663048Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:15:47.5663447Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:15:47.5663770Z ##[endgroup]
2026-01-14T08:15:47.6559289Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:15:47.6560325Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:15:47.6564160Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:15:47.9575477Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:15:47.9576400Z No packages marked for removal.
2026-01-14T08:15:47.9642641Z Dependencies resolved.
2026-01-14T08:15:47.9653096Z Nothing to do.
2026-01-14T08:15:47.9653596Z Complete!
2026-01-14T08:15:47.9997933Z + install_nvidia_driver_common
2026-01-14T08:15:48.0003578Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:15:48.0004115Z + lspci
2026-01-14T08:15:48.0006146Z Before installing NVIDIA driver
2026-01-14T08:15:48.0124160Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:15:48.0125297Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:15:48.0125922Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:15:48.0126540Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:15:48.0127276Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:15:48.0128165Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:15:48.0128762Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:48.0129368Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:48.0129909Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:48.0130432Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:15:48.0131068Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:15:48.0131634Z + lsmod
2026-01-14T08:15:48.0184114Z Module                  Size  Used by
2026-01-14T08:15:48.0184730Z nvidia_uvm           1925120  0
2026-01-14T08:15:48.0185060Z nvidia              14286848  1 nvidia_uvm
2026-01-14T08:15:48.0185522Z drm                   602112  1 nvidia
2026-01-14T08:15:48.0185985Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:15:48.0186401Z backlight              24576  1 drm
2026-01-14T08:15:48.0186762Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:15:48.0187218Z mgc                    86016  1
2026-01-14T08:15:48.0187600Z lustre               1085440  4
2026-01-14T08:15:48.0187900Z mdc                   294912  2 lustre
2026-01-14T08:15:48.0188342Z fid                    36864  1 mdc
2026-01-14T08:15:48.0188672Z lov                   356352  5 mdc,lustre
2026-01-14T08:15:48.0189061Z osc                   479232  5 mdc
2026-01-14T08:15:48.0189471Z lmv                   225280  2 lustre
2026-01-14T08:15:48.0190073Z fld                    49152  2 lov,lmv
2026-01-14T08:15:48.0190406Z ksocklnd              188416  1
2026-01-14T08:15:48.0190983Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:48.0191586Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:15:48.0192144Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:15:48.0192889Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:15:48.0193469Z xt_conntrack           16384  1
2026-01-14T08:15:48.0193828Z nft_chain_nat          16384  3
2026-01-14T08:15:48.0205215Z xt_MASQUERADE          20480  1
2026-01-14T08:15:48.0205541Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:15:48.0205879Z nf_conntrack_netlink    57344  0
2026-01-14T08:15:48.0206285Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:15:48.0206742Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:15:48.0207078Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:15:48.0207366Z xfrm_user              57344  1
2026-01-14T08:15:48.0207630Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:15:48.0207911Z xt_addrtype            16384  2
2026-01-14T08:15:48.0208170Z nft_compat             20480  4
2026-01-14T08:15:48.0208477Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:15:48.0208896Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:15:48.0209287Z br_netfilter           36864  0
2026-01-14T08:15:48.0209554Z bridge                323584  1 br_netfilter
2026-01-14T08:15:48.0209848Z stp                    16384  1 bridge
2026-01-14T08:15:48.0210129Z llc                    16384  2 bridge,stp
2026-01-14T08:15:48.0210411Z overlay               167936  0
2026-01-14T08:15:48.0210655Z tls                   139264  0
2026-01-14T08:15:48.0210902Z nls_ascii              16384  1
2026-01-14T08:15:48.0211150Z nls_cp437              20480  1
2026-01-14T08:15:48.0211462Z vfat                   24576  1
2026-01-14T08:15:48.0211715Z fat                    86016  1 vfat
2026-01-14T08:15:48.0211980Z sunrpc                700416  2 lnet
2026-01-14T08:15:48.0212255Z ghash_clmulni_intel    16384  0
2026-01-14T08:15:48.0212502Z i8042                  45056  0
2026-01-14T08:15:48.0212786Z serio                  28672  3 i8042
2026-01-14T08:15:48.0213046Z ena                   196608  0
2026-01-14T08:15:48.0213467Z button                 24576  0
2026-01-14T08:15:48.0213716Z sch_fq_codel           20480  33
2026-01-14T08:15:48.0213953Z fuse                  184320  1
2026-01-14T08:15:48.0214190Z loop                   36864  0
2026-01-14T08:15:48.0214424Z dm_mod                188416  0
2026-01-14T08:15:48.0214664Z configfs               57344  1
2026-01-14T08:15:48.0214898Z dmi_sysfs              20480  0
2026-01-14T08:15:48.0215138Z crc32_pclmul           16384  0
2026-01-14T08:15:48.0215383Z crc32c_intel           24576  0
2026-01-14T08:15:48.0215622Z efivarfs               24576  1
2026-01-14T08:15:48.0215860Z + modinfo nvidia
2026-01-14T08:15:48.0216229Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:15:48.0216671Z import_ns:      DMA_BUF
2026-01-14T08:15:48.0216904Z alias:          char-major-195-*
2026-01-14T08:15:48.0217160Z version:        580.82.07
2026-01-14T08:15:48.0217389Z supported:      external
2026-01-14T08:15:48.0217633Z license:        Dual MIT/GPL
2026-01-14T08:15:48.0217902Z firmware:       nvidia/580.82.07/gsp_tu10x.bin
2026-01-14T08:15:48.0218225Z firmware:       nvidia/580.82.07/gsp_ga10x.bin
2026-01-14T08:15:48.0218537Z srcversion:     BA7240A71DCF7DC6FE88C1D
2026-01-14T08:15:48.0218849Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:15:48.0219197Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:15:48.0219532Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:15:48.0219873Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:15:48.0220303Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:15:48.0220694Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:15:48.0221018Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:15:48.0221329Z depends:        i2c-core,drm
2026-01-14T08:15:48.0221573Z retpoline:      Y
2026-01-14T08:15:48.0221771Z name:           nvidia
2026-01-14T08:15:48.0222131Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:15:48.0222608Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:15:48.0223055Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:15:48.0223465Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:15:48.0223769Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:15:48.0224055Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:15:48.0224365Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:15:48.0224670Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:15:48.0224965Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:15:48.0225324Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:15:48.0225707Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:15:48.0226037Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:15:48.0226322Z parm:           NVreg_EnableMSI:int
2026-01-14T08:15:48.0226622Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:15:48.0226981Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:15:48.0227381Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:15:48.0227765Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:15:48.0228178Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:48.0228593Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:15:48.0229006Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:15:48.0229427Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:15:48.0229747Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:15:48.0230117Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:15:48.0230488Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:15:48.0230816Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:15:48.0231126Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:15:48.0231577Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:15:48.0231894Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:15:48.0232189Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:15:48.0232552Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:15:48.0232913Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:15:48.0233254Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:15:48.0233610Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:15:48.0233944Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:15:48.0234279Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:15:48.0234621Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:15:48.0234947Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:15:48.0235283Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:15:48.0235602Z parm:           NVreg_RmMsg:charp
2026-01-14T08:15:48.0235883Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:15:48.0236197Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:15:48.0236512Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:15:48.0236816Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:15:48.0237128Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:15:48.0237664Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:15:48.0238131Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:15:48.0238449Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:15:48.0238883Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:15:48.0239218Z parm:           rm_firmware_active:charp
2026-01-14T08:15:48.0239493Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:15:48.0239735Z ++ command -v nvidia-smi
2026-01-14T08:15:48.0239984Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:15:48.0240226Z + set +e
2026-01-14T08:15:48.0240529Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:15:51.4586042Z + INSTALLED_DRIVER_VERSION=580.82.07
2026-01-14T08:15:51.4586377Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:15:51.4586617Z + '[' 0 -ne 0 ']'
2026-01-14T08:15:51.4586830Z + '[' 580.82.07 '!=' 580.65.06 ']'
2026-01-14T08:15:51.4587315Z + echo 'NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing'
2026-01-14T08:15:51.4587832Z + sudo killall nvidia-persistenced
2026-01-14T08:15:51.4588303Z NVIDIA driver (580.82.07) has been installed, but we expect to have 580.65.06 instead. Continuing
2026-01-14T08:15:51.5771155Z nvidia-persistenced: no process found
2026-01-14T08:15:51.5795214Z + true
2026-01-14T08:15:51.5795570Z + set -e
2026-01-14T08:15:51.5795784Z + '[' 0 -eq 0 ']'
2026-01-14T08:15:51.5796005Z + '[' amzn2023 '!=' ubuntu20.04 ']'
2026-01-14T08:15:51.5796316Z + sudo yum groupinstall -y 'Development Tools'
2026-01-14T08:15:52.1159253Z Last metadata expiration check: 0:01:04 ago on Wed Jan 14 08:14:48 2026.
2026-01-14T08:15:52.1542609Z No match for group package "system-rpm-config"
2026-01-14T08:15:52.1558703Z No match for group package "rcs"
2026-01-14T08:15:52.1579124Z No match for group package "pkgconfig"
2026-01-14T08:15:52.2175891Z Dependencies resolved.
2026-01-14T08:15:52.2530846Z ================================================================================
2026-01-14T08:15:52.2531371Z  Package           Architecture     Version             Repository         Size
2026-01-14T08:15:52.2531832Z ================================================================================
2026-01-14T08:15:52.2532161Z Installing Groups:
2026-01-14T08:15:52.2532511Z  Development Tools                                                             
2026-01-14T08:15:52.2532821Z 
2026-01-14T08:15:52.2532912Z Transaction Summary
2026-01-14T08:15:52.2533171Z ================================================================================
2026-01-14T08:15:52.2533419Z 
2026-01-14T08:15:52.4983963Z ================================================================================
2026-01-14T08:15:52.4984342Z WARNING:
2026-01-14T08:15:52.4984864Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:15:52.4985099Z 
2026-01-14T08:15:52.4985192Z   Available Versions:
2026-01-14T08:15:52.4985337Z 
2026-01-14T08:15:52.4985436Z   Version 2023.10.20260105:
2026-01-14T08:15:52.4985753Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:15:52.4986062Z 
2026-01-14T08:15:52.4986193Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:15:52.4986407Z 
2026-01-14T08:15:52.4986490Z     Release notes:
2026-01-14T08:15:52.4986918Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:15:52.4987301Z 
2026-01-14T08:15:52.4987432Z ================================================================================
2026-01-14T08:15:52.4993390Z Complete!
2026-01-14T08:15:52.5442611Z ++ uname -r
2026-01-14T08:15:52.5456831Z + sudo yum install -y 'kernel-devel-uname-r == 6.1.158-180.294.amzn2023.x86_64'
2026-01-14T08:15:52.9930246Z Last metadata expiration check: 0:01:04 ago on Wed Jan 14 08:14:48 2026.
2026-01-14T08:15:53.0186469Z Using '==' operator in reldeps can result in an undefined behavior. It is deprecated and the support will be dropped in future versions. Use '=' operator instead.
2026-01-14T08:15:53.0306688Z Package kernel-devel-1:6.1.158-180.294.amzn2023.x86_64 is already installed.
2026-01-14T08:15:53.0931678Z Dependencies resolved.
2026-01-14T08:15:53.1290694Z Nothing to do.
2026-01-14T08:15:53.1291747Z Complete!
2026-01-14T08:15:53.1700303Z + sudo modprobe backlight
2026-01-14T08:15:53.3364747Z + sudo curl -fsL -o /tmp/nvidia_driver https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-580.65.06.run
2026-01-14T08:15:57.4827610Z + set +e
2026-01-14T08:15:57.4827878Z + sudo /bin/bash /tmp/nvidia_driver -s --no-drm
2026-01-14T08:15:58.7914484Z Verifying archive integrity... OK
2026-01-14T08:16:01.6271670Z Uncompressing NVIDIA Accelerated Graphics Driver for Linux-x86_64 580.65.06....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
2026-01-14T08:16:02.3335172Z 
2026-01-14T08:16:02.3335964Z WARNING: The nvidia-drm module will not be installed. As a result, DRM-KMS will not function with this installation of the NVIDIA driver.
2026-01-14T08:16:02.3336560Z 
2026-01-14T08:16:24.6237609Z 
2026-01-14T08:16:24.6240245Z WARNING: nvidia-installer was forced to guess the X library path '/usr/lib64' and X module path '/usr/lib64/xorg/modules'; these paths were not queryable from the system.  If X fails to find the NVIDIA X driver module, please install the `pkg-config` utility and the X.Org SDK/development package for your distribution and reinstall the driver.
2026-01-14T08:16:24.6242718Z 
2026-01-14T08:16:24.6259129Z 
2026-01-14T08:16:24.6260788Z WARNING: This NVIDIA driver package includes Vulkan components, but no Vulkan ICD loader was detected on this system. The NVIDIA Vulkan ICD will not function without the loader. Most distributions package the Vulkan loader; try installing the "vulkan-loader", "vulkan-icd-loader", or "libvulkan1" package.
2026-01-14T08:16:24.6261970Z 
2026-01-14T08:16:37.3991784Z + NVIDIA_INSTALLATION_STATUS=0
2026-01-14T08:16:37.3993799Z + RESET_GPU=0
2026-01-14T08:16:37.3994257Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:37.3997691Z ++ command -v nvidia-smi
2026-01-14T08:16:37.4001008Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:16:37.4007025Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:16:41.2268672Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:16:41.2268978Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:41.2269216Z + '[' 0 -ne 0 ']'
2026-01-14T08:16:41.2269430Z + '[' 0 -eq 1 ']'
2026-01-14T08:16:41.2269654Z + sudo rm -fv /tmp/nvidia_driver
2026-01-14T08:16:41.4573925Z removed '/tmp/nvidia_driver'
2026-01-14T08:16:41.4603773Z + set -e
2026-01-14T08:16:41.4607825Z + post_install_nvidia_driver_common
2026-01-14T08:16:41.4614195Z + sudo modprobe nvidia
2026-01-14T08:16:41.7265422Z + echo 'After installing NVIDIA driver'
2026-01-14T08:16:41.7265849Z + lspci
2026-01-14T08:16:41.7266329Z After installing NVIDIA driver
2026-01-14T08:16:41.7380715Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:16:41.7381432Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:16:41.7382038Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:16:41.7382802Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:16:41.7383841Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:16:41.7384398Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:16:41.7384900Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:41.7385341Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:41.7385877Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:41.7386320Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:16:41.7386810Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:16:41.7387219Z + lsmod
2026-01-14T08:16:41.7431098Z Module                  Size  Used by
2026-01-14T08:16:41.7431545Z nvidia_uvm           1921024  0
2026-01-14T08:16:41.7431942Z nvidia              14274560  1 nvidia_uvm
2026-01-14T08:16:41.7432340Z drm                   602112  1 nvidia
2026-01-14T08:16:41.7432759Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:16:41.7433109Z backlight              24576  1 drm
2026-01-14T08:16:41.7433393Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:16:41.7433670Z mgc                    86016  1
2026-01-14T08:16:41.7433925Z lustre               1085440  4
2026-01-14T08:16:41.7434174Z mdc                   294912  2 lustre
2026-01-14T08:16:41.7434481Z fid                    36864  1 mdc
2026-01-14T08:16:41.7434858Z lov                   356352  5 mdc,lustre
2026-01-14T08:16:41.7435239Z osc                   479232  5 mdc
2026-01-14T08:16:41.7435587Z lmv                   225280  2 lustre
2026-01-14T08:16:41.7435953Z fld                    49152  2 lov,lmv
2026-01-14T08:16:41.7436228Z ksocklnd              188416  1
2026-01-14T08:16:41.7436558Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:41.7437030Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:16:41.7437526Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:16:41.7438114Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:16:41.7438599Z xt_conntrack           16384  1
2026-01-14T08:16:41.7438857Z nft_chain_nat          16384  3
2026-01-14T08:16:41.7439114Z xt_MASQUERADE          20480  1
2026-01-14T08:16:41.7439406Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:16:41.7440021Z nf_conntrack_netlink    57344  0
2026-01-14T08:16:41.7440422Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:16:41.7440868Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:16:41.7441172Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:16:41.7441454Z xfrm_user              57344  1
2026-01-14T08:16:41.7441708Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:16:41.7441993Z xt_addrtype            16384  2
2026-01-14T08:16:41.7442255Z nft_compat             20480  4
2026-01-14T08:16:41.7442549Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:16:41.7442967Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:16:41.7443341Z br_netfilter           36864  0
2026-01-14T08:16:41.7443615Z bridge                323584  1 br_netfilter
2026-01-14T08:16:41.7443900Z stp                    16384  1 bridge
2026-01-14T08:16:41.7444187Z llc                    16384  2 bridge,stp
2026-01-14T08:16:41.7444481Z overlay               167936  0
2026-01-14T08:16:41.7444726Z tls                   139264  0
2026-01-14T08:16:41.7444972Z nls_ascii              16384  1
2026-01-14T08:16:41.7445212Z nls_cp437              20480  1
2026-01-14T08:16:41.7445452Z vfat                   24576  1
2026-01-14T08:16:41.7445692Z fat                    86016  1 vfat
2026-01-14T08:16:41.7445958Z sunrpc                700416  2 lnet
2026-01-14T08:16:41.7446223Z ghash_clmulni_intel    16384  0
2026-01-14T08:16:41.7446597Z i8042                  45056  0
2026-01-14T08:16:41.7446843Z serio                  28672  3 i8042
2026-01-14T08:16:41.7447110Z ena                   196608  0
2026-01-14T08:16:41.7447350Z button                 24576  0
2026-01-14T08:16:41.7447599Z sch_fq_codel           20480  33
2026-01-14T08:16:41.7447848Z fuse                  184320  1
2026-01-14T08:16:41.7448081Z loop                   36864  0
2026-01-14T08:16:41.7448324Z dm_mod                188416  0
2026-01-14T08:16:41.7448570Z configfs               57344  1
2026-01-14T08:16:41.7448821Z dmi_sysfs              20480  0
2026-01-14T08:16:41.7449339Z crc32_pclmul           16384  0
2026-01-14T08:16:41.7449586Z crc32c_intel           24576  0
2026-01-14T08:16:41.7449828Z efivarfs               24576  1
2026-01-14T08:16:41.7450077Z + modinfo nvidia
2026-01-14T08:16:41.7455177Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:16:41.7455855Z import_ns:      DMA_BUF
2026-01-14T08:16:41.7456199Z alias:          char-major-195-*
2026-01-14T08:16:41.7456561Z version:        580.65.06
2026-01-14T08:16:41.7456840Z supported:      external
2026-01-14T08:16:41.7457096Z license:        Dual MIT/GPL
2026-01-14T08:16:41.7457368Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:16:41.7457699Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:16:41.7458008Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:16:41.7458338Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:16:41.7458680Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:16:41.7459022Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:16:41.7459370Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:16:41.7459700Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:16:41.7460030Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:16:41.7460353Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:16:41.7460666Z depends:        i2c-core,drm
2026-01-14T08:16:41.7460912Z retpoline:      Y
2026-01-14T08:16:41.7461122Z name:           nvidia
2026-01-14T08:16:41.7461492Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:16:41.7462177Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:16:41.7462802Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:16:41.7463361Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:16:41.7463840Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:16:41.7464138Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:16:41.7464450Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:16:41.7464742Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:16:41.7465040Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:16:41.7465398Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:16:41.7465793Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:16:41.7466127Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:16:41.7466420Z parm:           NVreg_EnableMSI:int
2026-01-14T08:16:41.7466726Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:16:41.7467085Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:16:41.7467488Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:16:41.7467867Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:16:41.7468292Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:41.7468704Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:16:41.7469133Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:16:41.7469555Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:16:41.7469879Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:16:41.7470248Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:16:41.7470615Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:16:41.7471080Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:16:41.7471394Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:16:41.7471712Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:16:41.7472027Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:16:41.7472331Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:16:41.7472673Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:16:41.7473028Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:16:41.7473380Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:16:41.7473732Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:16:41.7474060Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:16:41.7474401Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:16:41.7474747Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:16:41.7475083Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:16:41.7475412Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:16:41.7475749Z parm:           NVreg_RmMsg:charp
2026-01-14T08:16:41.7476023Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:16:41.7476341Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:16:41.7476672Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:16:41.7477007Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:16:41.7477336Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:16:41.7477688Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:16:41.7478037Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:16:41.7478352Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:16:41.7478692Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:16:41.7479021Z parm:           rm_firmware_active:charp
2026-01-14T08:16:41.7479300Z + set +e
2026-01-14T08:16:41.7479480Z + nvidia-smi
2026-01-14T08:16:44.0815162Z Wed Jan 14 08:16:44 2026       
2026-01-14T08:16:44.0815639Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:44.0816211Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:16:44.0816735Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:44.0817270Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:16:44.0818100Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:16:44.0818583Z |                                         |                        |               MIG M. |
2026-01-14T08:16:44.0818963Z |=========================================+========================+======================|
2026-01-14T08:16:44.1152909Z |   0  NVIDIA A10G                    Off |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:16:44.1154100Z |  0%   25C    P0             55W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:44.1154909Z |                                         |                        |                  N/A |
2026-01-14T08:16:44.1155723Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:44.1156611Z |   1  NVIDIA A10G                    Off |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:16:44.1157484Z |  0%   25C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:44.1157962Z |                                         |                        |                  N/A |
2026-01-14T08:16:44.1158410Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:44.1158906Z |   2  NVIDIA A10G                    Off |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:16:44.1159370Z |  0%   24C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:16:44.1159963Z |                                         |                        |                  N/A |
2026-01-14T08:16:44.1160530Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:44.1161025Z |   3  NVIDIA A10G                    Off |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:16:44.1161596Z |  0%   24C    P0             56W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:16:44.1162258Z |                                         |                        |                  N/A |
2026-01-14T08:16:44.1162797Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:16:44.1163183Z 
2026-01-14T08:16:44.1163394Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:44.1164035Z | Processes:                                                                              |
2026-01-14T08:16:44.1164609Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:16:44.1165154Z |        ID   ID                                                               Usage      |
2026-01-14T08:16:44.1165683Z |=========================================================================================|
2026-01-14T08:16:44.1180443Z |  No running processes found                                                             |
2026-01-14T08:16:44.1181155Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:16:45.8039867Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:16:48.1159704Z NVIDIA A10G
2026-01-14T08:16:49.2125599Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:16:49.2126104Z + '[' 0 -eq 0 ']'
2026-01-14T08:16:49.2126564Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:16:49.2127122Z + set -e
2026-01-14T08:16:49.2127513Z INFO: Ignoring allowed status 0
2026-01-14T08:16:49.2139410Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:16:49.2144617Z + sudo yum install -y yum-utils
2026-01-14T08:16:49.6600754Z Last metadata expiration check: 0:02:01 ago on Wed Jan 14 08:14:48 2026.
2026-01-14T08:16:49.6888719Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:16:49.7519540Z Dependencies resolved.
2026-01-14T08:16:49.7879972Z Nothing to do.
2026-01-14T08:16:49.7880497Z Complete!
2026-01-14T08:16:49.8306708Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:16:49.8307531Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:49.8308429Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:50.1550760Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:16:50.2010779Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:16:50.7777198Z nvidia-container-toolkit                         18 kB/s | 833  B     00:00    
2026-01-14T08:16:50.8715558Z Dependencies resolved.
2026-01-14T08:16:50.9077435Z ================================================================================
2026-01-14T08:16:50.9078634Z  Package                       Arch   Version    Repository                Size
2026-01-14T08:16:50.9079283Z ================================================================================
2026-01-14T08:16:50.9079710Z Downgrading:
2026-01-14T08:16:50.9080075Z  libnvidia-container-tools     x86_64 1.17.8-1   nvidia-container-toolkit  40 k
2026-01-14T08:16:50.9080655Z  libnvidia-container1          x86_64 1.17.8-1   nvidia-container-toolkit 1.0 M
2026-01-14T08:16:50.9081219Z  nvidia-container-toolkit      x86_64 1.17.8-1   nvidia-container-toolkit 1.2 M
2026-01-14T08:16:50.9081923Z  nvidia-container-toolkit-base x86_64 1.17.8-1   nvidia-container-toolkit 5.8 M
2026-01-14T08:16:50.9082511Z 
2026-01-14T08:16:50.9082610Z Transaction Summary
2026-01-14T08:16:50.9082947Z ================================================================================
2026-01-14T08:16:50.9083305Z Downgrade  4 Packages
2026-01-14T08:16:50.9083452Z 
2026-01-14T08:16:50.9083555Z Total download size: 8.0 M
2026-01-14T08:16:50.9083811Z Downloading Packages:
2026-01-14T08:16:50.9322947Z (1/4): libnvidia-container-tools-1.17.8-1.x86_6 1.7 MB/s |  40 kB     00:00    
2026-01-14T08:16:50.9395529Z (2/4): libnvidia-container1-1.17.8-1.x86_64.rpm  33 MB/s | 1.0 MB     00:00    
2026-01-14T08:16:50.9548767Z (3/4): nvidia-container-toolkit-1.17.8-1.x86_64  28 MB/s | 1.2 MB     00:00    
2026-01-14T08:16:51.0326998Z (4/4): nvidia-container-toolkit-base-1.17.8-1.x  58 MB/s | 5.8 MB     00:00    
2026-01-14T08:16:51.0336632Z --------------------------------------------------------------------------------
2026-01-14T08:16:51.0339126Z Total                                            64 MB/s | 8.0 MB     00:00     
2026-01-14T08:16:51.0341626Z Running transaction check
2026-01-14T08:16:51.0474458Z Transaction check succeeded.
2026-01-14T08:16:51.0475160Z Running transaction test
2026-01-14T08:16:51.0980761Z Transaction test succeeded.
2026-01-14T08:16:51.0983780Z Running transaction
2026-01-14T08:16:51.6938461Z   Preparing        :                                                        1/1 
2026-01-14T08:16:51.7833083Z   Downgrading      : nvidia-container-toolkit-base-1.17.8-1.x86_64          1/8 
2026-01-14T08:16:51.7878413Z   Downgrading      : libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:16:51.8186957Z   Running scriptlet: libnvidia-container1-1.17.8-1.x86_64                   2/8 
2026-01-14T08:16:51.9277649Z   Downgrading      : libnvidia-container-tools-1.17.8-1.x86_64              3/8 
2026-01-14T08:16:51.9321294Z   Downgrading      : nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:16:51.9543119Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               4/8 
2026-01-14T08:16:51.9629136Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:51.9629733Z   Cleanup          : nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:51.9762932Z   Running scriptlet: nvidia-container-toolkit-1.18.1-1.x86_64               5/8 
2026-01-14T08:16:51.9847349Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:51.9850592Z   Cleanup          : libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:51.9974129Z   Running scriptlet: libnvidia-container-tools-1.18.1-1.x86_64              6/8 
2026-01-14T08:16:52.0064233Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:52.0064852Z   Cleanup          : libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:52.0207931Z   Running scriptlet: libnvidia-container1-1.18.1-1.x86_64                   7/8 
2026-01-14T08:16:52.0292235Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:52.0292949Z   Cleanup          : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:52.0426716Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:52.1056258Z   Running scriptlet: nvidia-container-toolkit-1.17.8-1.x86_64               8/8 
2026-01-14T08:16:54.9653055Z   Running scriptlet: nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8 
2026-01-14T08:16:54.9653679Z   Verifying        : libnvidia-container-tools-1.17.8-1.x86_64              1/8 
2026-01-14T08:16:54.9654245Z   Verifying        : libnvidia-container-tools-1.18.1-1.x86_64              2/8 
2026-01-14T08:16:54.9654811Z   Verifying        : libnvidia-container1-1.17.8-1.x86_64                   3/8 
2026-01-14T08:16:54.9655431Z   Verifying        : libnvidia-container1-1.18.1-1.x86_64                   4/8 
2026-01-14T08:16:54.9656182Z   Verifying        : nvidia-container-toolkit-1.17.8-1.x86_64               5/8 
2026-01-14T08:16:54.9657148Z   Verifying        : nvidia-container-toolkit-1.18.1-1.x86_64               6/8 
2026-01-14T08:16:54.9657696Z   Verifying        : nvidia-container-toolkit-base-1.17.8-1.x86_64          7/8 
2026-01-14T08:16:55.1241769Z   Verifying        : nvidia-container-toolkit-base-1.18.1-1.x86_64          8/8================================================================================
2026-01-14T08:16:55.1242401Z WARNING:
2026-01-14T08:16:55.1242650Z   A newer release of "Amazon Linux" is available.
2026-01-14T08:16:55.1242883Z 
2026-01-14T08:16:55.1242978Z   Available Versions:
2026-01-14T08:16:55.1243132Z 
2026-01-14T08:16:55.1243222Z   Version 2023.10.20260105:
2026-01-14T08:16:55.1243535Z     Run the following command to upgrade to 2023.10.20260105:
2026-01-14T08:16:55.1243803Z 
2026-01-14T08:16:55.1243929Z       dnf upgrade --releasever=2023.10.20260105
2026-01-14T08:16:55.1244145Z 
2026-01-14T08:16:55.1244238Z     Release notes:
2026-01-14T08:16:55.1244661Z      https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes-2023.10.20260105.html
2026-01-14T08:16:55.1245049Z 
2026-01-14T08:16:55.1245186Z ================================================================================
2026-01-14T08:16:55.1894175Z  
2026-01-14T08:16:55.1894698Z 
2026-01-14T08:16:55.1895060Z Downgraded:
2026-01-14T08:16:55.1895940Z   libnvidia-container-tools-1.17.8-1.x86_64                                     
2026-01-14T08:16:55.1897101Z   libnvidia-container1-1.17.8-1.x86_64                                          
2026-01-14T08:16:55.1898208Z   nvidia-container-toolkit-1.17.8-1.x86_64                                      
2026-01-14T08:16:55.1899356Z   nvidia-container-toolkit-base-1.17.8-1.x86_64                                 
2026-01-14T08:16:55.1899949Z 
2026-01-14T08:16:55.1900056Z Complete!
2026-01-14T08:16:55.2429864Z + sudo systemctl restart docker
2026-01-14T08:17:03.4777629Z Wed Jan 14 08:17:03 2026       
2026-01-14T08:17:03.4778470Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:03.4779558Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:03.4780610Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:03.4781596Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:03.4782556Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:03.4783035Z |                                         |                        |               MIG M. |
2026-01-14T08:17:03.4783426Z |=========================================+========================+======================|
2026-01-14T08:17:03.5126529Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:03.5127154Z |  0%   25C    P0             55W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:03.5127695Z |                                         |                        |                  N/A |
2026-01-14T08:17:03.5128150Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:03.5128654Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:03.5129145Z |  0%   25C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:03.5129570Z |                                         |                        |                  N/A |
2026-01-14T08:17:03.5130021Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:03.5130512Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:03.5130985Z |  0%   24C    P0             56W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:03.5131710Z |                                         |                        |                  N/A |
2026-01-14T08:17:03.5132166Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:03.5132658Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:03.5133135Z |  0%   24C    P0             51W /  300W |       0MiB /  23028MiB |      2%      Default |
2026-01-14T08:17:03.5133567Z |                                         |                        |                  N/A |
2026-01-14T08:17:03.5134005Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:03.5134546Z 
2026-01-14T08:17:03.5134752Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:03.5135250Z | Processes:                                                                              |
2026-01-14T08:17:03.5135736Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:03.5136212Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:03.5136609Z |=========================================================================================|
2026-01-14T08:17:03.5155701Z |  No running processes found                                                             |
2026-01-14T08:17:03.5156230Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:04.1483303Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:17:04.3782544Z 3.13: Pulling from docker/library/python
2026-01-14T08:17:04.4771322Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:17:04.4771620Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:17:04.4771882Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:17:04.4772139Z 26d823e3848f: Pulling fs layer
2026-01-14T08:17:04.4772391Z ca4b54413202: Pulling fs layer
2026-01-14T08:17:04.4772664Z b6513238a015: Pulling fs layer
2026-01-14T08:17:04.4772914Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:17:04.4773151Z 26d823e3848f: Waiting
2026-01-14T08:17:04.4773367Z ca4b54413202: Waiting
2026-01-14T08:17:04.4773578Z b6513238a015: Waiting
2026-01-14T08:17:04.4773819Z 9b57076d00d4: Waiting
2026-01-14T08:17:04.6022736Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:17:04.6023031Z 82e18c5e1c15: Download complete
2026-01-14T08:17:04.6610876Z 2ca1bfae7ba8: Verifying Checksum
2026-01-14T08:17:04.6611180Z 2ca1bfae7ba8: Download complete
2026-01-14T08:17:04.6993934Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:17:04.6994329Z be442a7e0d6f: Download complete
2026-01-14T08:17:04.7345800Z ca4b54413202: Verifying Checksum
2026-01-14T08:17:04.7346312Z ca4b54413202: Download complete
2026-01-14T08:17:04.7866654Z 9b57076d00d4: Download complete
2026-01-14T08:17:04.8288532Z b6513238a015: Verifying Checksum
2026-01-14T08:17:04.8289090Z b6513238a015: Download complete
2026-01-14T08:17:05.2234434Z 26d823e3848f: Verifying Checksum
2026-01-14T08:17:05.2235010Z 26d823e3848f: Download complete
2026-01-14T08:17:06.4549494Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:17:07.2080333Z 82e18c5e1c15: Pull complete
2026-01-14T08:17:09.7545477Z be442a7e0d6f: Pull complete
2026-01-14T08:17:16.9952808Z 26d823e3848f: Pull complete
2026-01-14T08:17:17.3710762Z ca4b54413202: Pull complete
2026-01-14T08:17:18.1444297Z b6513238a015: Pull complete
2026-01-14T08:17:18.1675389Z 9b57076d00d4: Pull complete
2026-01-14T08:17:18.1815164Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:18.1858105Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:23.9730030Z Wed Jan 14 08:17:23 2026       
2026-01-14T08:17:23.9730866Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:23.9732064Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:17:23.9733568Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:23.9734648Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:17:23.9735784Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:17:23.9736364Z |                                         |                        |               MIG M. |
2026-01-14T08:17:23.9736774Z |=========================================+========================+======================|
2026-01-14T08:17:24.0355219Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:17:24.0355725Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:24.0356158Z |                                         |                        |                  N/A |
2026-01-14T08:17:24.0356607Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:24.0357102Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:17:24.0357570Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:24.0357990Z |                                         |                        |                  N/A |
2026-01-14T08:17:24.0358451Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:24.0358932Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:17:24.0359404Z |  0%   22C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:24.0359834Z |                                         |                        |                  N/A |
2026-01-14T08:17:24.0360279Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:24.0360778Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:17:24.0361244Z |  0%   21C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:17:24.0361673Z |                                         |                        |                  N/A |
2026-01-14T08:17:24.0362121Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:17:24.0383567Z 
2026-01-14T08:17:24.0383914Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:24.0384425Z | Processes:                                                                              |
2026-01-14T08:17:24.0384928Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:17:24.0385394Z |        ID   ID                                                               Usage      |
2026-01-14T08:17:24.0385794Z |=========================================================================================|
2026-01-14T08:17:24.0421077Z |  No running processes found                                                             |
2026-01-14T08:17:24.0421599Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:17:25.7057699Z Command completed after 1 attempt(s).
2026-01-14T08:17:25.7166683Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T08:17:25.7167238Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T08:17:25.7167647Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T08:17:25.7167959Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T08:17:25.7168286Z [36;1m# Prune all of the docker images[0m
2026-01-14T08:17:25.7168593Z [36;1mdocker system prune -af[0m
2026-01-14T08:17:25.7184193Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:25.7184542Z env:
2026-01-14T08:17:25.7184974Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:25.7185316Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:25.7185558Z   PR_NUMBER: 3500
2026-01-14T08:17:25.7187073Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:25.7188765Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:25.7189319Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:25.7189848Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:25.7190217Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:25.7190516Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:25.7190861Z ##[endgroup]
2026-01-14T08:17:25.7544099Z "docker stop" requires at least 1 argument.
2026-01-14T08:17:25.7544440Z See 'docker stop --help'.
2026-01-14T08:17:25.7544610Z 
2026-01-14T08:17:25.7544766Z Usage:  docker stop [OPTIONS] CONTAINER [CONTAINER...]
2026-01-14T08:17:25.7545018Z 
2026-01-14T08:17:25.7545142Z Stop one or more running containers
2026-01-14T08:17:27.0397179Z Deleted Images:
2026-01-14T08:17:27.0397539Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T08:17:27.0398211Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:17:27.0398973Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T08:17:27.0399566Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T08:17:27.0400154Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T08:17:27.0400764Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T08:17:27.0401350Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T08:17:27.0401950Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T08:17:27.0402551Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T08:17:27.0403451Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T08:17:27.0403820Z 
2026-01-14T08:17:27.0697166Z Total reclaimed space: 1.109GB
2026-01-14T08:17:27.0802335Z ##[group]Run ./test-infra/.github/actions/setup-ssh
2026-01-14T08:17:27.0802700Z with:
2026-01-14T08:17:27.0803552Z   github-secret: ***
2026-01-14T08:17:27.0804232Z   instructions: All testing is done inside the container, to start an interactive session run:
   docker exec -it $(docker container ps --format '{{.ID}}') bash

2026-01-14T08:17:27.0804970Z   activate-with-label: false
2026-01-14T08:17:27.0805242Z   label: with-ssh
2026-01-14T08:17:27.0805481Z   remove-existing-keys: true
2026-01-14T08:17:27.0805753Z   fail-silently: true
2026-01-14T08:17:27.0805974Z env:
2026-01-14T08:17:27.0806226Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:27.0806566Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:27.0806825Z   PR_NUMBER: 3500
2026-01-14T08:17:27.0808356Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:27.0810049Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:27.0810606Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:27.0811396Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:27.0811773Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:27.0812084Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:27.0812423Z ##[endgroup]
2026-01-14T08:17:27.2009991Z Please see https://github.com/pytorch/pytorch/wiki/Debugging-using-with-ssh-for-Github-Actions for more info.
2026-01-14T08:17:27.6570206Z Grabbing public ssh keys from https://github.com/zxd1997066.keys
2026-01-14T08:17:27.7537639Z ~/.ssh/authorized_keys file found on node, removing ~/.ssh and starting fresh
2026-01-14T08:17:27.7553020Z Public keys pulled and installed to /home/ec2-user/.ssh/authorized_keys
2026-01-14T08:17:27.7597780Z Login using: ssh ec2-user@ec2-54-157-242-66.compute-1.amazonaws.com
2026-01-14T08:17:27.7598313Z All testing is done inside the container, to start an interactive session run:
2026-01-14T08:17:27.7598835Z    docker exec -it $(docker container ps --format '{{.ID}}') bash
2026-01-14T08:17:27.7765239Z ##[group]Run actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683
2026-01-14T08:17:27.7765642Z with:
2026-01-14T08:17:27.7765848Z   repository: pytorch/ao
2026-01-14T08:17:27.7766093Z   ref: refs/pull/3500/merge
2026-01-14T08:17:27.7766337Z   path: pytorch/ao
2026-01-14T08:17:27.7766550Z   fetch-depth: 1
2026-01-14T08:17:27.7766759Z   submodules: recursive
2026-01-14T08:17:27.7767087Z   token: ***
2026-01-14T08:17:27.7767287Z   ssh-strict: true
2026-01-14T08:17:27.7767494Z   ssh-user: git
2026-01-14T08:17:27.7767750Z   persist-credentials: true
2026-01-14T08:17:27.7768011Z   clean: true
2026-01-14T08:17:27.7768229Z   sparse-checkout-cone-mode: true
2026-01-14T08:17:27.7768507Z   fetch-tags: false
2026-01-14T08:17:27.7768729Z   show-progress: true
2026-01-14T08:17:27.7768940Z   lfs: false
2026-01-14T08:17:27.7769151Z   set-safe-directory: true
2026-01-14T08:17:27.7769377Z env:
2026-01-14T08:17:27.7769612Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:27.7770041Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:27.7770271Z   PR_NUMBER: 3500
2026-01-14T08:17:27.7771828Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:27.7773505Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:27.7774051Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:27.7774563Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:27.7774929Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:27.7775212Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:27.7775546Z ##[endgroup]
2026-01-14T08:17:27.8773763Z Syncing repository: pytorch/ao
2026-01-14T08:17:27.8782812Z ##[group]Getting Git version info
2026-01-14T08:17:27.8783246Z Working directory is '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao'
2026-01-14T08:17:27.8810628Z [command]/usr/bin/git version
2026-01-14T08:17:27.8865830Z git version 2.50.1
2026-01-14T08:17:27.8892346Z ##[endgroup]
2026-01-14T08:17:27.8907033Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/6a35e865-0e53-495a-9f86-d0ec30796506' before making global git config changes
2026-01-14T08:17:27.8907932Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T08:17:27.8923989Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:27.8963371Z ##[group]Initializing the repository
2026-01-14T08:17:27.8968016Z [command]/usr/bin/git init /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao
2026-01-14T08:17:27.9021410Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-01-14T08:17:27.9022267Z hint: is subject to change. To configure the initial branch name to use in all
2026-01-14T08:17:27.9022806Z hint: of your new repositories, which will suppress this warning, call:
2026-01-14T08:17:27.9023196Z hint:
2026-01-14T08:17:27.9023464Z hint: 	git config --global init.defaultBranch <name>
2026-01-14T08:17:27.9023784Z hint:
2026-01-14T08:17:27.9024098Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-01-14T08:17:27.9024624Z hint: 'development'. The just-created branch can be renamed via this command:
2026-01-14T08:17:27.9025032Z hint:
2026-01-14T08:17:27.9025235Z hint: 	git branch -m <name>
2026-01-14T08:17:27.9025479Z hint:
2026-01-14T08:17:27.9025811Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-01-14T08:17:27.9026456Z Initialized empty Git repository in /home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/
2026-01-14T08:17:27.9034291Z [command]/usr/bin/git remote add origin https://github.com/pytorch/ao
2026-01-14T08:17:27.9071299Z ##[endgroup]
2026-01-14T08:17:27.9073550Z ##[group]Disabling automatic garbage collection
2026-01-14T08:17:27.9075811Z [command]/usr/bin/git config --local gc.auto 0
2026-01-14T08:17:27.9113438Z ##[endgroup]
2026-01-14T08:17:27.9113926Z ##[group]Setting up auth
2026-01-14T08:17:27.9119303Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T08:17:27.9157936Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T08:17:27.9562606Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T08:17:27.9598863Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T08:17:28.0011007Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:28.0062415Z ##[endgroup]
2026-01-14T08:17:28.0062944Z ##[group]Fetching the repository
2026-01-14T08:17:28.0069873Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +refs/pull/3500/merge:refs/remotes/pull/3500/merge
2026-01-14T08:17:28.7231393Z From https://github.com/pytorch/ao
2026-01-14T08:17:28.7231919Z  * [new ref]         refs/pull/3500/merge -> pull/3500/merge
2026-01-14T08:17:28.7262326Z ##[endgroup]
2026-01-14T08:17:28.7262843Z ##[group]Determining the checkout info
2026-01-14T08:17:28.7265036Z ##[endgroup]
2026-01-14T08:17:28.7280026Z [command]/usr/bin/git sparse-checkout disable
2026-01-14T08:17:28.7327313Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-01-14T08:17:28.7363437Z ##[group]Checking out the ref
2026-01-14T08:17:28.7366817Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/3500/merge
2026-01-14T08:17:28.8844542Z Note: switching to 'refs/remotes/pull/3500/merge'.
2026-01-14T08:17:28.8844951Z 
2026-01-14T08:17:28.8845252Z You are in 'detached HEAD' state. You can look around, make experimental
2026-01-14T08:17:28.8845843Z changes and commit them, and you can discard any commits you make in this
2026-01-14T08:17:28.8846364Z state without impacting any branches by switching back to a branch.
2026-01-14T08:17:28.8846667Z 
2026-01-14T08:17:28.8846874Z If you want to create a new branch to retain commits you create, you may
2026-01-14T08:17:28.8847409Z do so (now or later) by using -c with the switch command. Example:
2026-01-14T08:17:28.8847711Z 
2026-01-14T08:17:28.8847827Z   git switch -c <new-branch-name>
2026-01-14T08:17:28.8848015Z 
2026-01-14T08:17:28.8848118Z Or undo this operation with:
2026-01-14T08:17:28.8848296Z 
2026-01-14T08:17:28.8848378Z   git switch -
2026-01-14T08:17:28.8848503Z 
2026-01-14T08:17:28.8848757Z Turn off this advice by setting config variable advice.detachedHead to false
2026-01-14T08:17:28.8850348Z 
2026-01-14T08:17:28.8850725Z HEAD is now at b34f898 Merge f07387cd29b2a97703e501a48808c413bf9d95ea into 985d970b5e16b58c1e5b8bab440169d3da78cf16
2026-01-14T08:17:28.8866292Z ##[endgroup]
2026-01-14T08:17:28.8877704Z ##[group]Setting up auth for fetching submodules
2026-01-14T08:17:28.8878445Z [command]/usr/bin/git config --global http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-01-14T08:17:28.8928952Z [command]/usr/bin/git config --global --unset-all url.https://github.com/.insteadOf
2026-01-14T08:17:28.8964596Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf git@github.com:
2026-01-14T08:17:28.9003251Z [command]/usr/bin/git config --global --add url.https://github.com/.insteadOf org-21003710@github.com:
2026-01-14T08:17:28.9035856Z ##[endgroup]
2026-01-14T08:17:28.9036517Z ##[group]Fetching submodules
2026-01-14T08:17:28.9039325Z [command]/usr/bin/git submodule sync --recursive
2026-01-14T08:17:28.9447497Z [command]/usr/bin/git -c protocol.version=2 submodule update --init --force --depth=1 --recursive
2026-01-14T08:17:28.9840738Z Submodule 'third_party/cutlass' (https://github.com/NVIDIA/cutlass) registered for path 'third_party/cutlass'
2026-01-14T08:17:28.9918960Z Cloning into '/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/third_party/cutlass'...
2026-01-14T08:17:31.1893938Z From https://github.com/NVIDIA/cutlass
2026-01-14T08:17:31.1894400Z  * branch            e51efbfe18fe4f4cbb66ab814c55bf4aa0185491 -> FETCH_HEAD
2026-01-14T08:17:31.9875368Z Submodule path 'third_party/cutlass': checked out 'e51efbfe18fe4f4cbb66ab814c55bf4aa0185491'
2026-01-14T08:17:31.9924786Z [command]/usr/bin/git submodule foreach --recursive git config --local gc.auto 0
2026-01-14T08:17:32.0323813Z Entering 'third_party/cutlass'
2026-01-14T08:17:32.0408846Z ##[endgroup]
2026-01-14T08:17:32.0409265Z ##[group]Persisting credentials for submodules
2026-01-14T08:17:32.0414869Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'url\.https\:\/\/github\.com\/\.insteadOf' && git config --local --unset-all 'url.https://github.com/.insteadOf' || :"
2026-01-14T08:17:32.0814363Z Entering 'third_party/cutlass'
2026-01-14T08:17:32.0920175Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local 'http.https://github.com/.extraheader' 'AUTHORIZATION: basic ***' && git config --local --show-origin --name-only --get-regexp remote.origin.url"
2026-01-14T08:17:32.1307151Z Entering 'third_party/cutlass'
2026-01-14T08:17:32.1384900Z file:/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao/.git/modules/third_party/cutlass/config	remote.origin.url
2026-01-14T08:17:32.1452864Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'git@github.com:'
2026-01-14T08:17:32.1837357Z Entering 'third_party/cutlass'
2026-01-14T08:17:32.1927679Z [command]/usr/bin/git submodule foreach --recursive git config --local --add 'url.https://github.com/.insteadOf' 'org-21003710@github.com:'
2026-01-14T08:17:32.2309651Z Entering 'third_party/cutlass'
2026-01-14T08:17:32.2390781Z ##[endgroup]
2026-01-14T08:17:32.2436706Z [command]/usr/bin/git log -1 --format=%H
2026-01-14T08:17:32.2467061Z b34f89824bef6a4573349bfbefa82a7db14ede35
2026-01-14T08:17:32.2729827Z Prepare all required actions
2026-01-14T08:17:32.2730755Z Getting action download info
2026-01-14T08:17:32.4160906Z Download action repository 'nick-fields/retry@v3.0.0' (SHA:7152eba30c6575329ac0576536151aca5a72780e)
2026-01-14T08:17:32.6378105Z ##[group]Run ./test-infra/.github/actions/calculate-docker-image
2026-01-14T08:17:32.6378529Z with:
2026-01-14T08:17:32.6378753Z   use-custom-docker-registry: true
2026-01-14T08:17:32.6379122Z   docker-image-name: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6379483Z   docker-build-dir: .ci/docker
2026-01-14T08:17:32.6379758Z   working-directory: pytorch/ao
2026-01-14T08:17:32.6380042Z   docker-build-script: ./build.sh
2026-01-14T08:17:32.6380651Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:32.6381026Z   force-push: false
2026-01-14T08:17:32.6381230Z env:
2026-01-14T08:17:32.6381471Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6381800Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:32.6382082Z   PR_NUMBER: 3500
2026-01-14T08:17:32.6383572Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:32.6385255Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:32.6385816Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:32.6386338Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:32.6386714Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:32.6387022Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:32.6387351Z ##[endgroup]
2026-01-14T08:17:32.6428690Z ##[group]Run set -ex
2026-01-14T08:17:32.6428970Z [36;1mset -ex[0m
2026-01-14T08:17:32.6429185Z [36;1m[0m
2026-01-14T08:17:32.6429557Z [36;1m# If the docker build directory or the build script doesn't exist, the action will[0m
2026-01-14T08:17:32.6430215Z [36;1m# gracefully return the docker image name as it is.  Pulling docker image in Linux[0m
2026-01-14T08:17:32.6430767Z [36;1m# job could then download the pre-built image as usual[0m
2026-01-14T08:17:32.6431467Z [36;1mif [[ -d "${DOCKER_BUILD_DIR}" ]] && [[ -f "${DOCKER_BUILD_DIR}/${DOCKER_BUILD_SCRIPT}" ]] && [[ "${USE_CUSTOM_DOCKER_REGISTRY}" == "true" ]]; then[0m
2026-01-14T08:17:32.6432131Z [36;1m  echo "skip=false" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6432447Z [36;1melse[0m
2026-01-14T08:17:32.6432700Z [36;1m  echo "skip=true" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6433133Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6433523Z [36;1m[0m
2026-01-14T08:17:32.6434080Z [36;1m  echo "Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ${REPO_NAME} repo..."[0m
2026-01-14T08:17:32.6434695Z [36;1m  exit 0[0m
2026-01-14T08:17:32.6434909Z [36;1mfi[0m
2026-01-14T08:17:32.6435110Z [36;1m[0m
2026-01-14T08:17:32.6435443Z [36;1mif [[ "${DOCKER_IMAGE_NAME}" == *"${DOCKER_REGISTRY}/${REPO_NAME}"* ]]; then[0m
2026-01-14T08:17:32.6436027Z [36;1m  # The docker image name already includes the ECR prefix and tag, so we can just[0m
2026-01-14T08:17:32.6436555Z [36;1m  # use it as it is, but first let's extract the tag[0m
2026-01-14T08:17:32.6437032Z [36;1m  DOCKER_TAG=$(echo "${DOCKER_IMAGE_NAME}" | awk -F '[:,]' '{print $2}')[0m
2026-01-14T08:17:32.6437526Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6438005Z [36;1m  echo "docker-image=${DOCKER_IMAGE_NAME}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6438443Z [36;1melse[0m
2026-01-14T08:17:32.6438700Z [36;1m  if [[ "${DOCKER_IMAGE_NAME}" == *:* ]]; then[0m
2026-01-14T08:17:32.6439276Z [36;1m    CUSTOM_TAG_PREFIX=${DOCKER_IMAGE_NAME#*:}[0m
2026-01-14T08:17:32.6439666Z [36;1m    DOCKER_IMAGE_NAME=${DOCKER_IMAGE_NAME%%:*}[0m
2026-01-14T08:17:32.6439991Z [36;1m  fi[0m
2026-01-14T08:17:32.6440432Z [36;1m  DOCKER_TAG=${CUSTOM_TAG_PREFIX:+${CUSTOM_TAG_PREFIX}-}$(git rev-parse HEAD:"${DOCKER_BUILD_DIR}")[0m
2026-01-14T08:17:32.6441042Z [36;1m  echo "docker-tag=${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6441661Z [36;1m  echo "docker-image=${DOCKER_REGISTRY}/${REPO_NAME}/${DOCKER_IMAGE_NAME}:${DOCKER_TAG}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6442355Z [36;1m  echo "custom-tag-prefix=${CUSTOM_TAG_PREFIX}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T08:17:32.6442887Z [36;1mfi[0m
2026-01-14T08:17:32.6452683Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:32.6453034Z env:
2026-01-14T08:17:32.6453273Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6453616Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:32.6453864Z   PR_NUMBER: 3500
2026-01-14T08:17:32.6455371Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:32.6457052Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:32.6457603Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:32.6458145Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:32.6458518Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:32.6458828Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:32.6459174Z   REPO_NAME: ao
2026-01-14T08:17:32.6459453Z   DOCKER_IMAGE_NAME: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6459808Z   DOCKER_BUILD_DIR: .ci/docker
2026-01-14T08:17:32.6460072Z   DOCKER_BUILD_SCRIPT: ./build.sh
2026-01-14T08:17:32.6460435Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:32.6460816Z   USE_CUSTOM_DOCKER_REGISTRY: true
2026-01-14T08:17:32.6461098Z   CUSTOM_TAG_PREFIX: 
2026-01-14T08:17:32.6461325Z ##[endgroup]
2026-01-14T08:17:32.6492977Z + [[ -d .ci/docker ]]
2026-01-14T08:17:32.6493215Z + echo skip=true
2026-01-14T08:17:32.6493501Z + echo docker-image=pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6494144Z + echo 'Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...'
2026-01-14T08:17:32.6494703Z + exit 0
2026-01-14T08:17:32.6495154Z Not using custom ECR registry.  Either it was not requested or there is no Docker build script in the ao repo...
2026-01-14T08:17:32.6539980Z ##[group]Run set -eux
2026-01-14T08:17:32.6540262Z [36;1mset -eux[0m
2026-01-14T08:17:32.6540703Z [36;1m# It's ok if this steps fails, it would then be an anonymous user like what we used to have[0m
2026-01-14T08:17:32.6541849Z [36;1maws secretsmanager get-secret-value --secret-id docker_hub_readonly_token | jq --raw-output '.SecretString' | jq -r .docker_hub_readonly_token | docker login --username pytorchbot --password-stdin || true[0m
2026-01-14T08:17:32.6552193Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:32.6552548Z env:
2026-01-14T08:17:32.6552809Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:32.6553170Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:32.6553421Z   PR_NUMBER: 3500
2026-01-14T08:17:32.6555135Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:32.6556854Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:32.6557410Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:32.6557956Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:32.6558327Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:32.6558643Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:32.6558983Z ##[endgroup]
2026-01-14T08:17:32.6597677Z + aws secretsmanager get-secret-value --secret-id docker_hub_readonly_token
2026-01-14T08:17:32.6598647Z + jq --raw-output .SecretString
2026-01-14T08:17:32.6599819Z + jq -r .docker_hub_readonly_token
2026-01-14T08:17:32.6601689Z + docker login --username pytorchbot --password-stdin
2026-01-14T08:17:33.2716125Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:33.2716727Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:33.2717261Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:33.2717617Z 
2026-01-14T08:17:33.2717712Z Login Succeeded
2026-01-14T08:17:33.2798960Z Prepare all required actions
2026-01-14T08:17:33.2840614Z ##[group]Run ./test-infra/.github/actions/pull-docker-image
2026-01-14T08:17:33.2840961Z with:
2026-01-14T08:17:33.2841215Z   docker-image: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:33.2841641Z   docker-registry: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:33.2842003Z env:
2026-01-14T08:17:33.2842245Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:33.2842585Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:33.2842828Z   PR_NUMBER: 3500
2026-01-14T08:17:33.2844320Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:33.2846026Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:33.2846569Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:33.2847098Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:33.2847470Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:33.2847766Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:33.2848092Z ##[endgroup]
2026-01-14T08:17:33.2884582Z ##[group]Run set -x
2026-01-14T08:17:33.2884935Z [36;1mset -x[0m
2026-01-14T08:17:33.2885143Z [36;1mset +e[0m
2026-01-14T08:17:33.2885347Z [36;1m[0m
2026-01-14T08:17:33.2885538Z [36;1mlogin() {[0m
2026-01-14T08:17:33.2885990Z [36;1m  aws ecr get-login-password --region us-east-1 | docker login -u AWS --password-stdin "$1"[0m
2026-01-14T08:17:33.2886490Z [36;1m}[0m
2026-01-14T08:17:33.2886673Z [36;1m[0m
2026-01-14T08:17:33.2886864Z [36;1mretry () {[0m
2026-01-14T08:17:33.2887123Z [36;1m  $*  || (sleep 1 && $*) || (sleep 2 && $*)[0m
2026-01-14T08:17:33.2887424Z [36;1m}[0m
2026-01-14T08:17:33.2887606Z [36;1m[0m
2026-01-14T08:17:33.2887818Z [36;1mretry login "${DOCKER_REGISTRY}"[0m
2026-01-14T08:17:33.2888103Z [36;1m[0m
2026-01-14T08:17:33.2888557Z [36;1mIMAGE_SIZE=$(docker manifest inspect "${DOCKER_IMAGE}" | jq '[.layers[].size, .config.size] | add / 1024 / 1024')[0m
2026-01-14T08:17:33.2889190Z [36;1mecho "Compressed size of image in MB: ${IMAGE_SIZE}"[0m
2026-01-14T08:17:33.2889537Z [36;1m[0m
2026-01-14T08:17:33.2889734Z [36;1mset -e[0m
2026-01-14T08:17:33.2890045Z [36;1m# ignore output since only exit code is used for conditional[0m
2026-01-14T08:17:33.2890510Z [36;1m# only pull docker image if it's not available locally[0m
2026-01-14T08:17:33.2891028Z [36;1mif ! docker inspect --type=image "${DOCKER_IMAGE}" >/dev/null 2>/dev/null; then[0m
2026-01-14T08:17:33.2891567Z [36;1m  retry docker pull "${DOCKER_IMAGE}"[0m
2026-01-14T08:17:33.2891863Z [36;1mfi[0m
2026-01-14T08:17:33.2901797Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:17:33.2902148Z env:
2026-01-14T08:17:33.2902389Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:33.2902732Z   REPOSITORY: pytorch/ao
2026-01-14T08:17:33.2902973Z   PR_NUMBER: 3500
2026-01-14T08:17:33.2904489Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:17:33.2906376Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:17:33.2906937Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:17:33.2907470Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:17:33.2908006Z   HAS_NVIDIA_GPU: true
2026-01-14T08:17:33.2908309Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:17:33.2908748Z   DOCKER_REGISTRY: 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:33.2909111Z ##[endgroup]
2026-01-14T08:17:33.2945082Z + set +e
2026-01-14T08:17:33.2945376Z + retry login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:33.2945779Z + login 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:33.2950290Z + aws ecr get-login-password --region us-east-1
2026-01-14T08:17:33.2950804Z + docker login -u AWS --password-stdin 308535385114.dkr.ecr.us-east-1.amazonaws.com
2026-01-14T08:17:33.8597028Z WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.
2026-01-14T08:17:33.8597597Z Configure a credential helper to remove this warning. See
2026-01-14T08:17:33.8598106Z https://docs.docker.com/engine/reference/commandline/login/#credentials-store
2026-01-14T08:17:33.8598497Z 
2026-01-14T08:17:33.8598644Z Login Succeeded
2026-01-14T08:17:33.8634194Z ++ docker manifest inspect pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:33.8635130Z ++ jq '[.layers[].size, .config.size] | add / 1024 / 1024'
2026-01-14T08:17:34.0561874Z + IMAGE_SIZE=7985.954789161682
2026-01-14T08:17:34.0562228Z + echo 'Compressed size of image in MB: 7985.954789161682'
2026-01-14T08:17:34.0562567Z + set -e
2026-01-14T08:17:34.0562866Z + docker inspect --type=image pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:34.0563305Z Compressed size of image in MB: 7985.954789161682
2026-01-14T08:17:34.0722146Z + retry docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:34.0722545Z + docker pull pytorch/almalinux-builder:cuda12.6
2026-01-14T08:17:34.2638202Z cuda12.6: Pulling from pytorch/almalinux-builder
2026-01-14T08:17:34.2638585Z 19877a9af8e3: Pulling fs layer
2026-01-14T08:17:34.2638852Z 7335f5694751: Pulling fs layer
2026-01-14T08:17:34.2639116Z e89b428500ef: Pulling fs layer
2026-01-14T08:17:34.2639398Z 2890bcc97ae2: Pulling fs layer
2026-01-14T08:17:34.2639662Z 8e7a9d654295: Pulling fs layer
2026-01-14T08:17:34.2639913Z 55070e1f6d59: Pulling fs layer
2026-01-14T08:17:34.2640178Z a6ffcda215dd: Pulling fs layer
2026-01-14T08:17:34.2640440Z 4f4fb700ef54: Pulling fs layer
2026-01-14T08:17:34.2640705Z d4e5a2339eb1: Pulling fs layer
2026-01-14T08:17:34.2640987Z 3b50177ed801: Pulling fs layer
2026-01-14T08:17:34.2641240Z 657cfc9d9d43: Pulling fs layer
2026-01-14T08:17:34.2641500Z 039239a19e2c: Pulling fs layer
2026-01-14T08:17:34.2641765Z 301a59dd8ea1: Pulling fs layer
2026-01-14T08:17:34.2642026Z 747a1c0117bc: Pulling fs layer
2026-01-14T08:17:34.2642282Z 2d6f0c29ad9f: Pulling fs layer
2026-01-14T08:17:34.2642534Z 2890bcc97ae2: Waiting
2026-01-14T08:17:34.2642761Z 5b7921a1b019: Pulling fs layer
2026-01-14T08:17:34.2643020Z a4392ccb83ef: Pulling fs layer
2026-01-14T08:17:34.2643279Z 3f0968dff130: Pulling fs layer
2026-01-14T08:17:34.2643522Z 8e7a9d654295: Waiting
2026-01-14T08:17:34.2643759Z 9323969b3930: Pulling fs layer
2026-01-14T08:17:34.2644009Z 55070e1f6d59: Waiting
2026-01-14T08:17:34.2644238Z b9f6732b07f0: Pulling fs layer
2026-01-14T08:17:34.2644491Z 32117f6e66ab: Pulling fs layer
2026-01-14T08:17:34.2644759Z bed95346686d: Pulling fs layer
2026-01-14T08:17:34.2645007Z a6ffcda215dd: Waiting
2026-01-14T08:17:34.2645251Z a73f5cbdff4f: Pulling fs layer
2026-01-14T08:17:34.2645499Z 4f4fb700ef54: Waiting
2026-01-14T08:17:34.2645722Z 657cfc9d9d43: Waiting
2026-01-14T08:17:34.2645930Z 3b50177ed801: Waiting
2026-01-14T08:17:34.2646389Z 3f0968dff130: Waiting
2026-01-14T08:17:34.2646601Z 039239a19e2c: Waiting
2026-01-14T08:17:34.2646811Z 9323969b3930: Waiting
2026-01-14T08:17:34.2647025Z 301a59dd8ea1: Waiting
2026-01-14T08:17:34.2647233Z 747a1c0117bc: Waiting
2026-01-14T08:17:34.2647456Z 2d6f0c29ad9f: Waiting
2026-01-14T08:17:34.2647666Z 5b7921a1b019: Waiting
2026-01-14T08:17:34.2647881Z a4392ccb83ef: Waiting
2026-01-14T08:17:34.2648093Z a73f5cbdff4f: Waiting
2026-01-14T08:17:34.2648311Z b9f6732b07f0: Waiting
2026-01-14T08:17:34.2648748Z 32117f6e66ab: Waiting
2026-01-14T08:17:34.2648968Z d4e5a2339eb1: Waiting
2026-01-14T08:17:34.2649460Z bed95346686d: Waiting
2026-01-14T08:17:34.3469158Z e89b428500ef: Verifying Checksum
2026-01-14T08:17:34.3469874Z e89b428500ef: Download complete
2026-01-14T08:17:34.7252072Z 2890bcc97ae2: Verifying Checksum
2026-01-14T08:17:34.7252635Z 2890bcc97ae2: Download complete
2026-01-14T08:17:35.0024149Z 19877a9af8e3: Verifying Checksum
2026-01-14T08:17:35.0024422Z 19877a9af8e3: Download complete
2026-01-14T08:17:35.0542351Z 55070e1f6d59: Download complete
2026-01-14T08:17:35.6099773Z a6ffcda215dd: Verifying Checksum
2026-01-14T08:17:35.6100362Z a6ffcda215dd: Download complete
2026-01-14T08:17:35.6573759Z 4f4fb700ef54: Verifying Checksum
2026-01-14T08:17:35.6574293Z 4f4fb700ef54: Download complete
2026-01-14T08:17:35.7094736Z d4e5a2339eb1: Verifying Checksum
2026-01-14T08:17:35.7095044Z d4e5a2339eb1: Download complete
2026-01-14T08:17:35.7602207Z 3b50177ed801: Verifying Checksum
2026-01-14T08:17:35.7603143Z 3b50177ed801: Download complete
2026-01-14T08:17:35.8090446Z 657cfc9d9d43: Verifying Checksum
2026-01-14T08:17:35.8090736Z 657cfc9d9d43: Download complete
2026-01-14T08:17:35.8665805Z 039239a19e2c: Verifying Checksum
2026-01-14T08:17:35.8666166Z 039239a19e2c: Download complete
2026-01-14T08:17:36.0465625Z 7335f5694751: Verifying Checksum
2026-01-14T08:17:36.0465909Z 7335f5694751: Download complete
2026-01-14T08:17:36.1772167Z 747a1c0117bc: Verifying Checksum
2026-01-14T08:17:36.1772955Z 747a1c0117bc: Download complete
2026-01-14T08:17:36.2228939Z 2d6f0c29ad9f: Verifying Checksum
2026-01-14T08:17:36.2229508Z 2d6f0c29ad9f: Download complete
2026-01-14T08:17:36.8087601Z 8e7a9d654295: Verifying Checksum
2026-01-14T08:17:36.8087918Z 8e7a9d654295: Download complete
2026-01-14T08:17:36.8575914Z a4392ccb83ef: Download complete
2026-01-14T08:17:36.9054144Z 3f0968dff130: Verifying Checksum
2026-01-14T08:17:36.9054444Z 3f0968dff130: Download complete
2026-01-14T08:17:36.9607328Z 9323969b3930: Verifying Checksum
2026-01-14T08:17:36.9607985Z 9323969b3930: Download complete
2026-01-14T08:17:37.1020856Z b9f6732b07f0: Verifying Checksum
2026-01-14T08:17:37.1021479Z b9f6732b07f0: Download complete
2026-01-14T08:17:37.1547529Z 32117f6e66ab: Download complete
2026-01-14T08:17:37.1963550Z bed95346686d: Download complete
2026-01-14T08:17:37.7174336Z 19877a9af8e3: Pull complete
2026-01-14T08:17:40.6801982Z 5b7921a1b019: Verifying Checksum
2026-01-14T08:17:40.6802307Z 5b7921a1b019: Download complete
2026-01-14T08:17:41.5205917Z 7335f5694751: Pull complete
2026-01-14T08:17:41.7172198Z e89b428500ef: Pull complete
2026-01-14T08:17:42.0070503Z 2890bcc97ae2: Pull complete
2026-01-14T08:17:43.1385364Z a73f5cbdff4f: Verifying Checksum
2026-01-14T08:17:43.1385700Z a73f5cbdff4f: Download complete
2026-01-14T08:17:48.2580556Z 8e7a9d654295: Pull complete
2026-01-14T08:17:48.2814995Z 55070e1f6d59: Pull complete
2026-01-14T08:17:49.5928678Z a6ffcda215dd: Pull complete
2026-01-14T08:17:49.6176232Z 4f4fb700ef54: Pull complete
2026-01-14T08:18:40.6721973Z d4e5a2339eb1: Pull complete
2026-01-14T08:18:40.6949904Z 3b50177ed801: Pull complete
2026-01-14T08:18:40.7176778Z 657cfc9d9d43: Pull complete
2026-01-14T08:18:40.7426581Z 039239a19e2c: Pull complete
2026-01-14T08:18:43.6306705Z 301a59dd8ea1: Verifying Checksum
2026-01-14T08:18:43.6307021Z 301a59dd8ea1: Download complete
2026-01-14T08:19:44.0029768Z 301a59dd8ea1: Pull complete
2026-01-14T08:19:44.6486099Z 747a1c0117bc: Pull complete
2026-01-14T08:19:45.0214240Z 2d6f0c29ad9f: Pull complete
2026-01-14T08:20:02.6547696Z 5b7921a1b019: Pull complete
2026-01-14T08:20:02.9307803Z a4392ccb83ef: Pull complete
2026-01-14T08:20:03.2244094Z 3f0968dff130: Pull complete
2026-01-14T08:20:03.5313512Z 9323969b3930: Pull complete
2026-01-14T08:20:04.1370696Z b9f6732b07f0: Pull complete
2026-01-14T08:20:04.6777759Z 32117f6e66ab: Pull complete
2026-01-14T08:20:05.2173348Z bed95346686d: Pull complete
2026-01-14T08:20:26.9260382Z a73f5cbdff4f: Pull complete
2026-01-14T08:20:27.1242731Z Digest: sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T08:20:27.2325939Z Status: Downloaded newer image for pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.2656252Z docker.io/pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.2721332Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:27.2722303Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:27.2732412Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:27.2732765Z env:
2026-01-14T08:20:27.2733016Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.2733350Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.2733593Z   PR_NUMBER: 3500
2026-01-14T08:20:27.2735127Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.2736816Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.2737367Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.2737892Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.2738262Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.2738561Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.2738891Z ##[endgroup]
2026-01-14T08:20:27.2944410Z Prepare all required actions
2026-01-14T08:20:27.2944745Z Getting action download info
2026-01-14T08:20:27.5031845Z ##[group]Run ./test-infra/.github/actions/setup-nvidia
2026-01-14T08:20:27.5032175Z with:
2026-01-14T08:20:27.5032372Z   driver-version: 580.65.06
2026-01-14T08:20:27.5032622Z env:
2026-01-14T08:20:27.5032859Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.5033194Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.5033436Z   PR_NUMBER: 3500
2026-01-14T08:20:27.5034926Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.5036650Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.5037200Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.5037724Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.5038099Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.5038394Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.5038737Z ##[endgroup]
2026-01-14T08:20:27.5190654Z ##[group]Run echo "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"
2026-01-14T08:20:27.5191580Z [36;1mecho "IN_CONTAINER_RUNNER=$(if [ -f /.inarc ] || [ -f /.incontainer ]; then echo true ; else echo false; fi)" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:27.5201330Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:27.5201880Z env:
2026-01-14T08:20:27.5202135Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.5202471Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.5202729Z   PR_NUMBER: 3500
2026-01-14T08:20:27.5204243Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.5205923Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.5206533Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.5207070Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.5207443Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.5207751Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.5208089Z ##[endgroup]
2026-01-14T08:20:27.5378388Z ##[group]Run set -euo pipefail
2026-01-14T08:20:27.5378729Z [36;1mset -euo pipefail[0m
2026-01-14T08:20:27.5378979Z [36;1m[0m
2026-01-14T08:20:27.5379188Z [36;1mhas_gpu=false[0m
2026-01-14T08:20:27.5379421Z [36;1mdevices=""[0m
2026-01-14T08:20:27.5379650Z [36;1m[0m
2026-01-14T08:20:27.5379912Z [36;1mif command -v nvidia-smi >/dev/null 2>&1; then[0m
2026-01-14T08:20:27.5380352Z [36;1m  if nvidia-smi -L >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:27.5380727Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:27.5381022Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:27.5381330Z [36;1m  fi[0m
2026-01-14T08:20:27.5381531Z [36;1mfi[0m
2026-01-14T08:20:27.5381736Z [36;1m[0m
2026-01-14T08:20:27.5381946Z [36;1mif [ "$has_gpu" = false ]; then[0m
2026-01-14T08:20:27.5382324Z [36;1m  if ls /dev/nvidia* >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:27.5382698Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:27.5382977Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:27.5383274Z [36;1m  fi[0m
2026-01-14T08:20:27.5383684Z [36;1mfi[0m
2026-01-14T08:20:27.5383883Z [36;1m[0m
2026-01-14T08:20:27.5384178Z [36;1mif [ "$has_gpu" = false ] && command -v lspci >/dev/null 2>&1; then[0m
2026-01-14T08:20:27.5384686Z [36;1m  if lspci | grep -i 'nvidia' >/tmp/nvidia_devices 2>/dev/null; then[0m
2026-01-14T08:20:27.5385090Z [36;1m    has_gpu=true[0m
2026-01-14T08:20:27.5385373Z [36;1m    devices=$(cat /tmp/nvidia_devices)[0m
2026-01-14T08:20:27.5385668Z [36;1m  fi[0m
2026-01-14T08:20:27.5385875Z [36;1mfi[0m
2026-01-14T08:20:27.5386062Z [36;1m[0m
2026-01-14T08:20:27.5386348Z [36;1mprintf 'HAS_NVIDIA=%s\n' "$has_gpu" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:27.5386870Z [36;1mprintf 'DETECTED_DEVICES<<EOF\n%s\nEOF\n' "$devices" >> "$GITHUB_OUTPUT"[0m
2026-01-14T08:20:27.5396199Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:27.5396558Z env:
2026-01-14T08:20:27.5396803Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.5397142Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.5397398Z   PR_NUMBER: 3500
2026-01-14T08:20:27.5398966Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.5400651Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.5401219Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.5401765Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.5402299Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.5402610Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.5402941Z ##[endgroup]
2026-01-14T08:20:27.6184149Z ##[group]Run if [ "${HAS_NVIDIA}" = "true" ]; then
2026-01-14T08:20:27.6184517Z [36;1mif [ "${HAS_NVIDIA}" = "true" ]; then[0m
2026-01-14T08:20:27.6184883Z [36;1m  echo "HAS_NVIDIA_GPU=true" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:27.6185384Z [36;1m  echo "GPU_FLAG=--gpus all -e NVIDIA_DRIVER_CAPABILITIES=all" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:27.6185833Z [36;1melse[0m
2026-01-14T08:20:27.6186108Z [36;1m  echo "HAS_NVIDIA_GPU=false" >> "${GITHUB_ENV}"[0m
2026-01-14T08:20:27.6186429Z [36;1mfi[0m
2026-01-14T08:20:27.6195342Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T08:20:27.6195689Z env:
2026-01-14T08:20:27.6195944Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.6196284Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.6196540Z   PR_NUMBER: 3500
2026-01-14T08:20:27.6198074Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.6199752Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.6200319Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.6200857Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.6201231Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.6201535Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.6201878Z   HAS_NVIDIA: true
2026-01-14T08:20:27.6202097Z ##[endgroup]
2026-01-14T08:20:27.6370204Z ##[group]Run nick-fields/retry@3e91a01664abd3c5cd539100d10d33b9c5b68482
2026-01-14T08:20:27.6370617Z with:
2026-01-14T08:20:27.6370823Z   timeout_minutes: 10
2026-01-14T08:20:27.6371049Z   max_attempts: 3
2026-01-14T08:20:27.6401427Z   command: # Is it disgusting to have a full shell script here in this github action? Sure
# But is it the best way to make it so that this action relies on nothing else? Absolutely
set -eou pipefail

DISTRIBUTION=$(. /etc/os-release;echo $ID$VERSION_ID)
DRIVER_FN="NVIDIA-Linux-x86_64-${DRIVER_VERSION}.run"

install_nvidia_docker2_amzn2() {
    (
        set -x
        # Needed for yum-config-manager
        sudo yum install -y yum-utils
        if [[ "${DISTRIBUTION}" == "amzn2023" ]] ; then
          YUM_REPO_URL="https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo"
        else
          # Amazon Linux 2
          YUM_REPO_URL="https://nvidia.github.io/nvidia-docker/${DISTRIBUTION}/nvidia-docker.repo"
        fi

        sudo yum-config-manager --add-repo "${YUM_REPO_URL}"
        sudo yum install -y \
          nvidia-container-toolkit-1.17.8 \
          libnvidia-container-tools-1.17.8 \
          libnvidia-container1-1.17.8 \
          nvidia-container-toolkit-base-1.17.8
        sudo systemctl restart docker
    )
}

install_nvidia_docker2_ubuntu20() {
    (
        set -x
        # Install nvidia-driver package if not installed
        status="$(dpkg-query -W --showformat='${db:Status-Status}' nvidia-docker2 2>&1)"
        if [ ! $? = 0 ] || [ ! "$status" = installed ]; then
          sudo apt-get install -y nvidia-container-toolkit-1.17.8
          sudo systemctl restart docker
        fi
    )
}

pre_install_nvidia_driver_amzn2() {
    (
        # Purge any nvidia driver installed from RHEL repo
        sudo yum remove -y nvidia-driver-latest-dkms
    )
}

install_nvidia_driver_common() {
    (
        # Try to gather more information about the runner and its existing NVIDIA driver if any
        echo "Before installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        HAS_NVIDIA_DRIVER=0
        # Check if NVIDIA driver has already been installed
        if [ -x "$(command -v nvidia-smi)" ]; then
            set +e
            # The driver exists, check its version next. Also check only the first GPU if there are more than one of them
            # so that the same driver version is not print over multiple lines
            INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
            NVIDIA_SMI_STATUS=$?

            if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                echo "Failed to get NVIDIA driver version ($INSTALLED_DRIVER_VERSION). Continuing"
            elif [ "$INSTALLED_DRIVER_VERSION" != "$DRIVER_VERSION" ]; then
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has been installed, but we expect to have $DRIVER_VERSION instead. Continuing"

                # Turn off persistent mode so that the installation script can unload the kernel module
                sudo killall nvidia-persistenced || true
            else
                HAS_NVIDIA_DRIVER=1
                echo "NVIDIA driver ($INSTALLED_DRIVER_VERSION) has already been installed. Skipping NVIDIA driver installation"
            fi
            set -e
        fi

        if [ "$HAS_NVIDIA_DRIVER" -eq 0 ]; then
            # CAUTION: this may need to be updated in future
            if [ "${DISTRIBUTION}" != ubuntu20.04 ]; then
                  sudo yum groupinstall -y "Development Tools"
                  # ensure our kernel install is the same as our underlying kernel,
                  # groupinstall "Development Tools" has a habit of mismatching kernel headers
                  sudo yum install -y "kernel-devel-uname-r == $(uname -r)"
                  sudo modprobe backlight
            fi
            sudo curl -fsL -o /tmp/nvidia_driver "https://s3.amazonaws.com/ossci-linux/nvidia_driver/$DRIVER_FN"

            set +e
            sudo /bin/bash /tmp/nvidia_driver -s --no-drm
            NVIDIA_INSTALLATION_STATUS=$?

            RESET_GPU=0
            if [ "$NVIDIA_INSTALLATION_STATUS" -ne 0 ]; then
                sudo cat /var/log/nvidia-installer.log
                # Fail to install NVIDIA driver, try to reset the GPU
                RESET_GPU=1
            elif [ -x "$(command -v nvidia-smi)" ]; then
                # Check again if nvidia-smi works even if the driver installation completes successfully
                INSTALLED_DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0)
                NVIDIA_SMI_STATUS=$?

                if [ "$NVIDIA_SMI_STATUS" -ne 0 ] && [ "$NVIDIA_SMI_STATUS" -ne 14 ]; then
                    RESET_GPU=1
                fi
            fi

            if [ "$RESET_GPU" -eq 1 ]; then
                NVIDIA_DEVICES=$(lspci -D | grep -i NVIDIA | cut -d' ' -f1)
                # The GPU can get stuck in a failure state if somehow the test crashs the GPU microcode. When this
                # happens, we'll try to reset all NVIDIA devices https://github.com/pytorch/pytorch/issues/88388
                for PCI_ID in $NVIDIA_DEVICES; do
                    DEVICE_ENABLED=$(cat /sys/bus/pci/devices/$PCI_ID/enable)

                    echo "Reseting $PCI_ID (enabled state: $DEVICE_ENABLED)"
                    # This requires sudo permission of course
                    echo "1" | sudo tee /sys/bus/pci/devices/$PCI_ID/reset
                    sleep 1
                done
            fi

            sudo rm -fv /tmp/nvidia_driver
            set -e
        fi
    )
}

post_install_nvidia_driver_common() {
    (
        sudo modprobe nvidia || true
        echo "After installing NVIDIA driver"
        lspci
        lsmod
        modinfo nvidia || true

        (
            set +e

            nvidia-smi
            # NB: Annoyingly, nvidia-smi command returns successfully with return code 0 even in
            # the case where the driver has already crashed as it still can get the driver version
            # and some basic information like the bus ID.  However, the rest of the information
            # would be missing (ERR!), for example:
            #
            # +-----------------------------------------------------------------------------+
            # | NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |
            # |-------------------------------+----------------------+----------------------+
            # | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
            # | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
            # |                               |                      |               MIG M. |
            # |===============================+======================+======================|
            # |   0  ERR!                Off  | 00000000:00:1E.0 Off |                 ERR! |
            # |ERR!  ERR! ERR!    ERR! / ERR! |   4184MiB / 23028MiB |    ERR!      Default |
            # |                               |                      |                 ERR! |
            # +-------------------------------+----------------------+----------------------+
            #
            # +-----------------------------------------------------------------------------+
            # | Processes:                                                                  |
            # |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
            # |        ID   ID                                                   Usage      |
            # |=============================================================================|
            # +-----------------------------------------------------------------------------+
            #
            # This should be reported as a failure instead as it will guarantee to fail when
            # Docker tries to run with --gpus all
            #
            # So, the correct check here is to query one of the missing piece of info like
            # GPU name, so that the command can fail accordingly
            nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
            NVIDIA_SMI_STATUS=$?

            # Allowable exit statuses for nvidia-smi, see: https://github.com/NVIDIA/gpu-operator/issues/285
            if [ "$NVIDIA_SMI_STATUS" -eq 0 ] || [ "$NVIDIA_SMI_STATUS" -eq 14 ]; then
                echo "INFO: Ignoring allowed status ${NVIDIA_SMI_STATUS}"
            else
                echo "ERROR: nvidia-smi exited with unresolved status ${NVIDIA_SMI_STATUS}"
                exit ${NVIDIA_SMI_STATUS}
            fi
            set -e
        )
    )
}

install_nvidia_driver_amzn2() {
    (
        set -x
        pre_install_nvidia_driver_amzn2
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

install_nvidia_driver_ubuntu20() {
    (
        set -x
        install_nvidia_driver_common
        post_install_nvidia_driver_common
    )
}

echo "== Installing nvidia driver ${DRIVER_FN} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_driver_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_driver_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Install container toolkit based on distribution
echo "== Installing nvidia container toolkit for ${DISTRIBUTION} =="
case "${DISTRIBUTION}" in
    amzn*)
        install_nvidia_docker2_amzn2
        ;;
    ubuntu20.04)
        install_nvidia_docker2_ubuntu20
        ;;
    *)
        echo "ERROR: Unknown distribution ${DISTRIBUTION}"
        exit 1
        ;;
esac

# Fix https://github.com/NVIDIA/nvidia-docker/issues/1648 on runners with
# more than one GPUs. This just needs to be run once. The command fails
# on subsequent runs and complains that the mode is already on, but that's
# ok
sudo nvidia-persistenced || true
# This should show persistence mode ON
nvidia-smi

# check if the container-toolkit is correctly installed and CUDA is available inside a container
docker run --rm -t --gpus=all public.ecr.aws/docker/library/python:3.13 nvidia-smi

2026-01-14T08:20:27.6431675Z   retry_wait_seconds: 10
2026-01-14T08:20:27.6431930Z   polling_interval_seconds: 1
2026-01-14T08:20:27.6432191Z   warning_on_retry: true
2026-01-14T08:20:27.6432443Z   continue_on_error: false
2026-01-14T08:20:27.6432686Z env:
2026-01-14T08:20:27.6432924Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:20:27.6433265Z   REPOSITORY: pytorch/ao
2026-01-14T08:20:27.6433508Z   PR_NUMBER: 3500
2026-01-14T08:20:27.6434996Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:20:27.6436671Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:20:27.6437237Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:20:27.6437804Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:20:27.6438187Z   HAS_NVIDIA_GPU: true
2026-01-14T08:20:27.6438486Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:20:27.6438842Z   DRIVER_VERSION: 580.65.06
2026-01-14T08:20:27.6439089Z ##[endgroup]
2026-01-14T08:20:27.7237078Z == Installing nvidia driver NVIDIA-Linux-x86_64-580.65.06.run ==
2026-01-14T08:20:27.7238840Z + pre_install_nvidia_driver_amzn2
2026-01-14T08:20:27.7242130Z + sudo yum remove -y nvidia-driver-latest-dkms
2026-01-14T08:20:28.0872918Z No match for argument: nvidia-driver-latest-dkms
2026-01-14T08:20:28.0873887Z No packages marked for removal.
2026-01-14T08:20:28.0924282Z Dependencies resolved.
2026-01-14T08:20:28.0934353Z Nothing to do.
2026-01-14T08:20:28.0934861Z Complete!
2026-01-14T08:20:28.1566765Z + install_nvidia_driver_common
2026-01-14T08:20:28.1570884Z + echo 'Before installing NVIDIA driver'
2026-01-14T08:20:28.1571300Z + lspci
2026-01-14T08:20:28.1573205Z Before installing NVIDIA driver
2026-01-14T08:20:28.1694867Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:28.1695902Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:28.1696497Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:28.1697108Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:28.1697802Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:28.1698372Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:28.1699027Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.1699636Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.1700227Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.1700752Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.1701234Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:28.1701646Z + lsmod
2026-01-14T08:20:28.1761660Z Module                  Size  Used by
2026-01-14T08:20:28.1762056Z veth                   36864  0
2026-01-14T08:20:28.1762597Z nvidia_modeset       1740800  0
2026-01-14T08:20:28.1763019Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:28.1763386Z wmi                    36864  1 video
2026-01-14T08:20:28.1763655Z nvidia_uvm           1921024  0
2026-01-14T08:20:28.1763950Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:28.1764273Z drm                   602112  1 nvidia
2026-01-14T08:20:28.1764562Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:28.1764915Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:28.1765255Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:28.1765742Z mgc                    86016  1
2026-01-14T08:20:28.1765992Z lustre               1085440  4
2026-01-14T08:20:28.1766229Z mdc                   294912  2 lustre
2026-01-14T08:20:28.1766502Z fid                    36864  1 mdc
2026-01-14T08:20:28.1766764Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:28.1767040Z osc                   479232  5 mdc
2026-01-14T08:20:28.1767293Z lmv                   225280  2 lustre
2026-01-14T08:20:28.1767580Z fld                    49152  2 lov,lmv
2026-01-14T08:20:28.1767868Z ksocklnd              188416  1
2026-01-14T08:20:28.1768197Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:28.1768664Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:28.1769151Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:28.1769739Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:28.1770225Z xt_conntrack           16384  1
2026-01-14T08:20:28.1770481Z nft_chain_nat          16384  3
2026-01-14T08:20:28.1770729Z xt_MASQUERADE          20480  1
2026-01-14T08:20:28.1771028Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:28.1771359Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:28.1771838Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:28.1772282Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:28.1772584Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:28.1772869Z xfrm_user              57344  1
2026-01-14T08:20:28.1773119Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:28.1773394Z xt_addrtype            16384  2
2026-01-14T08:20:28.1773635Z nft_compat             20480  4
2026-01-14T08:20:28.1773935Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:28.1774351Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:28.1774724Z br_netfilter           36864  0
2026-01-14T08:20:28.1774988Z bridge                323584  1 br_netfilter
2026-01-14T08:20:28.1775267Z stp                    16384  1 bridge
2026-01-14T08:20:28.1775682Z llc                    16384  2 bridge,stp
2026-01-14T08:20:28.1775955Z overlay               167936  0
2026-01-14T08:20:28.1776195Z tls                   139264  0
2026-01-14T08:20:28.1776428Z nls_ascii              16384  1
2026-01-14T08:20:28.1776666Z nls_cp437              20480  1
2026-01-14T08:20:28.1776905Z vfat                   24576  1
2026-01-14T08:20:28.1777141Z fat                    86016  1 vfat
2026-01-14T08:20:28.1777399Z sunrpc                700416  2 lnet
2026-01-14T08:20:28.1777698Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:28.1777967Z i8042                  45056  0
2026-01-14T08:20:28.1778203Z serio                  28672  3 i8042
2026-01-14T08:20:28.1778459Z ena                   196608  0
2026-01-14T08:20:28.1778696Z button                 24576  0
2026-01-14T08:20:28.1778940Z sch_fq_codel           20480  33
2026-01-14T08:20:28.1779178Z fuse                  184320  1
2026-01-14T08:20:28.1779412Z loop                   36864  0
2026-01-14T08:20:28.1779653Z dm_mod                188416  0
2026-01-14T08:20:28.1779886Z configfs               57344  1
2026-01-14T08:20:28.1780126Z dmi_sysfs              20480  0
2026-01-14T08:20:28.1780362Z crc32_pclmul           16384  0
2026-01-14T08:20:28.1780603Z crc32c_intel           24576  0
2026-01-14T08:20:28.1780839Z efivarfs               24576  1
2026-01-14T08:20:28.1781089Z + modinfo nvidia
2026-01-14T08:20:28.1783688Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:28.1784153Z import_ns:      DMA_BUF
2026-01-14T08:20:28.1784426Z alias:          char-major-195-*
2026-01-14T08:20:28.1784768Z version:        580.65.06
2026-01-14T08:20:28.1785010Z supported:      external
2026-01-14T08:20:28.1785248Z license:        Dual MIT/GPL
2026-01-14T08:20:28.1785636Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:28.1785963Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:28.1786278Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:28.1786603Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:28.1786953Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:28.1787309Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:28.1787646Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:28.1787984Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:28.1788312Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:28.1788642Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:28.1788954Z depends:        i2c-core,drm
2026-01-14T08:20:28.1789197Z retpoline:      Y
2026-01-14T08:20:28.1789411Z name:           nvidia
2026-01-14T08:20:28.1789759Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:28.1790241Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:28.1790680Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:28.1791099Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:28.1791411Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:28.1791699Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:28.1792006Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:28.1792296Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:28.1792595Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:28.1792947Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:28.1793338Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:28.1793665Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:28.1793957Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:28.1794260Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:28.1794623Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:28.1806844Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:28.1807308Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:28.1807901Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:28.1808330Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:28.1808754Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:28.1809182Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:28.1809528Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:28.1809897Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:28.1810278Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:28.1810615Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:28.1810936Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:28.1811260Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:28.1811709Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:28.1812021Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:28.1812380Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:28.1812749Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:28.1813102Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:28.1813469Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:28.1813799Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:28.1814146Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:28.1814497Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:28.1814845Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:28.1815183Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:28.1815518Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:28.1815808Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:28.1816217Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:28.1816547Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:28.1816857Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:28.1817190Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:28.1817542Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:28.1817903Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:28.1818224Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:28.1818574Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:28.1818915Z parm:           rm_firmware_active:charp
2026-01-14T08:20:28.1819196Z + HAS_NVIDIA_DRIVER=0
2026-01-14T08:20:28.1819445Z ++ command -v nvidia-smi
2026-01-14T08:20:28.1819694Z + '[' -x /usr/bin/nvidia-smi ']'
2026-01-14T08:20:28.1819934Z + set +e
2026-01-14T08:20:28.1820229Z ++ nvidia-smi --query-gpu=driver_version --format=csv,noheader --id=0
2026-01-14T08:20:28.2322217Z + INSTALLED_DRIVER_VERSION=580.65.06
2026-01-14T08:20:28.2322536Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:28.2322870Z + '[' 0 -ne 0 ']'
2026-01-14T08:20:28.2323090Z + '[' 580.65.06 '!=' 580.65.06 ']'
2026-01-14T08:20:28.2323346Z + HAS_NVIDIA_DRIVER=1
2026-01-14T08:20:28.2323791Z + echo 'NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation'
2026-01-14T08:20:28.2324271Z + set -e
2026-01-14T08:20:28.2324462Z + '[' 1 -eq 0 ']'
2026-01-14T08:20:28.2324837Z NVIDIA driver (580.65.06) has already been installed. Skipping NVIDIA driver installation
2026-01-14T08:20:28.2327310Z + post_install_nvidia_driver_common
2026-01-14T08:20:28.2334588Z + sudo modprobe nvidia
2026-01-14T08:20:28.3651251Z + echo 'After installing NVIDIA driver'
2026-01-14T08:20:28.3651628Z + lspci
2026-01-14T08:20:28.3651837Z After installing NVIDIA driver
2026-01-14T08:20:28.3767154Z 00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma]
2026-01-14T08:20:28.3767680Z 00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
2026-01-14T08:20:28.3768272Z 00:01.3 Non-VGA unclassified device: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 08)
2026-01-14T08:20:28.3768801Z 00:03.0 VGA compatible controller: Amazon.com, Inc. Device 1111
2026-01-14T08:20:28.3769479Z 00:04.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe EBS Controller
2026-01-14T08:20:28.3770012Z 00:05.0 Ethernet controller: Amazon.com, Inc. Elastic Network Adapter (ENA)
2026-01-14T08:20:28.3770499Z 00:1b.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.3770936Z 00:1c.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.3771360Z 00:1d.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.3771876Z 00:1e.0 3D controller: NVIDIA Corporation GA102GL [A10G] (rev a1)
2026-01-14T08:20:28.3772348Z 00:1f.0 Non-Volatile memory controller: Amazon.com, Inc. NVMe SSD Controller
2026-01-14T08:20:28.3772756Z + lsmod
2026-01-14T08:20:28.3819034Z Module                  Size  Used by
2026-01-14T08:20:28.3819333Z veth                   36864  0
2026-01-14T08:20:28.3819600Z nvidia_modeset       1740800  0
2026-01-14T08:20:28.3819871Z video                  65536  1 nvidia_modeset
2026-01-14T08:20:28.3820167Z wmi                    36864  1 video
2026-01-14T08:20:28.3820431Z nvidia_uvm           1921024  0
2026-01-14T08:20:28.3820732Z nvidia              14274560  19 nvidia_uvm,nvidia_modeset
2026-01-14T08:20:28.3821051Z drm                   602112  1 nvidia
2026-01-14T08:20:28.3821346Z drm_panel_orientation_quirks    32768  1 drm
2026-01-14T08:20:28.3821694Z backlight              24576  3 video,drm,nvidia_modeset
2026-01-14T08:20:28.3822034Z i2c_core              110592  2 nvidia,drm
2026-01-14T08:20:28.3822328Z mgc                    86016  1
2026-01-14T08:20:28.3822562Z lustre               1085440  4
2026-01-14T08:20:28.3822809Z mdc                   294912  2 lustre
2026-01-14T08:20:28.3823066Z fid                    36864  1 mdc
2026-01-14T08:20:28.3823335Z lov                   356352  5 mdc,lustre
2026-01-14T08:20:28.3823752Z osc                   479232  5 mdc
2026-01-14T08:20:28.3824012Z lmv                   225280  2 lustre
2026-01-14T08:20:28.3824279Z fld                    49152  2 lov,lmv
2026-01-14T08:20:28.3824546Z ksocklnd              188416  1
2026-01-14T08:20:28.3824877Z ptlrpc               1470464  8 fld,osc,fid,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:28.3825339Z obdclass             3366912  13 fld,osc,fid,ptlrpc,mgc,lov,mdc,lmv,lustre
2026-01-14T08:20:28.3825842Z lnet                  811008  7 osc,obdclass,ptlrpc,mgc,ksocklnd,lmv,lustre
2026-01-14T08:20:28.3826425Z libcfs                217088  12 fld,lnet,osc,fid,obdclass,ptlrpc,mgc,ksocklnd,lov,mdc,lmv,lustre
2026-01-14T08:20:28.3826919Z xt_conntrack           16384  1
2026-01-14T08:20:28.3827172Z nft_chain_nat          16384  3
2026-01-14T08:20:28.3827423Z xt_MASQUERADE          20480  1
2026-01-14T08:20:28.3827765Z nf_nat                 57344  2 nft_chain_nat,xt_MASQUERADE
2026-01-14T08:20:28.3828099Z nf_conntrack_netlink    57344  0
2026-01-14T08:20:28.3828499Z nf_conntrack          184320  4 xt_conntrack,nf_nat,nf_conntrack_netlink,xt_MASQUERADE
2026-01-14T08:20:28.3828939Z nf_defrag_ipv6         24576  1 nf_conntrack
2026-01-14T08:20:28.3829247Z nf_defrag_ipv4         16384  1 nf_conntrack
2026-01-14T08:20:28.3829529Z xfrm_user              57344  1
2026-01-14T08:20:28.3829785Z xfrm_algo              16384  1 xfrm_user
2026-01-14T08:20:28.3830067Z xt_addrtype            16384  2
2026-01-14T08:20:28.3830310Z nft_compat             20480  4
2026-01-14T08:20:28.3830608Z nf_tables             311296  57 nft_compat,nft_chain_nat
2026-01-14T08:20:28.3831017Z nfnetlink              20480  4 nft_compat,nf_conntrack_netlink,nf_tables
2026-01-14T08:20:28.3831396Z br_netfilter           36864  0
2026-01-14T08:20:28.3831658Z bridge                323584  1 br_netfilter
2026-01-14T08:20:28.3831948Z stp                    16384  1 bridge
2026-01-14T08:20:28.3832218Z llc                    16384  2 bridge,stp
2026-01-14T08:20:28.3832498Z overlay               167936  0
2026-01-14T08:20:28.3832746Z tls                   139264  0
2026-01-14T08:20:28.3832984Z nls_ascii              16384  1
2026-01-14T08:20:28.3833228Z nls_cp437              20480  1
2026-01-14T08:20:28.3833561Z vfat                   24576  1
2026-01-14T08:20:28.3833807Z fat                    86016  1 vfat
2026-01-14T08:20:28.3834063Z sunrpc                700416  2 lnet
2026-01-14T08:20:28.3834331Z ghash_clmulni_intel    16384  0
2026-01-14T08:20:28.3834578Z i8042                  45056  0
2026-01-14T08:20:28.3834823Z serio                  28672  3 i8042
2026-01-14T08:20:28.3835078Z ena                   196608  0
2026-01-14T08:20:28.3835321Z button                 24576  0
2026-01-14T08:20:28.3835568Z sch_fq_codel           20480  33
2026-01-14T08:20:28.3835814Z fuse                  184320  1
2026-01-14T08:20:28.3836053Z loop                   36864  0
2026-01-14T08:20:28.3836289Z dm_mod                188416  0
2026-01-14T08:20:28.3836533Z configfs               57344  1
2026-01-14T08:20:28.3836779Z dmi_sysfs              20480  0
2026-01-14T08:20:28.3837027Z crc32_pclmul           16384  0
2026-01-14T08:20:28.3837269Z crc32c_intel           24576  0
2026-01-14T08:20:28.3837536Z efivarfs               24576  1
2026-01-14T08:20:28.3837819Z + modinfo nvidia
2026-01-14T08:20:28.3842070Z filename:       /lib/modules/6.1.158-180.294.amzn2023.x86_64/kernel/drivers/video/nvidia.ko
2026-01-14T08:20:28.3842559Z import_ns:      DMA_BUF
2026-01-14T08:20:28.3842798Z alias:          char-major-195-*
2026-01-14T08:20:28.3843063Z version:        580.65.06
2026-01-14T08:20:28.3843301Z supported:      external
2026-01-14T08:20:28.3843540Z license:        Dual MIT/GPL
2026-01-14T08:20:28.3843823Z firmware:       nvidia/580.65.06/gsp_tu10x.bin
2026-01-14T08:20:28.3844149Z firmware:       nvidia/580.65.06/gsp_ga10x.bin
2026-01-14T08:20:28.3844467Z srcversion:     A69EBF72FC9D60E11E9A05C
2026-01-14T08:20:28.3844786Z alias:          of:N*T*Cnvidia,tegra264-displayC*
2026-01-14T08:20:28.3845136Z alias:          of:N*T*Cnvidia,tegra264-display
2026-01-14T08:20:28.3845570Z alias:          of:N*T*Cnvidia,tegra234-displayC*
2026-01-14T08:20:28.3845916Z alias:          of:N*T*Cnvidia,tegra234-display
2026-01-14T08:20:28.3846257Z alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
2026-01-14T08:20:28.3846610Z alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
2026-01-14T08:20:28.3846944Z alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
2026-01-14T08:20:28.3847245Z depends:        i2c-core,drm
2026-01-14T08:20:28.3847493Z retpoline:      Y
2026-01-14T08:20:28.3847722Z name:           nvidia
2026-01-14T08:20:28.3848104Z vermagic:       6.1.158-180.294.amzn2023.x86_64 SMP preempt mod_unload modversions 
2026-01-14T08:20:28.3848579Z parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
2026-01-14T08:20:28.3849186Z parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
2026-01-14T08:20:28.3849611Z parm:           NVreg_ResmanDebugLevel:int
2026-01-14T08:20:28.3849906Z parm:           NVreg_RmLogonRC:int
2026-01-14T08:20:28.3850204Z parm:           NVreg_ModifyDeviceFiles:int
2026-01-14T08:20:28.3850509Z parm:           NVreg_DeviceFileUID:int
2026-01-14T08:20:28.3850806Z parm:           NVreg_DeviceFileGID:int
2026-01-14T08:20:28.3851100Z parm:           NVreg_DeviceFileMode:int
2026-01-14T08:20:28.3851518Z parm:           NVreg_InitializeSystemMemoryAllocations:int
2026-01-14T08:20:28.3851906Z parm:           NVreg_UsePageAttributeTable:int
2026-01-14T08:20:28.3852235Z parm:           NVreg_EnablePCIeGen3:int
2026-01-14T08:20:28.3852531Z parm:           NVreg_EnableMSI:int
2026-01-14T08:20:28.3852825Z parm:           NVreg_EnableStreamMemOPs:int
2026-01-14T08:20:28.3853186Z parm:           NVreg_RestrictProfilingToAdminUsers:int
2026-01-14T08:20:28.3853582Z parm:           NVreg_PreserveVideoMemoryAllocations:int
2026-01-14T08:20:28.3853963Z parm:           NVreg_EnableS0ixPowerManagement:int
2026-01-14T08:20:28.3854375Z parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:28.3854802Z parm:           NVreg_DynamicPowerManagement:int
2026-01-14T08:20:28.3855222Z parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
2026-01-14T08:20:28.3855644Z parm:           NVreg_EnableGpuFirmware:int
2026-01-14T08:20:28.3857431Z parm:           NVreg_EnableGpuFirmwareLogs:int
2026-01-14T08:20:28.3857806Z parm:           NVreg_OpenRmEnableUnsupportedGpus:int
2026-01-14T08:20:28.3858181Z parm:           NVreg_EnableUserNUMAManagement:int
2026-01-14T08:20:28.3858511Z parm:           NVreg_MemoryPoolSize:int
2026-01-14T08:20:28.3858830Z parm:           NVreg_KMallocHeapMaxSize:int
2026-01-14T08:20:28.3859149Z parm:           NVreg_VMallocHeapMaxSize:int
2026-01-14T08:20:28.3859471Z parm:           NVreg_IgnoreMMIOCheck:int
2026-01-14T08:20:28.3859771Z parm:           NVreg_NvLinkDisable:int
2026-01-14T08:20:28.3860120Z parm:           NVreg_EnablePCIERelaxedOrderingMode:int
2026-01-14T08:20:28.3860482Z parm:           NVreg_RegisterPCIDriver:int
2026-01-14T08:20:28.3860833Z parm:           NVreg_RegisterPlatformDeviceDriver:int
2026-01-14T08:20:28.3861197Z parm:           NVreg_EnableResizableBar:int
2026-01-14T08:20:28.3861520Z parm:           NVreg_EnableDbgBreakpoint:int
2026-01-14T08:20:28.3861871Z parm:           NVreg_EnableNonblockingOpen:int
2026-01-14T08:20:28.3862213Z parm:           NVreg_CoherentGPUMemoryMode:charp
2026-01-14T08:20:28.3862552Z parm:           NVreg_RegistryDwords:charp
2026-01-14T08:20:28.3862891Z parm:           NVreg_RegistryDwordsPerDevice:charp
2026-01-14T08:20:28.3863216Z parm:           NVreg_RmMsg:charp
2026-01-14T08:20:28.3863499Z parm:           NVreg_GpuBlacklist:charp
2026-01-14T08:20:28.3863812Z parm:           NVreg_TemporaryFilePath:charp
2026-01-14T08:20:28.3864130Z parm:           NVreg_ExcludedGpus:charp
2026-01-14T08:20:28.3864431Z parm:           NVreg_DmaRemapPeerMmio:int
2026-01-14T08:20:28.3864762Z parm:           NVreg_RmNvlinkBandwidth:charp
2026-01-14T08:20:28.3865104Z parm:           NVreg_RmNvlinkBandwidthLinkCount:int
2026-01-14T08:20:28.3865570Z parm:           NVreg_ImexChannelCount:int
2026-01-14T08:20:28.3865894Z parm:           NVreg_CreateImexChannel0:int
2026-01-14T08:20:28.3866232Z parm:           NVreg_GrdmaPciTopoCheckOverride:int
2026-01-14T08:20:28.3866578Z parm:           rm_firmware_active:charp
2026-01-14T08:20:28.3866854Z + set +e
2026-01-14T08:20:28.3867041Z + nvidia-smi
2026-01-14T08:20:28.4281230Z Wed Jan 14 08:20:28 2026       
2026-01-14T08:20:28.4282096Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:28.4283223Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:20:28.4284259Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:28.4285316Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:20:28.4286422Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:20:28.4287374Z |                                         |                        |               MIG M. |
2026-01-14T08:20:28.4287833Z |=========================================+========================+======================|
2026-01-14T08:20:28.4884847Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:20:28.4885810Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:28.4886663Z |                                         |                        |                  N/A |
2026-01-14T08:20:28.4887486Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:28.4888029Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:20:28.4888502Z |  0%   19C    P8             11W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:28.4888921Z |                                         |                        |                  N/A |
2026-01-14T08:20:28.4889373Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:28.4890038Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:20:28.4890513Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:28.4890938Z |                                         |                        |                  N/A |
2026-01-14T08:20:28.4891380Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:28.4891946Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:20:28.4892414Z |  0%   18C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:20:28.4892848Z |                                         |                        |                  N/A |
2026-01-14T08:20:28.4893303Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:20:28.4909590Z 
2026-01-14T08:20:28.4909830Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:28.4910316Z | Processes:                                                                              |
2026-01-14T08:20:28.4910800Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:20:28.4911268Z |        ID   ID                                                               Usage      |
2026-01-14T08:20:28.4911671Z |=========================================================================================|
2026-01-14T08:20:28.4948462Z |  No running processes found                                                             |
2026-01-14T08:20:28.4949733Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:20:29.5590035Z + nvidia-smi --query-gpu=gpu_name --format=csv,noheader --id=0
2026-01-14T08:20:29.5774896Z NVIDIA A10G
2026-01-14T08:20:29.6052266Z + NVIDIA_SMI_STATUS=0
2026-01-14T08:20:29.6052730Z + '[' 0 -eq 0 ']'
2026-01-14T08:20:29.6053203Z + echo 'INFO: Ignoring allowed status 0'
2026-01-14T08:20:29.6053745Z + set -e
2026-01-14T08:20:29.6054143Z INFO: Ignoring allowed status 0
2026-01-14T08:20:29.6064200Z == Installing nvidia container toolkit for amzn2023 ==
2026-01-14T08:20:29.6069858Z + sudo yum install -y yum-utils
2026-01-14T08:20:30.0975450Z Last metadata expiration check: 0:03:40 ago on Wed Jan 14 08:16:50 2026.
2026-01-14T08:20:30.1259760Z Package dnf-utils-4.3.0-13.amzn2023.0.5.noarch is already installed.
2026-01-14T08:20:30.1883130Z Dependencies resolved.
2026-01-14T08:20:30.2245176Z Nothing to do.
2026-01-14T08:20:30.2245493Z Complete!
2026-01-14T08:20:30.3577290Z + [[ amzn2023 == \a\m\z\n\2\0\2\3 ]]
2026-01-14T08:20:30.3577838Z + YUM_REPO_URL=https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:30.3579467Z + sudo yum-config-manager --add-repo https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:30.6783755Z Adding repo from: https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo
2026-01-14T08:20:30.7313575Z + sudo yum install -y nvidia-container-toolkit-1.17.8 libnvidia-container-tools-1.17.8 libnvidia-container1-1.17.8 nvidia-container-toolkit-base-1.17.8
2026-01-14T08:20:31.2782875Z nvidia-container-toolkit                         19 kB/s | 833  B     00:00    
2026-01-14T08:20:31.3059728Z Package nvidia-container-toolkit-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:31.3065856Z Package libnvidia-container-tools-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:31.3070181Z Package libnvidia-container1-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:31.3077480Z Package nvidia-container-toolkit-base-1.17.8-1.x86_64 is already installed.
2026-01-14T08:20:31.3710944Z Dependencies resolved.
2026-01-14T08:20:31.4076819Z Nothing to do.
2026-01-14T08:20:31.4077235Z Complete!
2026-01-14T08:20:31.5514056Z + sudo systemctl restart docker
2026-01-14T08:21:15.8725947Z nvidia-persistenced failed to initialize. Check syslog for more details.
2026-01-14T08:21:15.9185577Z Wed Jan 14 08:21:15 2026       
2026-01-14T08:21:15.9186013Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:15.9186564Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:15.9187089Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:15.9187637Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:15.9188203Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:15.9188686Z |                                         |                        |               MIG M. |
2026-01-14T08:21:15.9189102Z |=========================================+========================+======================|
2026-01-14T08:21:15.9787971Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:15.9788460Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:15.9788883Z |                                         |                        |                  N/A |
2026-01-14T08:21:15.9789335Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:15.9789822Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:15.9790293Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:15.9790718Z |                                         |                        |                  N/A |
2026-01-14T08:21:15.9791532Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:15.9792021Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:15.9792490Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:15.9792926Z |                                         |                        |                  N/A |
2026-01-14T08:21:15.9793369Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:15.9793851Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:15.9794320Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:15.9794742Z |                                         |                        |                  N/A |
2026-01-14T08:21:15.9795188Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:15.9813739Z 
2026-01-14T08:21:15.9814007Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:15.9814485Z | Processes:                                                                              |
2026-01-14T08:21:15.9814967Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:15.9815421Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:15.9815821Z |=========================================================================================|
2026-01-14T08:21:15.9852365Z |  No running processes found                                                             |
2026-01-14T08:21:15.9852871Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:17.1248314Z Unable to find image 'public.ecr.aws/docker/library/python:3.13' locally
2026-01-14T08:21:17.3892815Z 3.13: Pulling from docker/library/python
2026-01-14T08:21:17.4619365Z 2ca1bfae7ba8: Pulling fs layer
2026-01-14T08:21:17.4619673Z 82e18c5e1c15: Pulling fs layer
2026-01-14T08:21:17.4620195Z be442a7e0d6f: Pulling fs layer
2026-01-14T08:21:17.4620459Z 26d823e3848f: Pulling fs layer
2026-01-14T08:21:17.4620718Z ca4b54413202: Pulling fs layer
2026-01-14T08:21:17.4620968Z b6513238a015: Pulling fs layer
2026-01-14T08:21:17.4621225Z 9b57076d00d4: Pulling fs layer
2026-01-14T08:21:17.4621463Z ca4b54413202: Waiting
2026-01-14T08:21:17.4621680Z b6513238a015: Waiting
2026-01-14T08:21:17.4621894Z 9b57076d00d4: Waiting
2026-01-14T08:21:17.4622110Z 26d823e3848f: Waiting
2026-01-14T08:21:17.5611951Z 82e18c5e1c15: Verifying Checksum
2026-01-14T08:21:17.5612256Z 82e18c5e1c15: Download complete
2026-01-14T08:21:17.6190657Z 2ca1bfae7ba8: Download complete
2026-01-14T08:21:17.6659870Z be442a7e0d6f: Verifying Checksum
2026-01-14T08:21:17.6660180Z be442a7e0d6f: Download complete
2026-01-14T08:21:17.6794182Z ca4b54413202: Verifying Checksum
2026-01-14T08:21:17.6794480Z ca4b54413202: Download complete
2026-01-14T08:21:17.7562689Z 9b57076d00d4: Download complete
2026-01-14T08:21:17.7700338Z b6513238a015: Verifying Checksum
2026-01-14T08:21:17.7701478Z b6513238a015: Download complete
2026-01-14T08:21:18.2004634Z 26d823e3848f: Verifying Checksum
2026-01-14T08:21:18.2004979Z 26d823e3848f: Download complete
2026-01-14T08:21:19.4429832Z 2ca1bfae7ba8: Pull complete
2026-01-14T08:21:20.1870168Z 82e18c5e1c15: Pull complete
2026-01-14T08:21:22.7248715Z be442a7e0d6f: Pull complete
2026-01-14T08:21:29.5299212Z 26d823e3848f: Pull complete
2026-01-14T08:21:29.8255198Z ca4b54413202: Pull complete
2026-01-14T08:21:30.6136200Z b6513238a015: Pull complete
2026-01-14T08:21:30.6382629Z 9b57076d00d4: Pull complete
2026-01-14T08:21:30.6519682Z Digest: sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T08:21:30.6564635Z Status: Downloaded newer image for public.ecr.aws/docker/library/python:3.13
2026-01-14T08:21:37.8404966Z Wed Jan 14 08:21:37 2026       
2026-01-14T08:21:37.8405457Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:37.8406018Z | NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |
2026-01-14T08:21:37.8406551Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:37.8407078Z | GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
2026-01-14T08:21:37.8407654Z | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
2026-01-14T08:21:37.8408133Z |                                         |                        |               MIG M. |
2026-01-14T08:21:37.8408524Z |=========================================+========================+======================|
2026-01-14T08:21:37.9000864Z |   0  NVIDIA A10G                    On  |   00000000:00:1B.0 Off |                    0 |
2026-01-14T08:21:37.9001809Z |  0%   20C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:37.9002592Z |                                         |                        |                  N/A |
2026-01-14T08:21:37.9003379Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:37.9003887Z |   1  NVIDIA A10G                    On  |   00000000:00:1C.0 Off |                    0 |
2026-01-14T08:21:37.9004358Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:37.9004783Z |                                         |                        |                  N/A |
2026-01-14T08:21:37.9005231Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:37.9005738Z |   2  NVIDIA A10G                    On  |   00000000:00:1D.0 Off |                    0 |
2026-01-14T08:21:37.9006202Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:37.9006644Z |                                         |                        |                  N/A |
2026-01-14T08:21:37.9007379Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:37.9007879Z |   3  NVIDIA A10G                    On  |   00000000:00:1E.0 Off |                    0 |
2026-01-14T08:21:37.9008357Z |  0%   19C    P8             10W /  300W |       0MiB /  23028MiB |      0%      Default |
2026-01-14T08:21:37.9008786Z |                                         |                        |                  N/A |
2026-01-14T08:21:37.9009231Z +-----------------------------------------+------------------------+----------------------+
2026-01-14T08:21:37.9027740Z 
2026-01-14T08:21:37.9028152Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:37.9028637Z | Processes:                                                                              |
2026-01-14T08:21:37.9029142Z |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
2026-01-14T08:21:37.9029612Z |        ID   ID                                                               Usage      |
2026-01-14T08:21:37.9030017Z |=========================================================================================|
2026-01-14T08:21:37.9066991Z |  No running processes found                                                             |
2026-01-14T08:21:37.9067531Z +-----------------------------------------------------------------------------------------+
2026-01-14T08:21:39.7599921Z Command completed after 1 attempt(s).
2026-01-14T08:21:39.7713827Z ##[group]Run set -ex
2026-01-14T08:21:39.7714093Z [36;1mset -ex[0m
2026-01-14T08:21:39.7714307Z [36;1m{[0m
2026-01-14T08:21:39.7714525Z [36;1m  echo "#!/usr/bin/env bash";[0m
2026-01-14T08:21:39.7714842Z [36;1m  echo "set -eou pipefail";[0m
2026-01-14T08:21:39.7715352Z [36;1m  # shellcheck disable=SC2016[0m
2026-01-14T08:21:39.7715692Z [36;1m  echo 'eval "$(conda shell.bash hook)"';[0m
2026-01-14T08:21:39.7716020Z [36;1m  echo "set -x";[0m
2026-01-14T08:21:39.7716270Z [36;1m  echo "${SCRIPT}";[0m
2026-01-14T08:21:39.7716548Z [36;1m} > "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:39.7716873Z [36;1mchmod +x "${RUNNER_TEMP}/exec_script"[0m
2026-01-14T08:21:39.7717475Z [36;1mpython3 "/home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py" ""[0m
2026-01-14T08:21:39.7731935Z shell: /usr/bin/bash -e {0}
2026-01-14T08:21:39.7732198Z env:
2026-01-14T08:21:39.7732444Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T08:21:39.7732812Z   REPOSITORY: pytorch/ao
2026-01-14T08:21:39.7733052Z   PR_NUMBER: 3500
2026-01-14T08:21:39.7734561Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T08:21:39.7736250Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T08:21:39.7736812Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T08:21:39.7737342Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T08:21:39.7737724Z   HAS_NVIDIA_GPU: true
2026-01-14T08:21:39.7738019Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T08:21:39.7738622Z   ALL_SECRETS: {
  "github_token": "***"
}
2026-01-14T08:21:39.7738913Z ##[endgroup]
2026-01-14T08:21:39.7781542Z + echo '#!/usr/bin/env bash'
2026-01-14T08:21:39.7781838Z + echo 'set -eou pipefail'
2026-01-14T08:21:39.7782105Z + echo 'eval "$(conda shell.bash hook)"'
2026-01-14T08:21:39.7782394Z + echo 'set -x'
2026-01-14T08:21:39.7782756Z + echo 'conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:21:39.7783192Z conda activate venv
2026-01-14T08:21:39.7783437Z python -m pip install --upgrade pip
2026-01-14T08:21:39.7783771Z pip install torch==2.9.1
2026-01-14T08:21:39.7784042Z sed -i '\'''\'' dev-requirements.txt
2026-01-14T08:21:39.7784345Z pip install -r dev-requirements.txt
2026-01-14T08:21:39.7784649Z pip install . --no-build-isolation
2026-01-14T08:21:39.7784966Z export CONDA=$(dirname $(dirname $(which conda)))
2026-01-14T08:21:39.7785340Z export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
2026-01-14T08:21:39.7785668Z pytest test --verbose -s
2026-01-14T08:21:39.7785905Z '
2026-01-14T08:21:39.7786181Z + chmod +x /home/ec2-user/actions-runner/_work/_temp/exec_script
2026-01-14T08:21:39.7798619Z + python3 /home/ec2-user/actions-runner/_work/ao/ao/test-infra/.github/scripts/run_with_env_secrets.py ''
2026-01-14T08:22:00.7388178Z Running command: 
2026-01-14T08:22:00.7393571Z         docker run             -e PR_NUMBER             -e RUNNER_ARTIFACT_DIR=/artifacts             -e RUNNER_DOCS_DIR=/docs             -e RUNNER_TEST_RESULTS_DIR=/test-results             --env-file="/home/ec2-user/actions-runner/_work/_temp/github_env_20985547555"             `# It is unknown why the container sees a different value for this.`             -e GITHUB_STEP_SUMMARY             -e SECRET_GITHUB_TOKEN             --cap-add=SYS_PTRACE             --detach             --ipc=host             --security-opt seccomp=unconfined             --shm-size=2g             --tty             --ulimit stack=10485760:83886080             --ulimit core=0             --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all             -v "/home/ec2-user/actions-runner/_work/ao/ao/pytorch/ao:/pytorch/ao"             -v "/home/ec2-user/actions-runner/_work/ao/ao/test-infra:/test-infra"             -v "/home/ec2-user/actions-runner/_work/_temp/artifacts:/artifacts"             -v "/home/ec2-user/actions-runner/_work/_temp/docs:/docs"             -v "/home/ec2-user/actions-runner/_work/_temp/test-results:/test-results"             -v "/home/ec2-user/actions-runner/_work/_temp/exec_script:/exec"             -v "/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_b06a515f-a7b7-4e87-9088-bd6bd656d1a1":"/home/ec2-user/actions-runner/_work/_temp/_runner_file_commands/step_summary_b06a515f-a7b7-4e87-9088-bd6bd656d1a1"             -w /pytorch/ao             "pytorch/almalinux-builder:cuda12.6"
2026-01-14T08:22:00.7399833Z         
2026-01-14T08:22:00.7400138Z 451254f3fa5348b7469a76b736b562f41522bc2bbdcbaf083564ac4d246c8605
2026-01-14T08:22:00.7400780Z Running command: docker exec -t 451254f3fa5348b7469a76b736b562f41522bc2bbdcbaf083564ac4d246c8605 /exec
2026-01-14T08:22:00.7401418Z + conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:00.7401811Z + local cmd=create
2026-01-14T08:22:00.7402011Z + case "$cmd" in
2026-01-14T08:22:00.7402353Z + __conda_exe create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:00.7402932Z + /opt/conda/bin/conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
2026-01-14T08:22:00.7403406Z Could not load conda plugin `menuinst`:
2026-01-14T08:22:00.7403609Z 
2026-01-14T08:22:00.7403724Z Plugin requires `conda` to be installed.
2026-01-14T08:22:00.7404742Z Collecting package metadata (current_repodata.json): - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ done
2026-01-14T08:22:00.7405845Z Solving environment: / unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.
2026-01-14T08:22:00.7407266Z Collecting package metadata (repodata.json): \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - done
2026-01-14T08:22:00.7408230Z Solving environment: | / - \ | / done
2026-01-14T08:22:00.7408457Z 
2026-01-14T08:22:00.7408462Z 
2026-01-14T08:22:00.7408593Z ==> WARNING: A newer version of conda exists. <==
2026-01-14T08:22:00.7408900Z   current version: 23.5.2
2026-01-14T08:22:00.7409150Z   latest version: 25.11.1
2026-01-14T08:22:00.7409302Z 
2026-01-14T08:22:00.7409409Z Please update conda by running
2026-01-14T08:22:00.7409580Z 
2026-01-14T08:22:00.7409697Z     $ conda update -n base -c defaults conda
2026-01-14T08:22:00.7409903Z 
2026-01-14T08:22:00.7410111Z Or to minimize the number of packages updated during conda update use
2026-01-14T08:22:00.7410412Z 
2026-01-14T08:22:00.7410508Z      conda install conda=25.11.1
2026-01-14T08:22:00.7410690Z 
2026-01-14T08:22:00.7410694Z 
2026-01-14T08:22:00.7410697Z 
2026-01-14T08:22:00.7410785Z ## Package Plan ##
2026-01-14T08:22:00.7410919Z 
2026-01-14T08:22:00.7411041Z   environment location: /opt/conda/envs/venv
2026-01-14T08:22:00.7411257Z 
2026-01-14T08:22:00.7411457Z   added / updated specs:
2026-01-14T08:22:00.7411699Z     - libgcc-ng=11.2.0
2026-01-14T08:22:00.7411927Z     - libstdcxx-ng=11.2.0
2026-01-14T08:22:00.7412162Z     - python=3.10
2026-01-14T08:22:00.7412288Z 
2026-01-14T08:22:00.7412292Z 
2026-01-14T08:22:00.7412405Z The following packages will be downloaded:
2026-01-14T08:22:00.7412621Z 
2026-01-14T08:22:00.7412731Z     package                    |            build
2026-01-14T08:22:00.7413052Z     ---------------------------|-----------------
2026-01-14T08:22:00.7413546Z     bzip2-1.0.8                |       h5eee18b_6         262 KB
2026-01-14T08:22:00.7413957Z     ld_impl_linux-64-2.44      |       h153f514_2         672 KB
2026-01-14T08:22:00.7414396Z     libffi-3.4.4               |       h6a678d5_1         141 KB
2026-01-14T08:22:00.7414788Z     libnsl-2.0.0               |       h5eee18b_0          31 KB
2026-01-14T08:22:00.7415255Z     libxcb-1.17.0              |       h9b100fa_0         430 KB
2026-01-14T08:22:00.7415651Z     libzlib-1.3.1              |       hb25bd0a_0          59 KB
2026-01-14T08:22:00.7416035Z     ncurses-6.5                |       h7934f7d_0         1.1 MB
2026-01-14T08:22:00.7416416Z     pip-25.3                   |     pyhc872135_0         1.1 MB
2026-01-14T08:22:00.7416807Z     pthread-stubs-0.3          |       h0ce48e5_1           5 KB
2026-01-14T08:22:00.7417212Z     python-3.10.19             |       h6fa692b_0        24.5 MB
2026-01-14T08:22:00.7417595Z     readline-8.3               |       hc2a1206_0         471 KB
2026-01-14T08:22:00.7418012Z     setuptools-80.9.0          |  py310h06a4308_0         1.4 MB
2026-01-14T08:22:00.7418421Z     sqlite-3.51.0              |       h2a70700_0         1.2 MB
2026-01-14T08:22:00.7418848Z     tk-8.6.15                  |       h54e0aa7_0         3.4 MB
2026-01-14T08:22:00.7419233Z     tzdata-2025b               |       h04d1e81_0         116 KB
2026-01-14T08:22:00.7419619Z     wheel-0.45.1               |  py310h06a4308_0         115 KB
2026-01-14T08:22:00.7420022Z     xorg-libx11-1.8.12         |       h9b100fa_1         895 KB
2026-01-14T08:22:00.7420436Z     xorg-libxau-1.0.12         |       h9b100fa_0          13 KB
2026-01-14T08:22:00.7420862Z     xorg-libxdmcp-1.1.5        |       h9b100fa_0          19 KB
2026-01-14T08:22:00.7421304Z     xorg-xorgproto-2024.1      |       h5eee18b_1         580 KB
2026-01-14T08:22:00.7421696Z     xz-5.6.4                   |       h5eee18b_1         567 KB
2026-01-14T08:22:00.7422068Z     zlib-1.3.1                 |       hb25bd0a_0          96 KB
2026-01-14T08:22:00.7422442Z     ------------------------------------------------------------
2026-01-14T08:22:00.7422796Z                                            Total:        37.1 MB
2026-01-14T08:22:00.7423016Z 
2026-01-14T08:22:00.7423140Z The following NEW packages will be INSTALLED:
2026-01-14T08:22:00.7423368Z 
2026-01-14T08:22:00.7423572Z   _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
2026-01-14T08:22:00.7424023Z   _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
2026-01-14T08:22:00.7424449Z   bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 
2026-01-14T08:22:00.7424937Z   ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 
2026-01-14T08:22:00.7425427Z   expat              pkgs/main/linux-64::expat-2.7.3-h3385a95_0 
2026-01-14T08:22:00.7425895Z   ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 
2026-01-14T08:22:00.7426370Z   libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
2026-01-14T08:22:00.7426806Z   libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
2026-01-14T08:22:00.7427256Z   libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
2026-01-14T08:22:00.7427679Z   libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 
2026-01-14T08:22:00.7428134Z   libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
2026-01-14T08:22:00.7428606Z   libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 
2026-01-14T08:22:00.7429035Z   libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 
2026-01-14T08:22:00.7429457Z   libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:00.7429875Z   ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 
2026-01-14T08:22:00.7430302Z   openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 
2026-01-14T08:22:00.7430713Z   pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 
2026-01-14T08:22:00.7431166Z   pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 
2026-01-14T08:22:00.7431729Z   python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 
2026-01-14T08:22:00.7432164Z   readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 
2026-01-14T08:22:00.7432641Z   setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 
2026-01-14T08:22:00.7433182Z   sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 
2026-01-14T08:22:00.7433577Z   tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 
2026-01-14T08:22:00.7433968Z   tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 
2026-01-14T08:22:00.7434384Z   wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 
2026-01-14T08:22:00.7434841Z   xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 
2026-01-14T08:22:00.7435317Z   xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 
2026-01-14T08:22:00.7435810Z   xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 
2026-01-14T08:22:00.7436338Z   xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 
2026-01-14T08:22:00.7436988Z   xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 
2026-01-14T08:22:00.7437371Z   zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 
2026-01-14T08:22:00.7437616Z 
2026-01-14T08:22:00.7437620Z 
2026-01-14T08:22:00.7437630Z 
2026-01-14T08:22:00.7437736Z Downloading and Extracting Packages
2026-01-14T08:22:00.7437932Z 
2026-01-14T08:22:00.7438075Z wheel-0.45.1         | 115 KB    | :   0% 0/1 [00:00<?, ?it/s]
2026-01-14T08:22:00.7438322Z 
2026-01-14T08:22:00.7438558Z tk-8.6.15            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s][A
2026-01-14T08:22:00.7438797Z 
2026-01-14T08:22:00.7438801Z 
2026-01-14T08:22:00.7439028Z libzlib-1.3.1        | 59 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A
2026-01-14T08:22:00.7439298Z 
2026-01-14T08:22:00.7439302Z 
2026-01-14T08:22:00.7439305Z 
2026-01-14T08:22:00.7439543Z python-3.10.19       | 24.5 MB   | :   0% 0/1 [00:00<?, ?it/s][A[A[A
2026-01-14T08:22:00.7439811Z 
2026-01-14T08:22:00.7439815Z 
2026-01-14T08:22:00.7439824Z 
2026-01-14T08:22:00.7439828Z 
2026-01-14T08:22:00.7440076Z readline-8.3         | 471 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A
2026-01-14T08:22:00.7440348Z 
2026-01-14T08:22:00.7440351Z 
2026-01-14T08:22:00.7440355Z 
2026-01-14T08:22:00.7440358Z 
2026-01-14T08:22:00.7440367Z 
2026-01-14T08:22:00.7440649Z xorg-xorgproto-2024. | 580 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A
2026-01-14T08:22:00.7440955Z 
2026-01-14T08:22:00.7440959Z 
2026-01-14T08:22:00.7440962Z 
2026-01-14T08:22:00.7440966Z 
2026-01-14T08:22:00.7440970Z 
2026-01-14T08:22:00.7440973Z 
2026-01-14T08:22:00.7441219Z bzip2-1.0.8          | 262 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A
2026-01-14T08:22:00.7441506Z 
2026-01-14T08:22:00.7441510Z 
2026-01-14T08:22:00.7441514Z 
2026-01-14T08:22:00.7441517Z 
2026-01-14T08:22:00.7441521Z 
2026-01-14T08:22:00.7441524Z 
2026-01-14T08:22:00.7441528Z 
2026-01-14T08:22:00.7441795Z libffi-3.4.4         | 141 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A
2026-01-14T08:22:00.7442101Z 
2026-01-14T08:22:00.7442104Z 
2026-01-14T08:22:00.7442108Z 
2026-01-14T08:22:00.7442112Z 
2026-01-14T08:22:00.7442115Z 
2026-01-14T08:22:00.7442119Z 
2026-01-14T08:22:00.7442122Z 
2026-01-14T08:22:00.7442126Z 
2026-01-14T08:22:00.7442387Z pip-25.3             | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A
2026-01-14T08:22:00.7442687Z 
2026-01-14T08:22:00.7442690Z 
2026-01-14T08:22:00.7442694Z 
2026-01-14T08:22:00.7442698Z 
2026-01-14T08:22:00.7442701Z 
2026-01-14T08:22:00.7442705Z 
2026-01-14T08:22:00.7442708Z 
2026-01-14T08:22:00.7442712Z 
2026-01-14T08:22:00.7442716Z 
2026-01-14T08:22:00.7443005Z pthread-stubs-0.3    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:00.7443325Z 
2026-01-14T08:22:00.7443335Z 
2026-01-14T08:22:00.7443339Z 
2026-01-14T08:22:00.7443342Z 
2026-01-14T08:22:00.7443346Z 
2026-01-14T08:22:00.7443349Z 
2026-01-14T08:22:00.7443353Z 
2026-01-14T08:22:00.7443357Z 
2026-01-14T08:22:00.7443360Z 
2026-01-14T08:22:00.7443463Z 
2026-01-14T08:22:00.7443733Z xz-5.6.4             | 567 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:00.7444026Z 
2026-01-14T08:22:00.7444039Z 
2026-01-14T08:22:00.7444043Z 
2026-01-14T08:22:00.7444047Z 
2026-01-14T08:22:00.7444155Z 
2026-01-14T08:22:00.7444158Z 
2026-01-14T08:22:00.7444162Z 
2026-01-14T08:22:00.7444165Z 
2026-01-14T08:22:00.7444169Z 
2026-01-14T08:22:00.7444173Z 
2026-01-14T08:22:00.7444176Z 
2026-01-14T08:22:04.2269054Z tzdata-2025b         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2269445Z 
2026-01-14T08:22:04.2269451Z 
2026-01-14T08:22:04.2269455Z 
2026-01-14T08:22:04.2269460Z 
2026-01-14T08:22:04.2269464Z 
2026-01-14T08:22:04.2269468Z 
2026-01-14T08:22:04.2269472Z 
2026-01-14T08:22:04.2269476Z 
2026-01-14T08:22:04.2269480Z 
2026-01-14T08:22:04.2269483Z 
2026-01-14T08:22:04.2269487Z 
2026-01-14T08:22:04.2269490Z 
2026-01-14T08:22:04.2269832Z ncurses-6.5          | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2270169Z 
2026-01-14T08:22:04.2270173Z 
2026-01-14T08:22:04.2270177Z 
2026-01-14T08:22:04.2270294Z 
2026-01-14T08:22:04.2270298Z 
2026-01-14T08:22:04.2270302Z 
2026-01-14T08:22:04.2270305Z 
2026-01-14T08:22:04.2270320Z 
2026-01-14T08:22:04.2270324Z 
2026-01-14T08:22:04.2270328Z 
2026-01-14T08:22:04.2270331Z 
2026-01-14T08:22:04.2270343Z 
2026-01-14T08:22:04.2270348Z 
2026-01-14T08:22:04.2270670Z xorg-libx11-1.8.12   | 895 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2271013Z 
2026-01-14T08:22:04.2271016Z 
2026-01-14T08:22:04.2271020Z 
2026-01-14T08:22:04.2271024Z 
2026-01-14T08:22:04.2271027Z 
2026-01-14T08:22:04.2271031Z 
2026-01-14T08:22:04.2271034Z 
2026-01-14T08:22:04.2271038Z 
2026-01-14T08:22:04.2271049Z 
2026-01-14T08:22:04.2271053Z 
2026-01-14T08:22:04.2271057Z 
2026-01-14T08:22:04.2271061Z 
2026-01-14T08:22:04.2271064Z 
2026-01-14T08:22:04.2271068Z 
2026-01-14T08:22:04.2271376Z zlib-1.3.1           | 96 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2271696Z 
2026-01-14T08:22:04.2271700Z 
2026-01-14T08:22:04.2271704Z 
2026-01-14T08:22:04.2271718Z 
2026-01-14T08:22:04.2271722Z 
2026-01-14T08:22:04.2271732Z 
2026-01-14T08:22:04.2271735Z 
2026-01-14T08:22:04.2271739Z 
2026-01-14T08:22:04.2271743Z 
2026-01-14T08:22:04.2271747Z 
2026-01-14T08:22:04.2271750Z 
2026-01-14T08:22:04.2271754Z 
2026-01-14T08:22:04.2271758Z 
2026-01-14T08:22:04.2271761Z 
2026-01-14T08:22:04.2271765Z 
2026-01-14T08:22:04.2272102Z ld_impl_linux-64-2.4 | 672 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2272464Z 
2026-01-14T08:22:04.2272468Z 
2026-01-14T08:22:04.2272472Z 
2026-01-14T08:22:04.2272475Z 
2026-01-14T08:22:04.2272479Z 
2026-01-14T08:22:04.2272482Z 
2026-01-14T08:22:04.2272486Z 
2026-01-14T08:22:04.2272490Z 
2026-01-14T08:22:04.2272493Z 
2026-01-14T08:22:04.2272497Z 
2026-01-14T08:22:04.2272508Z 
2026-01-14T08:22:04.2272512Z 
2026-01-14T08:22:04.2272515Z 
2026-01-14T08:22:04.2272519Z 
2026-01-14T08:22:04.2272522Z 
2026-01-14T08:22:04.2272526Z 
2026-01-14T08:22:04.2272882Z xorg-libxdmcp-1.1.5  | 19 KB     | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2273267Z 
2026-01-14T08:22:04.2273270Z 
2026-01-14T08:22:04.2273274Z 
2026-01-14T08:22:04.2273277Z 
2026-01-14T08:22:04.2273281Z 
2026-01-14T08:22:04.2273284Z 
2026-01-14T08:22:04.2273288Z 
2026-01-14T08:22:04.2273291Z 
2026-01-14T08:22:04.2273295Z 
2026-01-14T08:22:04.2273299Z 
2026-01-14T08:22:04.2273302Z 
2026-01-14T08:22:04.2273306Z 
2026-01-14T08:22:04.2273309Z 
2026-01-14T08:22:04.2273313Z 
2026-01-14T08:22:04.2273316Z 
2026-01-14T08:22:04.2273326Z 
2026-01-14T08:22:04.2273330Z 
2026-01-14T08:22:04.2273669Z libxcb-1.17.0        | 430 KB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2274031Z 
2026-01-14T08:22:04.2274034Z 
2026-01-14T08:22:04.2274394Z 
2026-01-14T08:22:04.2274399Z 
2026-01-14T08:22:04.2274402Z 
2026-01-14T08:22:04.2274406Z 
2026-01-14T08:22:04.2274409Z 
2026-01-14T08:22:04.2274413Z 
2026-01-14T08:22:04.2274423Z 
2026-01-14T08:22:04.2274426Z 
2026-01-14T08:22:04.2274430Z 
2026-01-14T08:22:04.2274570Z 
2026-01-14T08:22:04.2274574Z 
2026-01-14T08:22:04.2274578Z 
2026-01-14T08:22:04.2274581Z 
2026-01-14T08:22:04.2274585Z 
2026-01-14T08:22:04.2274588Z 
2026-01-14T08:22:04.2274592Z 
2026-01-14T08:22:04.2274946Z sqlite-3.51.0        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2275314Z 
2026-01-14T08:22:04.2275318Z 
2026-01-14T08:22:04.2275321Z 
2026-01-14T08:22:04.2275325Z 
2026-01-14T08:22:04.2275328Z 
2026-01-14T08:22:04.2275332Z 
2026-01-14T08:22:04.2275335Z 
2026-01-14T08:22:04.2275339Z 
2026-01-14T08:22:04.2275342Z 
2026-01-14T08:22:04.2275346Z 
2026-01-14T08:22:04.2275349Z 
2026-01-14T08:22:04.2275353Z 
2026-01-14T08:22:04.2275356Z 
2026-01-14T08:22:04.2275366Z 
2026-01-14T08:22:04.2275370Z 
2026-01-14T08:22:04.2275373Z 
2026-01-14T08:22:04.2275377Z 
2026-01-14T08:22:04.2275380Z 
2026-01-14T08:22:04.2275384Z 
2026-01-14T08:22:04.2275636Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2275933Z 
2026-01-14T08:22:04.2276208Z tk-8.6.15            | 3.4 MB    | :   0% 0.00453827661272385/1 [00:00<00:39, 39.54s/it][A
2026-01-14T08:22:04.2276510Z 
2026-01-14T08:22:04.2276513Z 
2026-01-14T08:22:04.2276517Z 
2026-01-14T08:22:04.2276847Z python-3.10.19       | 24.5 MB   | :   0% 0.0006386825426160966/1 [00:00<04:41, 281.29s/it][A[A[A
2026-01-14T08:22:04.2277192Z 
2026-01-14T08:22:04.2277196Z 
2026-01-14T08:22:04.2277199Z 
2026-01-14T08:22:04.2277203Z 
2026-01-14T08:22:04.2277534Z readline-8.3         | 471 KB    | :   3% 0.03400397653924861/1 [00:00<00:05,  5.21s/it][A[A[A[A
2026-01-14T08:22:04.2278055Z wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:01,  1.34s/it]
2026-01-14T08:22:04.2278366Z 
2026-01-14T08:22:04.2278370Z 
2026-01-14T08:22:04.2278664Z libzlib-1.3.1        | 59 KB     | :  27% 0.2699309685816432/1 [00:00<00:00,  1.42it/s][A[A
2026-01-14T08:22:04.2278981Z 
2026-01-14T08:22:04.2278985Z 
2026-01-14T08:22:04.2278989Z 
2026-01-14T08:22:04.2278999Z 
2026-01-14T08:22:04.2279004Z 
2026-01-14T08:22:04.2279016Z 
2026-01-14T08:22:04.2279020Z 
2026-01-14T08:22:04.2279423Z libffi-3.4.4         | 141 KB    | :  11% 0.11323440988036575/1 [00:00<00:01,  2.10s/it][A[A[A[A[A[A[A
2026-01-14T08:22:04.2279791Z 
2026-01-14T08:22:04.2279795Z 
2026-01-14T08:22:04.2279799Z 
2026-01-14T08:22:04.2279802Z 
2026-01-14T08:22:04.2279806Z 
2026-01-14T08:22:04.2280174Z xorg-xorgproto-2024. | 580 KB    | :   3% 0.02757436782092818/1 [00:00<00:08,  8.66s/it][A[A[A[A[A
2026-01-14T08:22:04.2280553Z 
2026-01-14T08:22:04.2280557Z 
2026-01-14T08:22:04.2280561Z 
2026-01-14T08:22:04.2280565Z 
2026-01-14T08:22:04.2280568Z 
2026-01-14T08:22:04.2280572Z 
2026-01-14T08:22:04.2280923Z bzip2-1.0.8          | 262 KB    | :   6% 0.06104685823297961/1 [00:00<00:03,  3.93s/it][A[A[A[A[A[A
2026-01-14T08:22:04.2281275Z 
2026-01-14T08:22:04.2281279Z 
2026-01-14T08:22:04.2281570Z libzlib-1.3.1        | 59 KB     | : 100% 1.0/1 [00:00<00:00,  1.42it/s]               [A[A
2026-01-14T08:22:04.2281893Z 
2026-01-14T08:22:04.2282159Z tk-8.6.15            | 3.4 MB    | :  68% 0.6807414919085775/1 [00:00<00:00,  3.00it/s] [A
2026-01-14T08:22:04.2282450Z 
2026-01-14T08:22:04.2282454Z 
2026-01-14T08:22:04.2282457Z 
2026-01-14T08:22:04.2282781Z python-3.10.19       | 24.5 MB   | :   8% 0.08302873054009255/1 [00:00<00:02,  2.74s/it]   [A[A[A
2026-01-14T08:22:04.2283115Z 
2026-01-14T08:22:04.2283119Z 
2026-01-14T08:22:04.2283123Z 
2026-01-14T08:22:04.2283126Z 
2026-01-14T08:22:04.2283130Z 
2026-01-14T08:22:04.2283133Z 
2026-01-14T08:22:04.2283137Z 
2026-01-14T08:22:04.2283141Z 
2026-01-14T08:22:04.2283144Z 
2026-01-14T08:22:04.2283560Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  3.33it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2283906Z 
2026-01-14T08:22:04.2283909Z 
2026-01-14T08:22:04.2283913Z 
2026-01-14T08:22:04.2283917Z 
2026-01-14T08:22:04.2283920Z 
2026-01-14T08:22:04.2283924Z 
2026-01-14T08:22:04.2283927Z 
2026-01-14T08:22:04.2283931Z 
2026-01-14T08:22:04.2284465Z pip-25.3             | 1.1 MB    | :   1% 0.013906347741873605/1 [00:00<00:21, 21.71s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2284842Z 
2026-01-14T08:22:04.2284845Z 
2026-01-14T08:22:04.2284849Z 
2026-01-14T08:22:04.2284853Z 
2026-01-14T08:22:04.2284856Z 
2026-01-14T08:22:04.2284860Z 
2026-01-14T08:22:04.2284863Z 
2026-01-14T08:22:04.2284867Z 
2026-01-14T08:22:04.2284870Z 
2026-01-14T08:22:04.2284874Z 
2026-01-14T08:22:04.2285261Z xz-5.6.4             | 567 KB    | :   3% 0.028233137059266496/1 [00:00<00:10, 10.92s/it][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2285648Z 
2026-01-14T08:22:04.2285652Z 
2026-01-14T08:22:04.2285655Z 
2026-01-14T08:22:04.2285659Z 
2026-01-14T08:22:04.2285663Z 
2026-01-14T08:22:04.2285674Z 
2026-01-14T08:22:04.2285678Z 
2026-01-14T08:22:04.2285681Z 
2026-01-14T08:22:04.2285685Z 
2026-01-14T08:22:04.2285688Z 
2026-01-14T08:22:04.2285692Z 
2026-01-14T08:22:04.2286105Z tzdata-2025b         | 116 KB    | :  14% 0.13742430088406501/1 [00:00<00:02,  2.56s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2286515Z 
2026-01-14T08:22:04.2286519Z 
2026-01-14T08:22:04.2286522Z 
2026-01-14T08:22:04.2286526Z 
2026-01-14T08:22:04.2286834Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  3.10it/s]                [A[A[A[A
2026-01-14T08:22:04.2287171Z 
2026-01-14T08:22:04.2287174Z 
2026-01-14T08:22:04.2287178Z 
2026-01-14T08:22:04.2287181Z 
2026-01-14T08:22:04.2287446Z readline-8.3         | 471 KB    | : 100% 1.0/1 [00:00<00:00,  3.10it/s][A[A[A[A
2026-01-14T08:22:04.2287741Z 
2026-01-14T08:22:04.2287745Z 
2026-01-14T08:22:04.2287755Z 
2026-01-14T08:22:04.2287759Z 
2026-01-14T08:22:04.2287763Z 
2026-01-14T08:22:04.2287766Z 
2026-01-14T08:22:04.2287770Z 
2026-01-14T08:22:04.2287778Z 
2026-01-14T08:22:04.2287782Z 
2026-01-14T08:22:04.2287786Z 
2026-01-14T08:22:04.2287789Z 
2026-01-14T08:22:04.2287793Z 
2026-01-14T08:22:04.2288199Z ncurses-6.5          | 1.1 MB    | :   1% 0.014401655346517857/1 [00:00<00:25, 25.74s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2288624Z 
2026-01-14T08:22:04.2288627Z 
2026-01-14T08:22:04.2288631Z 
2026-01-14T08:22:04.2288939Z python-3.10.19       | 24.5 MB   | :  17% 0.17308296904896217/1 [00:00<00:01,  1.75s/it][A[A[A
2026-01-14T08:22:04.2289266Z 
2026-01-14T08:22:04.2289270Z 
2026-01-14T08:22:04.2289274Z 
2026-01-14T08:22:04.2289277Z 
2026-01-14T08:22:04.2289281Z 
2026-01-14T08:22:04.2289284Z 
2026-01-14T08:22:04.2289295Z 
2026-01-14T08:22:04.2289298Z 
2026-01-14T08:22:04.2289302Z 
2026-01-14T08:22:04.2289306Z 
2026-01-14T08:22:04.2289310Z 
2026-01-14T08:22:04.2289313Z 
2026-01-14T08:22:04.2289317Z 
2026-01-14T08:22:04.2289758Z xorg-libx11-1.8.12   | 895 KB    | :   2% 0.017882324178246957/1 [00:00<00:21, 21.48s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2290190Z 
2026-01-14T08:22:04.2290194Z 
2026-01-14T08:22:04.2290203Z 
2026-01-14T08:22:04.2290207Z 
2026-01-14T08:22:04.2290211Z 
2026-01-14T08:22:04.2290215Z 
2026-01-14T08:22:04.2290218Z 
2026-01-14T08:22:04.2290222Z 
2026-01-14T08:22:04.2290230Z 
2026-01-14T08:22:04.2290233Z 
2026-01-14T08:22:04.2290237Z 
2026-01-14T08:22:04.2290240Z 
2026-01-14T08:22:04.2290244Z 
2026-01-14T08:22:04.2290247Z 
2026-01-14T08:22:04.2290657Z zlib-1.3.1           | 96 KB     | :  17% 0.16692817116658176/1 [00:00<00:01,  2.38s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2291073Z 
2026-01-14T08:22:04.2291077Z 
2026-01-14T08:22:04.2291080Z 
2026-01-14T08:22:04.2291084Z 
2026-01-14T08:22:04.2291087Z 
2026-01-14T08:22:04.2291091Z 
2026-01-14T08:22:04.2291095Z 
2026-01-14T08:22:04.2291099Z 
2026-01-14T08:22:04.2291102Z 
2026-01-14T08:22:04.2291106Z 
2026-01-14T08:22:04.2291110Z 
2026-01-14T08:22:04.2291113Z 
2026-01-14T08:22:04.2291117Z 
2026-01-14T08:22:04.2291209Z 
2026-01-14T08:22:04.2291213Z 
2026-01-14T08:22:04.2291738Z ld_impl_linux-64-2.4 | 672 KB    | :   2% 0.02380578754961961/1 [00:00<00:16, 17.10s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2292363Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  2.60it/s]                
2026-01-14T08:22:04.2292895Z wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:00<00:00,  2.60it/s]
2026-01-14T08:22:04.2293154Z 
2026-01-14T08:22:04.2293157Z 
2026-01-14T08:22:04.2293161Z 
2026-01-14T08:22:04.2293164Z 
2026-01-14T08:22:04.2293168Z 
2026-01-14T08:22:04.2293171Z 
2026-01-14T08:22:04.2293175Z 
2026-01-14T08:22:04.2293179Z 
2026-01-14T08:22:04.2293183Z 
2026-01-14T08:22:04.2293186Z 
2026-01-14T08:22:04.2293190Z 
2026-01-14T08:22:04.2293199Z 
2026-01-14T08:22:04.2293203Z 
2026-01-14T08:22:04.2293206Z 
2026-01-14T08:22:04.2293210Z 
2026-01-14T08:22:04.2293214Z 
2026-01-14T08:22:04.2293667Z xorg-libxdmcp-1.1.5  | 19 KB     | :  85% 0.85067497403946/1 [00:00<00:00,  1.89it/s][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2294113Z 
2026-01-14T08:22:04.2294117Z 
2026-01-14T08:22:04.2294121Z 
2026-01-14T08:22:04.2294124Z 
2026-01-14T08:22:04.2294134Z 
2026-01-14T08:22:04.2294137Z 
2026-01-14T08:22:04.2294141Z 
2026-01-14T08:22:04.2294144Z 
2026-01-14T08:22:04.2294152Z 
2026-01-14T08:22:04.2294156Z 
2026-01-14T08:22:04.2294160Z 
2026-01-14T08:22:04.2294163Z 
2026-01-14T08:22:04.2294167Z 
2026-01-14T08:22:04.2294170Z 
2026-01-14T08:22:04.2294174Z 
2026-01-14T08:22:04.2294178Z 
2026-01-14T08:22:04.2294181Z 
2026-01-14T08:22:04.2294629Z libxcb-1.17.0        | 430 KB    | :   4% 0.03717806167600808/1 [00:00<00:11, 12.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2295079Z 
2026-01-14T08:22:04.2295082Z 
2026-01-14T08:22:04.2295086Z 
2026-01-14T08:22:04.2295395Z python-3.10.19       | 24.5 MB   | :  27% 0.26633062027091225/1 [00:00<00:01,  1.44s/it][A[A[A
2026-01-14T08:22:04.2295721Z 
2026-01-14T08:22:04.2295725Z 
2026-01-14T08:22:04.2295728Z 
2026-01-14T08:22:04.2295742Z 
2026-01-14T08:22:04.2295745Z 
2026-01-14T08:22:04.2295749Z 
2026-01-14T08:22:04.2295753Z 
2026-01-14T08:22:04.2295756Z 
2026-01-14T08:22:04.2295760Z 
2026-01-14T08:22:04.2295763Z 
2026-01-14T08:22:04.2295767Z 
2026-01-14T08:22:04.2295771Z 
2026-01-14T08:22:04.2295778Z 
2026-01-14T08:22:04.2295782Z 
2026-01-14T08:22:04.2295785Z 
2026-01-14T08:22:04.2295789Z 
2026-01-14T08:22:04.2295793Z 
2026-01-14T08:22:04.2295796Z 
2026-01-14T08:22:04.2296263Z sqlite-3.51.0        | 1.2 MB    | :   1% 0.013350140517073497/1 [00:00<00:35, 35.58s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2296719Z 
2026-01-14T08:22:04.2296722Z 
2026-01-14T08:22:04.2296726Z 
2026-01-14T08:22:04.2296730Z 
2026-01-14T08:22:04.2296733Z 
2026-01-14T08:22:04.2296737Z 
2026-01-14T08:22:04.2296741Z 
2026-01-14T08:22:04.2296744Z 
2026-01-14T08:22:04.2296748Z 
2026-01-14T08:22:04.2296751Z 
2026-01-14T08:22:04.2296755Z 
2026-01-14T08:22:04.2296758Z 
2026-01-14T08:22:04.2296762Z 
2026-01-14T08:22:04.2296770Z 
2026-01-14T08:22:04.2296774Z 
2026-01-14T08:22:04.2296778Z 
2026-01-14T08:22:04.2296781Z 
2026-01-14T08:22:04.2296785Z 
2026-01-14T08:22:04.2296794Z 
2026-01-14T08:22:04.2297042Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2297338Z 
2026-01-14T08:22:04.2297342Z 
2026-01-14T08:22:04.2297345Z 
2026-01-14T08:22:04.2297349Z 
2026-01-14T08:22:04.2297352Z 
2026-01-14T08:22:04.2297356Z 
2026-01-14T08:22:04.2297707Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  2.28it/s]                [A[A[A[A[A[A
2026-01-14T08:22:04.2298053Z 
2026-01-14T08:22:04.2298056Z 
2026-01-14T08:22:04.2298060Z 
2026-01-14T08:22:04.2298063Z 
2026-01-14T08:22:04.2298067Z 
2026-01-14T08:22:04.2298071Z 
2026-01-14T08:22:04.2298349Z bzip2-1.0.8          | 262 KB    | : 100% 1.0/1 [00:00<00:00,  2.28it/s][A[A[A[A[A[A
2026-01-14T08:22:04.2298662Z 
2026-01-14T08:22:04.2298666Z 
2026-01-14T08:22:04.2298669Z 
2026-01-14T08:22:04.2298673Z 
2026-01-14T08:22:04.2298766Z 
2026-01-14T08:22:04.2298770Z 
2026-01-14T08:22:04.2298773Z 
2026-01-14T08:22:04.2298777Z 
2026-01-14T08:22:04.2298780Z 
2026-01-14T08:22:04.2299103Z pthread-stubs-0.3    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  3.33it/s][A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2299526Z 
2026-01-14T08:22:04.2299530Z 
2026-01-14T08:22:04.2299534Z 
2026-01-14T08:22:04.2299842Z python-3.10.19       | 24.5 MB   | :  36% 0.3583009064076302/1 [00:00<00:00,  1.30s/it] [A[A[A
2026-01-14T08:22:04.2300177Z 
2026-01-14T08:22:04.2300181Z 
2026-01-14T08:22:04.2300185Z 
2026-01-14T08:22:04.2300489Z python-3.10.19       | 24.5 MB   | :  52% 0.5198875896895025/1 [00:00<00:00,  1.04it/s][A[A[A
2026-01-14T08:22:04.2300812Z 
2026-01-14T08:22:04.2300816Z 
2026-01-14T08:22:04.2300820Z 
2026-01-14T08:22:04.2300823Z 
2026-01-14T08:22:04.2300827Z 
2026-01-14T08:22:04.2300831Z 
2026-01-14T08:22:04.2300834Z 
2026-01-14T08:22:04.2301182Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.46it/s]                [A[A[A[A[A[A[A
2026-01-14T08:22:04.2301534Z 
2026-01-14T08:22:04.2301538Z 
2026-01-14T08:22:04.2301541Z 
2026-01-14T08:22:04.2301545Z 
2026-01-14T08:22:04.2301548Z 
2026-01-14T08:22:04.2301552Z 
2026-01-14T08:22:04.2301555Z 
2026-01-14T08:22:04.2301854Z libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  1.46it/s][A[A[A[A[A[A[A
2026-01-14T08:22:04.2302171Z 
2026-01-14T08:22:04.2302175Z 
2026-01-14T08:22:04.2302179Z 
2026-01-14T08:22:04.2302483Z python-3.10.19       | 24.5 MB   | :  66% 0.6578430188945794/1 [00:00<00:00,  1.15it/s][A[A[A
2026-01-14T08:22:04.2302814Z 
2026-01-14T08:22:04.2302818Z 
2026-01-14T08:22:04.2302822Z 
2026-01-14T08:22:04.2303121Z python-3.10.19       | 24.5 MB   | :  79% 0.7906889877587275/1 [00:00<00:00,  1.20it/s][A[A[A
2026-01-14T08:22:04.2303445Z 
2026-01-14T08:22:04.2303448Z 
2026-01-14T08:22:04.2303460Z 
2026-01-14T08:22:04.2303464Z 
2026-01-14T08:22:04.2303467Z 
2026-01-14T08:22:04.2303821Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.18it/s]                [A[A[A[A[A
2026-01-14T08:22:04.2304188Z 
2026-01-14T08:22:04.2304192Z 
2026-01-14T08:22:04.2304196Z 
2026-01-14T08:22:04.2304200Z 
2026-01-14T08:22:04.2304203Z 
2026-01-14T08:22:04.2304505Z xorg-xorgproto-2024. | 580 KB    | : 100% 1.0/1 [00:00<00:00,  1.18it/s][A[A[A[A[A
2026-01-14T08:22:04.2304844Z 
2026-01-14T08:22:04.2304848Z 
2026-01-14T08:22:04.2304851Z 
2026-01-14T08:22:04.2305158Z python-3.10.19       | 24.5 MB   | :  91% 0.9139547184836342/1 [00:00<00:00,  1.21it/s][A[A[A
2026-01-14T08:22:04.2305490Z 
2026-01-14T08:22:04.2305494Z 
2026-01-14T08:22:04.2305497Z 
2026-01-14T08:22:04.2305501Z 
2026-01-14T08:22:04.2305505Z 
2026-01-14T08:22:04.2305508Z 
2026-01-14T08:22:04.2305512Z 
2026-01-14T08:22:04.2305515Z 
2026-01-14T08:22:04.2305519Z 
2026-01-14T08:22:04.2305523Z 
2026-01-14T08:22:04.2305870Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.03it/s]                 [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2306237Z 
2026-01-14T08:22:04.2306247Z 
2026-01-14T08:22:04.2306250Z 
2026-01-14T08:22:04.2306254Z 
2026-01-14T08:22:04.2306258Z 
2026-01-14T08:22:04.2306261Z 
2026-01-14T08:22:04.2306265Z 
2026-01-14T08:22:04.2306268Z 
2026-01-14T08:22:04.2306272Z 
2026-01-14T08:22:04.2306275Z 
2026-01-14T08:22:04.2306577Z xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:01<00:00,  1.03it/s][A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2306908Z 
2026-01-14T08:22:04.2307168Z tk-8.6.15            | 3.4 MB    | : 100% 1.0/1 [00:01<00:00,  3.00it/s]               [A
2026-01-14T08:22:04.2307459Z 
2026-01-14T08:22:04.2307463Z 
2026-01-14T08:22:04.2319373Z 
2026-01-14T08:22:04.2319385Z 
2026-01-14T08:22:04.2319389Z 
2026-01-14T08:22:04.2319392Z 
2026-01-14T08:22:04.2319396Z 
2026-01-14T08:22:04.2319400Z 
2026-01-14T08:22:04.2319403Z 
2026-01-14T08:22:04.2319407Z 
2026-01-14T08:22:04.2319411Z 
2026-01-14T08:22:04.2319414Z 
2026-01-14T08:22:04.2319418Z 
2026-01-14T08:22:04.2319422Z 
2026-01-14T08:22:04.2320042Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:01<00:00,  1.36s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2320456Z 
2026-01-14T08:22:04.2320460Z 
2026-01-14T08:22:04.2320464Z 
2026-01-14T08:22:04.2320467Z 
2026-01-14T08:22:04.2320471Z 
2026-01-14T08:22:04.2320475Z 
2026-01-14T08:22:04.2320558Z 
2026-01-14T08:22:04.2320561Z 
2026-01-14T08:22:04.2320565Z 
2026-01-14T08:22:04.2320569Z 
2026-01-14T08:22:04.2320572Z 
2026-01-14T08:22:04.2320576Z 
2026-01-14T08:22:04.2320579Z 
2026-01-14T08:22:04.2320583Z 
2026-01-14T08:22:04.2320928Z zlib-1.3.1           | 96 KB     | : 100% 1.0/1 [00:01<00:00,  1.36s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2321291Z 
2026-01-14T08:22:04.2321295Z 
2026-01-14T08:22:04.2321299Z 
2026-01-14T08:22:04.2321302Z 
2026-01-14T08:22:04.2321306Z 
2026-01-14T08:22:04.2321309Z 
2026-01-14T08:22:04.2321313Z 
2026-01-14T08:22:04.2321317Z 
2026-01-14T08:22:04.2321320Z 
2026-01-14T08:22:04.2321324Z 
2026-01-14T08:22:04.2321327Z 
2026-01-14T08:22:04.2321713Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.49s/it]                [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2322092Z 
2026-01-14T08:22:04.2322096Z 
2026-01-14T08:22:04.2322099Z 
2026-01-14T08:22:04.2322103Z 
2026-01-14T08:22:04.2322106Z 
2026-01-14T08:22:04.2322114Z 
2026-01-14T08:22:04.2322118Z 
2026-01-14T08:22:04.2322121Z 
2026-01-14T08:22:04.2322125Z 
2026-01-14T08:22:04.2322128Z 
2026-01-14T08:22:04.2322132Z 
2026-01-14T08:22:04.2322472Z tzdata-2025b         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.49s/it][A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2322824Z 
2026-01-14T08:22:04.2322827Z 
2026-01-14T08:22:04.2322831Z 
2026-01-14T08:22:04.2322834Z 
2026-01-14T08:22:04.2322838Z 
2026-01-14T08:22:04.2322841Z 
2026-01-14T08:22:04.2322845Z 
2026-01-14T08:22:04.2322848Z 
2026-01-14T08:22:04.2323190Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]                 [A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2323534Z 
2026-01-14T08:22:04.2323543Z 
2026-01-14T08:22:04.2323547Z 
2026-01-14T08:22:04.2323551Z 
2026-01-14T08:22:04.2323554Z 
2026-01-14T08:22:04.2323558Z 
2026-01-14T08:22:04.2323562Z 
2026-01-14T08:22:04.2323565Z 
2026-01-14T08:22:04.2323861Z pip-25.3             | 1.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it][A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2324179Z 
2026-01-14T08:22:04.2324183Z 
2026-01-14T08:22:04.2324187Z 
2026-01-14T08:22:04.2324190Z 
2026-01-14T08:22:04.2324194Z 
2026-01-14T08:22:04.2324197Z 
2026-01-14T08:22:04.2324201Z 
2026-01-14T08:22:04.2324204Z 
2026-01-14T08:22:04.2324208Z 
2026-01-14T08:22:04.2324211Z 
2026-01-14T08:22:04.2324215Z 
2026-01-14T08:22:04.2324218Z 
2026-01-14T08:22:04.2324222Z 
2026-01-14T08:22:04.2324225Z 
2026-01-14T08:22:04.2324229Z 
2026-01-14T08:22:04.2324647Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.57s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2325061Z 
2026-01-14T08:22:04.2325065Z 
2026-01-14T08:22:04.2325069Z 
2026-01-14T08:22:04.2325076Z 
2026-01-14T08:22:04.2325080Z 
2026-01-14T08:22:04.2325083Z 
2026-01-14T08:22:04.2325087Z 
2026-01-14T08:22:04.2325090Z 
2026-01-14T08:22:04.2325094Z 
2026-01-14T08:22:04.2325097Z 
2026-01-14T08:22:04.2325107Z 
2026-01-14T08:22:04.2325111Z 
2026-01-14T08:22:04.2325115Z 
2026-01-14T08:22:04.2325122Z 
2026-01-14T08:22:04.2325126Z 
2026-01-14T08:22:04.2325501Z ld_impl_linux-64-2.4 | 672 KB    | : 100% 1.0/1 [00:01<00:00,  1.57s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2325888Z 
2026-01-14T08:22:04.2325892Z 
2026-01-14T08:22:04.2325895Z 
2026-01-14T08:22:04.2325899Z 
2026-01-14T08:22:04.2325902Z 
2026-01-14T08:22:04.2325914Z 
2026-01-14T08:22:04.2325917Z 
2026-01-14T08:22:04.2325921Z 
2026-01-14T08:22:04.2325924Z 
2026-01-14T08:22:04.2325928Z 
2026-01-14T08:22:04.2325931Z 
2026-01-14T08:22:04.2325935Z 
2026-01-14T08:22:04.2325938Z 
2026-01-14T08:22:04.2325942Z 
2026-01-14T08:22:04.2325945Z 
2026-01-14T08:22:04.2325949Z 
2026-01-14T08:22:04.2326456Z xorg-libxdmcp-1.1.5  | 19 KB     | : 100% 1.0/1 [00:01<00:00,  1.89it/s]             [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2326888Z 
2026-01-14T08:22:04.2326892Z 
2026-01-14T08:22:04.2326896Z 
2026-01-14T08:22:04.2326900Z 
2026-01-14T08:22:04.2326903Z 
2026-01-14T08:22:04.2326977Z 
2026-01-14T08:22:04.2326981Z 
2026-01-14T08:22:04.2326984Z 
2026-01-14T08:22:04.2326988Z 
2026-01-14T08:22:04.2326992Z 
2026-01-14T08:22:04.2326995Z 
2026-01-14T08:22:04.2326999Z 
2026-01-14T08:22:04.2327002Z 
2026-01-14T08:22:04.2327401Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.69s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2327810Z 
2026-01-14T08:22:04.2327814Z 
2026-01-14T08:22:04.2327818Z 
2026-01-14T08:22:04.2327821Z 
2026-01-14T08:22:04.2327825Z 
2026-01-14T08:22:04.2327828Z 
2026-01-14T08:22:04.2327832Z 
2026-01-14T08:22:04.2327835Z 
2026-01-14T08:22:04.2327839Z 
2026-01-14T08:22:04.2327842Z 
2026-01-14T08:22:04.2327846Z 
2026-01-14T08:22:04.2327850Z 
2026-01-14T08:22:04.2327860Z 
2026-01-14T08:22:04.2328224Z xorg-libx11-1.8.12   | 895 KB    | : 100% 1.0/1 [00:01<00:00,  1.69s/it][A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2328599Z 
2026-01-14T08:22:04.2328603Z 
2026-01-14T08:22:04.2328606Z 
2026-01-14T08:22:04.2328610Z 
2026-01-14T08:22:04.2328617Z 
2026-01-14T08:22:04.2328621Z 
2026-01-14T08:22:04.2328624Z 
2026-01-14T08:22:04.2328628Z 
2026-01-14T08:22:04.2328631Z 
2026-01-14T08:22:04.2328635Z 
2026-01-14T08:22:04.2328638Z 
2026-01-14T08:22:04.2328642Z 
2026-01-14T08:22:04.2328645Z 
2026-01-14T08:22:04.2328649Z 
2026-01-14T08:22:04.2328659Z 
2026-01-14T08:22:04.2328663Z 
2026-01-14T08:22:04.2328667Z 
2026-01-14T08:22:04.2329075Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it]                [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2329488Z 
2026-01-14T08:22:04.2329492Z 
2026-01-14T08:22:04.2329496Z 
2026-01-14T08:22:04.2329499Z 
2026-01-14T08:22:04.2329503Z 
2026-01-14T08:22:04.2329509Z 
2026-01-14T08:22:04.2329521Z 
2026-01-14T08:22:04.2329525Z 
2026-01-14T08:22:04.2329529Z 
2026-01-14T08:22:04.2329532Z 
2026-01-14T08:22:04.2329536Z 
2026-01-14T08:22:04.2329540Z 
2026-01-14T08:22:04.2329543Z 
2026-01-14T08:22:04.2329547Z 
2026-01-14T08:22:04.2329550Z 
2026-01-14T08:22:04.2329560Z 
2026-01-14T08:22:04.2329564Z 
2026-01-14T08:22:04.2329943Z libxcb-1.17.0        | 430 KB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2330334Z 
2026-01-14T08:22:04.2330338Z 
2026-01-14T08:22:04.2330342Z 
2026-01-14T08:22:04.2330345Z 
2026-01-14T08:22:04.2330349Z 
2026-01-14T08:22:04.2330353Z 
2026-01-14T08:22:04.2330356Z 
2026-01-14T08:22:04.2330360Z 
2026-01-14T08:22:04.2330363Z 
2026-01-14T08:22:04.2330367Z 
2026-01-14T08:22:04.2330371Z 
2026-01-14T08:22:04.2330374Z 
2026-01-14T08:22:04.2330378Z 
2026-01-14T08:22:04.2330381Z 
2026-01-14T08:22:04.2330385Z 
2026-01-14T08:22:04.2330388Z 
2026-01-14T08:22:04.2330392Z 
2026-01-14T08:22:04.2330399Z 
2026-01-14T08:22:04.2330824Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.77s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2331238Z 
2026-01-14T08:22:04.2331242Z 
2026-01-14T08:22:04.2331246Z 
2026-01-14T08:22:04.2331253Z 
2026-01-14T08:22:04.2331257Z 
2026-01-14T08:22:04.2331260Z 
2026-01-14T08:22:04.2331264Z 
2026-01-14T08:22:04.2331267Z 
2026-01-14T08:22:04.2331357Z 
2026-01-14T08:22:04.2331362Z 
2026-01-14T08:22:04.2331365Z 
2026-01-14T08:22:04.2331369Z 
2026-01-14T08:22:04.2331372Z 
2026-01-14T08:22:04.2331384Z 
2026-01-14T08:22:04.2331388Z 
2026-01-14T08:22:04.2331391Z 
2026-01-14T08:22:04.2331395Z 
2026-01-14T08:22:04.2331399Z 
2026-01-14T08:22:04.2331781Z sqlite-3.51.0        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.77s/it][A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2332170Z 
2026-01-14T08:22:04.2332174Z 
2026-01-14T08:22:04.2332178Z 
2026-01-14T08:22:04.2332181Z 
2026-01-14T08:22:04.2332192Z 
2026-01-14T08:22:04.2332285Z 
2026-01-14T08:22:04.2332289Z 
2026-01-14T08:22:04.2332293Z 
2026-01-14T08:22:04.2332297Z 
2026-01-14T08:22:04.2332300Z 
2026-01-14T08:22:04.2332304Z 
2026-01-14T08:22:04.2332308Z 
2026-01-14T08:22:04.2332311Z 
2026-01-14T08:22:04.2332315Z 
2026-01-14T08:22:04.2332389Z 
2026-01-14T08:22:04.2332392Z 
2026-01-14T08:22:04.2332396Z 
2026-01-14T08:22:04.2332399Z 
2026-01-14T08:22:04.2332403Z 
2026-01-14T08:22:04.2332658Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:04.2332958Z 
2026-01-14T08:22:04.2332962Z 
2026-01-14T08:22:04.2332965Z 
2026-01-14T08:22:04.2332969Z 
2026-01-14T08:22:04.2332972Z 
2026-01-14T08:22:04.2332976Z 
2026-01-14T08:22:04.2332979Z 
2026-01-14T08:22:04.2332983Z 
2026-01-14T08:22:04.2332986Z 
2026-01-14T08:22:04.2332990Z 
2026-01-14T08:22:04.2332993Z 
2026-01-14T08:22:04.2332997Z 
2026-01-14T08:22:04.2333000Z 
2026-01-14T08:22:04.2333004Z 
2026-01-14T08:22:04.2333007Z 
2026-01-14T08:22:04.2333011Z 
2026-01-14T08:22:04.2333018Z 
2026-01-14T08:22:04.2333022Z 
2026-01-14T08:22:04.2333026Z 
2026-01-14T08:22:11.5997109Z  ... (more hidden) ...[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.5997829Z 
2026-01-14T08:22:11.5997838Z 
2026-01-14T08:22:11.5997846Z 
2026-01-14T08:22:11.5997880Z 
2026-01-14T08:22:11.5997888Z 
2026-01-14T08:22:11.5997895Z 
2026-01-14T08:22:11.5997902Z 
2026-01-14T08:22:11.5997910Z 
2026-01-14T08:22:11.5997917Z 
2026-01-14T08:22:11.5997924Z 
2026-01-14T08:22:11.5997932Z 
2026-01-14T08:22:11.5997939Z 
2026-01-14T08:22:11.5998740Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.39s/it]                 [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.5999514Z 
2026-01-14T08:22:11.5999522Z 
2026-01-14T08:22:11.5999530Z 
2026-01-14T08:22:11.5999538Z 
2026-01-14T08:22:11.5999545Z 
2026-01-14T08:22:11.5999552Z 
2026-01-14T08:22:11.5999559Z 
2026-01-14T08:22:11.5999566Z 
2026-01-14T08:22:11.5999573Z 
2026-01-14T08:22:11.5999580Z 
2026-01-14T08:22:11.5999613Z 
2026-01-14T08:22:11.5999620Z 
2026-01-14T08:22:11.6000288Z ncurses-6.5          | 1.1 MB    | : 100% 1.0/1 [00:03<00:00,  3.39s/it][A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6000936Z 
2026-01-14T08:22:11.6000940Z 
2026-01-14T08:22:11.6000943Z 
2026-01-14T08:22:11.6001316Z python-3.10.19       | 24.5 MB   | : 100% 1.0/1 [00:03<00:00,  1.21it/s]               [A[A[A
2026-01-14T08:22:11.6001647Z 
2026-01-14T08:22:11.6001651Z 
2026-01-14T08:22:11.6001654Z 
2026-01-14T08:22:11.6001658Z 
2026-01-14T08:22:11.6001661Z 
2026-01-14T08:22:11.6001665Z 
2026-01-14T08:22:11.6001668Z 
2026-01-14T08:22:11.6001672Z 
2026-01-14T08:22:11.6001675Z 
2026-01-14T08:22:11.6001679Z 
2026-01-14T08:22:11.6001683Z 
2026-01-14T08:22:11.6001686Z 
2026-01-14T08:22:11.6001690Z 
2026-01-14T08:22:11.6001693Z 
2026-01-14T08:22:11.6001697Z 
2026-01-14T08:22:11.6001716Z 
2026-01-14T08:22:11.6001719Z 
2026-01-14T08:22:11.6001723Z 
2026-01-14T08:22:11.6001726Z 
2026-01-14T08:22:11.6001810Z                       
2026-01-14T08:22:11.6002141Z [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6002501Z                                                                         
2026-01-14T08:22:11.6002731Z 
2026-01-14T08:22:11.6002735Z 
2026-01-14T08:22:11.6002947Z                                                                         [A
2026-01-14T08:22:11.6003195Z 
2026-01-14T08:22:11.6003199Z 
2026-01-14T08:22:11.6003396Z                                                                         [A[A
2026-01-14T08:22:11.6003640Z 
2026-01-14T08:22:11.6003644Z 
2026-01-14T08:22:11.6003647Z 
2026-01-14T08:22:11.6003847Z                                                                         [A[A[A
2026-01-14T08:22:11.6004090Z 
2026-01-14T08:22:11.6004094Z 
2026-01-14T08:22:11.6004106Z 
2026-01-14T08:22:11.6004110Z 
2026-01-14T08:22:11.6004321Z                                                                         [A[A[A[A
2026-01-14T08:22:11.6004572Z 
2026-01-14T08:22:11.6004576Z 
2026-01-14T08:22:11.6004926Z 
2026-01-14T08:22:11.6004930Z 
2026-01-14T08:22:11.6004934Z 
2026-01-14T08:22:11.6005163Z                                                                         [A[A[A[A[A
2026-01-14T08:22:11.6005417Z 
2026-01-14T08:22:11.6005421Z 
2026-01-14T08:22:11.6005425Z 
2026-01-14T08:22:11.6006529Z 
2026-01-14T08:22:11.6006533Z 
2026-01-14T08:22:11.6006536Z 
2026-01-14T08:22:11.6006764Z                                                                         [A[A[A[A[A[A
2026-01-14T08:22:11.6007034Z 
2026-01-14T08:22:11.6007037Z 
2026-01-14T08:22:11.6007041Z 
2026-01-14T08:22:11.6007044Z 
2026-01-14T08:22:11.6007048Z 
2026-01-14T08:22:11.6007052Z 
2026-01-14T08:22:11.6007055Z 
2026-01-14T08:22:11.6007285Z                                                                         [A[A[A[A[A[A[A
2026-01-14T08:22:11.6007555Z 
2026-01-14T08:22:11.6007559Z 
2026-01-14T08:22:11.6007562Z 
2026-01-14T08:22:11.6007566Z 
2026-01-14T08:22:11.6007569Z 
2026-01-14T08:22:11.6007573Z 
2026-01-14T08:22:11.6007584Z 
2026-01-14T08:22:11.6007588Z 
2026-01-14T08:22:11.6007819Z                                                                         [A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6008101Z 
2026-01-14T08:22:11.6008105Z 
2026-01-14T08:22:11.6008109Z 
2026-01-14T08:22:11.6008112Z 
2026-01-14T08:22:11.6008121Z 
2026-01-14T08:22:11.6008125Z 
2026-01-14T08:22:11.6008128Z 
2026-01-14T08:22:11.6008132Z 
2026-01-14T08:22:11.6008135Z 
2026-01-14T08:22:11.6008370Z                                                                         [A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6008646Z 
2026-01-14T08:22:11.6008650Z 
2026-01-14T08:22:11.6008653Z 
2026-01-14T08:22:11.6008657Z 
2026-01-14T08:22:11.6008660Z 
2026-01-14T08:22:11.6008664Z 
2026-01-14T08:22:11.6008668Z 
2026-01-14T08:22:11.6008671Z 
2026-01-14T08:22:11.6008675Z 
2026-01-14T08:22:11.6008678Z 
2026-01-14T08:22:11.6008921Z                                                                         [A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6009210Z 
2026-01-14T08:22:11.6009220Z 
2026-01-14T08:22:11.6009223Z 
2026-01-14T08:22:11.6009227Z 
2026-01-14T08:22:11.6009230Z 
2026-01-14T08:22:11.6009234Z 
2026-01-14T08:22:11.6009237Z 
2026-01-14T08:22:11.6009241Z 
2026-01-14T08:22:11.6009244Z 
2026-01-14T08:22:11.6009248Z 
2026-01-14T08:22:11.6009257Z 
2026-01-14T08:22:11.6009509Z                                                                         [A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6009798Z 
2026-01-14T08:22:11.6009802Z 
2026-01-14T08:22:11.6009805Z 
2026-01-14T08:22:11.6009809Z 
2026-01-14T08:22:11.6009812Z 
2026-01-14T08:22:11.6009816Z 
2026-01-14T08:22:11.6009819Z 
2026-01-14T08:22:11.6009823Z 
2026-01-14T08:22:11.6009826Z 
2026-01-14T08:22:11.6009830Z 
2026-01-14T08:22:11.6009834Z 
2026-01-14T08:22:11.6009837Z 
2026-01-14T08:22:11.6010093Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6010391Z 
2026-01-14T08:22:11.6010395Z 
2026-01-14T08:22:11.6010398Z 
2026-01-14T08:22:11.6010406Z 
2026-01-14T08:22:11.6010410Z 
2026-01-14T08:22:11.6010413Z 
2026-01-14T08:22:11.6010417Z 
2026-01-14T08:22:11.6010420Z 
2026-01-14T08:22:11.6010424Z 
2026-01-14T08:22:11.6010427Z 
2026-01-14T08:22:11.6010431Z 
2026-01-14T08:22:11.6010434Z 
2026-01-14T08:22:11.6010442Z 
2026-01-14T08:22:11.6010758Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6011047Z 
2026-01-14T08:22:11.6011051Z 
2026-01-14T08:22:11.6011054Z 
2026-01-14T08:22:11.6011058Z 
2026-01-14T08:22:11.6011061Z 
2026-01-14T08:22:11.6011065Z 
2026-01-14T08:22:11.6011069Z 
2026-01-14T08:22:11.6011072Z 
2026-01-14T08:22:11.6011076Z 
2026-01-14T08:22:11.6011079Z 
2026-01-14T08:22:11.6011083Z 
2026-01-14T08:22:11.6011086Z 
2026-01-14T08:22:11.6011090Z 
2026-01-14T08:22:11.6011093Z 
2026-01-14T08:22:11.6011432Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6011814Z 
2026-01-14T08:22:11.6011818Z 
2026-01-14T08:22:11.6011822Z 
2026-01-14T08:22:11.6011825Z 
2026-01-14T08:22:11.6011829Z 
2026-01-14T08:22:11.6011832Z 
2026-01-14T08:22:11.6011836Z 
2026-01-14T08:22:11.6011839Z 
2026-01-14T08:22:11.6011843Z 
2026-01-14T08:22:11.6011853Z 
2026-01-14T08:22:11.6011928Z 
2026-01-14T08:22:11.6011931Z 
2026-01-14T08:22:11.6011935Z 
2026-01-14T08:22:11.6011938Z 
2026-01-14T08:22:11.6011942Z 
2026-01-14T08:22:11.6012220Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6012515Z 
2026-01-14T08:22:11.6012519Z 
2026-01-14T08:22:11.6012522Z 
2026-01-14T08:22:11.6012526Z 
2026-01-14T08:22:11.6012539Z 
2026-01-14T08:22:11.6012542Z 
2026-01-14T08:22:11.6012546Z 
2026-01-14T08:22:11.6012550Z 
2026-01-14T08:22:11.6012553Z 
2026-01-14T08:22:11.6012557Z 
2026-01-14T08:22:11.6012560Z 
2026-01-14T08:22:11.6012564Z 
2026-01-14T08:22:11.6012567Z 
2026-01-14T08:22:11.6012571Z 
2026-01-14T08:22:11.6012574Z 
2026-01-14T08:22:11.6012582Z 
2026-01-14T08:22:11.6012862Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6013170Z 
2026-01-14T08:22:11.6013174Z 
2026-01-14T08:22:11.6013177Z 
2026-01-14T08:22:11.6013185Z 
2026-01-14T08:22:11.6013189Z 
2026-01-14T08:22:11.6013192Z 
2026-01-14T08:22:11.6013196Z 
2026-01-14T08:22:11.6013200Z 
2026-01-14T08:22:11.6013203Z 
2026-01-14T08:22:11.6013207Z 
2026-01-14T08:22:11.6013210Z 
2026-01-14T08:22:11.6013214Z 
2026-01-14T08:22:11.6013217Z 
2026-01-14T08:22:11.6013221Z 
2026-01-14T08:22:11.6013224Z 
2026-01-14T08:22:11.6013228Z 
2026-01-14T08:22:11.6013231Z 
2026-01-14T08:22:11.6013526Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6013838Z 
2026-01-14T08:22:11.6013841Z 
2026-01-14T08:22:11.6013845Z 
2026-01-14T08:22:11.6013848Z 
2026-01-14T08:22:11.6013852Z 
2026-01-14T08:22:11.6013856Z 
2026-01-14T08:22:11.6013864Z 
2026-01-14T08:22:11.6013868Z 
2026-01-14T08:22:11.6013871Z 
2026-01-14T08:22:11.6013875Z 
2026-01-14T08:22:11.6013878Z 
2026-01-14T08:22:11.6013882Z 
2026-01-14T08:22:11.6013885Z 
2026-01-14T08:22:11.6013897Z 
2026-01-14T08:22:11.6013901Z 
2026-01-14T08:22:11.6013908Z 
2026-01-14T08:22:11.6013912Z 
2026-01-14T08:22:11.6013915Z 
2026-01-14T08:22:11.6014214Z                                                                         [A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A
2026-01-14T08:22:11.6014528Z 
2026-01-14T08:22:11.6014532Z 
2026-01-14T08:22:11.6014535Z 
2026-01-14T08:22:11.6014644Z [A
2026-01-14T08:22:11.6014749Z 
2026-01-14T08:22:11.6014753Z 
2026-01-14T08:22:11.6014854Z [A[A
2026-01-14T08:22:11.6014969Z 
2026-01-14T08:22:11.6015126Z Preparing transaction: \ | / done
2026-01-14T08:22:11.6015591Z Verifying transaction: \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:22:11.6016247Z Executing transaction: \ | / - \ | / - \ | / - \ | / - \ | / - \ | / done
2026-01-14T08:22:11.6016695Z #
2026-01-14T08:22:11.6016899Z # To activate this environment, use
2026-01-14T08:22:11.6017173Z #
2026-01-14T08:22:11.6017362Z #     $ conda activate venv
2026-01-14T08:22:11.6017604Z #
2026-01-14T08:22:11.6017819Z # To deactivate an active environment, use
2026-01-14T08:22:11.6018110Z #
2026-01-14T08:22:11.6018296Z #     $ conda deactivate
2026-01-14T08:22:11.6018461Z 
2026-01-14T08:22:11.6018551Z + conda activate venv
2026-01-14T08:22:11.6018777Z + local cmd=activate
2026-01-14T08:22:11.6019006Z + case "$cmd" in
2026-01-14T08:22:11.6019235Z + __conda_activate activate venv
2026-01-14T08:22:11.6019500Z + '[' -n '' ']'
2026-01-14T08:22:11.6019715Z + local ask_conda
2026-01-14T08:22:11.6019930Z ++ PS1='(base) '
2026-01-14T08:22:11.6020172Z ++ __conda_exe shell.posix activate venv
2026-01-14T08:22:11.6020509Z ++ /opt/conda/bin/conda shell.posix activate venv
2026-01-14T08:22:11.6020948Z + ask_conda='PS1='\''(venv) '\''
2026-01-14T08:22:11.6021945Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:11.6023072Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:11.6023417Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:11.6023701Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:11.6024034Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:11.6024372Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:11.6024715Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:11.6025016Z export _CE_M='\'''\''
2026-01-14T08:22:11.6025273Z export _CE_CONDA='\'''\''
2026-01-14T08:22:11.6025581Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:11.6025933Z + eval 'PS1='\''(venv) '\''
2026-01-14T08:22:11.6026896Z export PATH='\''/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
2026-01-14T08:22:11.6027926Z export CONDA_PREFIX='\''/opt/conda/envs/venv'\''
2026-01-14T08:22:11.6028278Z export CONDA_SHLVL='\''2'\''
2026-01-14T08:22:11.6028554Z export CONDA_DEFAULT_ENV='\''venv'\''
2026-01-14T08:22:11.6028881Z export CONDA_PROMPT_MODIFIER='\''(venv) '\''
2026-01-14T08:22:11.6029210Z export CONDA_PREFIX_1='\''/opt/conda'\''
2026-01-14T08:22:11.6029544Z export CONDA_EXE='\''/opt/conda/bin/conda'\''
2026-01-14T08:22:11.6029847Z export _CE_M='\'''\''
2026-01-14T08:22:11.6030096Z export _CE_CONDA='\'''\''
2026-01-14T08:22:11.6030398Z export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\'''
2026-01-14T08:22:11.6030731Z ++ PS1='(venv) '
2026-01-14T08:22:11.6031649Z ++ export PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:11.6033270Z ++ PATH=/opt/conda/envs/venv/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/cuda-12.6/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
2026-01-14T08:22:11.6034261Z ++ export CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:11.6034572Z ++ CONDA_PREFIX=/opt/conda/envs/venv
2026-01-14T08:22:11.6034868Z ++ export CONDA_SHLVL=2
2026-01-14T08:22:11.6035108Z ++ CONDA_SHLVL=2
2026-01-14T08:22:11.6035340Z ++ export CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:11.6035628Z ++ CONDA_DEFAULT_ENV=venv
2026-01-14T08:22:11.6035899Z ++ export 'CONDA_PROMPT_MODIFIER=(venv) '
2026-01-14T08:22:11.6036227Z ++ CONDA_PROMPT_MODIFIER='(venv) '
2026-01-14T08:22:11.6036524Z ++ export CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:11.6036814Z ++ CONDA_PREFIX_1=/opt/conda
2026-01-14T08:22:11.6037084Z ++ export CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:11.6037398Z ++ CONDA_EXE=/opt/conda/bin/conda
2026-01-14T08:22:11.6037661Z ++ export _CE_M=
2026-01-14T08:22:11.6037879Z ++ _CE_M=
2026-01-14T08:22:11.6038089Z ++ export _CE_CONDA=
2026-01-14T08:22:11.6038319Z ++ _CE_CONDA=
2026-01-14T08:22:11.6038587Z ++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:11.6038942Z ++ CONDA_PYTHON_EXE=/opt/conda/bin/python
2026-01-14T08:22:11.6039237Z + __conda_hashr
2026-01-14T08:22:11.6039446Z + '[' -n '' ']'
2026-01-14T08:22:11.6039655Z + '[' -n '' ']'
2026-01-14T08:22:11.6039856Z + hash -r
2026-01-14T08:22:11.6040094Z + python -m pip install --upgrade pip
2026-01-14T08:22:11.6040594Z Requirement already satisfied: pip in /opt/conda/envs/venv/lib/python3.10/site-packages (25.3)
2026-01-14T08:22:11.6042717Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:22:11.6044317Z [0m+ pip install torch==2.9.1
2026-01-14T08:22:11.6044586Z Collecting torch==2.9.1
2026-01-14T08:22:11.6044987Z   Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)
2026-01-14T08:22:11.6045558Z Collecting filelock (from torch==2.9.1)
2026-01-14T08:22:11.6045977Z   Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)
2026-01-14T08:22:11.6046461Z Collecting typing-extensions>=4.10.0 (from torch==2.9.1)
2026-01-14T08:22:11.6046965Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:22:11.6047447Z Collecting sympy>=1.13.3 (from torch==2.9.1)
2026-01-14T08:22:11.6047842Z   Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:22:11.6048267Z Collecting networkx>=2.5.1 (from torch==2.9.1)
2026-01-14T08:22:11.6048679Z   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:22:11.6049276Z Collecting jinja2 (from torch==2.9.1)
2026-01-14T08:22:11.6049669Z   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-01-14T08:22:11.6050075Z Collecting fsspec>=0.8.5 (from torch==2.9.1)
2026-01-14T08:22:11.6050493Z   Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:22:11.6050978Z Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.9.1)
2026-01-14T08:22:11.6051710Z   Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6052392Z Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.9.1)
2026-01-14T08:22:11.6053091Z   Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6053769Z Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.9.1)
2026-01-14T08:22:11.6054444Z   Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6055104Z Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.9.1)
2026-01-14T08:22:11.6055668Z   Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:11.6056259Z Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.9.1)
2026-01-14T08:22:11.6056809Z   Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6057378Z Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.9.1)
2026-01-14T08:22:11.6058025Z   Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6058671Z Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.9.1)
2026-01-14T08:22:11.6059237Z   Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:11.6059808Z Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.9.1)
2026-01-14T08:22:17.9251637Z   Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:17.9252278Z Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.9.1)
2026-01-14T08:22:17.9252965Z   Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:17.9253641Z Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.9.1)
2026-01-14T08:22:17.9254206Z   Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)
2026-01-14T08:22:17.9254746Z Collecting nvidia-nccl-cu12==2.27.5 (from torch==2.9.1)
2026-01-14T08:22:17.9255348Z   Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)
2026-01-14T08:22:17.9255977Z Collecting nvidia-nvshmem-cu12==3.3.20 (from torch==2.9.1)
2026-01-14T08:22:17.9256899Z   Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)
2026-01-14T08:22:17.9257533Z Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.9.1)
2026-01-14T08:22:17.9258130Z   Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)
2026-01-14T08:22:17.9258776Z Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.9.1)
2026-01-14T08:22:17.9259605Z   Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:17.9260264Z Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.9.1)
2026-01-14T08:22:17.9260895Z   Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:17.9261491Z Collecting triton==3.5.1 (from torch==2.9.1)
2026-01-14T08:22:17.9262027Z   Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)
2026-01-14T08:22:17.9262650Z Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.9.1)
2026-01-14T08:22:17.9263141Z   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
2026-01-14T08:22:17.9263588Z Collecting MarkupSafe>=2.0 (from jinja2->torch==2.9.1)
2026-01-14T08:22:17.9264275Z   Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
2026-01-14T08:22:17.9265032Z Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)
2026-01-14T08:22:17.9268718Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/899.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:17.9269658Z [2K   [91m━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m53.7/899.8 MB[0m [31m268.5 MB/s[0m eta [36m0:00:04[0m
2026-01-14T08:22:17.9270549Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m108.0/899.8 MB[0m [31m268.9 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:17.9271462Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m164.6/899.8 MB[0m [31m273.1 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:17.9272351Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m228.1/899.8 MB[0m [31m283.6 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:17.9273231Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m292.0/899.8 MB[0m [31m290.4 MB/s[0m eta [36m0:00:03[0m
2026-01-14T08:22:17.9274134Z [2K   [91m━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m359.7/899.8 MB[0m [31m309.0 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:17.9275006Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m412.6/899.8 MB[0m [31m311.5 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:17.9275893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m476.3/899.8 MB[0m [31m304.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:17.9276797Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m537.1/899.8 MB[0m [31m304.4 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:17.9277676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m605.6/899.8 MB[0m [31m303.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9278562Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m672.7/899.8 MB[0m [31m321.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9279460Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m725.9/899.8 MB[0m [31m312.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9280338Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m799.8/899.8 MB[0m [31m327.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9281222Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m871.9/899.8 MB[0m [31m330.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9282071Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9283118Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9283973Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9284932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9285764Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9286586Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9287400Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9288237Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9289047Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9289870Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9290712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9291590Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9292427Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9293394Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:17.9294220Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4939097Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4941474Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4943150Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4944695Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4945521Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4946382Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4947230Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4950680Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4951555Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4952396Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4953228Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4954085Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4954911Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4955746Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4956594Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4957430Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4958265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4959088Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m899.7/899.8 MB[0m [31m312.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4960078Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m899.8/899.8 MB[0m [31m35.0 MB/s[0m  [33m0:00:09[0m
2026-01-14T08:22:25.4960831Z [?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)
2026-01-14T08:22:25.4961579Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/594.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:25.4962546Z [2K   [91m━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m87.8/594.3 MB[0m [31m440.2 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:25.4963446Z [2K   [91m━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m178.0/594.3 MB[0m [31m443.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4964339Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m267.9/594.3 MB[0m [31m444.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4965249Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m357.6/594.3 MB[0m [31m447.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4966149Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m447.2/594.3 MB[0m [31m446.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4967055Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m537.7/594.3 MB[0m [31m447.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4967932Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4968774Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4969604Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4970427Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4971364Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4972188Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4973016Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4973848Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4974673Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4975495Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4976421Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:25.4977257Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6249969Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6251496Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6252342Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6253320Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6254298Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6255293Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6256140Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6257008Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m594.3/594.3 MB[0m [31m447.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6257803Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m594.3/594.3 MB[0m [31m56.4 MB/s[0m  [33m0:00:05[0m
2026-01-14T08:22:31.6258651Z [?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)
2026-01-14T08:22:31.6259520Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/10.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:31.6260429Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m10.2/10.2 MB[0m [31m213.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:31.6261268Z [?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)
2026-01-14T08:22:31.6262100Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/88.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:31.6262977Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6263815Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6264633Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6265469Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6266299Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6267119Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m87.8/88.0 MB[0m [31m445.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6267900Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m88.0/88.0 MB[0m [31m69.5 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:22:31.6268744Z [?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)
2026-01-14T08:22:31.6269593Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/954.8 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:31.6270343Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m954.8/954.8 kB[0m [31m61.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:31.6271072Z [?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)
2026-01-14T08:22:31.6271840Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/706.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:31.6272682Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.7/706.8 MB[0m [31m448.9 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:31.6273602Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m179.6/706.8 MB[0m [31m447.8 MB/s[0m eta [36m0:00:02[0m
2026-01-14T08:22:31.6274527Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m269.7/706.8 MB[0m [31m448.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6275422Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m360.4/706.8 MB[0m [31m449.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6276372Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m450.6/706.8 MB[0m [31m449.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6277373Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m535.6/706.8 MB[0m [31m440.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6278291Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m627.6/706.8 MB[0m [31m442.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6279171Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6280105Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6280942Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6281779Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6282601Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6283439Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6284259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:31.6285116Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9436871Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9437780Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9438617Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9439487Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9440322Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9441159Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9442017Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9442836Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9443672Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9444493Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9445778Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9446670Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9447652Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9448468Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9449579Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9450415Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9451344Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9452158Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m706.7/706.8 MB[0m [31m444.4 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9452950Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m706.8/706.8 MB[0m [31m44.8 MB/s[0m  [33m0:00:06[0m
2026-01-14T08:22:37.9453800Z [?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)
2026-01-14T08:22:37.9454620Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/193.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:37.9455430Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m88.3/193.1 MB[0m [31m442.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9456325Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m180.9/193.1 MB[0m [31m450.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9457257Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9458097Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9458938Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9459768Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9460596Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9461415Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9462400Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9463216Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m192.9/193.1 MB[0m [31m450.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9464011Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m193.1/193.1 MB[0m [31m91.7 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:22:37.9464997Z [?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)
2026-01-14T08:22:37.9465803Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:37.9466531Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m27.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:37.9467233Z [?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)
2026-01-14T08:22:37.9467991Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/63.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:37.9468931Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m437.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9469744Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m437.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9470586Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m63.4/63.6 MB[0m [31m437.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:37.9471357Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m63.6/63.6 MB[0m [31m85.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:22:45.1114568Z [?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)
2026-01-14T08:22:45.1115676Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/267.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:45.1117012Z [2K   [91m━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.1/267.5 MB[0m [31m447.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1117934Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m179.6/267.5 MB[0m [31m447.8 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1118855Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1119880Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1120704Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1121516Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1122360Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1123179Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1124009Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1124856Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1125706Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1126537Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1127376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m267.4/267.5 MB[0m [31m448.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1128186Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m267.5/267.5 MB[0m [31m96.0 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:22:45.1129028Z [?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)
2026-01-14T08:22:45.1129874Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/288.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:45.1130697Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m88.1/288.2 MB[0m [31m441.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1131682Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m146.5/288.2 MB[0m [31m365.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1132570Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m232.8/288.2 MB[0m [31m386.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1133537Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1134368Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1135202Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1136116Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1136942Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1137756Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1138641Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m288.1/288.2 MB[0m [31m393.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1139447Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m288.2/288.2 MB[0m [31m123.0 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:22:45.1140184Z [?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)
2026-01-14T08:22:45.1153883Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/287.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:45.1154867Z [2K   [91m━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m89.4/287.2 MB[0m [31m447.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1155768Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━[0m [32m179.6/287.2 MB[0m [31m447.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1156658Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m270.0/287.2 MB[0m [31m448.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1157519Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1158349Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1159157Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1159997Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1160815Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:45.1161625Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2541250Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2542676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2543564Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2544428Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2545451Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2546304Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2547136Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2547999Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m287.0/287.2 MB[0m [31m448.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2548794Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m287.2/287.2 MB[0m [31m74.2 MB/s[0m  [33m0:00:03[0m
2026-01-14T08:22:52.2550051Z [?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)
2026-01-14T08:22:52.2550902Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/322.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:52.2551732Z [2K   [91m━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m88.1/322.3 MB[0m [31m441.2 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2552629Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m175.6/322.3 MB[0m [31m437.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2553538Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m266.1/322.3 MB[0m [31m441.5 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2554420Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2555250Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2556073Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2556917Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2557748Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2558563Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2559547Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2560428Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2561249Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2562229Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2563063Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2563893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2564734Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2565598Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2566439Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2567283Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2568140Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2568980Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2569821Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2570804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2571698Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2572524Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m322.2/322.3 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:22:52.2573423Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m322.3/322.3 MB[0m [31m52.2 MB/s[0m  [33m0:00:05[0m
2026-01-14T08:22:52.2574287Z [?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)
2026-01-14T08:22:52.2575130Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/39.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:22:52.2575913Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m445.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0368542Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m445.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0369713Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m39.1/39.3 MB[0m [31m445.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0370754Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m39.3/39.3 MB[0m [31m56.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:01.0372036Z [?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)
2026-01-14T08:23:01.0373209Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/124.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:01.0374079Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m89.1/124.7 MB[0m [31m446.7 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0375064Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0375931Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0376752Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0377591Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0378431Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0379327Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0380199Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m124.5/124.7 MB[0m [31m446.0 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0381243Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m124.7/124.7 MB[0m [31m72.1 MB/s[0m  [33m0:00:01[0m
2026-01-14T08:23:01.0382070Z [?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
2026-01-14T08:23:01.0382804Z Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)
2026-01-14T08:23:01.0383749Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/170.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:01.0384563Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m40.9/170.3 MB[0m [31m204.3 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0385441Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m88.1/170.3 MB[0m [31m219.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0386334Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m147.8/170.3 MB[0m [31m245.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0387215Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0388061Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0388881Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0389729Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0390560Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0391375Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0392220Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0393043Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0393858Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0394700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m170.1/170.3 MB[0m [31m258.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0395482Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m170.3/170.3 MB[0m [31m62.2 MB/s[0m  [33m0:00:02[0m
2026-01-14T08:23:01.0396087Z [?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)
2026-01-14T08:23:01.0396514Z Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)
2026-01-14T08:23:01.0397111Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:01.0397938Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m14.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:01.0398504Z [?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
2026-01-14T08:23:01.0399112Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:01.0399975Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m6.3/6.3 MB[0m [31m414.9 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:23:01.0400731Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.3/6.3 MB[0m [31m29.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:01.0401321Z [?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)
2026-01-14T08:23:01.0401976Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/536.2 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:23:01.0402717Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m536.2/536.2 kB[0m [31m2.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:23:01.0403369Z [?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-01-14T08:23:01.0403828Z Downloading filelock-3.20.3-py3-none-any.whl (16 kB)
2026-01-14T08:23:01.0404202Z Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-01-14T08:23:01.0404851Z Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)
2026-01-14T08:23:08.6314751Z Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch
2026-01-14T08:23:08.6316782Z [?25l
2026-01-14T08:23:08.6317268Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6317952Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6318586Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6319236Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6319884Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6320506Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6321146Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6321784Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6322426Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6324176Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6324829Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6325463Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6326249Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6326887Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 0/25[0m [nvidia-cusparselt-cu12]
2026-01-14T08:23:08.6327520Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/25[0m [mpmath]
2026-01-14T08:23:08.6328167Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/25[0m [mpmath]
2026-01-14T08:23:08.6328810Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 1/25[0m [mpmath]
2026-01-14T08:23:08.6329509Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 2/25[0m [typing-extensions]
2026-01-14T08:23:08.6330187Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6330825Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6331567Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6332212Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6332838Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6333470Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6334095Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6334871Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6335508Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6336132Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6336880Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6337514Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6338148Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6338781Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6339408Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6340061Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 3/25[0m [triton]
2026-01-14T08:23:08.6340685Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6341315Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6341968Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6342591Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6343221Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6343843Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6344474Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6345127Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:08.6345754Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1012168Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1014094Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1015157Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1015787Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1016410Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1017037Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1017911Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1018550Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1019179Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1019963Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1020592Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1021217Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1021843Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1022474Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1023121Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1023750Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1024375Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1025029Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 4/25[0m [sympy]
2026-01-14T08:23:16.1025720Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 5/25[0m [nvidia-nvtx-cu12]
2026-01-14T08:23:16.1026452Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1027193Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1027923Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1028968Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1029708Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1030430Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1031255Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1031983Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 6/25[0m [nvidia-nvshmem-cu12]
2026-01-14T08:23:16.1032731Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/25[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:16.1033479Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/25[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:16.1034241Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 7/25[0m [nvidia-nvjitlink-cu12]
2026-01-14T08:23:16.1034968Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1035688Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1036407Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1037120Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1037823Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1038529Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1039254Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1039953Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1040659Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1041380Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1042086Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1042790Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1043490Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:16.1044194Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:23.3099727Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:23.3100757Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:23.3101600Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:23.3102912Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 8/25[0m [nvidia-nccl-cu12]
2026-01-14T08:23:23.3103706Z [2K   [91m━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 9/25[0m [nvidia-curand-cu12]
2026-01-14T08:23:23.3104459Z [2K   [91m━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 9/25[0m [nvidia-curand-cu12]
2026-01-14T08:23:23.3105198Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m10/25[0m [nvidia-cufile-cu12]
2026-01-14T08:23:23.3106008Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3106796Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3107565Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3108384Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3109137Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3109892Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m12/25[0m [nvidia-cuda-nvrtc-cu12]
2026-01-14T08:23:23.3110648Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m13/25[0m [nvidia-cuda-cupti-cu12]
2026-01-14T08:23:23.3111492Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3112221Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3112952Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3113853Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3114580Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3115305Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3116031Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3116760Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3117494Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3118215Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3118954Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3119672Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3120395Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3121113Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3121831Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3122574Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3123316Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3124047Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3124784Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3125507Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3126228Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3126963Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3127792Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3128514Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━[0m [32m14/25[0m [nvidia-cublas-cu12]
2026-01-14T08:23:23.3129202Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:23.3129943Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:23.3130611Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:23.3131366Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:23.3132013Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:30.5146181Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━[0m [32m15/25[0m [networkx]
2026-01-14T08:23:30.5148134Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m16/25[0m [MarkupSafe]
2026-01-14T08:23:30.5148829Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m17/25[0m [fsspec]
2026-01-14T08:23:30.5149749Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━[0m [32m18/25[0m [filelock]
2026-01-14T08:23:30.5150511Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5151274Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5152028Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5152786Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5153794Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5154550Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5155315Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5156224Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5156984Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5157742Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5158547Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5159292Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5160051Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5160797Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5161557Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5162299Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m19/25[0m [nvidia-cusparse-cu12]
2026-01-14T08:23:30.5163041Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5163754Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5164472Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5165206Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5165916Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5166635Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5167370Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5168096Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5168813Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m20/25[0m [nvidia-cufft-cu12]
2026-01-14T08:23:30.5169533Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5170354Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5171068Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5171861Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5172680Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5173392Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5174108Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5174820Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5175534Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5176265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5176975Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5177697Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5178421Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:30.5179139Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5598778Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5599859Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5600892Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5601626Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5602348Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5603271Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5603978Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5604707Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5605425Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5606167Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5606893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5607611Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5608358Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5609072Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5609827Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5610582Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5611389Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5612122Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5612836Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5613550Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5614286Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5614994Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5615719Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5616429Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5617253Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5617969Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━[0m [32m21/25[0m [nvidia-cudnn-cu12]
2026-01-14T08:23:37.5618698Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5619568Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5620352Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5621098Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5621847Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5622603Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5623344Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5624078Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5624834Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5625578Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5626317Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5627061Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5627800Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5628560Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5629301Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:37.5630129Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m23/25[0m [nvidia-cusolver-cu12]
2026-01-14T08:23:45.2694218Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2695140Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2695787Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2696418Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2697292Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2697924Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2698533Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2699177Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2699804Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2700415Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2701034Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2701655Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2702300Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2702924Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2703536Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2704173Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2704785Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2705407Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2706024Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2706634Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2707356Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2707970Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2708589Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2709367Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2709979Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2710587Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2711197Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2711824Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2712432Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2713065Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2713684Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2714292Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2714926Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2723662Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2724382Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2725012Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2725637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2726376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2726999Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2727607Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2728327Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2728947Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2729565Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2730177Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2730786Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:45.2731566Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1577842Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1579290Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1580590Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1581992Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1583478Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1584231Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1585090Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1585866Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1586494Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1587108Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1587751Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1588361Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1588987Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1589608Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1590217Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1591084Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1591707Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1592332Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1593117Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1593733Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1594358Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1594982Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1595618Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1596272Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1596887Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1597517Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1598154Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1598786Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1599408Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1600028Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1600676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1601393Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1602019Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1602650Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1603364Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1604001Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1604627Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1605259Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1605896Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1606532Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1607150Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1607763Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1608403Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1609015Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1609637Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:23:53.1610262Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7035007Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7036005Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7036755Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7037381Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7038050Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7038664Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7039293Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7039913Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7040537Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━[0m [32m24/25[0m [torch]
2026-01-14T08:24:04.7041410Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m25/25[0m [torch]
2026-01-14T08:24:04.7041790Z [?25h
2026-01-14T08:24:04.7044645Z [1A[2KSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.3 fsspec-2026.1.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 triton-3.5.1 typing-extensions-4.15.0
2026-01-14T08:24:04.7048903Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:24:04.7050694Z [0m+ sed -i '' dev-requirements.txt
2026-01-14T08:24:04.7050999Z + pip install -r dev-requirements.txt
2026-01-14T08:24:04.7051470Z Collecting pytest==8.4.2 (from -r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7051953Z   Downloading pytest-8.4.2-py3-none-any.whl.metadata (7.7 kB)
2026-01-14T08:24:04.7052475Z Collecting unittest-xml-reporting (from -r dev-requirements.txt (line 3))
2026-01-14T08:24:04.7053076Z   Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl.metadata (11 kB)
2026-01-14T08:24:04.7053632Z Collecting parameterized (from -r dev-requirements.txt (line 4))
2026-01-14T08:24:04.7054169Z   Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)
2026-01-14T08:24:04.7054682Z Collecting packaging (from -r dev-requirements.txt (line 5))
2026-01-14T08:24:04.7055159Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:24:04.7055644Z Collecting transformers (from -r dev-requirements.txt (line 6))
2026-01-14T08:24:04.7056146Z   Downloading transformers-4.57.5-py3-none-any.whl.metadata (43 kB)
2026-01-14T08:24:04.7056646Z Collecting hypothesis (from -r dev-requirements.txt (line 7))
2026-01-14T08:24:04.7057134Z   Downloading hypothesis-6.150.2-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:24:04.7057642Z Collecting sentencepiece (from -r dev-requirements.txt (line 8))
2026-01-14T08:24:04.7058297Z   Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
2026-01-14T08:24:04.7058954Z Collecting expecttest (from -r dev-requirements.txt (line 9))
2026-01-14T08:24:04.7059445Z   Downloading expecttest-0.3.0-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:24:04.7059921Z Collecting pyyaml (from -r dev-requirements.txt (line 10))
2026-01-14T08:24:04.7060752Z   Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
2026-01-14T08:24:04.7061456Z Collecting bitsandbytes (from -r dev-requirements.txt (line 13))
2026-01-14T08:24:04.7062012Z   Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)
2026-01-14T08:24:04.7062562Z Collecting matplotlib (from -r dev-requirements.txt (line 14))
2026-01-14T08:24:04.7063339Z   Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)
2026-01-14T08:24:04.7063973Z Collecting pandas (from -r dev-requirements.txt (line 15))
2026-01-14T08:24:04.7064572Z   Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
2026-01-14T08:24:04.7065169Z Collecting fire (from -r dev-requirements.txt (line 16))
2026-01-14T08:24:04.7065597Z   Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)
2026-01-14T08:24:04.7066048Z Collecting tabulate (from -r dev-requirements.txt (line 17))
2026-01-14T08:24:04.7066512Z   Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
2026-01-14T08:24:04.7066975Z Collecting tiktoken (from -r dev-requirements.txt (line 18))
2026-01-14T08:24:04.7067517Z   Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
2026-01-14T08:24:04.7068046Z Collecting blobfile (from -r dev-requirements.txt (line 19))
2026-01-14T08:24:04.7068512Z   Downloading blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
2026-01-14T08:24:04.7068960Z Collecting lm_eval (from -r dev-requirements.txt (line 20))
2026-01-14T08:24:04.7069418Z   Downloading lm_eval-0.4.9.2-py3-none-any.whl.metadata (53 kB)
2026-01-14T08:24:04.7069877Z Collecting diskcache (from -r dev-requirements.txt (line 22))
2026-01-14T08:24:04.7070350Z   Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)
2026-01-14T08:24:04.7070829Z Collecting pycocotools (from -r dev-requirements.txt (line 23))
2026-01-14T08:24:04.7071549Z   Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.3 kB)
2026-01-14T08:24:04.7072259Z Collecting tqdm (from -r dev-requirements.txt (line 24))
2026-01-14T08:24:04.7072687Z   Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2026-01-14T08:24:04.7073169Z Collecting importlib_metadata (from -r dev-requirements.txt (line 25))
2026-01-14T08:24:04.7073720Z   Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:24:04.7074223Z Collecting ninja (from -r dev-requirements.txt (line 28))
2026-01-14T08:24:04.7074800Z   Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
2026-01-14T08:24:04.7075429Z Collecting cmake<4.0.0,>=3.19.0 (from -r dev-requirements.txt (line 31))
2026-01-14T08:24:04.7076048Z   Downloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:24:04.7076694Z Collecting ruff==0.11.6 (from -r dev-requirements.txt (line 34))
2026-01-14T08:24:04.7077282Z   Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2026-01-14T08:24:04.7077874Z Collecting pre-commit (from -r dev-requirements.txt (line 35))
2026-01-14T08:24:04.7078366Z   Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)
2026-01-14T08:24:04.7078948Z Collecting exceptiongroup>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7079538Z   Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)
2026-01-14T08:24:04.7080087Z Collecting iniconfig>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7080611Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:04.7081133Z Collecting pluggy<2,>=1.5 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7081652Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-01-14T08:24:04.7082163Z Collecting pygments>=2.7.2 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7082699Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:04.7083286Z Collecting tomli>=1 (from pytest==8.4.2->-r dev-requirements.txt (line 2))
2026-01-14T08:24:04.7083783Z   Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:04.7084295Z Collecting lxml (from unittest-xml-reporting->-r dev-requirements.txt (line 3))
2026-01-14T08:24:04.7085045Z   Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-01-14T08:24:04.7086006Z Requirement already satisfied: filelock in /opt/conda/envs/venv/lib/python3.10/site-packages (from transformers->-r dev-requirements.txt (line 6)) (3.20.3)
2026-01-14T08:24:04.7086923Z Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:04.7087526Z   Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:24:04.7088059Z Collecting numpy>=1.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:04.7088709Z   Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
2026-01-14T08:24:04.7089367Z Collecting regex!=2019.12.17 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:04.7090114Z   Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
2026-01-14T08:24:04.7090860Z Collecting requests (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:10.5255259Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-01-14T08:24:10.5256946Z Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:10.5258287Z   Downloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-01-14T08:24:10.5258998Z Collecting safetensors>=0.4.3 (from transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:10.5259699Z   Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
2026-01-14T08:24:10.5260896Z Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (2026.1.0)
2026-01-14T08:24:10.5262362Z Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6)) (4.15.0)
2026-01-14T08:24:10.5263525Z Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:10.5264305Z   Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
2026-01-14T08:24:10.5265017Z Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis->-r dev-requirements.txt (line 7))
2026-01-14T08:24:10.5265664Z   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:10.5266568Z Requirement already satisfied: torch<3,>=2.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from bitsandbytes->-r dev-requirements.txt (line 13)) (2.9.1)
2026-01-14T08:24:10.5267810Z Requirement already satisfied: sympy>=1.13.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.14.0)
2026-01-14T08:24:10.5269098Z Requirement already satisfied: networkx>=2.5.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.4.2)
2026-01-14T08:24:10.5270455Z Requirement already satisfied: jinja2 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.1.6)
2026-01-14T08:24:10.5271778Z Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.93)
2026-01-14T08:24:10.5273419Z Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:10.5274846Z Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:10.5276423Z Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (9.10.2.21)
2026-01-14T08:24:10.5277870Z Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.4.1)
2026-01-14T08:24:10.5279265Z Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.3.3.83)
2026-01-14T08:24:10.5280659Z Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (10.3.9.90)
2026-01-14T08:24:10.5282077Z Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (11.7.3.90)
2026-01-14T08:24:10.5283499Z Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.5.8.93)
2026-01-14T08:24:10.5284909Z Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (0.7.1)
2026-01-14T08:24:10.5286285Z Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (2.27.5)
2026-01-14T08:24:10.5287647Z Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.3.20)
2026-01-14T08:24:10.5289037Z Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.90)
2026-01-14T08:24:10.5290414Z Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (12.8.93)
2026-01-14T08:24:10.5291907Z Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.13.1.3)
2026-01-14T08:24:10.5293240Z Requirement already satisfied: triton==3.5.1 in /opt/conda/envs/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.5.1)
2026-01-14T08:24:10.5294154Z Collecting contourpy>=1.0.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5294857Z   Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
2026-01-14T08:24:10.5295542Z Collecting cycler>=0.10 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5296050Z   Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
2026-01-14T08:24:10.5296582Z Collecting fonttools>=4.22.0 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5297286Z   Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)
2026-01-14T08:24:10.5298021Z Collecting kiwisolver>=1.3.1 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5298812Z   Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
2026-01-14T08:24:10.5299479Z Collecting pillow>=8 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5300133Z   Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
2026-01-14T08:24:10.5300874Z Collecting pyparsing>=3 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5301413Z   Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)
2026-01-14T08:24:10.5301973Z Collecting python-dateutil>=2.7 (from matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:10.5302607Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:24:10.5303190Z Collecting pytz>=2020.1 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:24:10.5303694Z   Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
2026-01-14T08:24:10.5304219Z Collecting tzdata>=2022.7 (from pandas->-r dev-requirements.txt (line 15))
2026-01-14T08:24:10.5304733Z   Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)
2026-01-14T08:24:10.5305246Z Collecting termcolor (from fire->-r dev-requirements.txt (line 16))
2026-01-14T08:24:10.5305742Z   Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)
2026-01-14T08:24:10.5306287Z Collecting pycryptodomex>=3.8 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:24:10.5307001Z   Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
2026-01-14T08:24:10.5307744Z Collecting urllib3<3,>=1.25.3 (from blobfile->-r dev-requirements.txt (line 19))
2026-01-14T08:24:10.5308274Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-01-14T08:24:10.5308781Z Collecting accelerate>=0.26.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5309323Z   Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:24:10.5309839Z Collecting evaluate (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5310332Z   Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
2026-01-14T08:24:10.5310860Z Collecting datasets>=2.16.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5311391Z   Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)
2026-01-14T08:24:10.5311902Z Collecting jsonlines (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5312420Z   Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)
2026-01-14T08:24:10.5312945Z Collecting numexpr (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5313603Z   Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)
2026-01-14T08:24:10.5314264Z Collecting peft>=0.2.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5314765Z   Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)
2026-01-14T08:24:10.5315273Z Collecting pybind11>=2.6.2 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5315810Z   Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)
2026-01-14T08:24:10.5316336Z Collecting pytablewriter (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:10.5316907Z   Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)
2026-01-14T08:24:24.0248399Z Collecting rouge-score>=0.0.4 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0249286Z   Downloading rouge_score-0.1.2.tar.gz (17 kB)
2026-01-14T08:24:24.0250064Z   Installing build dependencies ... [?25l- \ | / done
2026-01-14T08:24:24.0250575Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:24.0251113Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:24.0251771Z [?25hCollecting sacrebleu>=1.5.0 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0252318Z   Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:24:24.0253109Z Collecting scikit-learn>=0.24.1 (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0253821Z   Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
2026-01-14T08:24:24.0254505Z Collecting sqlitedict (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0255113Z   Downloading sqlitedict-2.1.0.tar.gz (21 kB)
2026-01-14T08:24:24.0255535Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:24:24.0256003Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:24.0256485Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:24.0257088Z [?25hCollecting tqdm-multiprocess (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0257703Z   Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)
2026-01-14T08:24:24.0258256Z Collecting zstandard (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0258934Z   Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)
2026-01-14T08:24:24.0259581Z Collecting dill (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0260053Z   Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:24.0260552Z Collecting word2number (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0261000Z   Downloading word2number-1.1.zip (9.7 kB)
2026-01-14T08:24:24.0261409Z   Installing build dependencies ... [?25l- \ done
2026-01-14T08:24:24.0261894Z [?25h  Getting requirements to build wheel ... [?25l- done
2026-01-14T08:24:24.0262382Z [?25h  Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:24:24.0262959Z [?25hCollecting more_itertools (from lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0263525Z   Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)
2026-01-14T08:24:24.0264088Z Collecting zipp>=3.20 (from importlib_metadata->-r dev-requirements.txt (line 25))
2026-01-14T08:24:24.0264619Z   Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
2026-01-14T08:24:24.0265120Z Collecting cfgv>=2.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:24.0265635Z   Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)
2026-01-14T08:24:24.0266176Z Collecting identify>=1.0.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:24.0266744Z   Downloading identify-2.6.16-py2.py3-none-any.whl.metadata (4.4 kB)
2026-01-14T08:24:24.0267285Z Collecting nodeenv>=0.11.1 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:24.0267832Z   Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)
2026-01-14T08:24:24.0268379Z Collecting virtualenv>=20.10.0 (from pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:24.0268943Z   Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)
2026-01-14T08:24:24.0269509Z Collecting psutil (from accelerate>=0.26.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0270315Z   Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)
2026-01-14T08:24:24.0271133Z Collecting pyarrow>=21.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0271770Z   Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
2026-01-14T08:24:24.0272394Z Collecting httpx<1.0.0 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0272947Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-01-14T08:24:24.0273484Z Collecting xxhash (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0274251Z   Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:24.0275152Z Collecting multiprocess<0.70.19 (from datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0275798Z   Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)
2026-01-14T08:24:24.0276464Z Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:24.0277113Z   Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:24.0277919Z Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0278857Z   Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
2026-01-14T08:24:24.0279672Z Collecting anyio (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0280249Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:24.0280837Z Collecting certifi (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0281467Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-01-14T08:24:24.0282069Z Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0282705Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-01-14T08:24:24.0283284Z Collecting idna (from httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0283856Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-01-14T08:24:24.0284486Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0285113Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-01-14T08:24:24.0285896Z Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0286762Z   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
2026-01-14T08:24:24.0287583Z Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0288368Z   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:24.0289183Z Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0290006Z   Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
2026-01-14T08:24:24.0290778Z Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0291596Z   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
2026-01-14T08:24:24.0292355Z Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0293361Z   Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
2026-01-14T08:24:24.0294367Z Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0295379Z   Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
2026-01-14T08:24:24.0296394Z Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0297400Z   Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
2026-01-14T08:24:24.0298477Z Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.16.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0299454Z   Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
2026-01-14T08:24:24.0300253Z Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->-r dev-requirements.txt (line 14))
2026-01-14T08:24:24.0300999Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-01-14T08:24:24.0301604Z Collecting charset_normalizer<4,>=2 (from requests->transformers->-r dev-requirements.txt (line 6))
2026-01-14T08:24:24.0302482Z   Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-01-14T08:24:24.0303321Z Collecting absl-py (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0303885Z   Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)
2026-01-14T08:24:24.0304433Z Collecting nltk (from rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0304987Z   Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)
2026-01-14T08:24:24.0305534Z Collecting portalocker (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0306137Z   Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)
2026-01-14T08:24:24.0306716Z Collecting colorama (from sacrebleu>=1.5.0->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0307306Z   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
2026-01-14T08:24:24.0307897Z Collecting scipy>=1.8.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:24.0308624Z   Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
2026-01-14T08:24:24.0309344Z Collecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4141289Z   Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)
2026-01-14T08:24:25.4142248Z Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4143128Z   Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
2026-01-14T08:24:25.4144094Z Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (1.3.0)
2026-01-14T08:24:25.4145151Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:25.4145759Z   Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)
2026-01-14T08:24:25.4146384Z Collecting platformdirs<5,>=3.9.1 (from virtualenv>=20.10.0->pre-commit->-r dev-requirements.txt (line 35))
2026-01-14T08:24:25.4147023Z   Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:25.4148011Z Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes->-r dev-requirements.txt (line 13)) (3.0.3)
2026-01-14T08:24:25.4149204Z Collecting click (from nltk->rouge-score>=0.0.4->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4149768Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-01-14T08:24:25.4150651Z Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/envs/venv/lib/python3.10/site-packages (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20)) (80.9.0)
2026-01-14T08:24:25.4151709Z Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4152323Z   Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)
2026-01-14T08:24:25.4152935Z Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4153545Z   Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)
2026-01-14T08:24:25.4154368Z Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4154986Z   Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)
2026-01-14T08:24:25.4155572Z Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4156291Z   Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)
2026-01-14T08:24:25.4156865Z Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4157451Z   Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)
2026-01-14T08:24:25.4158110Z Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4158762Z   Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)
2026-01-14T08:24:25.4159401Z Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval->-r dev-requirements.txt (line 20))
2026-01-14T08:24:25.4160055Z   Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
2026-01-14T08:24:25.4160487Z Downloading pytest-8.4.2-py3-none-any.whl (365 kB)
2026-01-14T08:24:25.4161013Z Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)
2026-01-14T08:24:25.4161839Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/11.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4162594Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m11.5/11.5 MB[0m [31m155.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4163347Z [?25hDownloading cmake-3.31.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)
2026-01-14T08:24:25.4164110Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/27.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4164839Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m27.8/27.8 MB[0m [31m181.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4165431Z [?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-01-14T08:24:25.4165900Z Downloading unittest_xml_reporting-4.0.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:25.4166407Z Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)
2026-01-14T08:24:25.4166850Z Downloading packaging-25.0-py3-none-any.whl (66 kB)
2026-01-14T08:24:25.4167285Z Downloading transformers-4.57.5-py3-none-any.whl (12.0 MB)
2026-01-14T08:24:25.4167913Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4168655Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.0/12.0 MB[0m [31m208.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4169281Z [?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
2026-01-14T08:24:25.4169937Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/566.1 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4170751Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m566.1/566.1 kB[0m [31m51.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4171592Z [?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:25.4172340Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4173069Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m175.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4173842Z [?25hDownloading tokenizers-0.22.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
2026-01-14T08:24:25.4174618Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/3.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4175333Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m3.3/3.3 MB[0m [31m181.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4175938Z [?25hDownloading hypothesis-6.150.2-py3-none-any.whl (542 kB)
2026-01-14T08:24:25.4176847Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/542.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4185414Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m542.7/542.7 kB[0m [31m40.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4186151Z [?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
2026-01-14T08:24:25.4187038Z Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
2026-01-14T08:24:25.4187849Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.4 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4188566Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.4/1.4 MB[0m [31m114.6 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4189207Z [?25hDownloading expecttest-0.3.0-py3-none-any.whl (8.2 kB)
2026-01-14T08:24:25.4189897Z Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
2026-01-14T08:24:25.4190847Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/770.3 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4191634Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m770.3/770.3 kB[0m [31m74.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4192378Z [?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)
2026-01-14T08:24:25.4193110Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/59.1 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:25.4193928Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m55.6/59.1 MB[0m [31m277.6 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:25.4194739Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m59.1/59.1 MB[0m [31m162.1 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:25.4195576Z [?25hDownloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
2026-01-14T08:24:25.4196463Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2715570Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.7/8.7 MB[0m [31m188.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2716695Z [?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
2026-01-14T08:24:26.2717644Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/12.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2718389Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.8/12.8 MB[0m [31m201.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2719005Z [?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)
2026-01-14T08:24:26.2719405Z Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)
2026-01-14T08:24:26.2719930Z Downloading tiktoken-0.12.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.2 MB)
2026-01-14T08:24:26.2720871Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2721619Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m102.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2722202Z [?25hDownloading blobfile-3.1.0-py3-none-any.whl (75 kB)
2026-01-14T08:24:26.2722599Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-01-14T08:24:26.2723137Z Downloading lm_eval-0.4.9.2-py3-none-any.whl (8.2 MB)
2026-01-14T08:24:26.2723747Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/8.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2724460Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8.2/8.2 MB[0m [31m171.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2725046Z [?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)
2026-01-14T08:24:26.2725715Z Downloading pycocotools-2.0.11-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (472 kB)
2026-01-14T08:24:26.2726366Z Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
2026-01-14T08:24:26.2726802Z Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)
2026-01-14T08:24:26.2727355Z Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
2026-01-14T08:24:26.2727919Z Downloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)
2026-01-14T08:24:26.2728352Z Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)
2026-01-14T08:24:26.2728818Z Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)
2026-01-14T08:24:26.2729369Z Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
2026-01-14T08:24:26.2729926Z Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
2026-01-14T08:24:26.2730317Z Downloading datasets-4.4.2-py3-none-any.whl (512 kB)
2026-01-14T08:24:26.2730692Z Downloading dill-0.4.0-py3-none-any.whl (119 kB)
2026-01-14T08:24:26.2731079Z Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)
2026-01-14T08:24:26.2731557Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-01-14T08:24:26.2731945Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-01-14T08:24:26.2732371Z Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)
2026-01-14T08:24:26.2733039Z Downloading aiohttp-3.13.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)
2026-01-14T08:24:26.2733895Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2734625Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.7/1.7 MB[0m [31m133.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2735233Z [?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
2026-01-14T08:24:26.2735898Z Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)
2026-01-14T08:24:26.2736756Z Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)
2026-01-14T08:24:26.2737409Z Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
2026-01-14T08:24:26.2737964Z Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:26.2738360Z Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
2026-01-14T08:24:26.2738736Z Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
2026-01-14T08:24:26.2739155Z Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)
2026-01-14T08:24:26.2739819Z Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)
2026-01-14T08:24:26.2740605Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/4.9 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2741327Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4.9/4.9 MB[0m [31m175.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2742187Z [?25hDownloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)
2026-01-14T08:24:26.2742820Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-01-14T08:24:26.2743226Z Downloading identify-2.6.16-py2.py3-none-any.whl (99 kB)
2026-01-14T08:24:26.2743622Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-01-14T08:24:26.2744001Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-01-14T08:24:26.2744563Z Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
2026-01-14T08:24:26.2745358Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2746080Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m126.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2746850Z [?25hDownloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
2026-01-14T08:24:26.2747606Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2748336Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.3/5.3 MB[0m [31m195.5 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2748968Z [?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)
2026-01-14T08:24:26.2749805Z Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
2026-01-14T08:24:26.2750590Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/16.8 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2751387Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16.8/16.8 MB[0m [31m205.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2751977Z [?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)
2026-01-14T08:24:26.2752582Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/557.0 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2753328Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m557.0/557.0 kB[0m [31m48.7 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2754119Z [?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
2026-01-14T08:24:26.2755057Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/7.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2755785Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m7.0/7.0 MB[0m [31m192.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2756669Z [?25hDownloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)
2026-01-14T08:24:26.2757537Z Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
2026-01-14T08:24:26.2758237Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/47.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:26.2759024Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m47.4/47.6 MB[0m [31m442.1 MB/s[0m eta [36m0:00:01[0m
2026-01-14T08:24:26.2759816Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m47.6/47.6 MB[0m [31m222.4 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:26.2760434Z [?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)
2026-01-14T08:24:26.2761015Z Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
2026-01-14T08:24:28.8094967Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/2.3 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8095964Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.3/2.3 MB[0m [31m136.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8096574Z [?25hDownloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-01-14T08:24:28.8097196Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.2 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8097923Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.2/1.2 MB[0m [31m104.3 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8098516Z [?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)
2026-01-14T08:24:28.8099002Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-01-14T08:24:28.8099500Z Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
2026-01-14T08:24:28.8100135Z Downloading regex-2025.11.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)
2026-01-14T08:24:28.8100989Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/791.7 kB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8101743Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m791.7/791.7 kB[0m [31m73.0 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8102344Z [?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-01-14T08:24:28.8103022Z Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
2026-01-14T08:24:28.8103712Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-01-14T08:24:28.8104127Z Downloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)
2026-01-14T08:24:28.8104671Z Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)
2026-01-14T08:24:28.8105681Z Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
2026-01-14T08:24:28.8106455Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/9.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8107198Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9.7/9.7 MB[0m [31m199.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8107935Z [?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)
2026-01-14T08:24:28.8108469Z Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
2026-01-14T08:24:28.8109231Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/37.7 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8109960Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m37.7/37.7 MB[0m [31m225.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8110548Z [?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-01-14T08:24:28.8110992Z Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
2026-01-14T08:24:28.8111387Z Downloading tomli-2.4.0-py3-none-any.whl (14 kB)
2026-01-14T08:24:28.8111778Z Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)
2026-01-14T08:24:28.8112188Z Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)
2026-01-14T08:24:28.8112806Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/6.0 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8113516Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m6.0/6.0 MB[0m [31m191.9 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8114121Z [?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)
2026-01-14T08:24:28.8114563Z Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)
2026-01-14T08:24:28.8114947Z Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
2026-01-14T08:24:28.8115314Z Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)
2026-01-14T08:24:28.8115683Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-01-14T08:24:28.8116088Z Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
2026-01-14T08:24:28.8116486Z Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)
2026-01-14T08:24:28.8116905Z Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)
2026-01-14T08:24:28.8117304Z Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)
2026-01-14T08:24:28.8117896Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/1.5 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8118620Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.5/1.5 MB[0m [31m129.2 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8119183Z [?25hDownloading click-8.3.1-py3-none-any.whl (108 kB)
2026-01-14T08:24:28.8119722Z Downloading numexpr-2.14.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (440 kB)
2026-01-14T08:24:28.8120280Z Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)
2026-01-14T08:24:28.8120903Z Downloading psutil-7.2.1-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (154 kB)
2026-01-14T08:24:28.8121608Z Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)
2026-01-14T08:24:28.8122030Z Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)
2026-01-14T08:24:28.8122451Z Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)
2026-01-14T08:24:28.8122845Z Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
2026-01-14T08:24:28.8123256Z Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)
2026-01-14T08:24:28.8123655Z Downloading tabledata-1.3.4-py3-none-any.whl (11 kB)
2026-01-14T08:24:28.8124050Z Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)
2026-01-14T08:24:28.8124428Z Downloading typepy-1.3.4-py3-none-any.whl (31 kB)
2026-01-14T08:24:28.8124810Z Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)
2026-01-14T08:24:28.8125248Z Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)
2026-01-14T08:24:28.8125899Z Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
2026-01-14T08:24:28.8126781Z Downloading zstandard-0.25.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)
2026-01-14T08:24:28.8127558Z [?25l   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m0.0/5.6 MB[0m [31m?[0m eta [36m-:--:--[0m
2026-01-14T08:24:28.8128269Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5.6/5.6 MB[0m [31m194.8 MB/s[0m  [33m0:00:00[0m
2026-01-14T08:24:28.8129026Z [?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number
2026-01-14T08:24:28.8129640Z   Building wheel for rouge-score (pyproject.toml) ... [?25l- done
2026-01-14T08:24:28.8130645Z [?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=4ef61e42e65b1654e0df3bc9aa9bf33c066a41bba940aec054530e5cb149f4ba
2026-01-14T08:24:28.8131795Z   Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4
2026-01-14T08:24:28.8132495Z   Building wheel for sqlitedict (pyproject.toml) ... [?25l- done
2026-01-14T08:24:28.8133485Z [?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16957 sha256=ef12c320d3763f22a2559fb246af783e3b3d039da70a659a94dd19fc4023b8bb
2026-01-14T08:24:28.8134467Z   Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd
2026-01-14T08:24:28.8135175Z   Building wheel for word2number (pyproject.toml) ... [?25l- done
2026-01-14T08:24:28.8136142Z [?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5659 sha256=acd2f85868008e99c468a4091e8a03e1a99e524b5e16a892350980a6ae5a6a45
2026-01-14T08:24:28.8137139Z   Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b
2026-01-14T08:24:28.8137745Z Successfully built rouge-score sqlitedict word2number
2026-01-14T08:24:35.5359710Z Installing collected packages: word2number, sqlitedict, sortedcontainers, pytz, distlib, zstandard, zipp, xxhash, urllib3, tzdata, tqdm, tomli, threadpoolctl, termcolor, tcolorpy, tabulate, six, sentencepiece, safetensors, ruff, regex, pyyaml, pyparsing, pygments, pycryptodomex, pybind11, pyarrow, psutil, propcache, portalocker, pluggy, platformdirs, pillow, pathvalidate, parameterized, packaging, numpy, nodeenv, ninja, multidict, more_itertools, lxml, kiwisolver, joblib, iniconfig, idna, identify, hf-xet, h11, fsspec, frozenlist, fonttools, expecttest, exceptiongroup, diskcache, dill, cycler, colorama, cmake, click, charset_normalizer, chardet, cfgv, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, virtualenv, unittest-xml-reporting, tqdm-multiprocess, scipy, sacrebleu, requests, python-dateutil, pytest, pycocotools, numexpr, nltk, multiprocess, mbstrdecoder, jsonlines, importlib_metadata, hypothesis, httpcore, fire, contourpy, blobfile, anyio, aiosignal, typepy, tiktoken, scikit-learn, rouge-score, pre-commit, pandas, matplotlib, huggingface-hub, httpx, aiohttp, tokenizers, bitsandbytes, accelerate, transformers, datasets, DataProperty, tabledata, peft, evaluate, pytablewriter, lm_eval
2026-01-14T08:24:35.5364928Z [?25l
2026-01-14T08:24:35.5365341Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  0/112[0m [word2number]
2026-01-14T08:24:35.5366011Z [2K   [91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  2/112[0m [sortedcontainers]
2026-01-14T08:24:35.5366851Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  3/112[0m [pytz]
2026-01-14T08:24:35.5367504Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  3/112[0m [pytz]
2026-01-14T08:24:35.5368149Z [2K   [91m━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  4/112[0m [distlib]
2026-01-14T08:24:35.5368813Z [2K   [91m━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  5/112[0m [zstandard]
2026-01-14T08:24:35.5369461Z [2K   [91m━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  6/112[0m [zipp]
2026-01-14T08:24:35.5370134Z [2K   [91m━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  8/112[0m [urllib3]
2026-01-14T08:24:35.5370794Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  9/112[0m [tzdata]
2026-01-14T08:24:35.5371538Z [2K   [91m━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m  9/112[0m [tzdata]
2026-01-14T08:24:35.5372208Z [2K   [91m━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 10/112[0m [tqdm]
2026-01-14T08:24:35.5372870Z [2K   [91m━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 11/112[0m [tomli]
2026-01-14T08:24:35.5373550Z [2K   [91m━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 13/112[0m [termcolor]
2026-01-14T08:24:35.5374216Z [2K   [91m━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 15/112[0m [tabulate]
2026-01-14T08:24:35.5374894Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 17/112[0m [sentencepiece]
2026-01-14T08:24:35.5375619Z [2K   [91m━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 18/112[0m [safetensors]
2026-01-14T08:24:35.5376279Z [2K   [91m━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 20/112[0m [regex]
2026-01-14T08:24:35.5376948Z [2K   [91m━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 22/112[0m [pyparsing]
2026-01-14T08:24:35.5377642Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:35.5378319Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:35.5378981Z [2K   [91m━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 23/112[0m [pygments]
2026-01-14T08:24:35.5379669Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:35.5380480Z [2K   [91m━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 24/112[0m [pycryptodomex]
2026-01-14T08:24:35.5381158Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5381819Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5382571Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5383281Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5383933Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5384599Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5385258Z [2K   [91m━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 26/112[0m [pyarrow]
2026-01-14T08:24:35.5385925Z [2K   [91m━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 27/112[0m [psutil]
2026-01-14T08:24:35.5386583Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:24:35.5387232Z [2K   [91m━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 32/112[0m [pillow]
2026-01-14T08:24:35.5387899Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:35.5388555Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:35.5389197Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:35.5389851Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:35.5390485Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3347519Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3348905Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3350503Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3352094Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3353377Z [2K   [91m━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 36/112[0m [numpy]
2026-01-14T08:24:42.3354519Z [2K   [91m━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 41/112[0m [lxml]
2026-01-14T08:24:42.3355174Z [2K   [91m━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 43/112[0m [joblib]
2026-01-14T08:24:42.3355831Z [2K   [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:42.3356299Z [2K  Attempting uninstall: fsspec
2026-01-14T08:24:42.3356823Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:42.3357331Z [2K    Found existing installation: fsspec 2026.1.0
2026-01-14T08:24:42.3357873Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:42.3358360Z [2K    Uninstalling fsspec-2026.1.0:
2026-01-14T08:24:42.3358864Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:42.3359364Z [2K      Successfully uninstalled fsspec-2026.1.0
2026-01-14T08:24:42.3359893Z    [91m━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━━━[0m [32m 45/112[0m [idna]
2026-01-14T08:24:42.3360542Z [2K   [91m━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━━━[0m [32m 49/112[0m [fsspec]
2026-01-14T08:24:42.3361215Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:42.3361916Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:42.3362589Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:42.3363256Z [2K   [91m━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━━━━[0m [32m 51/112[0m [fonttools]
2026-01-14T08:24:42.3363926Z [2K   [91m━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━━[0m [32m 55/112[0m [dill]
2026-01-14T08:24:42.3364555Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3365245Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3365882Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3366521Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3367364Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3367998Z [2K   [91m━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━━[0m [32m 58/112[0m [cmake]
2026-01-14T08:24:42.3368635Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 59/112[0m [click]
2026-01-14T08:24:42.3369375Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━━━━[0m [32m 61/112[0m [chardet]
2026-01-14T08:24:42.3370044Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━━[0m [32m 69/112[0m [virtualenv]
2026-01-14T08:24:42.3370698Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3371423Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3372057Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3372712Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3373351Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3373984Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3374698Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3375345Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3375978Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3376630Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3377263Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3377910Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3378548Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3379180Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3379916Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3380558Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:42.3381181Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:49.7788237Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:49.7789173Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━━━[0m [32m 72/112[0m [scipy]
2026-01-14T08:24:49.7790307Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━━[0m [32m 76/112[0m [pytest]
2026-01-14T08:24:49.7790998Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━━━[0m [32m 77/112[0m [pycocotools]
2026-01-14T08:24:49.7791657Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:49.7792308Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:49.7792941Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:49.7793566Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━━━[0m [32m 79/112[0m [nltk]
2026-01-14T08:24:49.7794248Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━━[0m [32m 83/112[0m [importlib_metadata]
2026-01-14T08:24:49.7794979Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━━━[0m [32m 84/112[0m [hypothesis]
2026-01-14T08:24:49.7795620Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━━━━━[0m [32m 86/112[0m [fire]
2026-01-14T08:24:49.7796265Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━━[0m [32m 90/112[0m [aiosignal]
2026-01-14T08:24:49.7796958Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7797638Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7798323Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7799000Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7799700Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7800493Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7801169Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7801856Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7802697Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7803376Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━━[0m [32m 93/112[0m [scikit-learn]
2026-01-14T08:24:49.7804037Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7804671Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7805315Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7805969Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7806648Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7807287Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7807936Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7808574Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7809205Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7809839Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7810467Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7811106Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7811832Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7812571Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7813202Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7813836Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7814463Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7815098Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7815816Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7816507Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7817138Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━━[0m [32m 96/112[0m [pandas]
2026-01-14T08:24:49.7817803Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0733955Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0734691Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0735368Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0736039Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0736753Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━━[0m [32m 97/112[0m [matplotlib]
2026-01-14T08:24:57.0737450Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:24:57.0738177Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━━[0m [32m 98/112[0m [huggingface-hub]
2026-01-14T08:24:57.0738893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━━[0m [32m100/112[0m [aiohttp]
2026-01-14T08:24:57.0739560Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m101/112[0m [tokenizers]
2026-01-14T08:24:57.0740243Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:57.0740930Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:57.0741621Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:57.0742702Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━━[0m [32m102/112[0m [bitsandbytes]
2026-01-14T08:24:57.0743384Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m103/112[0m [accelerate]
2026-01-14T08:24:57.0744058Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━━[0m [32m103/112[0m [accelerate]
2026-01-14T08:24:57.0744898Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0745587Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0746274Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0746953Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0747670Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0748354Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0749217Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0749928Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0750611Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0751295Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0751979Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0752658Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0753362Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0754043Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0754737Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0755567Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0756246Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0756930Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0757612Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0758436Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0759132Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0759810Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0760506Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0761179Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0761862Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0762549Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0763230Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:24:57.0763935Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4265234Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4267412Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4268310Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4269118Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4269926Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4270723Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[90m╺[0m[90m━━[0m [32m104/112[0m [transformers]
2026-01-14T08:32:09.4271747Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:32:09.4272424Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━━[0m [32m105/112[0m [datasets]
2026-01-14T08:32:09.4273071Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m108/112[0m [peft]
2026-01-14T08:32:09.4273912Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m[90m━[0m [32m108/112[0m [peft]
2026-01-14T08:32:09.4274524Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4275121Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4275718Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4276304Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4276893Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4277499Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4278088Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4278676Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4279277Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4279868Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4280451Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4281038Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4281624Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4282306Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4282890Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4283473Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4284145Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4284726Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4285300Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4285876Z [2K   [91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m[91m╸[0m [32m111/112[0m [lm_eval]
2026-01-14T08:32:09.4286434Z [2K   [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m112/112[0m [lm_eval]
2026-01-14T08:32:09.4286815Z [?25h
2026-01-14T08:32:09.4294896Z [1A[2KSuccessfully installed DataProperty-1.1.0 absl-py-2.3.1 accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 async-timeout-5.0.1 attrs-25.4.0 bitsandbytes-0.49.1 blobfile-3.1.0 certifi-2026.1.4 cfgv-3.5.0 chardet-5.2.0 charset_normalizer-3.4.4 click-8.3.1 cmake-3.31.10 colorama-0.4.6 contourpy-1.3.2 cycler-0.12.1 datasets-4.4.2 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 evaluate-0.4.6 exceptiongroup-1.3.1 expecttest-0.3.0 fire-0.7.1 fonttools-4.61.1 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hypothesis-6.150.2 identify-2.6.16 idna-3.11 importlib_metadata-8.7.1 iniconfig-2.3.0 joblib-1.5.3 jsonlines-4.0.0 kiwisolver-1.4.9 lm_eval-0.4.9.2 lxml-6.0.2 matplotlib-3.10.8 mbstrdecoder-1.1.4 more_itertools-10.8.0 multidict-6.7.0 multiprocess-0.70.18 ninja-1.13.0 nltk-3.9.2 nodeenv-1.10.0 numexpr-2.14.1 numpy-2.2.6 packaging-25.0 pandas-2.3.3 parameterized-0.9.0 pathvalidate-3.3.1 peft-0.18.1 pillow-12.1.0 platformdirs-4.5.1 pluggy-1.6.0 portalocker-3.2.0 pre-commit-4.5.1 propcache-0.4.1 psutil-7.2.1 pyarrow-22.0.0 pybind11-3.0.1 pycocotools-2.0.11 pycryptodomex-3.23.0 pygments-2.19.2 pyparsing-3.3.1 pytablewriter-1.2.1 pytest-8.4.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 rouge-score-0.1.2 ruff-0.11.6 sacrebleu-2.6.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.15.3 sentencepiece-0.2.1 six-1.17.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 termcolor-3.3.0 threadpoolctl-3.6.0 tiktoken-0.12.0 tokenizers-0.22.2 tomli-2.4.0 tqdm-4.67.1 tqdm-multiprocess-0.0.11 transformers-4.57.5 typepy-1.3.4 tzdata-2025.3 unittest-xml-reporting-4.0.0 urllib3-2.6.3 virtualenv-20.36.1 word2number-1.1 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0 zstandard-0.25.0
2026-01-14T08:32:09.4303398Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:09.4305047Z [0m+ pip install . --no-build-isolation
2026-01-14T08:32:09.4305348Z Processing /pytorch/ao
2026-01-14T08:32:09.4305707Z   Preparing metadata (pyproject.toml) ... [?25l- done
2026-01-14T08:32:09.4306156Z [?25hBuilding wheels for collected packages: torchao
2026-01-14T08:32:09.4306834Z   Building wheel for torchao (pyproject.toml) ... [?25l- \ | / - \ | / - \ | / - \ | / - \ | done
2026-01-14T08:32:09.4308062Z [?25h  Created wheel for torchao: filename=torchao-0.16.0+gitb34f898-cp310-abi3-linux_x86_64.whl size=4852453 sha256=3e7e067acf51d9d9560c6f119bf16d473db69f233a401e69808f35d56862642a
2026-01-14T08:32:25.7506182Z   Stored in directory: /tmp/pip-ephem-wheel-cache-129gqlo4/wheels/d2/8b/29/aa26bc7679794c5ecae292c3b064b585980cbedb836e694414
2026-01-14T08:32:25.7507992Z Successfully built torchao
2026-01-14T08:32:25.7508524Z Installing collected packages: torchao
2026-01-14T08:32:25.7508858Z Successfully installed torchao-0.16.0+gitb34f898
2026-01-14T08:32:25.7510869Z [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.[0m[33m
2026-01-14T08:32:25.7512599Z [0m++++ which conda
2026-01-14T08:32:25.7512837Z +++ dirname /opt/conda/condabin/conda
2026-01-14T08:32:25.7513135Z ++ dirname /opt/conda/condabin
2026-01-14T08:32:25.7513400Z + export CONDA=/opt/conda
2026-01-14T08:32:25.7513630Z + CONDA=/opt/conda
2026-01-14T08:32:25.7514118Z + export LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:25.7514911Z + LD_LIBRARY_PATH=/opt/conda/lib/:/opt/rh/gcc-toolset-13/root/usr/lib64:/opt/rh/gcc-toolset-13/root/usr/lib:
2026-01-14T08:32:25.7515451Z + pytest test --verbose -s
2026-01-14T08:32:25.7515850Z [1m============================= test session starts ==============================[0m
2026-01-14T08:32:25.7516435Z platform linux -- Python 3.10.19, pytest-8.4.2, pluggy-1.6.0 -- /opt/conda/envs/venv/bin/python3.10
2026-01-14T08:32:25.7516926Z cachedir: .pytest_cache
2026-01-14T08:32:25.7517524Z hypothesis profile 'ci' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=(HealthCheck.too_slow,)
2026-01-14T08:32:25.7518165Z rootdir: /pytorch/ao
2026-01-14T08:32:25.7518396Z configfile: pyproject.toml
2026-01-14T08:32:25.7518670Z plugins: hypothesis-6.150.2, anyio-4.12.1
2026-01-14T08:32:25.7519003Z [1mcollecting ... [0m[1m
2026-01-14T08:32:25.7519420Z collecting 0 items                                                             [0m[1m
2026-01-14T08:32:25.7519974Z collecting 28 items                                                            [0m[1m
2026-01-14T08:32:25.7520522Z collecting 177 items                                                           [0m[1m
2026-01-14T08:32:25.7521101Z collecting 872 items / 3 skipped                                               [0m[1m
2026-01-14T08:32:25.7521699Z collecting 927 items / 5 skipped                                               [0m[1m
2026-01-14T08:32:25.7522307Z collecting 4003 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:25.7522905Z collecting 5650 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:25.7523511Z collecting 7568 items / 17 skipped                                             [0m[1m
2026-01-14T08:32:25.7524115Z collected 8953 items / 17 skipped                                              [0m
2026-01-14T08:32:25.7524430Z 
2026-01-14T08:32:25.7524826Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config0] [32mPASSED[0m
2026-01-14T08:32:25.7525573Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config1] [32mPASSED[0m
2026-01-14T08:32:25.7526304Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config2] [32mPASSED[0m
2026-01-14T08:32:25.7527039Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config3] [32mPASSED[0m
2026-01-14T08:32:25.7527775Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config4] [32mPASSED[0m
2026-01-14T08:32:25.7528507Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config5] [32mPASSED[0m
2026-01-14T08:32:25.7529244Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config6] [32mPASSED[0m
2026-01-14T08:32:25.7529968Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7] [32mPASSED[0m
2026-01-14T08:32:25.7530701Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config8] [32mPASSED[0m
2026-01-14T08:32:25.7531652Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config9] [32mPASSED[0m
2026-01-14T08:32:25.7532393Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config10] [32mPASSED[0m
2026-01-14T08:32:25.7533140Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config11] [32mPASSED[0m
2026-01-14T08:32:25.7533957Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config12] [32mPASSED[0m
2026-01-14T08:32:25.7534701Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config13] [32mPASSED[0m
2026-01-14T08:32:25.7535449Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14] [32mPASSED[0m
2026-01-14T08:32:25.7536184Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config15] [32mPASSED[0m
2026-01-14T08:32:25.7536922Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config16] [32mPASSED[0m
2026-01-14T08:32:25.7537664Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config17] [32mPASSED[0m
2026-01-14T08:32:25.7538405Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config18] [32mPASSED[0m
2026-01-14T08:32:25.7539187Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config19] [32mPASSED[0m
2026-01-14T08:32:25.7539949Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config20] [32mPASSED[0m
2026-01-14T08:32:25.7540693Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config21] [32mPASSED[0m
2026-01-14T08:32:25.7541419Z test/core/test_config.py::test_granularity_serialization[granularity0] [33mSKIPPED[0m
2026-01-14T08:32:25.7542115Z test/core/test_config.py::test_granularity_serialization[granularity1] [33mSKIPPED[0m
2026-01-14T08:32:25.7542813Z test/core/test_config.py::test_granularity_serialization[granularity2] [33mSKIPPED[0m
2026-01-14T08:32:25.7543427Z test/core/test_config.py::test_disallowed_modules [32mPASSED[0m
2026-01-14T08:32:25.7543956Z test/core/test_config.py::test_version_mismatch [32mPASSED[0m
2026-01-14T08:32:25.7544462Z test/core/test_config.py::test_default_version [32mPASSED[0m
2026-01-14T08:32:25.7545216Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:25.7548372Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:25.7549551Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:25.7550514Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:25.7551459Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_copy__mismatch_metadata_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:25.7552363Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module [32mPASSED[0m
2026-01-14T08:32:25.7553213Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_register_new_dispatch [32mPASSED[0m
2026-01-14T08:32:25.7554077Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_tensor_core_layout_transpose [32mPASSED[0m
2026-01-14T08:32:25.7554973Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:25.7555869Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:25.7556763Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:25.7557658Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:25.7558547Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_test_copy__apply_apply_quant4 [32mPASSED[0m
2026-01-14T08:32:25.7559650Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_affine_quantized_intx_static [32mPASSED[0m
2026-01-14T08:32:25.7560527Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant0 [32mPASSED[0m
2026-01-14T08:32:25.7561366Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant1 [32mPASSED[0m
2026-01-14T08:32:25.7562318Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant2 [32mPASSED[0m
2026-01-14T08:32:25.7563142Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_to_device_apply_quant3 [32mPASSED[0m
2026-01-14T08:32:25.7563934Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only [32mPASSED[0m
2026-01-14T08:32:25.7564770Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7565688Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_alias_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7566672Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7567685Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7568666Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_matmul_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7569573Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_mm_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7570523Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_and_copy_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7571556Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T08:32:25.7572488Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_gemlite_cuda_float16 [33mSKIPPED[0m
2026-01-14T08:32:25.7573421Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_slice_int4wo_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:32:25.7574518Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_bfloat16 [32mPASSED[0m
2026-01-14T08:32:34.8464053Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e4m3fn_float32 [32mPASSED[0m
2026-01-14T08:32:34.8465438Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_bfloat16 [32mPASSED[0m
2026-01-14T08:32:34.8466660Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_choose_scale_float8_bounds_float8_e5m2_float32 [32mPASSED[0m
2026-01-14T08:32:34.8467947Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:34.8469488Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:34.8471157Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:34.8472825Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:34.8474483Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:34.8476130Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:34.8478063Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:34.8479384Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e4m3fn_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:34.8480833Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size0 [32mPASSED[0m
2026-01-14T08:32:34.8482182Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size1 [32mPASSED[0m
2026-01-14T08:32:34.8483482Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size2 [32mPASSED[0m
2026-01-14T08:32:34.8484776Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_bfloat16_block_size3 [32mPASSED[0m
2026-01-14T08:32:34.8486088Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size0 [32mPASSED[0m
2026-01-14T08:32:34.8487385Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size1 [32mPASSED[0m
2026-01-14T08:32:34.8488680Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size2 [32mPASSED[0m
2026-01-14T08:32:34.8490001Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_float8_e5m2_float32_block_size3 [32mPASSED[0m
2026-01-14T08:32:34.8491358Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_dequantize_affine_float8_scale_broadcasting [32mPASSED[0m
2026-01-14T08:32:34.8492559Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity0 [33mSKIPPED[0m
2026-01-14T08:32:34.8493712Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_expected_kernels_on_gpu_granularity1 [33mSKIPPED[0m
2026-01-14T08:32:34.8495027Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8496497Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8497951Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8499397Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8500855Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8502300Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8503739Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8505182Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_bfloat16_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8506623Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8508147Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8509602Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8511171Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_False_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8512602Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8514037Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8515468Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T08:32:34.8516896Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_fp8_linear_variants_float32_mode_static_compile_True_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T08:32:34.8518111Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_invalid_granularity [32mPASSED[0m
2026-01-14T08:32:34.8519125Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_mismatched_granularity [32mPASSED[0m
2026-01-14T08:32:34.8520152Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_per_row_with_float32 [33mSKIPPED[0m
2026-01-14T08:32:34.8521201Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_preprocess_scale_3d_reshape [32mPASSED[0m
2026-01-14T08:32:34.8522347Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:32:34.8523179Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:32:34.8523560Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:32:34.8524080Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:32:34.8524532Z graph_break []
2026-01-14T08:32:34.8524766Z [32mPASSED[0m
2026-01-14T08:32:34.8525488Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e4m3fn_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:32:34.8526310Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:32:34.8526792Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:32:34.8527308Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:32:34.8527642Z graph_break []
2026-01-14T08:32:34.8527864Z [32mPASSED[0m
2026-01-14T08:32:34.8528580Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_bfloat16 frames [('total', 2), ('ok', 2)]
2026-01-14T08:32:34.8529405Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:32:34.8529876Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:32:34.8530394Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:32:34.8530716Z graph_break []
2026-01-14T08:32:34.8530960Z [32mPASSED[0m
2026-01-14T08:32:34.8531734Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_quantize_dequantize_fp8_inductor_float8_e5m2_float32 frames [('total', 2), ('ok', 2)]
2026-01-14T08:32:34.8532555Z stats [('calls_captured', 2), ('unique_graphs', 2)]
2026-01-14T08:32:34.8533125Z aot_autograd [('total', 2), ('autograd_cache_miss', 2), ('autograd_cache_saved', 2), ('ok', 2)]
2026-01-14T08:33:24.4247224Z inductor [('fxgraph_cache_miss', 2), ('extern_calls', 2)]
2026-01-14T08:33:24.4247594Z graph_break []
2026-01-14T08:33:24.4248199Z [32mPASSED[0m
2026-01-14T08:33:24.4248922Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_serialization_mode_static [33mSKIPPED[0m
2026-01-14T08:33:24.4250748Z test/dtypes/test_affine_quantized_float.py::TestAffineQuantizedFloat8Compile::test_unsupported_granularity [32mPASSED[0m
2026-01-14T08:33:24.4252283Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:32:34.854000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 1247
2026-01-14T08:33:24.4253654Z I0114 08:32:34.855000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 1248
2026-01-14T08:33:24.4254543Z I0114 08:32:34.856000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 2 with pid 1249
2026-01-14T08:33:24.4255420Z I0114 08:32:34.857000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 3 with pid 1250
2026-01-14T08:33:24.4256884Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4258043Z   warnings.warn(
2026-01-14T08:33:24.4259128Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4260257Z   warnings.warn(
2026-01-14T08:33:24.4261331Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4262517Z   warnings.warn(
2026-01-14T08:33:24.4263577Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4264712Z   warnings.warn(
2026-01-14T08:33:24.4264952Z [32mPASSED[0m
2026-01-14T08:33:24.4265933Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float16 I0114 08:32:47.483000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 2999
2026-01-14T08:33:24.4267278Z I0114 08:32:47.484000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 3000
2026-01-14T08:33:24.4268157Z I0114 08:32:47.485000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 2 with pid 3001
2026-01-14T08:33:24.4269043Z I0114 08:32:47.486000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 3 with pid 3002
2026-01-14T08:33:24.4270496Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4271676Z   warnings.warn(
2026-01-14T08:33:24.4272746Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4274070Z   warnings.warn(
2026-01-14T08:33:24.4275143Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4276355Z   warnings.warn(
2026-01-14T08:33:24.4277413Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4278540Z   warnings.warn(
2026-01-14T08:33:24.4278780Z [32mPASSED[0m
2026-01-14T08:33:24.4279747Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8woAffineQuantizedTensorParallel::test_tp_float32 I0114 08:32:59.009000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 4704
2026-01-14T08:33:24.4281099Z I0114 08:32:59.010000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 4705
2026-01-14T08:33:24.4282027Z I0114 08:32:59.011000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 2 with pid 4706
2026-01-14T08:33:24.4282917Z I0114 08:32:59.012000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 3 with pid 4707
2026-01-14T08:33:24.4284363Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4285492Z   warnings.warn(
2026-01-14T08:33:24.4286576Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4287710Z   warnings.warn(
2026-01-14T08:33:24.4288776Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4289910Z   warnings.warn(
2026-01-14T08:33:24.4290973Z /pytorch/ao/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T08:33:24.4292153Z   warnings.warn(
2026-01-14T08:33:24.4292397Z [32mPASSED[0m
2026-01-14T08:33:24.4293078Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt4woAffineQuantizedTensorParallel::test_tp_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:24.4294190Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestGemliteLayoutTensorParallel::test_tp_gemlite_float16 [33mSKIPPED[0m
2026-01-14T08:33:24.4295579Z test/dtypes/test_affine_quantized_tensor_parallel.py::TestInt8dqAffineQuantizedTensorParallel::test_tp_bfloat16 I0114 08:33:10.345000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 6499
2026-01-14T08:33:24.4296926Z I0114 08:33:10.347000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 6500
2026-01-14T08:33:24.4297812Z I0114 08:33:10.348000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 2 with pid 6501
2026-01-14T08:33:24.4298681Z I0114 08:33:10.349000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 3 with pid 6502
2026-01-14T08:33:24.4299286Z [32mPASSED[0m
2026-01-14T08:33:24.4299648Z test/dtypes/test_bitpacking.py::test_CPU[0-1] [32mPASSED[0m
2026-01-14T08:33:24.4300281Z test/dtypes/test_bitpacking.py::test_CPU[0-2] [32mPASSED[0m
2026-01-14T08:33:24.4300791Z test/dtypes/test_bitpacking.py::test_CPU[0-3] [32mPASSED[0m
2026-01-14T08:33:24.4301288Z test/dtypes/test_bitpacking.py::test_CPU[0-4] [32mPASSED[0m
2026-01-14T08:33:24.4301788Z test/dtypes/test_bitpacking.py::test_CPU[0-5] [32mPASSED[0m
2026-01-14T08:33:24.4302410Z test/dtypes/test_bitpacking.py::test_CPU[0-6] [32mPASSED[0m
2026-01-14T08:33:24.4302910Z test/dtypes/test_bitpacking.py::test_CPU[0-7] [32mPASSED[0m
2026-01-14T08:33:24.4303414Z test/dtypes/test_bitpacking.py::test_CPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:24.4303929Z test/dtypes/test_bitpacking.py::test_CPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:24.4304441Z test/dtypes/test_bitpacking.py::test_CPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:24.4304948Z test/dtypes/test_bitpacking.py::test_CPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:24.4305461Z test/dtypes/test_bitpacking.py::test_CPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:24.4305975Z test/dtypes/test_bitpacking.py::test_CPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:24.4306484Z test/dtypes/test_bitpacking.py::test_CPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:24.4306980Z test/dtypes/test_bitpacking.py::test_CPU[1-1] [32mPASSED[0m
2026-01-14T08:33:24.4307508Z test/dtypes/test_bitpacking.py::test_CPU[1-2] [32mPASSED[0m
2026-01-14T08:33:24.4308010Z test/dtypes/test_bitpacking.py::test_CPU[1-3] [32mPASSED[0m
2026-01-14T08:33:24.4317290Z test/dtypes/test_bitpacking.py::test_CPU[1-4] [32mPASSED[0m
2026-01-14T08:33:24.4317802Z test/dtypes/test_bitpacking.py::test_CPU[1-5] [32mPASSED[0m
2026-01-14T08:33:24.4318305Z test/dtypes/test_bitpacking.py::test_CPU[1-6] [32mPASSED[0m
2026-01-14T08:33:24.4318793Z test/dtypes/test_bitpacking.py::test_CPU[1-7] [32mPASSED[0m
2026-01-14T08:33:24.4319288Z test/dtypes/test_bitpacking.py::test_GPU[0-1] [32mPASSED[0m
2026-01-14T08:33:24.4319772Z test/dtypes/test_bitpacking.py::test_GPU[0-2] [32mPASSED[0m
2026-01-14T08:33:24.4320274Z test/dtypes/test_bitpacking.py::test_GPU[0-3] [32mPASSED[0m
2026-01-14T08:33:24.4320760Z test/dtypes/test_bitpacking.py::test_GPU[0-4] [32mPASSED[0m
2026-01-14T08:33:24.4321264Z test/dtypes/test_bitpacking.py::test_GPU[0-5] [32mPASSED[0m
2026-01-14T08:33:28.3895988Z test/dtypes/test_bitpacking.py::test_GPU[0-6] [32mPASSED[0m
2026-01-14T08:33:28.3896550Z test/dtypes/test_bitpacking.py::test_GPU[0-7] [32mPASSED[0m
2026-01-14T08:33:28.3897072Z test/dtypes/test_bitpacking.py::test_GPU[-1-1] [32mPASSED[0m
2026-01-14T08:33:28.3897586Z test/dtypes/test_bitpacking.py::test_GPU[-1-2] [32mPASSED[0m
2026-01-14T08:33:28.3898093Z test/dtypes/test_bitpacking.py::test_GPU[-1-3] [32mPASSED[0m
2026-01-14T08:33:28.3898598Z test/dtypes/test_bitpacking.py::test_GPU[-1-4] [32mPASSED[0m
2026-01-14T08:33:28.3899098Z test/dtypes/test_bitpacking.py::test_GPU[-1-5] [32mPASSED[0m
2026-01-14T08:33:28.3899603Z test/dtypes/test_bitpacking.py::test_GPU[-1-6] [32mPASSED[0m
2026-01-14T08:33:28.3900122Z test/dtypes/test_bitpacking.py::test_GPU[-1-7] [32mPASSED[0m
2026-01-14T08:33:28.3900631Z test/dtypes/test_bitpacking.py::test_GPU[1-1] [32mPASSED[0m
2026-01-14T08:33:28.3901133Z test/dtypes/test_bitpacking.py::test_GPU[1-2] [32mPASSED[0m
2026-01-14T08:33:28.3901631Z test/dtypes/test_bitpacking.py::test_GPU[1-3] [32mPASSED[0m
2026-01-14T08:33:28.3902139Z test/dtypes/test_bitpacking.py::test_GPU[1-4] [32mPASSED[0m
2026-01-14T08:33:28.3902633Z test/dtypes/test_bitpacking.py::test_GPU[1-5] [32mPASSED[0m
2026-01-14T08:33:28.3903135Z test/dtypes/test_bitpacking.py::test_GPU[1-6] [32mPASSED[0m
2026-01-14T08:33:28.3903627Z test/dtypes/test_bitpacking.py::test_GPU[1-7] [32mPASSED[0m
2026-01-14T08:33:28.3904152Z test/dtypes/test_bitpacking.py::test_compile[0-1] [32mPASSED[0m
2026-01-14T08:33:28.3904697Z test/dtypes/test_bitpacking.py::test_compile[0-2] [32mPASSED[0m
2026-01-14T08:33:28.3905226Z test/dtypes/test_bitpacking.py::test_compile[0-3] [32mPASSED[0m
2026-01-14T08:33:28.3906060Z test/dtypes/test_bitpacking.py::test_compile[0-4] [32mPASSED[0m
2026-01-14T08:33:28.3906597Z test/dtypes/test_bitpacking.py::test_compile[0-5] [32mPASSED[0m
2026-01-14T08:33:28.3907130Z test/dtypes/test_bitpacking.py::test_compile[0-6] [32mPASSED[0m
2026-01-14T08:33:28.3907656Z test/dtypes/test_bitpacking.py::test_compile[0-7] [32mPASSED[0m
2026-01-14T08:33:28.3908352Z test/dtypes/test_bitpacking.py::test_compile[-1-1] [32mPASSED[0m
2026-01-14T08:33:28.3908890Z test/dtypes/test_bitpacking.py::test_compile[-1-2] [32mPASSED[0m
2026-01-14T08:33:28.3909423Z test/dtypes/test_bitpacking.py::test_compile[-1-3] [32mPASSED[0m
2026-01-14T08:33:28.3909967Z test/dtypes/test_bitpacking.py::test_compile[-1-4] [32mPASSED[0m
2026-01-14T08:33:28.3910499Z test/dtypes/test_bitpacking.py::test_compile[-1-5] [32mPASSED[0m
2026-01-14T08:33:28.3911037Z test/dtypes/test_bitpacking.py::test_compile[-1-6] [32mPASSED[0m
2026-01-14T08:33:28.3911567Z test/dtypes/test_bitpacking.py::test_compile[-1-7] [32mPASSED[0m
2026-01-14T08:33:28.3912111Z test/dtypes/test_bitpacking.py::test_compile[1-1] [32mPASSED[0m
2026-01-14T08:33:28.3912650Z test/dtypes/test_bitpacking.py::test_compile[1-2] [32mPASSED[0m
2026-01-14T08:33:28.3913186Z test/dtypes/test_bitpacking.py::test_compile[1-3] [32mPASSED[0m
2026-01-14T08:33:28.3913722Z test/dtypes/test_bitpacking.py::test_compile[1-4] [32mPASSED[0m
2026-01-14T08:33:28.3914253Z test/dtypes/test_bitpacking.py::test_compile[1-5] [32mPASSED[0m
2026-01-14T08:33:28.3914787Z test/dtypes/test_bitpacking.py::test_compile[1-6] [32mPASSED[0m
2026-01-14T08:33:28.3915311Z test/dtypes/test_bitpacking.py::test_compile[1-7] [32mPASSED[0m
2026-01-14T08:33:28.3916129Z test/dtypes/test_bitpacking.py::test_pack_example tensor([  0, 105, 151,  37], device='cuda:0', dtype=torch.uint8) tensor([ 39, 146], device='cuda:0', dtype=torch.uint8)
2026-01-14T08:33:28.3916874Z [32mPASSED[0m
2026-01-14T08:33:28.3917415Z test/dtypes/test_bitpacking.py::test_pack_example_CPU tensor([  0, 105, 151,  37], dtype=torch.uint8) tensor([ 39, 146], dtype=torch.uint8)
2026-01-14T08:33:28.3918062Z [32mPASSED[0m
2026-01-14T08:33:28.3918539Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3919267Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:33:28.3919993Z test/dtypes/test_nf4.py::TestNF4Linear::test_backward_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:33:28.3920815Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3921729Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3922628Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3923535Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3924456Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3925346Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_bfloat16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3926241Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3927132Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3928023Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3928929Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3929813Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3930796Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float16_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3931788Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3932724Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3933695Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape0_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3934581Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_16 [32mPASSED[0m
2026-01-14T08:33:28.3935477Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_32 [32mPASSED[0m
2026-01-14T08:33:28.3936365Z test/dtypes/test_nf4.py::TestNF4Linear::test_chunk_size_equivalence_float32_shape1_chunk_size_8 [32mPASSED[0m
2026-01-14T08:33:28.3937143Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size0 [32mPASSED[0m
2026-01-14T08:33:28.3937814Z test/dtypes/test_nf4.py::TestNF4Linear::test_empty_like_input_size1 [32mPASSED[0m
2026-01-14T08:33:28.3938513Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3939254Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float16 [32mPASSED[0m
2026-01-14T08:33:28.3939989Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_diff_meta_float32 [32mPASSED[0m
2026-01-14T08:33:28.3940718Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3941450Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float16 [32mPASSED[0m
2026-01-14T08:33:28.3942169Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_nf4_same_meta_float32 [32mPASSED[0m
2026-01-14T08:33:28.3942895Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3943613Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float16 [32mPASSED[0m
2026-01-14T08:33:28.3944331Z test/dtypes/test_nf4.py::TestNF4Linear::test_load_from_state_dicts_float32 [32mPASSED[0m
2026-01-14T08:33:28.3945026Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:28.3945703Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float16 [33mSKIPPED[0m
2026-01-14T08:33:28.3946373Z test/dtypes/test_nf4.py::TestNF4Linear::test_nf4_bnb_linear_float32 [33mSKIPPED[0m
2026-01-14T08:33:28.3947050Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3947756Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float16 [32mPASSED[0m
2026-01-14T08:33:28.3948448Z test/dtypes/test_nf4.py::TestNF4Linear::test_output_dtype_match_float32 [32mPASSED[0m
2026-01-14T08:33:28.3949374Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_False [32mPASSED[0m
2026-01-14T08:33:28.3950079Z test/dtypes/test_nf4.py::TestNF4Linear::test_quantize_api_compile_True [32mPASSED[0m
2026-01-14T08:33:28.3950824Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_bfloat16 [33mSKIPPED[0m
2026-01-14T08:33:28.3951616Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float16 [33mSKIPPED[0m
2026-01-14T08:33:28.3952406Z test/dtypes/test_nf4.py::TestNF4Linear::test_reconstruction_qlora_vs_bnb_float32 [33mSKIPPED[0m
2026-01-14T08:33:28.3953153Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3953886Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float16 [32mPASSED[0m
2026-01-14T08:33:28.3954593Z test/dtypes/test_nf4.py::TestNF4Linear::test_register_nf4_as_param_float32 [32mPASSED[0m
2026-01-14T08:33:28.3955294Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_bfloat16 [32mPASSED[0m
2026-01-14T08:33:28.3956115Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_bfloat16 Autotune Choices Stats:
2026-01-14T08:33:28.3957490Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_10", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:33:28.3958740Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:28.3958988Z strides: [32, 1], [1, 32]
2026-01-14T08:33:28.3959245Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:33:28.3959977Z   triton_mm_10 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:33:34.7714976Z   triton_mm_11 0.0235 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:33:34.7716522Z   triton_mm_4 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7717960Z   triton_mm_8 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:33:34.7719408Z   triton_mm_9 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:33:34.7720850Z   triton_mm_0 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:33:34.7722278Z   triton_mm_5 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7723709Z   triton_mm_7 0.0246 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:33:34.7725141Z   triton_mm_2 0.0256 ms 88.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7726583Z   triton_mm_1 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7727785Z SingleProcess AUTOTUNE benchmarking takes 0.1571 seconds and 0.2868 seconds precompiling for 13 choices
2026-01-14T08:33:34.7728697Z [32mPASSED[0m
2026-01-14T08:33:34.7729268Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float16 Autotune Choices Stats:
2026-01-14T08:33:34.7731019Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_20", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.022463999688625336, "best_triton_pos": 0}
2026-01-14T08:33:34.7732561Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:34.7732850Z strides: [32, 1], [1, 32]
2026-01-14T08:33:34.7733165Z dtypes: torch.float16, torch.float16
2026-01-14T08:33:34.7734066Z   triton_mm_20 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:33:34.7735525Z   triton_mm_16 0.0225 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7736969Z   triton_mm_17 0.0225 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7738874Z   triton_mm_18 0.0225 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7740323Z   triton_mm_14 0.0236 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7741949Z   triton_mm_21 0.0236 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:33:34.7743382Z   triton_mm_12 0.0246 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:33:34.7744822Z   triton_mm_13 0.0246 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7746261Z   triton_mm_15 0.0246 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:33:34.7747756Z   triton_mm_19 0.0246 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:33:34.7749208Z SingleProcess AUTOTUNE benchmarking takes 0.2853 seconds and 0.3168 seconds precompiling for 13 choices
2026-01-14T08:33:34.7749933Z [32mPASSED[0m
2026-01-14T08:33:34.7750498Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_compile_float32 Autotune Choices Stats:
2026-01-14T08:33:34.7752301Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_31", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:33:34.7753831Z AUTOTUNE mm(64x32, 32x32)
2026-01-14T08:33:34.7754152Z strides: [32, 1], [1, 32]
2026-01-14T08:33:34.7754477Z dtypes: torch.float32, torch.float32
2026-01-14T08:33:34.7755457Z   triton_mm_31 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:33:34.7757015Z   triton_mm_28 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7758550Z   triton_mm_32 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:33:34.7760091Z   triton_mm_35 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:33:34.7761654Z   triton_mm_25 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:33:34.7763190Z   triton_mm_33 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:33:34.7764751Z   triton_mm_34 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:33:34.7766303Z   triton_mm_26 0.0257 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:33:34.7768051Z   triton_mm_24 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:33:34.7769598Z   triton_mm_27 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:33:34.7770893Z SingleProcess AUTOTUNE benchmarking takes 0.1625 seconds and 0.2913 seconds precompiling for 13 choices
2026-01-14T08:33:34.7772071Z [32mPASSED[0m
2026-01-14T08:33:34.7772764Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float16 [32mPASSED[0m
2026-01-14T08:33:34.7773832Z test/dtypes/test_nf4.py::TestNF4Linear::test_smoketest_linear_float32 [32mPASSED[0m
2026-01-14T08:33:34.7774857Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16 [32mPASSED[0m
2026-01-14T08:33:34.7775623Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_device [32mPASSED[0m
2026-01-14T08:33:34.7776391Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16 [32mPASSED[0m
2026-01-14T08:33:34.7777150Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32 [32mPASSED[0m
2026-01-14T08:33:34.7777925Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_bfloat16 [32mPASSED[0m
2026-01-14T08:33:34.7778696Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float16 [32mPASSED[0m
2026-01-14T08:33:34.7779465Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_dtype_float32 [32mPASSED[0m
2026-01-14T08:33:34.7780204Z test/dtypes/test_nf4.py::TestFSDPOps::test_pin_memory [32mPASSED[0m
2026-01-14T08:33:34.7781022Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_2d_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:33:34.7781972Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:33:34.7782948Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:33:34.7783903Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size1 [32mPASSED[0m
2026-01-14T08:33:34.7784855Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size2 [32mPASSED[0m
2026-01-14T08:33:34.7785829Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_as_strided_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:33:34.7786767Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size1 [32mPASSED[0m
2026-01-14T08:33:34.7787652Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size2 [32mPASSED[0m
2026-01-14T08:33:34.7788550Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_deepcopy_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.8706827Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8709440Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.8710528Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_invalid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.8711335Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8712276Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.8713121Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_new_zeros_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.8714174Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_1d_invalid [32mPASSED[0m
2026-01-14T08:35:33.8715008Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_2d_invalid [32mPASSED[0m
2026-01-14T08:35:33.8715701Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8716411Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.8717155Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_slice_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.8717888Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_invalid_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.8718931Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.8719643Z test/dtypes/test_nf4.py::TestFSDPOps::test_tensor_view_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8720258Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cpu [32mPASSED[0m
2026-01-14T08:35:33.8720971Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_cuda [32mPASSED[0m
2026-01-14T08:35:33.8721516Z test/dtypes/test_nf4.py::TestFSDPOps::test_to_module [32mPASSED[0m
2026-01-14T08:35:33.8722165Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_3d_input_size0 [32mPASSED[0m
2026-01-14T08:35:33.8722924Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8723692Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.8724503Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_invalid_divide_input_size_261632 [32mPASSED[0m
2026-01-14T08:35:33.8725266Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size1 [32mPASSED[0m
2026-01-14T08:35:33.8725967Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size2 [32mPASSED[0m
2026-01-14T08:35:33.8726684Z test/dtypes/test_nf4.py::TestFSDPOps::test_torch_chunk_valid_input_size_262144 [32mPASSED[0m
2026-01-14T08:35:33.8727675Z test/dtypes/test_nf4.py::TestQLoRA::test_qlora_fsdp2 I0114 08:33:35.928000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 9811
2026-01-14T08:35:33.8728762Z I0114 08:33:35.929000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 9812
2026-01-14T08:35:33.8729345Z dist init r=1, world=2
2026-01-14T08:35:33.8729572Z dist init r=0, world=2
2026-01-14T08:35:33.8730524Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:35:33.8731684Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.8731994Z [32mPASSED[0m
2026-01-14T08:35:33.8732665Z test/dtypes/test_nf4.py::TestComm::test_comm I0114 08:33:46.451000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 9992
2026-01-14T08:35:33.8733723Z I0114 08:33:46.452000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 9993
2026-01-14T08:35:33.8734306Z dist init r=0, world=2
2026-01-14T08:35:33.8734526Z dist init r=1, world=2
2026-01-14T08:35:33.8735470Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:35:33.8736475Z   warnings.warn(  # warn only once
2026-01-14T08:35:33.8736775Z [32mPASSED[0m
2026-01-14T08:35:33.8737259Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8738019Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8738766Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8739504Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8740245Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8741032Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8741775Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8742513Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8744128Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8744884Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8745618Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8746445Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8747187Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8747919Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[64-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8748663Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8749728Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8750485Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8751225Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8751975Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8752726Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8753463Z test/dtypes/test_uintx.py::test_uintx_quant_on_cpu_then_move_to_cuda[128-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8754200Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8754924Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8755650Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8756377Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8757102Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8757827Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8758548Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8759279Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8760002Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8760728Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8761452Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8762170Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8762903Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8763635Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8764363Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8765106Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8765835Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8766573Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8767300Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8768036Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8768917Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8769667Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:35:33.8770429Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:35:33.8771352Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:35:33.8772185Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:35:33.8772944Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:35:33.8773695Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:35:33.8774456Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:35:33.8775224Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6006655Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6009091Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6009980Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6010769Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6011625Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6012386Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6013157Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6013925Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6014707Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6015474Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6016234Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6017013Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6017774Z test/dtypes/test_uintx.py::test_uintx_weight_only_model_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6018497Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6019187Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6019878Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6020604Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6021283Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6021961Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6022638Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-32-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6023317Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6023998Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6024669Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6025355Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6026033Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6027038Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6027730Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-64-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6028415Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6029302Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6030277Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6031130Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6031823Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6032502Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6033187Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[cpu-128-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6033895Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6034613Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6035324Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6036048Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6036768Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6037472Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6038197Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-32-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6038990Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6039835Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6048481Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6049403Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6050180Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6050892Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6051670Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-64-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6052390Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6053116Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6053835Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6054568Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6055283Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6056004Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6056731Z test/dtypes/test_uintx.py::test_uintx_weight_only_quant[device1-128-dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6057392Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6057992Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6058577Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6059170Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6059751Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6060526Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6061124Z test/dtypes/test_uintx.py::test_uintx_target_dtype[dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6061738Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6062520Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6063164Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6063813Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6064453Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6065101Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6065753Z test/dtypes/test_uintx.py::test_uintx_target_dtype_compile[dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6066366Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype0] [32mPASSED[0m
2026-01-14T08:37:47.6066951Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype1] [32mPASSED[0m
2026-01-14T08:37:47.6067523Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype2] [32mPASSED[0m
2026-01-14T08:37:47.6068102Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype3] [32mPASSED[0m
2026-01-14T08:37:47.6068683Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype4] [32mPASSED[0m
2026-01-14T08:37:47.6069253Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype5] [32mPASSED[0m
2026-01-14T08:37:47.6069832Z test/dtypes/test_uintx.py::test_uintx_model_size[dtype6] [32mPASSED[0m
2026-01-14T08:37:47.6070401Z test/dtypes/test_uintx.py::test_uintx_api_deprecation [32mPASSED[0m
2026-01-14T08:37:47.6071234Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims0-valid.layer-filter_fqns0-True] [32mPASSED[0m
2026-01-14T08:37:47.6072496Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims1-skip_layer.linear-filter_fqns1-False] [32mPASSED[0m
2026-01-14T08:37:47.6073606Z test/float8/test_auto_filter.py::test_end_to_end_filtering[tensorwise-module_dims2-valid.layer-filter_fqns2-False] [32mPASSED[0m
2026-01-14T08:37:47.6074657Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims3-valid.layer-filter_fqns3-True] [32mPASSED[0m
2026-01-14T08:37:47.6075720Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims4-skip_layer.linear-filter_fqns4-False] [32mPASSED[0m
2026-01-14T08:37:47.6076781Z test/float8/test_auto_filter.py::test_end_to_end_filtering[rowwise-module_dims5-valid.layer-filter_fqns5-False] [32mPASSED[0m
2026-01-14T08:37:47.6077633Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_rowwise [32mPASSED[0m
2026-01-14T08:37:47.6078342Z test/float8/test_auto_filter.py::test_exact_boundary_dimensions_tensorwise [32mPASSED[0m
2026-01-14T08:37:47.6079006Z test/float8/test_auto_filter.py::test_partial_fqn_matching [32mPASSED[0m
2026-01-14T08:37:47.6079666Z test/float8/test_base.py::TestFloat8TrainingTensor::test_preserves_dtype [32mPASSED[0m
2026-01-14T08:37:47.6080476Z test/float8/test_base.py::TestFloat8TrainingTensor::test_differentiable_casts [32mPASSED[0m
2026-01-14T08:37:47.6081189Z test/float8/test_base.py::TestFloat8TrainingTensor::test_split_cat [32mPASSED[0m
2026-01-14T08:37:47.6081870Z test/float8/test_base.py::TestFloat8TrainingTensor::test_index_put [32mPASSED[0m
2026-01-14T08:37:47.6082530Z test/float8/test_base.py::TestFloat8TrainingTensor::test_copy_ [32mPASSED[0m
2026-01-14T08:37:47.8397670Z test/float8/test_base.py::TestFloat8TrainingTensor::test_transpose [32mPASSED[0m
2026-01-14T08:37:47.8398651Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape0] [32mPASSED[0m
2026-01-14T08:37:47.8399573Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape1] [32mPASSED[0m
2026-01-14T08:37:47.8400657Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True-0-shape2] [32mPASSED[0m
2026-01-14T08:37:47.8401587Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape0] [32mPASSED[0m
2026-01-14T08:37:47.8402510Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape1] [32mPASSED[0m
2026-01-14T08:37:47.8403555Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[True--1-shape2] [32mPASSED[0m
2026-01-14T08:37:47.8404465Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape0] [32mPASSED[0m
2026-01-14T08:37:47.8405388Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape1] [32mPASSED[0m
2026-01-14T08:37:47.8406294Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False-0-shape2] [32mPASSED[0m
2026-01-14T08:37:47.8407232Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape0] [32mPASSED[0m
2026-01-14T08:37:47.8408160Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape1] [32mPASSED[0m
2026-01-14T08:37:47.8409075Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_dynamic_cast[False--1-shape2] [32mPASSED[0m
2026-01-14T08:37:47.8409920Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_reshape [32mPASSED[0m
2026-01-14T08:37:47.8411002Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:47.8412485Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:47.8413857Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:47.8415245Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:47.8416652Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:47.8418065Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.AXISWISE-ScalingGranularity.TENSORWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:47.8419460Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape0] [33mSKIPPED[0m
2026-01-14T08:37:47.8420910Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape1] [33mSKIPPED[0m
2026-01-14T08:37:47.8422307Z test/float8/test_base.py::TestFloat8TrainingTensor::test_axiswise_gemm[ScalingGranularity.TENSORWISE-ScalingGranularity.AXISWISE-a_shape2] [33mSKIPPED[0m
2026-01-14T08:37:47.8423329Z test/float8/test_base.py::TestFloat8TrainingTensor::test_fp8_dtype [32mPASSED[0m
2026-01-14T08:37:47.8424586Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8426315Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8428040Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8429856Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8431575Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8433299Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8435098Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8436804Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8438529Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8440245Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8441953Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8443669Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[False-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8445390Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8447098Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8448815Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8450855Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8452613Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8454344Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-False-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8456056Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8457758Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8459464Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8461221Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape0-True] [32mPASSED[0m
2026-01-14T08:37:47.8464118Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape1-True] [32mPASSED[0m
2026-01-14T08:37:47.8465837Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_config_params[True-True-linear_dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-x_shape2-True] [32mPASSED[0m
2026-01-14T08:37:47.8467411Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:47.8468699Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:47.8470001Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:47.8471305Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0033458Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0034914Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0036192Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0037472Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0038750Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0040054Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0041351Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0042626Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype0-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0043901Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0045178Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0046434Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0047709Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0048973Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0050448Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0051792Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0053077Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0054541Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0055837Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0057107Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0058513Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype1-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0059784Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0061102Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0062376Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0063655Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0064913Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0066193Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-True-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0067457Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0068743Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape0-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0070052Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0071352Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape1-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0072630Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:48.0073912Z test/float8/test_base.py::TestFloat8Linear::test_linear_from_recipe[linear_dtype2-False-x_shape2-Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:48.0075151Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:48.0076318Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:48.0077482Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.TENSORWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:48.0078632Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:48.0079763Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:48.0080887Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:48.0082079Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype0-True] [32mPASSED[0m
2026-01-14T08:37:48.0083296Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype1-True] [32mPASSED[0m
2026-01-14T08:37:48.0084597Z test/float8/test_base.py::TestFloat8Linear::test_autocast_outputs[Float8LinearRecipeName.ROWWISE_WITH_GW_HP-linear_dtype2-True] [32mPASSED[0m
2026-01-14T08:37:48.0085481Z test/float8/test_base.py::TestFloat8Linear::test_repr [32mPASSED[0m
2026-01-14T08:37:48.0086090Z test/float8/test_base.py::TestFloat8Linear::test_inference_mode [33mSKIPPED[0m
2026-01-14T08:37:48.0086836Z test/float8/test_base.py::TestFloat8Linear::test_quantize [33mSKIPPED[0m (C...)
2026-01-14T08:37:48.0087576Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:48.0088380Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:48.0089193Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:48.0089993Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:48.0090814Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:48.0091677Z test/float8/test_base.py::TestScaledMM::test_scaled_mm_vs_emulated[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:48.0092414Z test/float8/test_base.py::TestScaledMM::test_different_configs_error [33mSKIPPED[0m
2026-01-14T08:37:48.0093141Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:48.0093881Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:48.0094628Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[True-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:48.0095377Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype0] [33mSKIPPED[0m
2026-01-14T08:37:48.0096119Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype1] [33mSKIPPED[0m
2026-01-14T08:37:48.0096873Z test/float8/test_base.py::TestScaledMM::test_pad_inner_dim[False-base_dtype2] [33mSKIPPED[0m
2026-01-14T08:37:48.0097613Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype0] [32mPASSED[0m
2026-01-14T08:37:48.0098357Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype1] [32mPASSED[0m
2026-01-14T08:37:48.0099097Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype2] [32mPASSED[0m
2026-01-14T08:37:48.0099846Z test/float8/test_base.py::TestNumerics::test_small_amax_float16[float8_dtype3] [32mPASSED[0m
2026-01-14T08:37:48.0100595Z test/float8/test_base.py::TestFloat8LinearUtils::test_fp8_tensor_statistics [32mPASSED[0m
2026-01-14T08:37:48.0101357Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_linears_with_filters [32mPASSED[0m
2026-01-14T08:37:55.5586992Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear [32mPASSED[0m
2026-01-14T08:37:55.5587974Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_root_linear_with_children_raises [32mPASSED[0m
2026-01-14T08:37:55.5588919Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears [32mPASSED[0m
2026-01-14T08:37:55.5589820Z test/float8/test_base.py::TestFloat8LinearUtils::test_swap_submodule_linears_with_skip [32mPASSED[0m
2026-01-14T08:37:55.5591038Z test/float8/test_compile.py::test_eager_only[dtype0-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:37:55.5592580Z test/float8/test_compile.py::test_eager_only[dtype1-True-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True] [32mPASSED[0m
2026-01-14T08:37:55.5593960Z test/float8/test_compile.py::test_aot_eager[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:37:55.5595434Z test/float8/test_compile.py::test_aot_eager[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-True-True] [32mPASSED[0m
2026-01-14T08:37:55.5597276Z test/float8/test_compile.py::test_inductor_from_config_params[dtype0-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:37:55.5598972Z test/float8/test_compile.py::test_inductor_from_config_params[dtype1-ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC-False-True] [33mSKIPPED[0m
2026-01-14T08:37:55.5600538Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:55.5601570Z test/float8/test_compile.py::test_inductor_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:55.5602494Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_input [33mSKIPPED[0m
2026-01-14T08:37:55.5603313Z test/float8/test_compile.py::TestGraphBreaks::test_float8_graph_output [33mSKIPPED[0m
2026-01-14T08:37:55.5604215Z test/float8/test_compile.py::TestGraphBreaks::test_float8_with_graph_break_in_the_middle [33mSKIPPED[0m
2026-01-14T08:37:55.5605135Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype0] [33mSKIPPED[0m
2026-01-14T08:37:55.5605982Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype1] [33mSKIPPED[0m
2026-01-14T08:37:55.5606825Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[True-dtype2] [33mSKIPPED[0m
2026-01-14T08:37:55.5607675Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype0] [33mSKIPPED[0m
2026-01-14T08:37:55.5608525Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype1] [33mSKIPPED[0m
2026-01-14T08:37:55.5609366Z test/float8/test_compile.py::test_dynamic_scale_numeric_parity[False-dtype2] [33mSKIPPED[0m
2026-01-14T08:37:55.5610282Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case0] [32mPASSED[0m
2026-01-14T08:37:55.5611252Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case1] [32mPASSED[0m
2026-01-14T08:37:55.5612337Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case2] [32mPASSED[0m
2026-01-14T08:37:55.5613372Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case3] [32mPASSED[0m
2026-01-14T08:37:55.5614336Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case4] [32mPASSED[0m
2026-01-14T08:37:55.5615339Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case5] [32mPASSED[0m
2026-01-14T08:37:55.5616336Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case6] [32mPASSED[0m
2026-01-14T08:37:55.5617323Z test/float8/test_float8_utils.py::test_round_scale_down_to_power_of_2_valid_inputs[test_case7] [32mPASSED[0m
2026-01-14T08:37:55.5618198Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype0] [32mPASSED[0m
2026-01-14T08:37:55.5618954Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype1] [32mPASSED[0m
2026-01-14T08:37:55.5619722Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype2] [32mPASSED[0m
2026-01-14T08:37:55.5620520Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype3] [32mPASSED[0m
2026-01-14T08:37:55.5621318Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype4] [32mPASSED[0m
2026-01-14T08:37:55.5622166Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype5] [32mPASSED[0m
2026-01-14T08:37:55.5622951Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype6] [32mPASSED[0m
2026-01-14T08:37:55.5623739Z test/float8/test_float8_utils.py::test_non_float32_input[invalid_dtype7] [32mPASSED[0m
2026-01-14T08:37:55.5625111Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_config_params[ScalingType.DYNAMIC-ScalingType.DYNAMIC-ScalingType.DYNAMIC] [33mSKIPPED[0m
2026-01-14T08:37:55.5626961Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE] [33mSKIPPED[0m
2026-01-14T08:37:55.5628541Z test/float8/test_numerics_integration.py::TestFloat8NumericsIntegrationTest::test_encoder_fw_bw_from_recipe[Float8LinearRecipeName.ROWWISE_WITH_GW_HP] [33mSKIPPED[0m
2026-01-14T08:37:55.5629633Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_2bit [32mPASSED[0m
2026-01-14T08:37:55.5630357Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_3bit [32mPASSED[0m
2026-01-14T08:37:55.5630955Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_4bit [32mPASSED[0m
2026-01-14T08:37:55.5631541Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_5bit [32mPASSED[0m
2026-01-14T08:37:55.5632237Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_6bit [32mPASSED[0m
2026-01-14T08:37:55.5632817Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_7bit [32mPASSED[0m
2026-01-14T08:37:55.5633402Z test/hqq/test_hqq_affine.py::TestHQQ::test_hqq_plain_8bit [32mPASSED[0m
2026-01-14T08:37:55.5634065Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm Autotune Choices Stats:
2026-01-14T08:37:55.5635483Z {"num_choices": 5, "num_triton_choices": 4, "best_kernel": "triton_mm_38", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:37:55.5636823Z AUTOTUNE int_mm(32x32, 32x16)
2026-01-14T08:37:55.5637072Z strides: [32, 1], [16, 1]
2026-01-14T08:37:55.5637325Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:55.5638019Z   triton_mm_38 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=2
2026-01-14T08:37:55.5639152Z   triton_mm_39 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:37:55.5640291Z   triton_mm_36 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:37:55.5641416Z   triton_mm_37 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=2
2026-01-14T08:37:55.5642122Z   _int_mm 0.0349 ms 70.5% 
2026-01-14T08:37:55.5642607Z SingleProcess AUTOTUNE benchmarking takes 0.0623 seconds and 0.1298 seconds precompiling for 5 choices
2026-01-14T08:37:55.5643272Z [32mPASSED[0m
2026-01-14T08:37:55.5643868Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test__int_mm_eager_and_torch_compile_numerics Autotune Choices Stats:
2026-01-14T08:37:55.5645384Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_49", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.07577600330114365, "best_triton_pos": 0}
2026-01-14T08:37:55.5646515Z AUTOTUNE int_mm(17x1536, 1536x1536)
2026-01-14T08:37:55.5646788Z strides: [s15, 1], [s21, 1]
2026-01-14T08:37:55.5647041Z dtypes: torch.int8, torch.int8
2026-01-14T08:37:55.5647740Z   triton_mm_49 0.0758 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:37:55.5648888Z   triton_mm_52 0.0809 ms 93.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:37:55.5650226Z   triton_mm_48 0.0952 ms 79.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:37:55.5651599Z   triton_mm_50 0.0952 ms 79.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:37:55.5652786Z   triton_mm_44 0.1014 ms 74.7% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:37:55.5654047Z   triton_mm_46 0.1024 ms 74.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:37:55.5654766Z   _int_mm 0.1219 ms 62.2% 
2026-01-14T08:37:55.5655437Z   triton_mm_53 0.1444 ms 52.5% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:38:02.4518481Z   triton_mm_47 0.1618 ms 46.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:02.4520034Z   triton_mm_51 0.1618 ms 46.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:02.4521018Z SingleProcess AUTOTUNE benchmarking takes 0.2203 seconds and 0.4344 seconds precompiling for 11 choices
2026-01-14T08:38:02.4521570Z Autotune Choices Stats:
2026-01-14T08:38:02.4522664Z {"num_choices": 10, "num_triton_choices": 9, "best_kernel": "triton_mm_59", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.2170879989862442, "best_triton_pos": 0}
2026-01-14T08:38:02.4523821Z AUTOTUNE int_mm(136x4096, 4096x1536)
2026-01-14T08:38:02.4524096Z strides: [s15, 1], [s21, 1]
2026-01-14T08:38:02.4524351Z dtypes: torch.int8, torch.int8
2026-01-14T08:38:02.4525057Z   triton_mm_59 0.2171 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:38:02.4526199Z   triton_mm_62 0.2314 ms 93.8% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:38:02.4527331Z   triton_mm_54 0.2642 ms 82.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4528462Z   triton_mm_58 0.2898 ms 74.9% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:02.4529760Z   triton_mm_56 0.3052 ms 71.1% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4530609Z   _int_mm 0.3154 ms 68.8% 
2026-01-14T08:38:02.4531274Z   triton_mm_60 0.3492 ms 62.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:38:02.4532493Z   triton_mm_57 0.4393 ms 49.4% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:02.4533639Z   triton_mm_55 0.4506 ms 48.2% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4534780Z   triton_mm_61 0.4977 ms 43.6% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:02.4535746Z SingleProcess AUTOTUNE benchmarking takes 0.3312 seconds and 0.4710 seconds precompiling for 10 choices
2026-01-14T08:38:02.4536514Z [32mPASSED[0m
2026-01-14T08:38:02.4537597Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cpu [32mPASSED[0m
2026-01-14T08:38:02.4538691Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_dynamic_quant_per_channel_numerics_cuda [33mSKIPPED[0m
2026-01-14T08:38:02.4539679Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cpu [32mPASSED[0m
2026-01-14T08:38:02.4540772Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_per_token_linear_cuda [32mPASSED[0m
2026-01-14T08:38:02.4541696Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cpu [32mPASSED[0m
2026-01-14T08:38:02.4542624Z test/integration/test_integration.py::PythonQuantUtilOpUnitTest::test_quantize_per_token_cuda [32mPASSED[0m
2026-01-14T08:38:02.4543630Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4544689Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4545747Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4546783Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:38:02.4547804Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:38:02.4548826Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_rowwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:38:02.4550159Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4551239Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4552328Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4553388Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_3 [33mSKIPPED[0m
2026-01-14T08:38:02.4554443Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_4 [33mSKIPPED[0m
2026-01-14T08:38:02.4555496Z test/integration/test_integration.py::TestSubclass::test_aq_float8_dynamic_quant_tensorwise_scaling_subclass_5 [33mSKIPPED[0m
2026-01-14T08:38:02.4556495Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4557453Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4558408Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:02.4559357Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:38:02.4560285Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:38:02.4561200Z test/integration/test_integration.py::TestSubclass::test_aq_float8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:38:02.4562175Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_0_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4563137Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4563753Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4563927Z 
2026-01-14T08:38:02.4564087Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4564821Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4565378Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4565551Z 
2026-01-14T08:38:02.4565671Z [32mPASSED[0m
2026-01-14T08:38:02.4566298Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_1_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4567374Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4567919Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4568086Z 
2026-01-14T08:38:02.4568244Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4568833Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4569385Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4569554Z 
2026-01-14T08:38:02.4569680Z [32mPASSED[0m
2026-01-14T08:38:02.4570306Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_2_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4571259Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4571854Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4572034Z 
2026-01-14T08:38:02.4572182Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:02.4572769Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:02.4573320Z     return fn(*args, **kwargs)
2026-01-14T08:38:02.4573486Z 
2026-01-14T08:38:02.4573611Z [32mPASSED[0m
2026-01-14T08:38:02.4574099Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_3 Autotune Choices Stats:
2026-01-14T08:38:02.4575518Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_67", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:02.4576643Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:38:02.4576894Z strides: [64, 1], [1, 64]
2026-01-14T08:38:02.4577148Z dtypes: torch.int8, torch.int8
2026-01-14T08:38:02.4577844Z   triton_mm_67 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:02.4578981Z   triton_mm_63 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:02.4580098Z   triton_mm_64 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:26.6361371Z   triton_mm_65 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:26.6363854Z   triton_mm_66 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:26.6364633Z   _int_mm 0.0358 ms 68.6% 
2026-01-14T08:38:26.6365127Z SingleProcess AUTOTUNE benchmarking takes 0.0762 seconds and 0.1206 seconds precompiling for 6 choices
2026-01-14T08:38:26.6365858Z [32mPASSED[0m
2026-01-14T08:38:26.6366437Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_4 [32mPASSED[0m
2026-01-14T08:38:26.6367301Z test/integration/test_integration.py::TestSubclass::test_aq_int8_dynamic_quant_subclass_5 [32mPASSED[0m
2026-01-14T08:38:26.6368202Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_0_cpu [32mPASSED[0m
2026-01-14T08:38:26.6369383Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_1_cpu [32mPASSED[0m
2026-01-14T08:38:26.6370322Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_2_cpu [32mPASSED[0m
2026-01-14T08:38:26.6371235Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_3 [32mPASSED[0m
2026-01-14T08:38:26.6372385Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_4 [32mPASSED[0m
2026-01-14T08:38:26.6373280Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_2_subclass_5 [32mPASSED[0m
2026-01-14T08:38:26.6374139Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_0_cpu Autotune Choices Stats:
2026-01-14T08:38:26.6374909Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.04104000004190311}
2026-01-14T08:38:26.6375380Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:26.6375652Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:26.6375963Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:38:26.6376283Z   addmm 0.0410 ms 100.0% 
2026-01-14T08:38:26.6376518Z   bias_addmm 0.0728 ms 56.4% 
2026-01-14T08:38:26.6376996Z SingleProcess AUTOTUNE benchmarking takes 0.2540 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:38:26.6377586Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:26.6378179Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:26.6378753Z     return fn(*args, **kwargs)
2026-01-14T08:38:26.6378946Z 
2026-01-14T08:38:26.6379054Z cudagraph partition due to non gpu ops
2026-01-14T08:38:26.6379361Z [32mPASSED[0m
2026-01-14T08:38:26.6379889Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_1_cpu Autotune Choices Stats:
2026-01-14T08:38:26.6380672Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.0730899998870882}
2026-01-14T08:38:26.6381132Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:26.6381398Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:26.6381694Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:38:26.6382019Z   addmm 0.0731 ms 100.0% 
2026-01-14T08:38:26.6382250Z   bias_addmm 0.0982 ms 74.4% 
2026-01-14T08:38:26.6382730Z SingleProcess AUTOTUNE benchmarking takes 0.2536 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:38:26.6383302Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:26.6383894Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:26.6384443Z     return fn(*args, **kwargs)
2026-01-14T08:38:26.6384606Z 
2026-01-14T08:38:26.6384714Z cudagraph partition due to non gpu ops
2026-01-14T08:38:26.6385031Z [32mPASSED[0m
2026-01-14T08:38:26.6385556Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_2_cpu Autotune Choices Stats:
2026-01-14T08:38:26.6386333Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.06669100002909545}
2026-01-14T08:38:26.6386813Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:26.6387084Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:26.6387407Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:26.6395704Z   addmm 0.0667 ms 100.0% 
2026-01-14T08:38:26.6396096Z   bias_addmm 0.0915 ms 72.9% 
2026-01-14T08:38:26.6396804Z SingleProcess AUTOTUNE benchmarking takes 0.2536 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:38:26.6397403Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:26.6398229Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:26.6399030Z     return fn(*args, **kwargs)
2026-01-14T08:38:26.6399204Z 
2026-01-14T08:38:26.6399325Z cudagraph partition due to non gpu ops
2026-01-14T08:38:26.6399811Z [32mPASSED[0m
2026-01-14T08:38:26.6400352Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_3 Autotune Choices Stats:
2026-01-14T08:38:26.6401790Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_79", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:26.6403014Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:26.6403292Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:26.6403597Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:38:26.6404371Z   triton_mm_79 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:26.6405522Z   triton_mm_82 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:26.6406650Z   triton_mm_78 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:26.6407786Z   triton_mm_80 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:26.6408914Z   triton_mm_81 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:26.6410093Z   triton_mm_83 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:26.6411227Z   triton_mm_84 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:26.6412547Z   triton_mm_85 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:26.6413693Z   triton_mm_86 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:26.6414830Z   triton_mm_87 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:26.6415781Z SingleProcess AUTOTUNE benchmarking takes 0.1529 seconds and 0.2026 seconds precompiling for 12 choices
2026-01-14T08:38:26.6416353Z [32mPASSED[0m
2026-01-14T08:38:26.6416879Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_4 Autotune Choices Stats:
2026-01-14T08:38:26.6418316Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_96", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:38:26.6419459Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:26.6419730Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:26.6420040Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:38:26.6420803Z   triton_mm_96 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:26.6421938Z   triton_mm_89 0.0245 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:26.6423163Z   triton_mm_97 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:26.6424292Z   triton_mm_88 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:26.6425499Z   triton_mm_90 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:26.6426636Z   triton_mm_91 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:26.6427764Z   triton_mm_92 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:26.6428901Z   triton_mm_94 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:33.6531607Z   triton_mm_95 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:33.6532991Z   triton_mm_93 0.0266 ms 88.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:33.6534110Z SingleProcess AUTOTUNE benchmarking takes 0.1537 seconds and 0.1812 seconds precompiling for 12 choices
2026-01-14T08:38:33.6534939Z [32mPASSED[0m
2026-01-14T08:38:33.6535485Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_3_subclass_5 Autotune Choices Stats:
2026-01-14T08:38:33.6537132Z {"num_choices": 12, "num_triton_choices": 10, "best_kernel": "triton_mm_101", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:33.6538469Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:38:33.6538748Z strides: [0, 1], [64, 1], [32, 1]
2026-01-14T08:38:33.6539099Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:33.6539968Z   triton_mm_101 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:33.6541298Z   triton_mm_103 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:33.6542566Z   triton_mm_100 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:33.6543888Z   triton_mm_98 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:33.6545134Z   triton_mm_99 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:33.6546456Z   triton_mm_102 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:33.6547689Z   triton_mm_104 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:33.6549512Z   triton_mm_105 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:33.6550927Z   triton_mm_106 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:33.6552399Z   triton_mm_107 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:33.6553495Z SingleProcess AUTOTUNE benchmarking takes 0.1544 seconds and 0.1896 seconds precompiling for 12 choices
2026-01-14T08:38:33.6554123Z [32mPASSED[0m
2026-01-14T08:38:33.6554794Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6555866Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6556958Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6557977Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_3 [33mSKIPPED[0m
2026-01-14T08:38:33.6558979Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_4 [33mSKIPPED[0m
2026-01-14T08:38:33.6559989Z test/integration/test_integration.py::TestSubclass::test_aq_int8_weight_only_quant_subclass_5 [33mSKIPPED[0m
2026-01-14T08:38:33.6560986Z test/integration/test_integration.py::TestSubclass::test_autoquantizable_flatten_unflatten [32mPASSED[0m
2026-01-14T08:38:33.6561914Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6562804Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6563677Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_2_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6564550Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_3 [33mSKIPPED[0m
2026-01-14T08:38:33.6565403Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_4 [33mSKIPPED[0m
2026-01-14T08:38:33.6566241Z test/integration/test_integration.py::TestSubclass::test_gemlite_layout_5 [33mSKIPPED[0m
2026-01-14T08:38:33.6567226Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6568366Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:33.6569402Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_2_cpu Autotune Choices Stats:
2026-01-14T08:38:33.6570293Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.02986100002999592}
2026-01-14T08:38:33.6570773Z AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:38:33.6571148Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:33.6571569Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:33.6571936Z   addmm 0.0299 ms 100.0% 
2026-01-14T08:38:33.6572253Z   bias_addmm 0.0551 ms 54.2% 
2026-01-14T08:38:33.6572750Z SingleProcess AUTOTUNE benchmarking takes 0.2536 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:38:33.6573349Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6574041Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6574597Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6574768Z 
2026-01-14T08:38:33.6574922Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6575525Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6576171Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6576340Z 
2026-01-14T08:38:33.6576609Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6577205Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6577744Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6577996Z 
2026-01-14T08:38:33.6578143Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6578730Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6579279Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6579452Z 
2026-01-14T08:38:33.6579619Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6580299Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6580844Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6581012Z 
2026-01-14T08:38:33.6581158Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6581752Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6582294Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6582465Z 
2026-01-14T08:38:33.6582611Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:33.6583202Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:33.6583749Z     return fn(*args, **kwargs)
2026-01-14T08:38:33.6583916Z 
2026-01-14T08:38:33.6584066Z [32mPASSED[0m
2026-01-14T08:38:33.6584666Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:38:33.6585620Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:38:33.6586503Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_hqq_quant_subclass_api_5 Autotune Choices Stats:
2026-01-14T08:38:33.6588067Z {"num_choices": 7, "num_triton_choices": 5, "best_kernel": "triton_mm_112", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:38:33.6589207Z AUTOTUNE addmm(16x16, 16x16, 16x16)
2026-01-14T08:38:33.6589480Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:33.6589801Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:33.6590571Z   triton_mm_112 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:38:33.6591721Z   triton_mm_108 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:38:33.6592857Z   triton_mm_109 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:38:33.6593983Z   triton_mm_110 0.0267 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:38:33.6595123Z   triton_mm_111 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:38:33.6595827Z   addmm 0.0512 ms 50.0% 
2026-01-14T08:38:33.6596060Z   bias_addmm 0.0686 ms 37.3% 
2026-01-14T08:38:44.7328634Z SingleProcess AUTOTUNE benchmarking takes 0.0949 seconds and 0.1289 seconds precompiling for 7 choices
2026-01-14T08:38:44.7329729Z [32mPASSED[0m
2026-01-14T08:38:44.7330415Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:44.7332735Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:44.7333850Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_2_cpu [32mPASSED[0m
2026-01-14T08:38:44.7334779Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_3 [33mSKIPPED[0m
2026-01-14T08:38:44.7335899Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_4 [33mSKIPPED[0m
2026-01-14T08:38:44.7336922Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_5 [32mPASSED[0m
2026-01-14T08:38:44.7338002Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_0_cpu [33mSKIPPED[0m
2026-01-14T08:38:44.7339127Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_1_cpu [33mSKIPPED[0m
2026-01-14T08:38:44.7340183Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_2_cpu Autotune Choices Stats:
2026-01-14T08:38:44.7341015Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.07202100005088141}
2026-01-14T08:38:44.7341506Z AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:38:44.7341786Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:44.7342115Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:44.7342451Z   addmm 0.0720 ms 100.0% 
2026-01-14T08:38:44.7342692Z   bias_addmm 0.1031 ms 69.9% 
2026-01-14T08:38:44.7343272Z SingleProcess AUTOTUNE benchmarking takes 0.2542 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:38:44.7343953Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7344558Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7345111Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7345301Z 
2026-01-14T08:38:44.7345518Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7346110Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7346759Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7346933Z 
2026-01-14T08:38:44.7347080Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7347669Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7348215Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7348379Z 
2026-01-14T08:38:44.7348524Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7349434Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7350094Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7350265Z 
2026-01-14T08:38:44.7350410Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7351097Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7351634Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7351796Z 
2026-01-14T08:38:44.7351951Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:44.7352660Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:44.7353304Z     return fn(*args, **kwargs)
2026-01-14T08:38:44.7353486Z 
2026-01-14T08:38:44.7353629Z [32mPASSED[0m
2026-01-14T08:38:44.7354254Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_3 [33mSKIPPED[0m
2026-01-14T08:38:44.7355249Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_4 [33mSKIPPED[0m
2026-01-14T08:38:44.7356352Z test/integration/test_integration.py::TestSubclass::test_int4_weight_only_quant_subclass_api_grouped_5 Autotune Choices Stats:
2026-01-14T08:38:44.7358027Z {"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_113", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:38:44.7359437Z AUTOTUNE addmm(256x16, 256x16, 16x16)
2026-01-14T08:38:44.7359743Z strides: [0, 1], [16, 1], [1, 16]
2026-01-14T08:38:44.7360144Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:44.7360930Z   triton_mm_113 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:44.7362096Z   triton_mm_114 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:38:44.7363353Z   triton_mm_117 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:44.7364605Z   triton_mm_121 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:44.7365780Z   triton_mm_122 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:44.7366935Z   triton_mm_115 0.0266 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:38:44.7368073Z   triton_mm_116 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:44.7369220Z   triton_mm_118 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:44.7370449Z   triton_mm_119 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:44.7371762Z   triton_mm_120 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:44.7372734Z SingleProcess AUTOTUNE benchmarking takes 0.1658 seconds and 0.1424 seconds precompiling for 13 choices
2026-01-14T08:38:44.7373272Z Autotune Choices Stats:
2026-01-14T08:38:44.7374368Z {"num_choices": 13, "num_triton_choices": 11, "best_kernel": "triton_mm_160", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:44.7375702Z AUTOTUNE addmm(256x8, 256x8, 8x8)
2026-01-14T08:38:44.7375987Z strides: [0, 1], [8, 1], [1, 8]
2026-01-14T08:38:44.7376295Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:38:44.7377113Z   triton_mm_160 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:44.7378448Z   triton_mm_161 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:44.7379620Z   triton_mm_164 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:44.7380889Z   triton_mm_162 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:44.7382239Z   triton_mm_163 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:44.7383552Z   triton_mm_166 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:38:44.7384910Z   triton_mm_165 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:38:44.7386071Z   triton_mm_157 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:44.7387236Z   triton_mm_158 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:38:44.7388518Z   triton_mm_159 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:38:44.7389553Z SingleProcess AUTOTUNE benchmarking takes 0.1675 seconds and 0.1752 seconds precompiling for 13 choices
2026-01-14T08:38:44.7390187Z [32mPASSED[0m
2026-01-14T08:38:44.7390830Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_00_cpu [33mSKIPPED[0m
2026-01-14T08:38:44.7391871Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_01_cpu [33mSKIPPED[0m
2026-01-14T08:38:49.2774621Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_02_cpu [33mSKIPPED[0m
2026-01-14T08:38:49.2775668Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_03_cpu [33mSKIPPED[0m
2026-01-14T08:38:49.2776580Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_04_cpu [33mSKIPPED[0m
2026-01-14T08:38:49.2777497Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_05_cpu [33mSKIPPED[0m
2026-01-14T08:38:49.2778415Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_06 [33mSKIPPED[0m
2026-01-14T08:38:49.2779289Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_07 [33mSKIPPED[0m
2026-01-14T08:38:49.2780165Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_08 [33mSKIPPED[0m
2026-01-14T08:38:49.2781035Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_09 [33mSKIPPED[0m
2026-01-14T08:38:49.2781917Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_10 [33mSKIPPED[0m
2026-01-14T08:38:49.2782795Z test/integration/test_integration.py::TestSubclass::test_int8_dynamic_quant_subclass_api_11 [33mSKIPPED[0m
2026-01-14T08:38:49.2783757Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_0_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2784737Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2785287Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2785464Z 
2026-01-14T08:38:49.2785613Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2786207Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2786745Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2786911Z 
2026-01-14T08:38:49.2787062Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2787950Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2788498Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2788666Z 
2026-01-14T08:38:49.2788811Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2789555Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2790102Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2790265Z 
2026-01-14T08:38:49.2790411Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2790992Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2791525Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2791693Z 
2026-01-14T08:38:49.2791839Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2792427Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2792962Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2793127Z 
2026-01-14T08:38:49.2793257Z [32mPASSED[0m
2026-01-14T08:38:49.2793949Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_1_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2794920Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2795462Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2795637Z 
2026-01-14T08:38:49.2795781Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2796363Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2796902Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2797074Z 
2026-01-14T08:38:49.2797219Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2797803Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2798348Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2798511Z 
2026-01-14T08:38:49.2798661Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2799235Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2799780Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2799943Z 
2026-01-14T08:38:49.2800087Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2800667Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2801212Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2801374Z 
2026-01-14T08:38:49.2801519Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2802103Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2802642Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2802811Z 
2026-01-14T08:38:49.2802925Z [32mPASSED[0m
2026-01-14T08:38:49.2803558Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_2_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2804523Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2805068Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2805232Z 
2026-01-14T08:38:49.2805376Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2805960Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2806495Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2806668Z 
2026-01-14T08:38:49.2806814Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2807491Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2808028Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2808193Z 
2026-01-14T08:38:49.2808344Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:38:49.2808918Z    File "/opt/conda/envs/venv/lib/python3.10/site-packages/torch/_dynamo/external_utils.py", line 68, in inner
2026-01-14T08:38:49.2809539Z     return fn(*args, **kwargs)
2026-01-14T08:38:49.2809703Z 
2026-01-14T08:38:49.2809817Z [32mPASSED[0m
2026-01-14T08:38:49.2810332Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_3 Autotune Choices Stats:
2026-01-14T08:38:49.2811853Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_202", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02454400062561035, "best_triton_pos": 0}
2026-01-14T08:38:49.2813012Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:49.2813257Z strides: [64, 1], [32, 1]
2026-01-14T08:38:49.2813503Z dtypes: torch.float32, torch.float32
2026-01-14T08:38:49.2814231Z   triton_mm_202 0.0245 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:49.2815402Z   triton_mm_204 0.0245 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:49.2816549Z   triton_mm_208 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:49.2817695Z   triton_mm_207 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:49.2818841Z   triton_mm_201 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:49.2819979Z   triton_mm_203 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:49.2821130Z   triton_mm_205 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:49.2822273Z   triton_mm_206 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:49.2823408Z   triton_mm_209 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:49.2824611Z   triton_mm_210 0.0256 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:49.2825574Z SingleProcess AUTOTUNE benchmarking takes 0.1343 seconds and 0.2810 seconds precompiling for 11 choices
2026-01-14T08:38:49.2826099Z Autotune Choices Stats:
2026-01-14T08:38:49.2827182Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_211", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:49.2828301Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:49.2828548Z strides: [32, 1], [32, 1]
2026-01-14T08:38:49.2828794Z dtypes: torch.float32, torch.float32
2026-01-14T08:38:49.2829607Z   triton_mm_211 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:49.2830765Z   triton_mm_212 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:49.2831986Z   triton_mm_213 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:49.2833131Z   triton_mm_214 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8525589Z   triton_mm_215 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8526852Z   triton_mm_216 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8527587Z   mm 0.0399 ms 61.5% 
2026-01-14T08:38:57.8528057Z SingleProcess AUTOTUNE benchmarking takes 0.0893 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:57.8528811Z [32mPASSED[0m
2026-01-14T08:38:57.8529341Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_4 Autotune Choices Stats:
2026-01-14T08:38:57.8530784Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_222", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:57.8532032Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:57.8532271Z strides: [64, 1], [32, 1]
2026-01-14T08:38:57.8532525Z dtypes: torch.float16, torch.float16
2026-01-14T08:38:57.8533250Z   triton_mm_222 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8534416Z   triton_mm_223 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8535582Z   triton_mm_226 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8536726Z   triton_mm_219 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8537877Z   triton_mm_217 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:57.8539023Z   triton_mm_218 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8540175Z   triton_mm_220 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8541326Z   triton_mm_221 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8542468Z   triton_mm_224 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8543923Z   triton_mm_225 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8544970Z SingleProcess AUTOTUNE benchmarking takes 0.1437 seconds and 0.1015 seconds precompiling for 11 choices
2026-01-14T08:38:57.8545616Z Autotune Choices Stats:
2026-01-14T08:38:57.8547005Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_230", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.025567999109625816, "best_triton_pos": 0}
2026-01-14T08:38:57.8548588Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:57.8548824Z strides: [32, 1], [32, 1]
2026-01-14T08:38:57.8549266Z dtypes: torch.float16, torch.float16
2026-01-14T08:38:57.8549987Z   triton_mm_230 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8551151Z   triton_mm_227 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:57.8552301Z   triton_mm_228 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8553446Z   triton_mm_229 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8554590Z   triton_mm_231 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8555737Z   triton_mm_232 0.0256 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8556442Z   mm 0.0399 ms 64.0% 
2026-01-14T08:38:57.8556908Z SingleProcess AUTOTUNE benchmarking takes 0.0919 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:38:57.8557464Z [32mPASSED[0m
2026-01-14T08:38:57.8557990Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_subclass_api_5 Autotune Choices Stats:
2026-01-14T08:38:57.8559422Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_241", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:38:57.8560551Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:38:57.8560789Z strides: [64, 1], [32, 1]
2026-01-14T08:38:57.8561044Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:38:57.8561781Z   triton_mm_241 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8562933Z   triton_mm_234 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8564086Z   triton_mm_235 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8565237Z   triton_mm_236 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8566378Z   triton_mm_237 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8567664Z   triton_mm_239 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8568816Z   triton_mm_240 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:38:57.8569958Z   triton_mm_242 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:38:57.8571230Z   triton_mm_233 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:57.8572426Z   triton_mm_238 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8573383Z SingleProcess AUTOTUNE benchmarking takes 0.1437 seconds and 0.0980 seconds precompiling for 11 choices
2026-01-14T08:38:57.8573919Z Autotune Choices Stats:
2026-01-14T08:38:57.8575005Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_243", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:38:57.8576182Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:38:57.8576418Z strides: [32, 1], [32, 1]
2026-01-14T08:38:57.8576670Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:38:57.8577405Z   triton_mm_243 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:38:57.8578563Z   triton_mm_244 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:38:57.8579718Z   triton_mm_245 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:38:57.8580876Z   triton_mm_246 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9345522Z   triton_mm_248 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:25.9346802Z   triton_mm_247 0.0266 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:25.9347817Z   mm 0.0399 ms 64.1% 
2026-01-14T08:39:25.9348499Z SingleProcess AUTOTUNE benchmarking takes 0.0876 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:25.9349568Z [32mPASSED[0m
2026-01-14T08:39:25.9350371Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_0_cpu Autotune Choices Stats:
2026-01-14T08:39:25.9351561Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_0", "best_time": 0.005940000164628145}
2026-01-14T08:39:25.9352183Z AUTOTUNE packed_linear(32x64, 1459233x1, 32x64)
2026-01-14T08:39:25.9352491Z strides: [64, 1], [1, 0], [64, 1]
2026-01-14T08:39:25.9352888Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:39:25.9360886Z   cpp_CppMicroGemmFP32Vec_0 0.0059 ms 100.0% 
2026-01-14T08:39:25.9361205Z   _mkl_linear 0.0267 ms 22.2% 
2026-01-14T08:39:25.9361699Z SingleProcess AUTOTUNE benchmarking takes 0.2475 seconds and 2.4050 seconds precompiling for 2 choices
2026-01-14T08:39:25.9362224Z Autotune Choices Stats:
2026-01-14T08:39:25.9362730Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_1", "best_time": 0.0059300000430084765}
2026-01-14T08:39:25.9363589Z AUTOTUNE packed_linear(32x32, 1459233x1, 32x32)
2026-01-14T08:39:25.9363895Z strides: [32, 1], [1, 0], [32, 1]
2026-01-14T08:39:25.9364201Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:39:25.9364548Z   cpp_CppMicroGemmFP32Vec_1 0.0059 ms 100.0% 
2026-01-14T08:39:25.9364848Z   _mkl_linear 0.0266 ms 22.3% 
2026-01-14T08:39:25.9365492Z SingleProcess AUTOTUNE benchmarking takes 0.2475 seconds and 2.3919 seconds precompiling for 2 choices
2026-01-14T08:39:25.9366079Z [32mPASSED[0m
2026-01-14T08:39:25.9366619Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_1_cpu Autotune Choices Stats:
2026-01-14T08:39:25.9367480Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_2", "best_time": 0.006649999932051287}
2026-01-14T08:39:25.9368032Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:25.9368259Z strides: [64, 1], [1, 64]
2026-01-14T08:39:25.9368507Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:25.9368814Z   cpp_CppMicroGemmFP32Vec_2 0.0066 ms 100.0% 
2026-01-14T08:39:25.9369105Z   mm 0.0316 ms 21.0% 
2026-01-14T08:39:25.9369564Z SingleProcess AUTOTUNE benchmarking takes 0.2523 seconds and 2.6103 seconds precompiling for 2 choices
2026-01-14T08:39:25.9370084Z Autotune Choices Stats:
2026-01-14T08:39:25.9370588Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_3", "best_time": 0.00641999986328301}
2026-01-14T08:39:25.9371119Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:25.9371435Z strides: [32, 1], [1, 32]
2026-01-14T08:39:25.9371676Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:25.9371986Z   cpp_CppMicroGemmFP32Vec_3 0.0064 ms 100.0% 
2026-01-14T08:39:25.9372270Z   mm 0.0311 ms 20.7% 
2026-01-14T08:39:25.9372731Z SingleProcess AUTOTUNE benchmarking takes 0.2525 seconds and 2.6201 seconds precompiling for 2 choices
2026-01-14T08:39:25.9373282Z [32mPASSED[0m
2026-01-14T08:39:25.9373803Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_2_cpu Autotune Choices Stats:
2026-01-14T08:39:25.9374662Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_4", "best_time": 0.00718100000085542}
2026-01-14T08:39:25.9375229Z AUTOTUNE _weight_int8pack_mm(32x64, 32x64, 32)
2026-01-14T08:39:25.9375532Z strides: [64, 1], [64, 1], [1]
2026-01-14T08:39:25.9375824Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:39:25.9376179Z   cpp_CppMicroGemmFP32Vec_4 0.0072 ms 100.0% 
2026-01-14T08:39:25.9376486Z   _weight_int8pack_mm 0.0186 ms 38.7% 
2026-01-14T08:39:25.9376986Z SingleProcess AUTOTUNE benchmarking takes 0.2480 seconds and 2.5620 seconds precompiling for 2 choices
2026-01-14T08:39:25.9377503Z Autotune Choices Stats:
2026-01-14T08:39:25.9377993Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "cpp_CppMicroGemmFP32Vec_5", "best_time": 0.007040999889795785}
2026-01-14T08:39:25.9378572Z AUTOTUNE _weight_int8pack_mm(32x32, 32x32, 32)
2026-01-14T08:39:25.9378866Z strides: [32, 1], [32, 1], [1]
2026-01-14T08:39:25.9379162Z dtypes: torch.bfloat16, torch.int8, torch.bfloat16
2026-01-14T08:39:25.9379512Z   cpp_CppMicroGemmFP32Vec_5 0.0070 ms 100.0% 
2026-01-14T08:39:25.9379815Z   _weight_int8pack_mm 0.0175 ms 40.2% 
2026-01-14T08:39:25.9380328Z SingleProcess AUTOTUNE benchmarking takes 0.2478 seconds and 2.5709 seconds precompiling for 2 choices
2026-01-14T08:39:25.9380867Z [32mPASSED[0m
2026-01-14T08:39:25.9381378Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_3 Autotune Choices Stats:
2026-01-14T08:39:25.9382867Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_258", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:25.9384009Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:25.9384247Z strides: [64, 1], [1, 64]
2026-01-14T08:39:25.9384582Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:25.9385310Z   triton_mm_258 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:25.9386472Z   triton_mm_252 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:25.9387707Z   triton_mm_250 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9388852Z   triton_mm_254 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9390005Z   triton_mm_255 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:25.9391152Z   triton_mm_249 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:25.9392299Z   triton_mm_251 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:25.9393445Z   triton_mm_253 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9394595Z   triton_mm_256 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:25.9395756Z   triton_mm_257 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:25.9396708Z SingleProcess AUTOTUNE benchmarking takes 0.1363 seconds and 0.3072 seconds precompiling for 11 choices
2026-01-14T08:39:25.9397238Z Autotune Choices Stats:
2026-01-14T08:39:25.9398329Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_259", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:39:25.9399454Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:25.9399691Z strides: [32, 1], [1, 32]
2026-01-14T08:39:25.9399936Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:25.9400657Z   triton_mm_259 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:25.9401829Z   triton_mm_260 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9402976Z   triton_mm_261 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:25.9404141Z   triton_mm_262 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:25.9405292Z   triton_mm_263 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:25.9406440Z   triton_mm_264 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:25.9407239Z   mm 0.0379 ms 67.6% 
2026-01-14T08:39:25.9407694Z SingleProcess AUTOTUNE benchmarking takes 0.0873 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:25.9408259Z [32mPASSED[0m
2026-01-14T08:39:25.9408768Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_4 Autotune Choices Stats:
2026-01-14T08:39:25.9410281Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_273", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:39:25.9411453Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:25.9411680Z strides: [64, 1], [1, 64]
2026-01-14T08:39:25.9411930Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:29.8478771Z   triton_mm_273 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8480319Z   triton_mm_265 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:29.8481826Z   triton_mm_268 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8483299Z   triton_mm_271 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8484769Z   triton_mm_272 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8486245Z   triton_mm_274 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8487706Z   triton_mm_266 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8489179Z   triton_mm_267 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8490653Z   triton_mm_269 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8492223Z   triton_mm_270 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8493514Z SingleProcess AUTOTUNE benchmarking takes 0.1449 seconds and 0.1094 seconds precompiling for 11 choices
2026-01-14T08:39:29.8494184Z Autotune Choices Stats:
2026-01-14T08:39:29.8495573Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_278", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:39:29.8497038Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:29.8497325Z strides: [32, 1], [1, 32]
2026-01-14T08:39:29.8497647Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:29.8498553Z   triton_mm_278 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8500026Z   triton_mm_277 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8501809Z   triton_mm_275 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:29.8503278Z   triton_mm_276 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8504902Z   triton_mm_279 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8506358Z   triton_mm_280 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8507261Z   mm 0.0399 ms 61.5% 
2026-01-14T08:39:29.8507837Z SingleProcess AUTOTUNE benchmarking takes 0.0880 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:29.8508723Z [32mPASSED[0m
2026-01-14T08:39:29.8509391Z test/integration/test_integration.py::TestSubclass::test_int8_weight_only_quant_with_freeze_5 Autotune Choices Stats:
2026-01-14T08:39:29.8511221Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_283", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:39:29.8512675Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:39:29.8512963Z strides: [64, 1], [32, 1]
2026-01-14T08:39:29.8513269Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:29.8514189Z   triton_mm_283 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8515795Z   triton_mm_288 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8516959Z   triton_mm_289 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8518122Z   triton_mm_282 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8519268Z   triton_mm_284 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8520418Z   triton_mm_285 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8521574Z   triton_mm_286 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8522719Z   triton_mm_287 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8523872Z   triton_mm_290 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8525029Z   triton_mm_281 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:29.8525986Z SingleProcess AUTOTUNE benchmarking takes 0.1416 seconds and 0.1092 seconds precompiling for 11 choices
2026-01-14T08:39:29.8526515Z Autotune Choices Stats:
2026-01-14T08:39:29.8527690Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_291", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:39:29.8528815Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:39:29.8529136Z strides: [32, 1], [32, 1]
2026-01-14T08:39:29.8529386Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:29.8530123Z   triton_mm_291 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:29.8531283Z   triton_mm_292 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8532581Z   triton_mm_293 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:29.8533790Z   triton_mm_294 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:29.8534941Z   triton_mm_295 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:29.8536104Z   triton_mm_296 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:29.8536818Z   mm 0.0399 ms 64.1% 
2026-01-14T08:39:29.8537277Z SingleProcess AUTOTUNE benchmarking takes 0.0873 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:39:29.8537851Z [32mPASSED[0m
2026-01-14T08:39:29.8538341Z test/integration/test_integration.py::TestDynamicQuant::test_dynamic_quant [32mPASSED[0m
2026-01-14T08:39:29.8539260Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_embedding_quant [32mPASSED[0m
2026-01-14T08:39:29.8540259Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_groupwise_quant [32mPASSED[0m
2026-01-14T08:39:29.8541157Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant [32mPASSED[0m
2026-01-14T08:39:37.9456080Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:39:37.9457191Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:39:37.9458219Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:39:37.9459174Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_3 Autotune Choices Stats:
2026-01-14T08:39:37.9460679Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_299", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:37.9461924Z AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:37.9462151Z strides: [4, 1], [5, 1]
2026-01-14T08:39:37.9462391Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:37.9463134Z   triton_mm_299 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:37.9464307Z   triton_mm_301 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:37.9465772Z   triton_mm_297 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:37.9466936Z   triton_mm_298 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:37.9468256Z   triton_mm_300 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:37.9468962Z   mm 0.0369 ms 63.9% 
2026-01-14T08:39:37.9469432Z SingleProcess AUTOTUNE benchmarking takes 0.0759 seconds and 0.1664 seconds precompiling for 6 choices
2026-01-14T08:39:37.9469958Z Autotune Choices Stats:
2026-01-14T08:39:37.9471057Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_306", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:37.9472189Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:37.9472415Z strides: [4, 1], [5, 1]
2026-01-14T08:39:37.9472660Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:37.9473387Z   triton_mm_306 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:37.9474569Z   triton_mm_311 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:39:37.9475747Z   triton_mm_308 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:37.9476908Z   triton_mm_312 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:37.9478069Z   triton_mm_302 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:37.9479237Z   triton_mm_303 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:39:37.9480386Z   triton_mm_304 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:37.9481542Z   triton_mm_305 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:37.9482709Z   triton_mm_307 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:37.9483863Z   triton_mm_309 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:37.9484836Z SingleProcess AUTOTUNE benchmarking takes 0.1495 seconds and 0.2001 seconds precompiling for 12 choices
2026-01-14T08:39:37.9485359Z Autotune Choices Stats:
2026-01-14T08:39:37.9486452Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_317", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:39:37.9487575Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:37.9487797Z strides: [4, 1], [5, 1]
2026-01-14T08:39:37.9488043Z dtypes: torch.float32, torch.float32
2026-01-14T08:39:37.9488846Z   triton_mm_317 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:37.9490014Z   triton_mm_314 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:37.9491258Z   triton_mm_313 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:37.9492482Z   triton_mm_315 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:37.9493645Z   triton_mm_316 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:37.9494357Z   mm 0.0369 ms 66.7% 
2026-01-14T08:39:37.9494852Z SingleProcess AUTOTUNE benchmarking takes 0.0761 seconds and 0.2199 seconds precompiling for 6 choices
2026-01-14T08:39:37.9495449Z [32mPASSED[0m
2026-01-14T08:39:37.9496008Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_4 Autotune Choices Stats:
2026-01-14T08:39:37.9497495Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_322", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:37.9498618Z AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:37.9498853Z strides: [4, 1], [5, 1]
2026-01-14T08:39:37.9499095Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:37.9499839Z   triton_mm_322 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:37.9501006Z   triton_mm_321 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:37.9502163Z   triton_mm_318 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:37.9503322Z   triton_mm_319 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:37.9504483Z   triton_mm_320 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:37.9505196Z   mm 0.0430 ms 54.8% 
2026-01-14T08:39:37.9505671Z SingleProcess AUTOTUNE benchmarking takes 0.0757 seconds and 0.2210 seconds precompiling for 6 choices
2026-01-14T08:39:37.9506198Z Autotune Choices Stats:
2026-01-14T08:39:37.9507296Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_333", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:37.9508434Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:37.9508655Z strides: [4, 1], [5, 1]
2026-01-14T08:39:37.9508902Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:37.9509634Z   triton_mm_333 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:37.9510896Z   triton_mm_323 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:39:44.8102979Z   triton_mm_324 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:39:44.8104539Z   triton_mm_325 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:44.8105717Z   triton_mm_330 0.0255 ms 92.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:44.8106880Z   triton_mm_328 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:44.8108051Z   triton_mm_326 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:44.8109211Z   triton_mm_327 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:44.8110367Z   triton_mm_329 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:44.8111532Z   triton_mm_331 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:39:44.8112503Z SingleProcess AUTOTUNE benchmarking takes 0.1495 seconds and 0.1389 seconds precompiling for 12 choices
2026-01-14T08:39:44.8113031Z Autotune Choices Stats:
2026-01-14T08:39:44.8114152Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_335", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:44.8115304Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:44.8115530Z strides: [4, 1], [5, 1]
2026-01-14T08:39:44.8115783Z dtypes: torch.float16, torch.float16
2026-01-14T08:39:44.8116560Z   triton_mm_335 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:44.8117728Z   triton_mm_336 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:44.8118887Z   triton_mm_337 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:44.8120037Z   triton_mm_338 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:44.8121190Z   triton_mm_334 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:44.8121906Z   mm 0.0440 ms 53.5% 
2026-01-14T08:39:44.8122363Z SingleProcess AUTOTUNE benchmarking takes 0.0757 seconds and 0.1294 seconds precompiling for 6 choices
2026-01-14T08:39:44.8123112Z [32mPASSED[0m
2026-01-14T08:39:44.8123684Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_force_mixed_mm_5 Autotune Choices Stats:
2026-01-14T08:39:44.8125328Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_343", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:44.8126460Z AUTOTUNE mm(2x4, 4x5)
2026-01-14T08:39:44.8126682Z strides: [4, 1], [5, 1]
2026-01-14T08:39:44.8126932Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:44.8127742Z   triton_mm_343 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:44.8128911Z   triton_mm_341 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:39:44.8130067Z   triton_mm_342 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:39:44.8131224Z   triton_mm_339 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:44.8132461Z   triton_mm_340 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:44.8133177Z   mm 0.0369 ms 63.9% 
2026-01-14T08:39:44.8133638Z SingleProcess AUTOTUNE benchmarking takes 0.0749 seconds and 0.1324 seconds precompiling for 6 choices
2026-01-14T08:39:44.8134162Z Autotune Choices Stats:
2026-01-14T08:39:44.8135248Z {"num_choices": 12, "num_triton_choices": 11, "best_kernel": "triton_mm_350", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:39:44.8136379Z AUTOTUNE mm(125x4, 4x5)
2026-01-14T08:39:44.8136605Z strides: [4, 1], [5, 1]
2026-01-14T08:39:44.8136859Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:44.8137595Z   triton_mm_350 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:39:44.8138759Z   triton_mm_347 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:39:44.8139917Z   triton_mm_348 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:39:44.8141082Z   triton_mm_353 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:39:44.8142247Z   triton_mm_352 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:39:44.8143412Z   triton_mm_349 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:44.8144575Z   triton_mm_345 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:39:44.8145725Z   triton_mm_346 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:39:44.8146942Z   triton_mm_351 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:39:44.8148185Z   triton_mm_354 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=128, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:39:44.8149409Z SingleProcess AUTOTUNE benchmarking takes 0.1504 seconds and 0.1511 seconds precompiling for 12 choices
2026-01-14T08:39:44.8149939Z Autotune Choices Stats:
2026-01-14T08:39:44.8151149Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_356", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:39:44.8152277Z AUTOTUNE mm(4x4, 4x5)
2026-01-14T08:39:44.8152502Z strides: [4, 1], [5, 1]
2026-01-14T08:39:44.8152749Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:39:44.8153486Z   triton_mm_356 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=1
2026-01-14T08:39:44.8154656Z   triton_mm_359 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=1
2026-01-14T08:39:44.8155814Z   triton_mm_355 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=1
2026-01-14T08:39:44.8156986Z   triton_mm_357 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=1
2026-01-14T08:40:04.2742112Z   triton_mm_358 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=16, EVEN_K=False, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=1
2026-01-14T08:40:04.2743415Z   mm 0.0369 ms 66.7% 
2026-01-14T08:40:04.2744223Z SingleProcess AUTOTUNE benchmarking takes 0.0754 seconds and 0.1553 seconds precompiling for 6 choices
2026-01-14T08:40:04.2745355Z [32mPASSED[0m
2026-01-14T08:40:04.2746454Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2748211Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2750179Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2751860Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_3 [32mPASSED[0m
2026-01-14T08:40:04.2753488Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_4 [32mPASSED[0m
2026-01-14T08:40:04.2755240Z test/integration/test_integration.py::TestWeightOnlyInt8Quant::test_weight_only_quant_use_mixed_mm_5 [32mPASSED[0m
2026-01-14T08:40:04.2756832Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2758260Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2759756Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2761115Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_3 Autotune Choices Stats:
2026-01-14T08:40:04.2763468Z {"num_choices": 5, "num_triton_choices": 4, "best_kernel": "triton_mm_431", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:04.2765417Z AUTOTUNE int_mm(32x32, 32x32)
2026-01-14T08:40:04.2765801Z strides: [32, 1], [1, 32]
2026-01-14T08:40:04.2766164Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:04.2767632Z   triton_mm_431 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:04.2769613Z   triton_mm_428 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:04.2772086Z   triton_mm_429 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:04.2774079Z   triton_mm_430 0.0256 ms 96.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:04.2775281Z   _int_mm 0.0369 ms 66.7% 
2026-01-14T08:40:04.2776068Z SingleProcess AUTOTUNE benchmarking takes 0.0633 seconds and 0.0847 seconds precompiling for 5 choices
2026-01-14T08:40:04.2776957Z Autotune Choices Stats:
2026-01-14T08:40:04.2778834Z {"num_choices": 6, "num_triton_choices": 5, "best_kernel": "triton_mm_426", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:04.2780769Z AUTOTUNE int_mm(32x64, 64x32)
2026-01-14T08:40:04.2781187Z strides: [64, 1], [1, 64]
2026-01-14T08:40:04.2781592Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:04.2782785Z   triton_mm_426 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:04.2784778Z   triton_mm_424 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:04.2786797Z   triton_mm_425 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:04.2788635Z   triton_mm_427 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:04.2790654Z   triton_mm_423 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:04.2791882Z   _int_mm 0.0369 ms 63.8% 
2026-01-14T08:40:04.2792678Z SingleProcess AUTOTUNE benchmarking takes 0.0727 seconds and 0.0002 seconds precompiling for 6 choices
2026-01-14T08:40:04.2793633Z [32mPASSED[0m
2026-01-14T08:40:04.2794562Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_4 [32mPASSED[0m
2026-01-14T08:40:04.2796007Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_dqtensors_5 [32mPASSED[0m
2026-01-14T08:40:04.2797572Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2799143Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:04.2800607Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_2_cpu Autotune Choices Stats:
2026-01-14T08:40:04.2801983Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.038441000015154714}
2026-01-14T08:40:04.2802798Z AUTOTUNE addmm(32x32, 32x64, 64x32)
2026-01-14T08:40:04.2803254Z strides: [0, 1], [64, 1], [1, 64]
2026-01-14T08:40:04.2803779Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:04.2804282Z   addmm 0.0384 ms 100.0% 
2026-01-14T08:40:04.2804625Z   bias_addmm 0.0623 ms 61.7% 
2026-01-14T08:40:04.2805357Z SingleProcess AUTOTUNE benchmarking takes 0.2546 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:40:04.2806335Z Autotune Choices Stats:
2026-01-14T08:40:04.2807014Z {"num_choices": 2, "num_triton_choices": 0, "best_kernel": "addmm", "best_time": 0.03809000008914154}
2026-01-14T08:40:04.2807790Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:40:04.2808233Z strides: [0, 1], [32, 1], [1, 32]
2026-01-14T08:40:04.2808888Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:04.2809459Z   addmm 0.0381 ms 100.0% 
2026-01-14T08:40:04.2809817Z   bias_addmm 0.0616 ms 61.8% 
2026-01-14T08:40:04.2810646Z SingleProcess AUTOTUNE benchmarking takes 0.2543 seconds and 0.0001 seconds precompiling for 2 choices
2026-01-14T08:40:04.2811742Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:04.2812565Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:04.2813258Z     x = self.lin1(x)
2026-01-14T08:40:04.2813487Z 
2026-01-14T08:40:04.2813724Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:04.2814558Z    File "/pytorch/ao/test/integration/test_integration.py", line 878, in forward
2026-01-14T08:40:04.2815244Z     x = self.relu(x)
2026-01-14T08:40:04.2815461Z 
2026-01-14T08:40:04.2815711Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:04.2816497Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:04.2817216Z     x = self.lin2(x)
2026-01-14T08:40:04.2817445Z 
2026-01-14T08:40:04.2817672Z [32mPASSED[0m
2026-01-14T08:40:04.2818594Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_3 [33mSKIPPED[0m
2026-01-14T08:40:04.2820145Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_4 [33mSKIPPED[0m
2026-01-14T08:40:04.2821504Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int4woqtensors_5 Autotune Choices Stats:
2026-01-14T08:40:04.2823890Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_450", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:04.2825786Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:04.2826180Z strides: [64, 1], [1, 64]
2026-01-14T08:40:04.2826620Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:40:04.2827837Z   triton_mm_450 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:04.2829815Z   triton_mm_451 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:04.2831815Z   triton_mm_452 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:04.2833887Z   triton_mm_453 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:04.2835698Z   triton_mm_454 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:04.2837381Z   triton_mm_455 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:04.2839099Z   triton_mm_456 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:04.2840903Z   triton_mm_457 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:09.0372521Z   triton_mm_458 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:09.0373763Z   triton_mm_459 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:09.0374902Z SingleProcess AUTOTUNE benchmarking takes 0.1435 seconds and 0.0929 seconds precompiling for 11 choices
2026-01-14T08:40:09.0375434Z Autotune Choices Stats:
2026-01-14T08:40:09.0376521Z {"num_choices": 8, "num_triton_choices": 6, "best_kernel": "triton_mm_462", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:09.0377741Z AUTOTUNE addmm(32x32, 32x32, 32x32)
2026-01-14T08:40:09.0378037Z strides: [0, 1], [32, 1], [1, 32]
2026-01-14T08:40:09.0378359Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:09.0379151Z   triton_mm_462 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:09.0388321Z   triton_mm_460 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:09.0389556Z   triton_mm_461 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:09.0390710Z   triton_mm_463 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:09.0391869Z   triton_mm_464 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:09.0393023Z   triton_mm_465 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:09.0393741Z   addmm 0.0522 ms 47.1% 
2026-01-14T08:40:09.0393984Z   bias_addmm 0.0727 ms 33.8% 
2026-01-14T08:40:09.0394473Z SingleProcess AUTOTUNE benchmarking takes 0.1057 seconds and 0.0002 seconds precompiling for 8 choices
2026-01-14T08:40:09.0395215Z [32mPASSED[0m
2026-01-14T08:40:09.0395852Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_0_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0396705Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:09.0397136Z     x = self.lin1(x)
2026-01-14T08:40:09.0397274Z 
2026-01-14T08:40:09.0397429Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0397906Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0398320Z     x = self.lin2(x)
2026-01-14T08:40:09.0398464Z 
2026-01-14T08:40:09.0398611Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0399080Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:09.0399501Z     x = self.lin1(x)
2026-01-14T08:40:09.0399635Z 
2026-01-14T08:40:09.0399794Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0400256Z    File "/pytorch/ao/test/integration/test_integration.py", line 878, in forward
2026-01-14T08:40:09.0400677Z     x = self.relu(x)
2026-01-14T08:40:09.0400810Z 
2026-01-14T08:40:09.0400955Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0401425Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0401838Z     x = self.lin2(x)
2026-01-14T08:40:09.0402104Z 
2026-01-14T08:40:09.0402252Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0402724Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0403136Z     x = self.lin2(x)
2026-01-14T08:40:09.0403362Z 
2026-01-14T08:40:09.0403485Z [32mPASSED[0m
2026-01-14T08:40:09.0404103Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_1_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0404932Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:09.0405357Z     x = self.lin1(x)
2026-01-14T08:40:09.0405494Z 
2026-01-14T08:40:09.0405639Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0406114Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0406527Z     x = self.lin2(x)
2026-01-14T08:40:09.0406668Z 
2026-01-14T08:40:09.0406819Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0407280Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:09.0407701Z     x = self.lin1(x)
2026-01-14T08:40:09.0407836Z 
2026-01-14T08:40:09.0407986Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0408451Z    File "/pytorch/ao/test/integration/test_integration.py", line 878, in forward
2026-01-14T08:40:09.0408871Z     x = self.relu(x)
2026-01-14T08:40:09.0409005Z 
2026-01-14T08:40:09.0409150Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0409621Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0410038Z     x = self.lin2(x)
2026-01-14T08:40:09.0410175Z 
2026-01-14T08:40:09.0410320Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0410789Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0411206Z     x = self.lin2(x)
2026-01-14T08:40:09.0411448Z 
2026-01-14T08:40:09.0411579Z [32mPASSED[0m
2026-01-14T08:40:09.0412192Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_2_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0413021Z    File "/pytorch/ao/test/integration/test_integration.py", line 877, in forward
2026-01-14T08:40:09.0413441Z     x = self.lin1(x)
2026-01-14T08:40:09.0413583Z 
2026-01-14T08:40:09.0413728Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0414198Z    File "/pytorch/ao/test/integration/test_integration.py", line 878, in forward
2026-01-14T08:40:09.0414610Z     x = self.relu(x)
2026-01-14T08:40:09.0414744Z 
2026-01-14T08:40:09.0414896Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0415356Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0415780Z     x = self.lin2(x)
2026-01-14T08:40:09.0415914Z 
2026-01-14T08:40:09.0416061Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:40:09.0416530Z    File "/pytorch/ao/test/integration/test_integration.py", line 879, in forward
2026-01-14T08:40:09.0416950Z     x = self.lin2(x)
2026-01-14T08:40:09.0417082Z 
2026-01-14T08:40:09.0417196Z [32mPASSED[0m
2026-01-14T08:40:09.0417693Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_3 Autotune Choices Stats:
2026-01-14T08:40:09.0419121Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_469", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:09.0420265Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:09.0420512Z strides: [64, 1], [32, 1]
2026-01-14T08:40:09.0420762Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:09.0421639Z   triton_mm_469 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:09.0422808Z   triton_mm_466 0.0255 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:09.0424048Z   triton_mm_467 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:09.0425205Z   triton_mm_468 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:09.0426357Z   triton_mm_470 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:09.0427520Z   triton_mm_471 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:09.0428681Z   triton_mm_472 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:09.0429837Z   triton_mm_473 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:09.0430993Z   triton_mm_474 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:09.0432155Z   triton_mm_475 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:09.0433120Z SingleProcess AUTOTUNE benchmarking takes 0.1387 seconds and 0.3249 seconds precompiling for 11 choices
2026-01-14T08:40:09.0433654Z Autotune Choices Stats:
2026-01-14T08:40:09.0434739Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_477", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:40:09.0435869Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:40:09.0436109Z strides: [32, 1], [32, 1]
2026-01-14T08:40:09.0436357Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:09.0437088Z   triton_mm_477 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9309879Z   triton_mm_478 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:12.9311485Z   triton_mm_479 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9312663Z   triton_mm_481 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:12.9313827Z   triton_mm_480 0.0266 ms 96.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:12.9314983Z   triton_mm_476 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:12.9315701Z   mm 0.0389 ms 65.8% 
2026-01-14T08:40:12.9316474Z SingleProcess AUTOTUNE benchmarking takes 0.0893 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:40:12.9317221Z [32mPASSED[0m
2026-01-14T08:40:12.9317738Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_4 Autotune Choices Stats:
2026-01-14T08:40:12.9319175Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_485", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.025599999353289604, "best_triton_pos": 0}
2026-01-14T08:40:12.9321327Z AUTOTUNE mm(32x64, 64x32)
2026-01-14T08:40:12.9321574Z strides: [64, 1], [32, 1]
2026-01-14T08:40:12.9321836Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:12.9322568Z   triton_mm_485 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:12.9323745Z   triton_mm_487 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9324907Z   triton_mm_489 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:12.9326064Z   triton_mm_490 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:12.9327229Z   triton_mm_491 0.0256 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:12.9328384Z   triton_mm_488 0.0266 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:12.9329531Z   triton_mm_486 0.0276 ms 92.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9330682Z   triton_mm_482 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:12.9331965Z   triton_mm_483 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9333111Z   triton_mm_484 0.0287 ms 89.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:12.9334071Z SingleProcess AUTOTUNE benchmarking takes 0.1478 seconds and 0.0683 seconds precompiling for 11 choices
2026-01-14T08:40:12.9334594Z Autotune Choices Stats:
2026-01-14T08:40:12.9335680Z {"num_choices": 7, "num_triton_choices": 6, "best_kernel": "triton_mm_492", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:12.9336813Z AUTOTUNE mm(32x32, 32x32)
2026-01-14T08:40:12.9337044Z strides: [32, 1], [32, 1]
2026-01-14T08:40:12.9337292Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:12.9338005Z   triton_mm_492 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:12.9339166Z   triton_mm_493 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9340411Z   triton_mm_494 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:12.9341565Z   triton_mm_497 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:12.9342791Z   triton_mm_496 0.0255 ms 96.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:12.9343939Z   triton_mm_495 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9344641Z   mm 0.0410 ms 60.0% 
2026-01-14T08:40:12.9345104Z SingleProcess AUTOTUNE benchmarking takes 0.0879 seconds and 0.0002 seconds precompiling for 7 choices
2026-01-14T08:40:12.9345664Z [32mPASSED[0m
2026-01-14T08:40:12.9346226Z test/integration/test_integration.py::TestSaveLoadMeta::test_save_load_int8woqtensors_5 [32mPASSED[0m
2026-01-14T08:40:12.9347013Z test/integration/test_integration.py::UtilsUnitTest::test_shape_logger [32mPASSED[0m
2026-01-14T08:40:12.9347794Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_00_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9348628Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_01_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9349793Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_02_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9350611Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_03_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9351423Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_04_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9352245Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_05_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9353111Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_06_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9353924Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_07_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9354738Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_08_cpu [33mSKIPPED[0m
2026-01-14T08:40:12.9355538Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_09 [33mSKIPPED[0m
2026-01-14T08:40:12.9356326Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_10 [33mSKIPPED[0m
2026-01-14T08:40:12.9357173Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_11 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:12.9357973Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:12.9358426Z Autotune Choices Stats:
2026-01-14T08:40:12.9359512Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_517", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:40:12.9360654Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:12.9360943Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:12.9361251Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:40:12.9362020Z   triton_mm_517 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:12.9363226Z   triton_mm_514 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:12.9364584Z   triton_mm_515 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:12.9365743Z   triton_mm_523 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:12.9366886Z   triton_mm_516 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:12.9368156Z   triton_mm_519 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:22.6982499Z   triton_mm_520 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:22.6983927Z   triton_mm_524 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:22.6985093Z   triton_mm_521 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.6986255Z   triton_mm_518 0.0297 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:22.6987231Z SingleProcess AUTOTUNE benchmarking takes 0.1804 seconds and 0.6348 seconds precompiling for 14 choices
2026-01-14T08:40:22.6988008Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:22.6988541Z Autotune Choices Stats:
2026-01-14T08:40:22.6989651Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_536", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:22.6990809Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:22.6991067Z strides: [128, 1], [128, 1]
2026-01-14T08:40:22.6991328Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:22.6992057Z   triton_mm_536 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:22.6993221Z   triton_mm_531 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:22.6994363Z   triton_mm_526 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:22.6995521Z   triton_mm_530 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:22.6996673Z   triton_mm_534 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:22.6997826Z   triton_mm_528 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:22.6998976Z   triton_mm_529 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:22.7000136Z   triton_mm_532 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:22.7001583Z   triton_mm_533 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7002746Z   triton_mm_535 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7003873Z SingleProcess AUTOTUNE benchmarking takes 0.1657 seconds and 0.6482 seconds precompiling for 13 choices
2026-01-14T08:40:22.7004794Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.011ms 
2026-01-14T08:40:22.7005774Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.011ms 
2026-01-14T08:40:22.7006410Z Autotune Choices Stats:
2026-01-14T08:40:22.7007510Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_545", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:22.7008646Z AUTOTUNE int_mm(32x128, 128x128)
2026-01-14T08:40:22.7008902Z strides: [128, 1], [1, 128]
2026-01-14T08:40:22.7009161Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:22.7009861Z   triton_mm_545 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:22.7011001Z   triton_mm_538 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:22.7012275Z   triton_mm_539 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7013410Z   triton_mm_540 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7014554Z   triton_mm_541 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:22.7015718Z   triton_mm_542 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:22.7016843Z   triton_mm_543 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:22.7017964Z   triton_mm_546 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:22.7019097Z   triton_mm_547 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:22.7020239Z   triton_mm_544 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:22.7021189Z SingleProcess AUTOTUNE benchmarking takes 0.1385 seconds and 0.1894 seconds precompiling for 11 choices
2026-01-14T08:40:22.7022081Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.011ms
2026-01-14T08:40:22.7023094Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.029ms 
2026-01-14T08:40:22.7024159Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.50
2026-01-14T08:40:22.7025210Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:40:22.7025657Z 
2026-01-14T08:40:22.7025970Z [32mPASSED[0m
2026-01-14T08:40:22.7026505Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_12 [33mSKIPPED[0m
2026-01-14T08:40:22.7027302Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_13 [33mSKIPPED[0m
2026-01-14T08:40:22.7028240Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_14 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:22.7029036Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:40:22.7029494Z Autotune Choices Stats:
2026-01-14T08:40:22.7030593Z {"num_choices": 16, "num_triton_choices": 14, "best_kernel": "triton_mm_565", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:22.7031737Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:22.7032021Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:22.7032327Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:40:22.7033096Z   triton_mm_565 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:22.7034261Z   triton_mm_566 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7035485Z   triton_mm_568 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7036647Z   triton_mm_569 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:22.7037790Z   triton_mm_558 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:29.5305466Z   triton_mm_562 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:29.5306787Z   triton_mm_567 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5307943Z   triton_mm_561 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:29.5309130Z   triton_mm_559 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:29.5310282Z   triton_mm_560 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:29.5311258Z SingleProcess AUTOTUNE benchmarking takes 0.2026 seconds and 0.2505 seconds precompiling for 16 choices
2026-01-14T08:40:29.5312032Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:29.5312560Z Autotune Choices Stats:
2026-01-14T08:40:29.5313662Z {"num_choices": 15, "num_triton_choices": 14, "best_kernel": "triton_mm_577", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.021503999829292297, "best_triton_pos": 0}
2026-01-14T08:40:29.5314817Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:29.5315350Z strides: [128, 1], [128, 1]
2026-01-14T08:40:29.5315617Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:29.5316340Z   triton_mm_577 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:29.5317669Z   triton_mm_583 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5318827Z   triton_mm_580 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5319979Z   triton_mm_581 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5321139Z   triton_mm_582 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5322291Z   triton_mm_584 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5323443Z   triton_mm_585 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:29.5324593Z   triton_mm_579 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:29.5325744Z   triton_mm_572 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:29.5326939Z   triton_mm_574 0.0246 ms 87.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:29.5327896Z SingleProcess AUTOTUNE benchmarking takes 0.1833 seconds and 0.2274 seconds precompiling for 15 choices
2026-01-14T08:40:29.5328784Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.006ms 
2026-01-14T08:40:29.5329756Z >>time: 0.005ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.006ms 
2026-01-14T08:40:29.5330759Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.005ms
2026-01-14T08:40:29.5331738Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:40:29.5332187Z 
2026-01-14T08:40:29.5332491Z [32mPASSED[0m
2026-01-14T08:40:29.5333028Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_15 [33mSKIPPED[0m
2026-01-14T08:40:29.5333815Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_16 [33mSKIPPED[0m
2026-01-14T08:40:29.5334673Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_compile_17 activation_shapes: torch.Size([32, 128]), times_seen: 2
2026-01-14T08:40:29.5335480Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:40:29.5335940Z Autotune Choices Stats:
2026-01-14T08:40:29.5337048Z {"num_choices": 16, "num_triton_choices": 14, "best_kernel": "triton_mm_604", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:29.5338196Z AUTOTUNE addmm(32x128, 32x128, 128x128)
2026-01-14T08:40:29.5338483Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:29.5338900Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:29.5339687Z   triton_mm_604 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5340856Z   triton_mm_605 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5342095Z   triton_mm_606 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5343254Z   triton_mm_607 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5344417Z   triton_mm_608 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5345569Z   triton_mm_609 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:29.5346732Z   triton_mm_598 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:29.5347869Z   triton_mm_601 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:29.5349267Z   triton_mm_602 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:29.5350423Z   triton_mm_603 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:29.5351376Z SingleProcess AUTOTUNE benchmarking takes 0.2012 seconds and 0.2863 seconds precompiling for 16 choices
2026-01-14T08:40:29.5352148Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:29.5352685Z Autotune Choices Stats:
2026-01-14T08:40:29.5353769Z {"num_choices": 15, "num_triton_choices": 14, "best_kernel": "triton_mm_621", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:29.5354904Z AUTOTUNE mm(32x128, 128x128)
2026-01-14T08:40:29.5355147Z strides: [128, 1], [128, 1]
2026-01-14T08:40:29.5355409Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:40:29.5356191Z   triton_mm_621 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:29.5357352Z   triton_mm_623 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:29.5358517Z   triton_mm_619 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:29.5359669Z   triton_mm_616 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:29.5360811Z   triton_mm_617 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:40.0530105Z   triton_mm_620 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=32, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0532359Z   triton_mm_622 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:40.0534536Z   triton_mm_612 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:40.0536448Z   triton_mm_613 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:40.0538333Z   triton_mm_615 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:40.0540044Z SingleProcess AUTOTUNE benchmarking takes 0.1863 seconds and 0.2015 seconds precompiling for 15 choices
2026-01-14T08:40:40.0541501Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:40:40.0543029Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.006ms 
2026-01-14T08:40:40.0544703Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:40:40.0546148Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:40:40.0546857Z 
2026-01-14T08:40:40.0547270Z [32mPASSED[0m
2026-01-14T08:40:40.0548215Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:40.0549857Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:40.0551311Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:40.0552871Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_3 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:40.0554339Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:40.0555116Z Autotune Choices Stats:
2026-01-14T08:40:40.0557051Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_635", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:40.0559055Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:40.0559501Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:40.0560023Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:40:40.0561333Z   triton_mm_635 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:40:40.0563388Z   triton_mm_636 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:40.0565393Z   triton_mm_639 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:40.0567419Z   triton_mm_644 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:40.0569705Z   triton_mm_638 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:40.0571686Z   triton_mm_643 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0573680Z   triton_mm_634 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:40.0575860Z   triton_mm_640 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0577678Z   triton_mm_637 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:40.0579574Z   triton_mm_641 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0581256Z SingleProcess AUTOTUNE benchmarking takes 0.1753 seconds and 0.6571 seconds precompiling for 14 choices
2026-01-14T08:40:40.0582581Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:40.0583509Z Autotune Choices Stats:
2026-01-14T08:40:40.0585408Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_649", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:40.0587336Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:40.0587757Z strides: [128, 1], [128, 1]
2026-01-14T08:40:40.0588174Z dtypes: torch.float32, torch.float32
2026-01-14T08:40:40.0589426Z   triton_mm_649 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:40.0591440Z   triton_mm_654 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:40.0593456Z   triton_mm_657 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:40.0595456Z   triton_mm_648 0.0245 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:40.0597456Z   triton_mm_652 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0599384Z   triton_mm_655 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0601327Z   triton_mm_656 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:40.0603301Z   triton_mm_646 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:40.0605284Z   triton_mm_650 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:40.0607260Z   triton_mm_651 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:40.0609205Z SingleProcess AUTOTUNE benchmarking takes 0.1596 seconds and 0.6968 seconds precompiling for 13 choices
2026-01-14T08:40:40.0610729Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.010ms 
2026-01-14T08:40:40.0612423Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.008ms 
2026-01-14T08:40:40.0613501Z Autotune Choices Stats:
2026-01-14T08:40:40.0615074Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_660", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:40:40.0616791Z AUTOTUNE int_mm(16x128, 128x128)
2026-01-14T08:40:40.0617186Z strides: [128, 1], [1, 128]
2026-01-14T08:40:40.0617572Z dtypes: torch.int8, torch.int8
2026-01-14T08:40:40.0618769Z   triton_mm_660 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:40.0620751Z   triton_mm_662 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:40.0622678Z   triton_mm_659 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4658485Z   triton_mm_667 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:40:49.4659862Z   triton_mm_658 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:49.4661036Z   triton_mm_661 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:49.4662166Z   triton_mm_663 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:49.4663307Z   triton_mm_664 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:49.4664435Z   triton_mm_665 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:49.4665554Z   triton_mm_666 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4666512Z SingleProcess AUTOTUNE benchmarking takes 0.1250 seconds and 0.1628 seconds precompiling for 11 choices
2026-01-14T08:40:49.4667423Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.008ms
2026-01-14T08:40:49.4668424Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.020ms 
2026-01-14T08:40:49.4669491Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.03
2026-01-14T08:40:49.4670454Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:40:49.4670896Z 
2026-01-14T08:40:49.4671213Z [32mPASSED[0m
2026-01-14T08:40:49.4671827Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_4 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:49.4672647Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:40:49.4673380Z Autotune Choices Stats:
2026-01-14T08:40:49.4674486Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_686", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:49.4675816Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:49.4676100Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:49.4676410Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:40:49.4677192Z   triton_mm_686 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4678360Z   triton_mm_681 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:49.4679515Z   triton_mm_683 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:49.4680664Z   triton_mm_684 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:49.4681817Z   triton_mm_687 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:49.4682976Z   triton_mm_688 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4684135Z   triton_mm_689 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4685276Z   triton_mm_690 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:49.4686443Z   triton_mm_692 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:49.4687605Z   triton_mm_678 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:49.4688616Z SingleProcess AUTOTUNE benchmarking takes 0.2131 seconds and 0.2273 seconds precompiling for 17 choices
2026-01-14T08:40:49.4697306Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:49.4697889Z Autotune Choices Stats:
2026-01-14T08:40:49.4699004Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_707", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.021503999829292297, "best_triton_pos": 0}
2026-01-14T08:40:49.4700158Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:49.4700410Z strides: [128, 1], [128, 1]
2026-01-14T08:40:49.4700660Z dtypes: torch.float16, torch.float16
2026-01-14T08:40:49.4701415Z   triton_mm_707 0.0215 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:49.4702575Z   triton_mm_697 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:49.4703839Z   triton_mm_700 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4704993Z   triton_mm_701 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4706218Z   triton_mm_702 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:49.4707374Z   triton_mm_703 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4708531Z   triton_mm_704 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:49.4709673Z   triton_mm_705 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:49.4710830Z   triton_mm_706 0.0225 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:49.4711989Z   triton_mm_696 0.0236 ms 91.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:49.4712939Z SingleProcess AUTOTUNE benchmarking takes 0.1925 seconds and 0.1841 seconds precompiling for 16 choices
2026-01-14T08:40:49.4713816Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:40:49.4714790Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:40:49.4715793Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:40:49.4716801Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.012ms 
2026-01-14T08:40:49.4717856Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.82
2026-01-14T08:40:49.4718813Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:40:49.4719250Z 
2026-01-14T08:40:49.4719409Z [32mPASSED[0m
2026-01-14T08:40:49.4720005Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_double_access_5 activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:40:49.4720843Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:40:49.4721297Z Autotune Choices Stats:
2026-01-14T08:40:53.9754342Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_738", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:40:53.9755577Z AUTOTUNE addmm(16x128, 16x128, 128x128)
2026-01-14T08:40:53.9755878Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:40:53.9756205Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:40:53.9757008Z   triton_mm_738 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:53.9758191Z   triton_mm_740 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:53.9759760Z   triton_mm_742 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:53.9760929Z   triton_mm_734 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:53.9762278Z   triton_mm_737 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:53.9763428Z   triton_mm_739 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:53.9764578Z   triton_mm_735 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:53.9765735Z   triton_mm_728 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:40:53.9766881Z   triton_mm_729 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:40:53.9768047Z   triton_mm_730 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:53.9769022Z SingleProcess AUTOTUNE benchmarking takes 0.2120 seconds and 0.1961 seconds precompiling for 17 choices
2026-01-14T08:40:53.9769796Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:40:53.9770333Z Autotune Choices Stats:
2026-01-14T08:40:53.9771572Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_746", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:40:53.9772732Z AUTOTUNE mm(16x128, 128x128)
2026-01-14T08:40:53.9772988Z strides: [128, 1], [128, 1]
2026-01-14T08:40:53.9773247Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:40:53.9773990Z   triton_mm_746 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:53.9775152Z   triton_mm_747 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:40:53.9776317Z   triton_mm_748 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:53.9777487Z   triton_mm_749 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:40:53.9778646Z   triton_mm_752 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:40:53.9779815Z   triton_mm_755 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:40:53.9780975Z   triton_mm_756 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:40:53.9782131Z   triton_mm_757 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:40:53.9783454Z   triton_mm_753 0.0235 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:40:53.9784615Z   triton_mm_745 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:40:53.9787076Z SingleProcess AUTOTUNE benchmarking takes 0.1918 seconds and 0.1845 seconds precompiling for 16 choices
2026-01-14T08:40:53.9787956Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:40:53.9788926Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:40:53.9789937Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:40:53.9790760Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:40:53.9791108Z 
2026-01-14T08:40:53.9791430Z [32mPASSED[0m
2026-01-14T08:40:53.9791983Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9792798Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9793609Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9794396Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_3 [33mSKIPPED[0m
2026-01-14T08:40:53.9795156Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_4 [33mSKIPPED[0m
2026-01-14T08:40:53.9795926Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_float8_5 [33mSKIPPED[0m
2026-01-14T08:40:53.9796762Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_hp_float activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:53.9797575Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:53.9798274Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>, to_beat: infms 
2026-01-14T08:40:53.9798945Z best_cls=<class 'torchao.quantization.autoquant.AQFloat32LinearWeight'>
2026-01-14T08:40:53.9799305Z 
2026-01-14T08:40:53.9799460Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:53.9799953Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:53.9800648Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:40:53.9801453Z best_cls=<class 'torchao.quantization.autoquant.AQBFloat16LinearWeight'>
2026-01-14T08:40:53.9801883Z 
2026-01-14T08:40:53.9802071Z activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:40:53.9802688Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:40:53.9803498Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>, to_beat: infms 
2026-01-14T08:40:53.9804174Z best_cls=<class 'torchao.quantization.autoquant.AQFloat16LinearWeight'>
2026-01-14T08:40:53.9804513Z 
2026-01-14T08:40:53.9804640Z [32mPASSED[0m
2026-01-14T08:40:53.9805151Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_0_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9805964Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_1_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9806767Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_2_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9807557Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_3 [33mSKIPPED[0m
2026-01-14T08:40:53.9808320Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_4 [33mSKIPPED[0m
2026-01-14T08:40:53.9809186Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_int4wo_5 [33mSKIPPED[0m
2026-01-14T08:40:53.9809986Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_00_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9810796Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_01_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9811906Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_02_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9812910Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_03_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9813856Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_04_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9814669Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_05_cpu [33mSKIPPED[0m
2026-01-14T08:40:53.9815490Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_06_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3416262Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_07_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3417150Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_08_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3417949Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_09 [33mSKIPPED[0m
2026-01-14T08:41:04.3418728Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_10 [33mSKIPPED[0m
2026-01-14T08:41:04.3419490Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_11 [32mPASSED[0m
2026-01-14T08:41:04.3420249Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_12 [33mSKIPPED[0m
2026-01-14T08:41:04.3421018Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_13 [33mSKIPPED[0m
2026-01-14T08:41:04.3421780Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_14 [32mPASSED[0m
2026-01-14T08:41:04.3422551Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_15 [33mSKIPPED[0m
2026-01-14T08:41:04.3423318Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_16 [33mSKIPPED[0m
2026-01-14T08:41:04.3424070Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_kwargs_17 [32mPASSED[0m
2026-01-14T08:41:04.3424854Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3425651Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3426442Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3427213Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_3 [32mPASSED[0m
2026-01-14T08:41:04.3427961Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_4 [32mPASSED[0m
2026-01-14T08:41:04.3428709Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_manual_5 [32mPASSED[0m
2026-01-14T08:41:04.3429476Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_0_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3430237Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_1_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3431003Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_2_cpu [33mSKIPPED[0m
2026-01-14T08:41:04.3431816Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_3 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:04.3432609Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float32, bias_shape: torch.Size([4096])
2026-01-14T08:41:04.3433078Z Autotune Choices Stats:
2026-01-14T08:41:04.3434783Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "bias_addmm", "best_time": 0.1443839967250824, "best_triton_pos": 2, "best_triton_time": 0.187391996383667, "best_triton_kernel": "triton_mm_774", "best_triton_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4"}
2026-01-14T08:41:04.3436223Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:04.3436508Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:41:04.3436826Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:04.3437336Z   bias_addmm 0.1444 ms 100.0% 
2026-01-14T08:41:04.3437575Z   addmm 0.1495 ms 96.6% 
2026-01-14T08:41:04.3438259Z   triton_mm_774 0.1874 ms 77.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:04.3439413Z   triton_mm_770 0.1915 ms 75.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:04.3440566Z   triton_mm_778 0.1915 ms 75.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:04.3441707Z   triton_mm_777 0.1935 ms 74.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:04.3442846Z   triton_mm_771 0.2007 ms 71.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:04.3444057Z   triton_mm_769 0.2150 ms 67.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:04.3445207Z   triton_mm_773 0.2570 ms 56.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:04.3446349Z   triton_mm_768 0.3103 ms 46.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:04.3447304Z SingleProcess AUTOTUNE benchmarking takes 0.4145 seconds and 0.6876 seconds precompiling for 14 choices
2026-01-14T08:41:04.3448063Z >>time: 0.145ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:04.3448947Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.145ms 
2026-01-14T08:41:04.3450125Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.038ms 
2026-01-14T08:41:04.3450752Z Autotune Choices Stats:
2026-01-14T08:41:04.3451923Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_789", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.05222399905323982, "best_triton_pos": 0}
2026-01-14T08:41:04.3453064Z AUTOTUNE int_mm(1x4096, 4096x4096)
2026-01-14T08:41:04.3453320Z strides: [4096, 1], [1, 4096]
2026-01-14T08:41:04.3453581Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:04.3454270Z   triton_mm_789 0.0522 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:04.3455415Z   triton_mm_788 0.0532 ms 98.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:04.3456536Z   triton_mm_785 0.0553 ms 94.4% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:04.3457648Z   triton_mm_786 0.0563 ms 92.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:04.3458904Z   triton_mm_784 0.0614 ms 85.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:04.3460024Z   triton_mm_782 0.0758 ms 68.9% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:04.3461263Z   triton_mm_781 0.0778 ms 67.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:04.3462386Z   triton_mm_780 0.1331 ms 39.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:04.3463502Z   triton_mm_783 0.1331 ms 39.2% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:04.3464643Z   triton_mm_787 0.1352 ms 38.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:04.3465591Z SingleProcess AUTOTUNE benchmarking takes 0.1638 seconds and 0.3182 seconds precompiling for 11 choices
2026-01-14T08:41:04.3466485Z >>time: 0.048ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:41:04.3467375Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:41:04.3467816Z 
2026-01-14T08:41:04.3467953Z [32mPASSED[0m
2026-01-14T08:41:04.3468499Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_4 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:04.3469285Z weight_shape: torch.Size([4096, 4096]), dtype: torch.float16, bias_shape: torch.Size([4096])
2026-01-14T08:41:04.3469736Z Autotune Choices Stats:
2026-01-14T08:41:04.3470834Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_804", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.08294399827718735, "best_triton_pos": 0}
2026-01-14T08:41:04.3471988Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:04.3472269Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:41:04.3472582Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:04.3473349Z   triton_mm_804 0.0829 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:13.6243273Z   triton_mm_800 0.0840 ms 98.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6244498Z   triton_mm_792 0.0860 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:13.6245654Z   triton_mm_797 0.0860 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6246893Z   triton_mm_794 0.0881 ms 94.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:13.6247613Z   addmm 0.0891 ms 93.1% 
2026-01-14T08:41:13.6247863Z   bias_addmm 0.0911 ms 91.0% 
2026-01-14T08:41:13.6248546Z   triton_mm_802 0.0911 ms 91.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:13.6250309Z   triton_mm_799 0.0932 ms 89.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:13.6251615Z   triton_mm_801 0.0963 ms 86.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6252745Z SingleProcess AUTOTUNE benchmarking takes 0.3275 seconds and 0.4017 seconds precompiling for 17 choices
2026-01-14T08:41:13.6253519Z >>time: 0.085ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:13.6254401Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.085ms 
2026-01-14T08:41:13.6255367Z >>time: 0.037ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.037ms 
2026-01-14T08:41:13.6256426Z >>time: 0.049ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.037ms
2026-01-14T08:41:13.6257318Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:41:13.6257765Z 
2026-01-14T08:41:13.6258079Z [32mPASSED[0m
2026-01-14T08:41:13.6258657Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_mha_5 activation_shapes: torch.Size([1, 4096]), times_seen: 1
2026-01-14T08:41:13.6259462Z weight_shape: torch.Size([4096, 4096]), dtype: torch.bfloat16, bias_shape: torch.Size([4096])
2026-01-14T08:41:13.6259936Z Autotune Choices Stats:
2026-01-14T08:41:13.6261033Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_829", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.08294399827718735, "best_triton_pos": 0}
2026-01-14T08:41:13.6262273Z AUTOTUNE addmm(1x4096, 1x4096, 4096x4096)
2026-01-14T08:41:13.6262566Z strides: [0, 1], [4096, 1], [1, 4096]
2026-01-14T08:41:13.6262904Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:41:13.6263690Z   triton_mm_829 0.0829 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:13.6264853Z   triton_mm_822 0.0860 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6266002Z   triton_mm_825 0.0860 ms 96.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6267150Z   triton_mm_817 0.0881 ms 94.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:13.6268301Z   triton_mm_819 0.0881 ms 94.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:13.6269011Z   addmm 0.0891 ms 93.1% 
2026-01-14T08:41:13.6269247Z   bias_addmm 0.0922 ms 90.0% 
2026-01-14T08:41:13.6269919Z   triton_mm_827 0.0942 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:13.6271072Z   triton_mm_824 0.0983 ms 84.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:13.6272217Z   triton_mm_826 0.1004 ms 82.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6273165Z SingleProcess AUTOTUNE benchmarking takes 0.3325 seconds and 0.3975 seconds precompiling for 17 choices
2026-01-14T08:41:13.6274028Z >>time: 0.084ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:13.6274899Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.084ms 
2026-01-14T08:41:13.6275863Z >>time: 0.038ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.038ms 
2026-01-14T08:41:13.6276952Z >>time: 0.048ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.038ms
2026-01-14T08:41:13.6277836Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>
2026-01-14T08:41:13.6278281Z 
2026-01-14T08:41:13.6278401Z [32mPASSED[0m
2026-01-14T08:41:13.6278973Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_0 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:13.6279770Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:13.6280223Z Autotune Choices Stats:
2026-01-14T08:41:13.6281299Z {"num_choices": 15, "num_triton_choices": 13, "best_kernel": "triton_mm_846", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:41:13.6282449Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:13.6282741Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:13.6283048Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:13.6283814Z   triton_mm_846 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:13.6284961Z   triton_mm_847 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6286139Z   triton_mm_848 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:13.6287316Z   triton_mm_849 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:13.6288461Z   triton_mm_850 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:13.6289606Z   triton_mm_841 0.0255 ms 92.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:13.6290748Z   triton_mm_844 0.0255 ms 92.2% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:13.6291943Z   triton_mm_840 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:13.6293078Z   triton_mm_842 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:13.6294221Z   triton_mm_843 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:13.6295164Z SingleProcess AUTOTUNE benchmarking takes 0.1902 seconds and 0.6538 seconds precompiling for 15 choices
2026-01-14T08:41:13.6295936Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:13.6297114Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.31756591796875
2026-01-14T08:41:13.6298513Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.40925216674805
2026-01-14T08:41:13.6300004Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.288150787353516
2026-01-14T08:41:13.6300990Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:13.6301340Z 
2026-01-14T08:41:13.6301455Z [32mPASSED[0m
2026-01-14T08:41:16.1083353Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_1 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:16.1084210Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:41:16.1084676Z Autotune Choices Stats:
2026-01-14T08:41:16.1085914Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_859", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:16.1087089Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:16.1087378Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:16.1087684Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:16.1088563Z   triton_mm_859 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:16.1089734Z   triton_mm_862 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1091006Z   triton_mm_866 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1092282Z   triton_mm_867 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1093498Z   triton_mm_860 0.0246 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1094700Z   triton_mm_864 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=128, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:16.1095840Z   triton_mm_853 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:16.1097098Z   triton_mm_854 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:16.1098234Z   triton_mm_855 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:16.1099474Z   triton_mm_856 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:16.1100605Z SingleProcess AUTOTUNE benchmarking takes 0.2168 seconds and 0.5449 seconds precompiling for 17 choices
2026-01-14T08:41:16.1101375Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:16.1102556Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 53.3125
2026-01-14T08:41:16.1104240Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 54.0
2026-01-14T08:41:16.1105688Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 48.15625
2026-01-14T08:41:16.1106833Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:16.1107180Z 
2026-01-14T08:41:16.1107481Z [32mPASSED[0m
2026-01-14T08:41:16.1108064Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_min_sqnr_2 activation_shapes: torch.Size([128, 128]), times_seen: 1
2026-01-14T08:41:16.1108868Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:41:16.1109327Z Autotune Choices Stats:
2026-01-14T08:41:16.1110423Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_873", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:16.1111554Z AUTOTUNE addmm(128x128, 128x128, 128x128)
2026-01-14T08:41:16.1111847Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:16.1112170Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:41:16.1112948Z   triton_mm_873 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:16.1114105Z   triton_mm_882 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=128, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1115258Z   triton_mm_876 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:16.1116395Z   triton_mm_868 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:16.1117532Z   triton_mm_869 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:16.1118669Z   triton_mm_870 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:16.1119804Z   triton_mm_871 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:16.1120935Z   triton_mm_872 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:16.1122058Z   triton_mm_874 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:16.1123198Z   triton_mm_875 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:16.1124147Z SingleProcess AUTOTUNE benchmarking takes 0.2155 seconds and 0.5185 seconds precompiling for 17 choices
2026-01-14T08:41:16.1124914Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:16.1125966Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:41:16.1127385Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'> because the sqnr is too small, minimum expected sqnr: 60, got 49.0
2026-01-14T08:41:16.1128721Z skipping q_cls: <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> because the sqnr is too small, minimum expected sqnr: 60, got 46.25
2026-01-14T08:41:16.1129765Z best_cls=<class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>
2026-01-14T08:41:16.1130113Z 
2026-01-14T08:41:16.1130257Z [32mPASSED[0m
2026-01-14T08:41:16.1130737Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_00_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:16.1131442Z [33mSKIPPED[0m
2026-01-14T08:41:16.1131928Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_01_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:16.1132495Z [33mSKIPPED[0m
2026-01-14T08:41:16.1132967Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_02_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:16.1133534Z [33mSKIPPED[0m
2026-01-14T08:41:16.1134008Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_03_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:16.1134575Z [33mSKIPPED[0m
2026-01-14T08:41:16.1135046Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_04_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:16.1135627Z [33mSKIPPED[0m
2026-01-14T08:41:16.1136096Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_05_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:16.1136670Z [33mSKIPPED[0m
2026-01-14T08:41:16.1137141Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_06_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:16.1137701Z [33mSKIPPED[0m
2026-01-14T08:41:16.1138177Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_07_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:16.1138738Z [33mSKIPPED[0m
2026-01-14T08:41:16.1139216Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_08_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:16.1139778Z [33mSKIPPED[0m
2026-01-14T08:41:16.1140252Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_09_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:16.1140825Z [33mSKIPPED[0m
2026-01-14T08:41:16.1141294Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_10_cpu (m, k, n):  (16, 128, 128)
2026-01-14T08:41:16.1141865Z [33mSKIPPED[0m
2026-01-14T08:41:16.1142329Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_11_cpu (m, k, n):  (64, 128, 128)
2026-01-14T08:41:16.1142899Z [33mSKIPPED[0m
2026-01-14T08:41:25.1081483Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_12_cpu (m, k, n):  (16, 128, 256)
2026-01-14T08:41:25.1082462Z [33mSKIPPED[0m
2026-01-14T08:41:25.1082948Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_13_cpu (m, k, n):  (16, 256, 128)
2026-01-14T08:41:25.1083551Z [33mSKIPPED[0m
2026-01-14T08:41:25.1084028Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_14_cpu (m, k, n):  (64, 256, 128)
2026-01-14T08:41:25.1084595Z [33mSKIPPED[0m
2026-01-14T08:41:25.1085054Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_15 (m, k, n):  (16, 128, 128)
2026-01-14T08:41:25.1085622Z [32mPASSED[0m
2026-01-14T08:41:25.1086081Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_16 (m, k, n):  (64, 128, 128)
2026-01-14T08:41:25.1086675Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:41:25.1087173Z weight_shape: torch.Size([128, 128]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:25.1087634Z Autotune Choices Stats:
2026-01-14T08:41:25.1089043Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_884", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:25.1092811Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:41:25.1093110Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:25.1093425Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:25.1094414Z   triton_mm_884 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1095588Z   triton_mm_883 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:25.1096748Z   triton_mm_886 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1097915Z   triton_mm_885 0.0266 ms 92.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1099104Z   triton_mm_892 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1100254Z   triton_mm_888 0.0287 ms 85.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1101408Z   triton_mm_887 0.0317 ms 77.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1102562Z   triton_mm_890 0.0317 ms 77.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1103716Z   triton_mm_893 0.0358 ms 68.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.1104865Z   triton_mm_889 0.0369 ms 66.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:25.1105831Z SingleProcess AUTOTUNE benchmarking takes 0.1779 seconds and 0.9658 seconds precompiling for 14 choices
2026-01-14T08:41:25.1106606Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:25.1107150Z Autotune Choices Stats:
2026-01-14T08:41:25.1108246Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_902", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.022592000663280487, "best_triton_pos": 0}
2026-01-14T08:41:25.1109398Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:41:25.1109644Z strides: [128, 1], [128, 1]
2026-01-14T08:41:25.1109906Z dtypes: torch.float32, torch.float32
2026-01-14T08:41:25.1110650Z   triton_mm_902 0.0226 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1111822Z   triton_mm_900 0.0235 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1112997Z   triton_mm_903 0.0236 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.1114153Z   triton_mm_904 0.0236 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1115390Z   triton_mm_905 0.0236 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.1116553Z   triton_mm_895 0.0246 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:25.1117784Z   triton_mm_897 0.0246 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1118933Z   triton_mm_898 0.0246 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1120098Z   triton_mm_899 0.0246 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1121251Z   triton_mm_901 0.0246 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:25.1122217Z SingleProcess AUTOTUNE benchmarking takes 0.1612 seconds and 0.8509 seconds precompiling for 13 choices
2026-01-14T08:41:25.1123118Z >>time: 0.016ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:41:25.1123757Z Autotune Choices Stats:
2026-01-14T08:41:25.1124847Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_907", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:25.1125976Z AUTOTUNE int_mm(64x128, 128x128)
2026-01-14T08:41:25.1126229Z strides: [128, 1], [1, 128]
2026-01-14T08:41:25.1126485Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:25.1127195Z   triton_mm_907 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:25.1128352Z   triton_mm_908 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1129504Z   triton_mm_909 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:25.1130650Z   triton_mm_910 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.1139793Z   triton_mm_911 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:25.1140949Z   triton_mm_912 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1142096Z   triton_mm_913 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:25.1143246Z   triton_mm_914 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:25.1144383Z   triton_mm_915 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:25.1145749Z   triton_mm_916 0.0246 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:25.1146712Z SingleProcess AUTOTUNE benchmarking takes 0.1384 seconds and 0.2244 seconds precompiling for 11 choices
2026-01-14T08:41:25.1147619Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.013ms
2026-01-14T08:41:32.6650967Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.042ms 
2026-01-14T08:41:32.6652162Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 2.50
2026-01-14T08:41:32.6653131Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:32.6653579Z 
2026-01-14T08:41:32.6653885Z [32mPASSED[0m
2026-01-14T08:41:32.6654373Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_17 (m, k, n):  (16, 128, 256)
2026-01-14T08:41:32.6655014Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:41:32.6655507Z weight_shape: torch.Size([256, 128]), dtype: torch.float32, bias_shape: torch.Size([256])
2026-01-14T08:41:32.6655964Z Autotune Choices Stats:
2026-01-14T08:41:32.6657071Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_928", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:32.6658244Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:41:32.6658528Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:32.6658837Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:32.6659617Z   triton_mm_928 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:32.6660796Z   triton_mm_930 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:32.6661941Z   triton_mm_931 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:32.6663096Z   triton_mm_936 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6664248Z   triton_mm_929 0.0246 ms 91.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:32.6665399Z   triton_mm_927 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:32.6666562Z   triton_mm_932 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:32.6667715Z   triton_mm_933 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6668868Z   triton_mm_934 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6670024Z   triton_mm_937 0.0256 ms 88.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:32.6670988Z SingleProcess AUTOTUNE benchmarking takes 0.1768 seconds and 0.6165 seconds precompiling for 14 choices
2026-01-14T08:41:32.6672028Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:32.6672571Z Autotune Choices Stats:
2026-01-14T08:41:32.6673665Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_946", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02348800003528595, "best_triton_pos": 0}
2026-01-14T08:41:32.6674967Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:41:32.6675224Z strides: [128, 1], [256, 1]
2026-01-14T08:41:32.6675482Z dtypes: torch.float32, torch.float32
2026-01-14T08:41:32.6676226Z   triton_mm_946 0.0235 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6677407Z   triton_mm_944 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:32.6678572Z   triton_mm_947 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:32.6679738Z   triton_mm_948 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6680938Z   triton_mm_939 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:32.6682104Z   triton_mm_941 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:32.6683272Z   triton_mm_942 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:32.6684428Z   triton_mm_943 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:32.6685592Z   triton_mm_945 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6686749Z   triton_mm_949 0.0246 ms 95.6% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:32.6687710Z SingleProcess AUTOTUNE benchmarking takes 0.1600 seconds and 0.6523 seconds precompiling for 13 choices
2026-01-14T08:41:32.6688598Z >>time: 0.018ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.010ms 
2026-01-14T08:41:32.6689589Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.010ms 
2026-01-14T08:41:32.6690237Z Autotune Choices Stats:
2026-01-14T08:41:32.6691393Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_959", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:41:32.6692532Z AUTOTUNE int_mm(16x128, 128x256)
2026-01-14T08:41:32.6692802Z strides: [128, 1], [1, 128]
2026-01-14T08:41:32.6693063Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:32.6693766Z   triton_mm_959 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6695018Z   triton_mm_960 0.0236 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:32.6696170Z   triton_mm_952 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6697404Z   triton_mm_953 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:32.6698547Z   triton_mm_956 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:32.6699672Z   triton_mm_957 0.0246 ms 95.8% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:32.6700810Z   triton_mm_955 0.0256 ms 92.1% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:32.6701942Z   triton_mm_951 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:32.6703074Z   triton_mm_954 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:32.6704211Z   triton_mm_958 0.0256 ms 92.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:32.6705162Z SingleProcess AUTOTUNE benchmarking takes 0.1255 seconds and 0.1848 seconds precompiling for 11 choices
2026-01-14T08:41:32.6706076Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.010ms
2026-01-14T08:41:40.3479466Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.033ms 
2026-01-14T08:41:40.3481706Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 2.00
2026-01-14T08:41:40.3482789Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:40.3483239Z 
2026-01-14T08:41:40.3483558Z [32mPASSED[0m
2026-01-14T08:41:40.3484059Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_18 (m, k, n):  (16, 256, 128)
2026-01-14T08:41:40.3484654Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:41:40.3485162Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:40.3485624Z Autotune Choices Stats:
2026-01-14T08:41:40.3486728Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_974", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:40.3487899Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:41:40.3488188Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:41:40.3488508Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:40.3489295Z   triton_mm_974 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.3490462Z   triton_mm_972 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:40.3492043Z   triton_mm_973 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:40.3493203Z   triton_mm_977 0.0266 ms 92.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3494346Z   triton_mm_980 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3495670Z   triton_mm_981 0.0276 ms 88.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:40.3496820Z   triton_mm_971 0.0297 ms 82.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:40.3497970Z   triton_mm_976 0.0307 ms 80.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:40.3499129Z   triton_mm_975 0.0338 ms 72.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:40.3500281Z   triton_mm_978 0.0369 ms 66.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3501245Z SingleProcess AUTOTUNE benchmarking takes 0.1762 seconds and 0.7533 seconds precompiling for 14 choices
2026-01-14T08:41:40.3502073Z >>time: 0.012ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:40.3502608Z Autotune Choices Stats:
2026-01-14T08:41:40.3503709Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_993", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.022495999932289124, "best_triton_pos": 0}
2026-01-14T08:41:40.3504843Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:41:40.3505105Z strides: [256, 1], [128, 1]
2026-01-14T08:41:40.3505367Z dtypes: torch.float32, torch.float32
2026-01-14T08:41:40.3506103Z   triton_mm_993 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:40.3507259Z   triton_mm_989 0.0225 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3508396Z   triton_mm_986 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.3509547Z   triton_mm_987 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:40.3510702Z   triton_mm_990 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3511851Z   triton_mm_992 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3513006Z   triton_mm_994 0.0236 ms 95.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:40.3514161Z   triton_mm_991 0.0245 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:40.3515392Z   triton_mm_983 0.0246 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:40.3516543Z   triton_mm_984 0.0246 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:40.3517576Z SingleProcess AUTOTUNE benchmarking takes 0.1592 seconds and 0.6762 seconds precompiling for 13 choices
2026-01-14T08:41:40.3518441Z >>time: 0.018ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.012ms 
2026-01-14T08:41:40.3519418Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.012ms 
2026-01-14T08:41:40.3520046Z Autotune Choices Stats:
2026-01-14T08:41:40.3521136Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_1003", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:40.3522259Z AUTOTUNE int_mm(16x256, 256x128)
2026-01-14T08:41:40.3522510Z strides: [256, 1], [1, 256]
2026-01-14T08:41:40.3522762Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:40.3523465Z   triton_mm_1003 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3524603Z   triton_mm_997 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3525739Z   triton_mm_1004 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:40.3526871Z   triton_mm_995 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:40.3527999Z   triton_mm_996 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:40.3529129Z   triton_mm_1001 0.0256 ms 88.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:40.3530254Z   triton_mm_998 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:40.3531429Z   triton_mm_999 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:40.3532625Z   triton_mm_1000 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:40.3533756Z   triton_mm_1002 0.0266 ms 84.6% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:40.3534720Z SingleProcess AUTOTUNE benchmarking takes 0.1281 seconds and 0.1783 seconds precompiling for 11 choices
2026-01-14T08:41:40.3535610Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.012ms
2026-01-14T08:41:47.8033564Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.041ms 
2026-01-14T08:41:47.8034704Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 2.50
2026-01-14T08:41:47.8036099Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:47.8036556Z 
2026-01-14T08:41:47.8036881Z [32mPASSED[0m
2026-01-14T08:41:47.8037374Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_19 (m, k, n):  (64, 256, 128)
2026-01-14T08:41:47.8038143Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:41:47.8038643Z weight_shape: torch.Size([128, 256]), dtype: torch.float32, bias_shape: torch.Size([128])
2026-01-14T08:41:47.8039098Z Autotune Choices Stats:
2026-01-14T08:41:47.8040215Z {"num_choices": 14, "num_triton_choices": 12, "best_kernel": "triton_mm_1016", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.027648000046610832, "best_triton_pos": 0}
2026-01-14T08:41:47.8041476Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:41:47.8041761Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:41:47.8042077Z dtypes: torch.float32, torch.float32, torch.float32
2026-01-14T08:41:47.8042858Z   triton_mm_1016 0.0276 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8044034Z   triton_mm_1015 0.0358 ms 77.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:47.8045196Z   triton_mm_1018 0.0379 ms 73.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8046351Z   triton_mm_1017 0.0389 ms 71.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8047501Z   triton_mm_1024 0.0389 ms 71.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8048662Z   triton_mm_1022 0.0420 ms 65.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8049996Z   triton_mm_1020 0.0430 ms 64.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8051142Z   triton_mm_1019 0.0451 ms 61.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8052357Z   triton_mm_1021 0.0471 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:47.8053567Z   triton_mm_1025 0.0471 ms 58.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:47.8054539Z SingleProcess AUTOTUNE benchmarking takes 0.1819 seconds and 1.0005 seconds precompiling for 14 choices
2026-01-14T08:41:47.8055316Z >>time: 0.017ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:47.8055861Z Autotune Choices Stats:
2026-01-14T08:41:47.8056962Z {"num_choices": 13, "num_triton_choices": 12, "best_kernel": "triton_mm_1028", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:41:47.8058116Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:41:47.8058366Z strides: [256, 1], [128, 1]
2026-01-14T08:41:47.8058634Z dtypes: torch.float32, torch.float32
2026-01-14T08:41:47.8059509Z   triton_mm_1028 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8060691Z   triton_mm_1030 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8061974Z   triton_mm_1029 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8063118Z   triton_mm_1036 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8064279Z   triton_mm_1033 0.0256 ms 92.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:47.8065448Z   triton_mm_1037 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:47.8066598Z   triton_mm_1027 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:47.8067763Z   triton_mm_1032 0.0297 ms 79.3% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8068927Z   triton_mm_1031 0.0307 ms 76.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8070081Z   triton_mm_1034 0.0307 ms 76.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8071050Z SingleProcess AUTOTUNE benchmarking takes 0.1608 seconds and 0.9381 seconds precompiling for 13 choices
2026-01-14T08:41:47.8071923Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.017ms 
2026-01-14T08:41:47.8072568Z Autotune Choices Stats:
2026-01-14T08:41:47.8073667Z {"num_choices": 11, "num_triton_choices": 10, "best_kernel": "triton_mm_1043", "best_kernel_desc": "ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:47.8074807Z AUTOTUNE int_mm(64x256, 256x128)
2026-01-14T08:41:47.8075067Z strides: [256, 1], [1, 256]
2026-01-14T08:41:47.8075324Z dtypes: torch.int8, torch.int8
2026-01-14T08:41:47.8076035Z   triton_mm_1043 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:47.8077214Z   triton_mm_1048 0.0225 ms 100.0% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:47.8078376Z   triton_mm_1040 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8079522Z   triton_mm_1047 0.0236 ms 95.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:47.8080664Z   triton_mm_1039 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:47.8081890Z   triton_mm_1041 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:47.8083020Z   triton_mm_1042 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:47.8084157Z   triton_mm_1044 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8086336Z   triton_mm_1045 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:47.8087479Z   triton_mm_1046 0.0246 ms 91.7% ACC_TYPE='tl.int32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:47.8088452Z SingleProcess AUTOTUNE benchmarking takes 0.1368 seconds and 0.2466 seconds precompiling for 11 choices
2026-01-14T08:41:47.8089382Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.013ms
2026-01-14T08:41:47.8090390Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.042ms 
2026-01-14T08:41:50.9024249Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.67
2026-01-14T08:41:50.9025245Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:41:50.9025689Z 
2026-01-14T08:41:50.9025990Z [32mPASSED[0m
2026-01-14T08:41:50.9026474Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_20 (m, k, n):  (16, 128, 128)
2026-01-14T08:41:50.9027036Z [32mPASSED[0m
2026-01-14T08:41:50.9027488Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_21 (m, k, n):  (64, 128, 128)
2026-01-14T08:41:50.9028101Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:41:50.9028591Z weight_shape: torch.Size([128, 128]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:41:50.9029048Z Autotune Choices Stats:
2026-01-14T08:41:50.9030145Z {"num_choices": 15, "num_triton_choices": 13, "best_kernel": "triton_mm_1064", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:50.9031380Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:41:50.9031662Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:50.9031968Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:50.9032745Z   triton_mm_1064 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:50.9033930Z   triton_mm_1068 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9035083Z   triton_mm_1069 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9036241Z   triton_mm_1061 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:50.9037398Z   triton_mm_1065 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:41:50.9038545Z   triton_mm_1066 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9039952Z   triton_mm_1067 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:50.9041127Z   triton_mm_1071 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:50.9042425Z   triton_mm_1059 0.0246 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:50.9043577Z   triton_mm_1063 0.0246 ms 91.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:50.9044595Z SingleProcess AUTOTUNE benchmarking takes 0.1894 seconds and 0.3406 seconds precompiling for 15 choices
2026-01-14T08:41:50.9045360Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:50.9045899Z Autotune Choices Stats:
2026-01-14T08:41:50.9046985Z {"num_choices": 14, "num_triton_choices": 13, "best_kernel": "triton_mm_1075", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:50.9048119Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:41:50.9048365Z strides: [128, 1], [128, 1]
2026-01-14T08:41:50.9048615Z dtypes: torch.float16, torch.float16
2026-01-14T08:41:50.9049596Z   triton_mm_1075 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:50.9050770Z   triton_mm_1080 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:50.9052015Z   triton_mm_1081 0.0226 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9053185Z   triton_mm_1079 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9054349Z   triton_mm_1082 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9055510Z   triton_mm_1083 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:50.9056680Z   triton_mm_1084 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:50.9057836Z   triton_mm_1072 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:50.9059002Z   triton_mm_1073 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:50.9060162Z   triton_mm_1074 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:50.9061121Z SingleProcess AUTOTUNE benchmarking takes 0.1705 seconds and 0.2909 seconds precompiling for 14 choices
2026-01-14T08:41:50.9061993Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:41:50.9063140Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:41:50.9064037Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:41:50.9064525Z 
2026-01-14T08:41:50.9064775Z [32mPASSED[0m
2026-01-14T08:41:50.9065238Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_22 (m, k, n):  (16, 128, 256)
2026-01-14T08:41:50.9065836Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:41:50.9066330Z weight_shape: torch.Size([256, 128]), dtype: torch.float16, bias_shape: torch.Size([256])
2026-01-14T08:41:50.9066775Z Autotune Choices Stats:
2026-01-14T08:41:50.9067887Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_1095", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:41:50.9069030Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:41:50.9069312Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:41:50.9069618Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:50.9070394Z   triton_mm_1095 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:41:50.9071579Z   triton_mm_1097 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:50.9072746Z   triton_mm_1098 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:50.9073926Z   triton_mm_1099 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:50.9075101Z   triton_mm_1101 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:50.9076276Z   triton_mm_1104 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:50.9077456Z   triton_mm_1105 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9078628Z   triton_mm_1106 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:50.9079795Z   triton_mm_1107 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:58.1676670Z   triton_mm_1096 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:58.1677752Z SingleProcess AUTOTUNE benchmarking takes 0.2162 seconds and 0.2263 seconds precompiling for 17 choices
2026-01-14T08:41:58.1678539Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:58.1679077Z Autotune Choices Stats:
2026-01-14T08:41:58.1680183Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_1118", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:58.1681350Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:41:58.1681936Z strides: [128, 1], [256, 1]
2026-01-14T08:41:58.1682203Z dtypes: torch.float16, torch.float16
2026-01-14T08:41:58.1682944Z   triton_mm_1118 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1684283Z   triton_mm_1119 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:58.1685449Z   triton_mm_1112 0.0226 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:58.1686615Z   triton_mm_1120 0.0235 ms 95.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1687796Z   triton_mm_1115 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:58.1688947Z   triton_mm_1116 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:58.1690116Z   triton_mm_1121 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1691351Z   triton_mm_1123 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:58.1692512Z   triton_mm_1124 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:58.1693677Z   triton_mm_1111 0.0236 ms 95.4% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:41:58.1694648Z SingleProcess AUTOTUNE benchmarking takes 0.1952 seconds and 0.1925 seconds precompiling for 16 choices
2026-01-14T08:41:58.1695521Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.008ms 
2026-01-14T08:41:58.1696503Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:41:58.1697504Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:41:58.1698505Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:41:58.1699573Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.50
2026-01-14T08:41:58.1700523Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:41:58.1700975Z 
2026-01-14T08:41:58.1701287Z [32mPASSED[0m
2026-01-14T08:41:58.1701769Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_23 (m, k, n):  (16, 256, 128)
2026-01-14T08:41:58.1702375Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:41:58.1702875Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:41:58.1703325Z Autotune Choices Stats:
2026-01-14T08:41:58.1704429Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_1157", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:41:58.1705654Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:41:58.1705941Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:41:58.1706254Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:41:58.1707021Z   triton_mm_1157 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:41:58.1708279Z   triton_mm_1158 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:58.1709442Z   triton_mm_1147 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:41:58.1710596Z   triton_mm_1148 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:58.1711759Z   triton_mm_1149 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:58.1712910Z   triton_mm_1151 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:58.1714071Z   triton_mm_1152 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1715228Z   triton_mm_1153 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1716445Z   triton_mm_1154 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:58.1717609Z   triton_mm_1155 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1718570Z SingleProcess AUTOTUNE benchmarking takes 0.2176 seconds and 0.2813 seconds precompiling for 17 choices
2026-01-14T08:41:58.1719342Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:41:58.1719873Z Autotune Choices Stats:
2026-01-14T08:41:58.1720963Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_1173", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8", "best_time": 0.023520000278949738, "best_triton_pos": 0}
2026-01-14T08:41:58.1722112Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:41:58.1722367Z strides: [256, 1], [128, 1]
2026-01-14T08:41:58.1722626Z dtypes: torch.float16, torch.float16
2026-01-14T08:41:58.1723362Z   triton_mm_1173 0.0235 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:41:58.1724540Z   triton_mm_1169 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:41:58.1725703Z   triton_mm_1170 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:41:58.1726867Z   triton_mm_1174 0.0236 ms 99.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:41:58.1728110Z   triton_mm_1165 0.0236 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:58.1729271Z   triton_mm_1164 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:41:58.1730506Z   triton_mm_1166 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:41:58.1731703Z   triton_mm_1168 0.0246 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4649670Z   triton_mm_1163 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:06.4650941Z   triton_mm_1160 0.0256 ms 91.9% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:06.4651993Z SingleProcess AUTOTUNE benchmarking takes 0.2002 seconds and 0.2289 seconds precompiling for 16 choices
2026-01-14T08:42:06.4652876Z >>time: 0.010ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.007ms 
2026-01-14T08:42:06.4653868Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:42:06.4654865Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.006ms
2026-01-14T08:42:06.4655757Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:06.4656204Z 
2026-01-14T08:42:06.4656528Z [32mPASSED[0m
2026-01-14T08:42:06.4657018Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_24 (m, k, n):  (64, 256, 128)
2026-01-14T08:42:06.4657622Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:42:06.4658114Z weight_shape: torch.Size([128, 256]), dtype: torch.float16, bias_shape: torch.Size([128])
2026-01-14T08:42:06.4658572Z Autotune Choices Stats:
2026-01-14T08:42:06.4659685Z {"num_choices": 15, "num_triton_choices": 13, "best_kernel": "triton_mm_1194", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:42:06.4660870Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:42:06.4661159Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:42:06.4661474Z dtypes: torch.float16, torch.float16, torch.float16
2026-01-14T08:42:06.4662266Z   triton_mm_1194 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4663450Z   triton_mm_1192 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4664616Z   triton_mm_1195 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4665780Z   triton_mm_1196 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:06.4666937Z   triton_mm_1197 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:06.4668394Z   triton_mm_1185 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:06.4669561Z   triton_mm_1189 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:06.4670716Z   triton_mm_1193 0.0266 ms 88.5% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:06.4672657Z   triton_mm_1186 0.0276 ms 85.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:06.4673823Z   triton_mm_1187 0.0276 ms 85.2% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:06.4674786Z SingleProcess AUTOTUNE benchmarking takes 0.2010 seconds and 0.3789 seconds precompiling for 15 choices
2026-01-14T08:42:06.4675568Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:06.4676106Z Autotune Choices Stats:
2026-01-14T08:42:06.4677202Z {"num_choices": 14, "num_triton_choices": 13, "best_kernel": "triton_mm_1209", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:42:06.4678404Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:42:06.4678654Z strides: [256, 1], [128, 1]
2026-01-14T08:42:06.4678919Z dtypes: torch.float16, torch.float16
2026-01-14T08:42:06.4679654Z   triton_mm_1209 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:06.4680827Z   triton_mm_1199 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:06.4681994Z   triton_mm_1202 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:06.4683156Z   triton_mm_1204 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:06.4684340Z   triton_mm_1206 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:06.4685511Z   triton_mm_1207 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4686682Z   triton_mm_1208 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4695970Z   triton_mm_1198 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:06.4697210Z   triton_mm_1200 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:06.4698384Z   triton_mm_1201 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:06.4699353Z SingleProcess AUTOTUNE benchmarking takes 0.1764 seconds and 0.3282 seconds precompiling for 14 choices
2026-01-14T08:42:06.4700335Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.011ms 
2026-01-14T08:42:06.4701337Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.009ms
2026-01-14T08:42:06.4702337Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.015ms 
2026-01-14T08:42:06.4703484Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 0.34
2026-01-14T08:42:06.4704438Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:42:06.4704878Z 
2026-01-14T08:42:06.4705033Z [32mPASSED[0m
2026-01-14T08:42:06.4705508Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_25 (m, k, n):  (16, 128, 128)
2026-01-14T08:42:06.4706061Z [32mPASSED[0m
2026-01-14T08:42:06.4706519Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_26 (m, k, n):  (64, 128, 128)
2026-01-14T08:42:06.4707118Z activation_shapes: torch.Size([64, 128]), times_seen: 1
2026-01-14T08:42:06.4707639Z weight_shape: torch.Size([128, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:42:06.4708124Z Autotune Choices Stats:
2026-01-14T08:42:06.4709224Z {"num_choices": 15, "num_triton_choices": 13, "best_kernel": "triton_mm_1238", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:42:06.4710386Z AUTOTUNE addmm(64x128, 64x128, 128x128)
2026-01-14T08:42:06.4710673Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:06.4710994Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:06.4711788Z   triton_mm_1238 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4712963Z   triton_mm_1241 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:06.4714125Z   triton_mm_1231 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:10.3150273Z   triton_mm_1233 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3152352Z   triton_mm_1234 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3154314Z   triton_mm_1235 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3156292Z   triton_mm_1236 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3158181Z   triton_mm_1237 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:10.3160157Z   triton_mm_1239 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:10.3162143Z   triton_mm_1243 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:10.3163812Z SingleProcess AUTOTUNE benchmarking takes 0.1928 seconds and 0.3460 seconds precompiling for 15 choices
2026-01-14T08:42:10.3165505Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:10.3166419Z Autotune Choices Stats:
2026-01-14T08:42:10.3168329Z {"num_choices": 14, "num_triton_choices": 13, "best_kernel": "triton_mm_1253", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:42:10.3170615Z AUTOTUNE mm(64x128, 128x128)
2026-01-14T08:42:10.3171045Z strides: [128, 1], [128, 1]
2026-01-14T08:42:10.3171636Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:42:10.3172923Z   triton_mm_1253 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3174992Z   triton_mm_1254 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3176882Z   triton_mm_1245 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3178884Z   triton_mm_1255 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:10.3180945Z   triton_mm_1246 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3183008Z   triton_mm_1247 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3185009Z   triton_mm_1248 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3186966Z   triton_mm_1249 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3189066Z   triton_mm_1250 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=8
2026-01-14T08:42:10.3191030Z   triton_mm_1252 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:10.3192666Z SingleProcess AUTOTUNE benchmarking takes 0.1764 seconds and 0.2849 seconds precompiling for 14 choices
2026-01-14T08:42:10.3194174Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.008ms 
2026-01-14T08:42:10.3195870Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.008ms
2026-01-14T08:42:10.3197349Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:10.3198053Z 
2026-01-14T08:42:10.3198454Z [32mPASSED[0m
2026-01-14T08:42:10.3199194Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_27 (m, k, n):  (16, 128, 256)
2026-01-14T08:42:10.3200125Z activation_shapes: torch.Size([16, 128]), times_seen: 1
2026-01-14T08:42:10.3200962Z weight_shape: torch.Size([256, 128]), dtype: torch.bfloat16, bias_shape: torch.Size([256])
2026-01-14T08:42:10.3201694Z Autotune Choices Stats:
2026-01-14T08:42:10.3203752Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_1273", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:42:10.3205765Z AUTOTUNE addmm(16x256, 16x128, 128x256)
2026-01-14T08:42:10.3206243Z strides: [0, 1], [128, 1], [1, 128]
2026-01-14T08:42:10.3206804Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:10.3208137Z   triton_mm_1273 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:10.3210381Z   triton_mm_1276 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:10.3212492Z   triton_mm_1281 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3214474Z   triton_mm_1268 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:42:10.3216467Z   triton_mm_1275 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3218477Z   triton_mm_1277 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3220501Z   triton_mm_1278 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3222500Z   triton_mm_1279 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:10.3224530Z   triton_mm_1280 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:10.3226614Z   triton_mm_1270 0.0257 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:10.3228142Z SingleProcess AUTOTUNE benchmarking takes 0.2176 seconds and 0.2787 seconds precompiling for 17 choices
2026-01-14T08:42:10.3229313Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:10.3230039Z Autotune Choices Stats:
2026-01-14T08:42:10.3231711Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_1296", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:42:10.3233600Z AUTOTUNE mm(16x128, 128x256)
2026-01-14T08:42:10.3234007Z strides: [128, 1], [256, 1]
2026-01-14T08:42:10.3234385Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:42:10.3235656Z   triton_mm_1296 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:10.3237644Z   triton_mm_1290 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:10.3239607Z   triton_mm_1294 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:10.3241486Z   triton_mm_1284 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:20.4901461Z   triton_mm_1286 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:20.4902975Z   triton_mm_1287 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:20.4904314Z   triton_mm_1288 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:20.4905478Z   triton_mm_1289 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4906638Z   triton_mm_1291 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:20.4907815Z   triton_mm_1292 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4908788Z SingleProcess AUTOTUNE benchmarking takes 0.2020 seconds and 0.2132 seconds precompiling for 16 choices
2026-01-14T08:42:20.4909666Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.008ms 
2026-01-14T08:42:20.4910644Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.007ms 
2026-01-14T08:42:20.4911651Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:42:20.4912532Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:42:20.4912970Z 
2026-01-14T08:42:20.4913274Z [32mPASSED[0m
2026-01-14T08:42:20.4913763Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_28 (m, k, n):  (16, 256, 128)
2026-01-14T08:42:20.4914364Z activation_shapes: torch.Size([16, 256]), times_seen: 1
2026-01-14T08:42:20.4914860Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:42:20.4915328Z Autotune Choices Stats:
2026-01-14T08:42:20.4916429Z {"num_choices": 17, "num_triton_choices": 15, "best_kernel": "triton_mm_1308", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:42:20.4917581Z AUTOTUNE addmm(16x128, 16x256, 256x128)
2026-01-14T08:42:20.4917868Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:42:20.4918188Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:20.4918981Z   triton_mm_1308 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=2
2026-01-14T08:42:20.4920154Z   triton_mm_1309 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:20.4921317Z   triton_mm_1310 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:20.4922482Z   triton_mm_1311 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:20.4923650Z   triton_mm_1314 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4924894Z   triton_mm_1318 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4926058Z   triton_mm_1319 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=4
2026-01-14T08:42:20.4927301Z   triton_mm_1321 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:20.4928458Z   triton_mm_1312 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:20.4929619Z   triton_mm_1315 0.0256 ms 96.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4930594Z SingleProcess AUTOTUNE benchmarking takes 0.2194 seconds and 0.2552 seconds precompiling for 17 choices
2026-01-14T08:42:20.4931508Z >>time: 0.011ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:20.4932046Z Autotune Choices Stats:
2026-01-14T08:42:20.4933143Z {"num_choices": 16, "num_triton_choices": 15, "best_kernel": "triton_mm_1326", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2", "best_time": 0.023552000522613525, "best_triton_pos": 0}
2026-01-14T08:42:20.4934287Z AUTOTUNE mm(16x256, 256x128)
2026-01-14T08:42:20.4934540Z strides: [256, 1], [128, 1]
2026-01-14T08:42:20.4934796Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:42:20.4935528Z   triton_mm_1326 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=2
2026-01-14T08:42:20.4936696Z   triton_mm_1328 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:20.4937858Z   triton_mm_1330 0.0236 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4939027Z   triton_mm_1329 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:20.4940178Z   triton_mm_1335 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:20.4941344Z   triton_mm_1336 0.0246 ms 95.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:20.4942500Z   triton_mm_1322 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:20.4943645Z   triton_mm_1324 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=4
2026-01-14T08:42:20.4944803Z   triton_mm_1327 0.0256 ms 92.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=16, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:20.4945958Z   triton_mm_1331 0.0257 ms 91.8% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=16, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:20.4946913Z SingleProcess AUTOTUNE benchmarking takes 0.2049 seconds and 0.2366 seconds precompiling for 16 choices
2026-01-14T08:42:20.4947874Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.011ms 
2026-01-14T08:42:20.4948852Z >>time: 0.014ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight2'>, to_beat: 0.011ms 
2026-01-14T08:42:20.4950121Z >>time: 0.006ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.011ms
2026-01-14T08:42:20.4951124Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>, to_beat: 0.038ms 
2026-01-14T08:42:20.4952184Z >>time: 0.009ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> interpolated, breakeven constant: 1.53
2026-01-14T08:42:20.4953148Z best_cls=<class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'>
2026-01-14T08:42:20.4953589Z 
2026-01-14T08:42:20.4953717Z [32mPASSED[0m
2026-01-14T08:42:20.4954194Z test/integration/test_integration.py::TestAutoQuant::test_autoquant_one_input_29 (m, k, n):  (64, 256, 128)
2026-01-14T08:42:20.4954792Z activation_shapes: torch.Size([64, 256]), times_seen: 1
2026-01-14T08:42:20.4955284Z weight_shape: torch.Size([128, 256]), dtype: torch.bfloat16, bias_shape: torch.Size([128])
2026-01-14T08:42:20.4955745Z Autotune Choices Stats:
2026-01-14T08:42:20.4956847Z {"num_choices": 15, "num_triton_choices": 13, "best_kernel": "triton_mm_1369", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8", "best_time": 0.02252800017595291, "best_triton_pos": 0}
2026-01-14T08:42:20.4957998Z AUTOTUNE addmm(64x128, 64x256, 256x128)
2026-01-14T08:42:20.4958285Z strides: [0, 1], [256, 1], [1, 256]
2026-01-14T08:42:27.0903374Z dtypes: torch.bfloat16, torch.bfloat16, torch.bfloat16
2026-01-14T08:42:27.0904612Z   triton_mm_1369 0.0225 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:27.0905805Z   triton_mm_1362 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0906971Z   triton_mm_1365 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:27.0908140Z   triton_mm_1368 0.0236 ms 95.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:27.0909303Z   triton_mm_1358 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0910466Z   triton_mm_1360 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:27.0911617Z   triton_mm_1364 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:27.0912785Z   triton_mm_1366 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:27.0913943Z   triton_mm_1367 0.0246 ms 91.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:27.0915093Z   triton_mm_1361 0.0256 ms 88.1% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0916425Z SingleProcess AUTOTUNE benchmarking takes 0.1898 seconds and 0.4533 seconds precompiling for 15 choices
2026-01-14T08:42:27.0917204Z >>time: 0.013ms for <class 'torchao.quantization.autoquant.AQDefaultLinearWeight'>, to_beat: infms 
2026-01-14T08:42:27.0917748Z Autotune Choices Stats:
2026-01-14T08:42:27.0918857Z {"num_choices": 14, "num_triton_choices": 13, "best_kernel": "triton_mm_1371", "best_kernel_desc": "ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4", "best_time": 0.02457600086927414, "best_triton_pos": 0}
2026-01-14T08:42:27.0920184Z AUTOTUNE mm(64x256, 256x128)
2026-01-14T08:42:27.0920444Z strides: [256, 1], [128, 1]
2026-01-14T08:42:27.0920708Z dtypes: torch.bfloat16, torch.bfloat16
2026-01-14T08:42:27.0921450Z   triton_mm_1371 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=128, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0922634Z   triton_mm_1372 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=32, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:27.0923799Z   triton_mm_1377 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:27.0924976Z   triton_mm_1378 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=4, num_warps=8
2026-01-14T08:42:27.0926145Z   triton_mm_1382 0.0246 ms 100.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=8
2026-01-14T08:42:27.0927306Z   triton_mm_1380 0.0246 ms 99.7% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=3, num_warps=4
2026-01-14T08:42:27.0928469Z   triton_mm_1370 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=32, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=1, num_warps=2
2026-01-14T08:42:27.0929624Z   triton_mm_1373 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=32, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=5, num_warps=8
2026-01-14T08:42:27.0930776Z   triton_mm_1374 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0932020Z   triton_mm_1375 0.0256 ms 96.0% ACC_TYPE='tl.float32', ALLOW_TF32=False, BLOCK_K=32, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, USE_FAST_ACCUM=False, num_stages=2, num_warps=4
2026-01-14T08:42:27.0932982Z SingleProcess AUTOTUNE benchmarking takes 0.1746 seconds and 0.3055 seconds precompiling for 14 choices
2026-01-14T08:42:27.0933857Z >>time: 0.007ms for <class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>, to_beat: 0.013ms 
2026-01-14T08:42:27.0934861Z >>time: 0.008ms for <class 'torchao.quantization.autoquant.AQInt8DynamicallyQuantizedLinearWeight'> matmul, to_beat: 0.007ms
2026-01-14T08:42:27.0935745Z best_cls=<class 'torchao.quantization.autoquant.AQInt8WeightOnlyQuantizedLinearWeight'>
2026-01-14T08:42:27.0936193Z 
2026-01-14T08:42:27.0936507Z [32mPASSED[0m
2026-01-14T08:42:27.0936972Z test/integration/test_integration.py::TestAOTI::test_aoti_00 [33mSKIPPED[0m
2026-01-14T08:42:27.0937620Z test/integration/test_integration.py::TestAOTI::test_aoti_01 [33mSKIPPED[0m
2026-01-14T08:42:27.0938258Z test/integration/test_integration.py::TestAOTI::test_aoti_02 [33mSKIPPED[0m
2026-01-14T08:42:27.0938884Z test/integration/test_integration.py::TestAOTI::test_aoti_03 [33mSKIPPED[0m
2026-01-14T08:42:27.0939520Z test/integration/test_integration.py::TestAOTI::test_aoti_04 [33mSKIPPED[0m
2026-01-14T08:42:27.0940240Z test/integration/test_integration.py::TestAOTI::test_aoti_05 [33mSKIPPED[0m
2026-01-14T08:42:27.0940872Z test/integration/test_integration.py::TestAOTI::test_aoti_06 [33mSKIPPED[0m
2026-01-14T08:42:27.0941506Z test/integration/test_integration.py::TestAOTI::test_aoti_07 [33mSKIPPED[0m
2026-01-14T08:42:27.0942135Z test/integration/test_integration.py::TestAOTI::test_aoti_08 [33mSKIPPED[0m
2026-01-14T08:42:27.0942851Z test/integration/test_integration.py::TestAOTI::test_aoti_09 [33mSKIPPED[0m
2026-01-14T08:42:27.0943481Z test/integration/test_integration.py::TestAOTI::test_aoti_10 [33mSKIPPED[0m
2026-01-14T08:42:27.0944109Z test/integration/test_integration.py::TestAOTI::test_aoti_11 [33mSKIPPED[0m
2026-01-14T08:42:27.0944742Z test/integration/test_integration.py::TestAOTI::test_aoti_12 [33mSKIPPED[0m
2026-01-14T08:42:27.0945365Z test/integration/test_integration.py::TestAOTI::test_aoti_13 [33mSKIPPED[0m
2026-01-14T08:42:27.0945999Z test/integration/test_integration.py::TestAOTI::test_aoti_14 [33mSKIPPED[0m
2026-01-14T08:42:27.0946631Z test/integration/test_integration.py::TestAOTI::test_aoti_15 [33mSKIPPED[0m
2026-01-14T08:42:27.0947264Z test/integration/test_integration.py::TestAOTI::test_aoti_16 [33mSKIPPED[0m
2026-01-14T08:42:27.0947890Z test/integration/test_integration.py::TestAOTI::test_aoti_17 [33mSKIPPED[0m
2026-01-14T08:42:27.0948554Z test/integration/test_integration.py::TestExport::test_export_00 [32mPASSED[0m
2026-01-14T08:42:27.0949407Z test/integration/test_integration.py::TestExport::test_export_01 [32mPASSED[0m
2026-01-14T08:42:27.0950063Z test/integration/test_integration.py::TestExport::test_export_02 [32mPASSED[0m
2026-01-14T08:42:27.0950716Z test/integration/test_integration.py::TestExport::test_export_03 [32mPASSED[0m
2026-01-14T08:42:27.0951365Z test/integration/test_integration.py::TestExport::test_export_04 [32mPASSED[0m
2026-01-14T08:42:27.0952022Z test/integration/test_integration.py::TestExport::test_export_05 [32mPASSED[0m
2026-01-14T08:42:27.0952736Z test/integration/test_integration.py::TestExport::test_export_06 [32mPASSED[0m
2026-01-14T08:42:27.0953383Z test/integration/test_integration.py::TestExport::test_export_07 [32mPASSED[0m
2026-01-14T08:42:27.0954040Z test/integration/test_integration.py::TestExport::test_export_08 [32mPASSED[0m
2026-01-14T08:42:27.0954692Z test/integration/test_integration.py::TestExport::test_export_09 [32mPASSED[0m
2026-01-14T08:42:27.0955357Z test/integration/test_integration.py::TestExport::test_export_10 [32mPASSED[0m
2026-01-14T08:42:27.0956006Z test/integration/test_integration.py::TestExport::test_export_11 [32mPASSED[0m
2026-01-14T08:42:27.0956659Z test/integration/test_integration.py::TestExport::test_export_12 [32mPASSED[0m
2026-01-14T08:42:27.0957315Z test/integration/test_integration.py::TestExport::test_export_13 [32mPASSED[0m
2026-01-14T08:42:27.0957964Z test/integration/test_integration.py::TestExport::test_export_14 [32mPASSED[0m
2026-01-14T08:42:27.0958617Z test/integration/test_integration.py::TestExport::test_export_15 [32mPASSED[0m
2026-01-14T08:42:27.0959270Z test/integration/test_integration.py::TestExport::test_export_16 [32mPASSED[0m
2026-01-14T08:42:27.0959929Z test/integration/test_integration.py::TestExport::test_export_17 [32mPASSED[0m
2026-01-14T08:42:27.0960588Z test/integration/test_integration.py::TestExport::test_export_18 [32mPASSED[0m
2026-01-14T08:42:27.0961240Z test/integration/test_integration.py::TestExport::test_export_19 [32mPASSED[0m
2026-01-14T08:42:27.0961899Z test/integration/test_integration.py::TestExport::test_export_20 [32mPASSED[0m
2026-01-14T08:42:27.0962591Z test/integration/test_integration.py::TestExport::test_export_21 [32mPASSED[0m
2026-01-14T08:42:27.0963259Z test/integration/test_integration.py::TestExport::test_export_22 [32mPASSED[0m
2026-01-14T08:42:27.0963913Z test/integration/test_integration.py::TestExport::test_export_23 [32mPASSED[0m
2026-01-14T08:44:15.1955526Z test/integration/test_integration.py::TestExport::test_export_float8 [33mSKIPPED[0m
2026-01-14T08:44:15.1959047Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_00 [33mSKIPPED[0m
2026-01-14T08:44:15.1960038Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_01 [33mSKIPPED[0m
2026-01-14T08:44:15.1960790Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_02 [33mSKIPPED[0m
2026-01-14T08:44:15.1962004Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_03 [33mSKIPPED[0m
2026-01-14T08:44:15.1963005Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_04 [33mSKIPPED[0m
2026-01-14T08:44:15.1964041Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_05 [32mPASSED[0m
2026-01-14T08:44:15.1964795Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_06 [33mSKIPPED[0m
2026-01-14T08:44:15.1965554Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_07 [33mSKIPPED[0m
2026-01-14T08:44:15.1966321Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_08 [33mSKIPPED[0m
2026-01-14T08:44:15.1967110Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_09 [33mSKIPPED[0m
2026-01-14T08:44:15.1967853Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_10 [33mSKIPPED[0m
2026-01-14T08:44:15.1968607Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_11 [32mPASSED[0m
2026-01-14T08:44:15.1969354Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_12 [33mSKIPPED[0m
2026-01-14T08:44:15.1970099Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_13 [33mSKIPPED[0m
2026-01-14T08:44:15.1970865Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_14 [33mSKIPPED[0m
2026-01-14T08:44:15.1971714Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_15 [33mSKIPPED[0m
2026-01-14T08:44:15.1972462Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_16 [33mSKIPPED[0m
2026-01-14T08:44:15.1973209Z test/integration/test_integration.py::TestUtils::test_get_model_size_aqt_17 [32mPASSED[0m
2026-01-14T08:44:15.1974059Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cpu cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:44:15.1974889Z    File "/pytorch/ao/test/integration/test_integration.py", line 1569, in forward
2026-01-14T08:44:15.1975320Z     x = self.linear1(x)
2026-01-14T08:44:15.1975476Z 
2026-01-14T08:44:15.1975628Z cudagraph partition due to non gpu ops. Found from : 
2026-01-14T08:44:15.1976112Z    File "/pytorch/ao/test/integration/test_integration.py", line 1570, in forward
2026-01-14T08:44:15.1976539Z     x = self.linear2(x)
2026-01-14T08:44:15.1976685Z 
2026-01-14T08:44:15.1976810Z [32mPASSED[0m
2026-01-14T08:44:15.1977333Z test/integration/test_integration.py::TestBenchmarkModel::test_benchmark_model_cuda [32mPASSED[0m
2026-01-14T08:44:15.1978318Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_hf_models_model_info0 [33mSKIPPED[0m
2026-01-14T08:44:15.1979420Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_deprecated_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:44:15.1980493Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info0 [33mSKIPPED[0m
2026-01-14T08:44:15.1981527Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info1 [33mSKIPPED[0m
2026-01-14T08:44:15.1982548Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info2 [33mSKIPPED[0m
2026-01-14T08:44:15.1983572Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info3 [33mSKIPPED[0m
2026-01-14T08:44:15.1984594Z test/integration/test_load_and_run_checkpoint.py::TestLoadAndRunCheckpoint::test_single_linear_model_info4 [33mSKIPPED[0m
2026-01-14T08:44:15.1985535Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda [32mPASSED[0m
2026-01-14T08:44:15.1986196Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda [32mPASSED[0m
2026-01-14T08:44:15.1986919Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_0_cuda [33mSKIPPED[0m
2026-01-14T08:44:15.1988669Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_float8_1_cuda [33mSKIPPED[0m
2026-01-14T08:44:15.1989363Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda [32mPASSED[0m
2026-01-14T08:44:15.1990061Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu [32mPASSED[0m
2026-01-14T08:44:15.1990752Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda [32mPASSED[0m
2026-01-14T08:44:15.1991443Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu [32mPASSED[0m
2026-01-14T08:44:15.1992155Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-2-512-128] Relative Error: 0.052789
2026-01-14T08:44:15.1992714Z [32mPASSED[0m
2026-01-14T08:44:15.1993186Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-3-2048-2048] Relative Error: 0.052619
2026-01-14T08:44:15.1993753Z [32mPASSED[0m
2026-01-14T08:44:15.1994207Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-4-3584-640] Relative Error: 0.052605
2026-01-14T08:44:15.1994769Z [32mPASSED[0m
2026-01-14T08:44:15.1995230Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-13-8704-8576] Relative Error: 0.052641
2026-01-14T08:44:15.1995801Z [32mPASSED[0m
2026-01-14T08:44:15.1996268Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-26-18944-1664] Relative Error: 0.052629
2026-01-14T08:44:15.1996843Z [32mPASSED[0m
2026-01-14T08:44:15.1997314Z test/kernel/test_blockwise_triton.py::test_blockwise_quant_dequant[dtype0-67-6656-1408] Relative Error: 0.052626
2026-01-14T08:44:15.1997871Z [32mPASSED[0m
2026-01-14T08:44:15.1998313Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-2-512-128] Relative Error: 0.076733
2026-01-14T08:44:15.1998839Z [32mPASSED[0m
2026-01-14T08:44:15.1999282Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-3-2048-2048] Relative Error: 0.073021
2026-01-14T08:44:15.1999822Z [32mPASSED[0m
2026-01-14T08:44:15.2000265Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-4-3584-640] Relative Error: 0.073371
2026-01-14T08:44:15.2000797Z [32mPASSED[0m
2026-01-14T08:44:15.2001243Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-13-8704-8576] Relative Error: 0.073475
2026-01-14T08:44:15.2001787Z [32mPASSED[0m
2026-01-14T08:44:15.2002231Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-26-18944-1664] Relative Error: 0.073329
2026-01-14T08:44:15.2002784Z [32mPASSED[0m
2026-01-14T08:44:15.2003228Z test/kernel/test_blockwise_triton.py::test_blockwise_fp8_gemm[dtype0-67-6656-1408] Relative Error: 0.073540
2026-01-14T08:44:15.2003783Z [32mPASSED[0m
2026-01-14T08:44:15.2004443Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:44:15.2005542Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:44:15.2006641Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:44:15.2007723Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:44:15.2008819Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:44:15.2009919Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:44:15.2011107Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x128[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:44:15.2012385Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-512-128] [33mSKIPPED[0m
2026-01-14T08:44:15.2013665Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-2-5120-1280] [33mSKIPPED[0m
2026-01-14T08:44:15.2014743Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-3-2048-2048] [33mSKIPPED[0m
2026-01-14T08:44:15.2015815Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-4-3584-640] [33mSKIPPED[0m
2026-01-14T08:44:15.2016894Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-13-8704-8576] [33mSKIPPED[0m
2026-01-14T08:44:15.2018257Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-26-18944-1664] [33mSKIPPED[0m
2026-01-14T08:44:15.2019612Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_fp8_gemm_1x128_128x1[dtype0-67-6656-1408] [33mSKIPPED[0m
2026-01-14T08:44:15.2020918Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[128] [33mSKIPPED[0m
2026-01-14T08:44:15.2022187Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_lhs[256] [33mSKIPPED[0m
2026-01-14T08:44:15.2023445Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[128] [33mSKIPPED[0m
2026-01-14T08:44:15.2024707Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_rhs[256] [33mSKIPPED[0m
2026-01-14T08:44:15.2026095Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:44:15.2027564Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:44:15.7218122Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:44:15.7219361Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_act_quant_transposed_lhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:44:15.7220523Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-128] [33mSKIPPED[0m
2026-01-14T08:44:15.7221647Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-1024-256] [33mSKIPPED[0m
2026-01-14T08:44:15.7222778Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-128] [33mSKIPPED[0m
2026-01-14T08:44:15.7223910Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_rhs[4096-16384-256] [33mSKIPPED[0m
2026-01-14T08:44:15.7225044Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[128] [33mSKIPPED[0m
2026-01-14T08:44:15.7226186Z test/prototype/blockwise_fp8_training/test_blockwise_kernels.py::test_triton_quantize_fp8_weight_quant_transposed_rhs[256] [33mSKIPPED[0m
2026-01-14T08:44:15.7227270Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_fp8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:44:15.7228289Z test/prototype/inductor/test_qsdpa_fusion.py::SDPAPatternRewriterCpuTests::test_int8_sdpa_rewriter_cpu [33mSKIPPED[0m
2026-01-14T08:44:15.7229317Z test/prototype/module_swap_quantization/test_kmeans_codebook.py::TestKmeansCodebook::test_kmeans_codebook [33mSKIPPED[0m
2026-01-14T08:44:15.7230570Z test/prototype/module_swap_quantization/test_llm_ptq_data_getter.py::TestPTQDataGetter::test_data_getter [33mSKIPPED[0m
2026-01-14T08:44:15.7231562Z test/prototype/module_swap_quantization/test_module_swap.py::TestEmbeddingSwap::test_embedding_swap [32mPASSED[0m
2026-01-14T08:44:15.7232861Z test/prototype/module_swap_quantization/test_module_swap_quantization_utils.py::TestQuantizedModuleUtils::test_set_bit_widths_by_name [32mPASSED[0m
2026-01-14T08:44:15.7234015Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic [32mPASSED[0m
2026-01-14T08:44:15.7235106Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantize_dynamic_vectorized [32mPASSED[0m
2026-01-14T08:44:15.7236196Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear [32mPASSED[0m
2026-01-14T08:44:15.7237269Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_init [32mPASSED[0m
2026-01-14T08:44:15.7238421Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients [32mPASSED[0m
2026-01-14T08:44:15.7239712Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_activation_scale [32mPASSED[0m
2026-01-14T08:44:15.7241051Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_quantized_linear_passes_gradients_to_weight_scale [32mPASSED[0m
2026-01-14T08:44:15.7242366Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_all_options [32mPASSED[0m
2026-01-14T08:44:15.7243624Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedLinear::test_set_weight_scale_to_min_max_test_correct [32mPASSED[0m
2026-01-14T08:44:15.7244795Z test/prototype/module_swap_quantization/test_quantized_modules.py::TestQuantizedEmbedding::test_quantized_embedding [32mPASSED[0m
2026-01-14T08:44:15.7245894Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_qmin_qmax [32mPASSED[0m
2026-01-14T08:44:15.7256818Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max [32mPASSED[0m
2026-01-14T08:44:15.7257957Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_from_min_max_vectorized [32mPASSED[0m
2026-01-14T08:44:15.7259043Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_asymmetric [32mPASSED[0m
2026-01-14T08:44:15.7260107Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max [32mPASSED[0m
2026-01-14T08:44:15.7261213Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_from_min_max_tensorized [32mPASSED[0m
2026-01-14T08:44:15.7262311Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_offset_symmetric [32mPASSED[0m
2026-01-14T08:44:15.7263325Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_get_scale_param_size [32mPASSED[0m
2026-01-14T08:44:15.7264311Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward [32mPASSED[0m
2026-01-14T08:44:15.7265358Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_asymmetric_clipping [32mPASSED[0m
2026-01-14T08:44:15.7266435Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric [32mPASSED[0m
2026-01-14T08:44:15.7267521Z test/prototype/module_swap_quantization/test_quantizers.py::TestIntQuantizer::test_quantize_forward_symmetric_clipping [32mPASSED[0m
2026-01-14T08:44:15.7268753Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_codebook_quantizer [32mPASSED[0m
2026-01-14T08:44:15.7269783Z test/prototype/module_swap_quantization/test_quantizers.py::TestCodebookQuantizer::test_vector_quantizer [32mPASSED[0m
2026-01-14T08:44:15.7270954Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max [32mPASSED[0m
2026-01-14T08:44:15.7272083Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMinMax::test_set_weight_min_max_grouped [32mPASSED[0m
2026-01-14T08:44:15.7273179Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse [32mPASSED[0m
2026-01-14T08:44:15.7274241Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightMSE::test_set_weight_mse_grouped [32mPASSED[0m
2026-01-14T08:44:15.7275468Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss [32mPASSED[0m
2026-01-14T08:44:15.7276932Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestSetWeightRangeActivationLoss::test_set_weight_range_activation_loss_progressive [32mPASSED[0m
2026-01-14T08:44:15.7278321Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting [32mPASSED[0m
2026-01-14T08:44:15.7279701Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestStaticActivationRangeSetting::test_static_activation_range_setting_no_input [32mPASSED[0m
2026-01-14T08:44:15.7281020Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales [32mPASSED[0m
2026-01-14T08:44:15.7282344Z test/prototype/module_swap_quantization/test_range_setting_methods.py::TestQuantizePerGroupScales::test_quantize_per_group_scales_dont_change_per_channel [32mPASSED[0m
2026-01-14T08:44:15.7283592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7284693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.7285789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7286937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.7288018Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7289107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.7290199Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7291356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.7292451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7293544Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.7294629Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.7295732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8050204Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8051409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8052527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8053758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8054875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8055976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8057083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8058191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8059292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8060409Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8061520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8062625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8063741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8064851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8065953Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8067132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8068241Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8069359Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8070486Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8071609Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[2-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8072715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8073809Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8074905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8076007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8077100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8078285Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8079383Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8080477Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8081657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8082746Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8083847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8084959Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8086060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8087167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8088284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8089392Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-True-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8090500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8091661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8092775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8093880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8094982Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8096086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8097203Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8098321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-True-False-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:15.8099445Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8100548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8101669Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8102792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-True-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8103903Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8105028Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8106248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:15.8107428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_mx[3-False-False-False-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:15.8108704Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8110183Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8111553Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8112933Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8114324Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8115730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8117145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8733175Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8734579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8735954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8737318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8738697Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8740079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8741471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8742877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8744281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8745672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8747050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8748430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8750127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8751877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8753627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8755149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.8756564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.8757943Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8759323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8760698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8762083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8763478Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8764880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8766285Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.8767738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.8769133Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8770501Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8771951Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8773334Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8774736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8776143Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8777555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8778974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8780364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8781815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8783206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8784665Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8786055Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8787465Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8788880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8790291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8791693Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8793074Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8794466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8795874Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8797335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.8798766Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.8800189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.8801607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.9423110Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9424529Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9425914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9427320Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9428728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9430151Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9431729Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.9433163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.9434663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9436038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9437466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9438850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9440252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9441663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9443067Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9444477Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9445863Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9447238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9448625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9450160Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9451741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9453155Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9454555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9455970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9457379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9458755Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9460145Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9461764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9463173Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9464706Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9466113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.9467579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.9468985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9470365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9471755Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9473152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9474562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9475988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9477414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:15.9478829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:15.9480226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9481614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9483011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9484403Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9485818Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9487249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9488675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:15.9490102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:15.9491674Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0092421Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0093988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0095384Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0096788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0098210Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0099632Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0101057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0102466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0103866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0105262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0106664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0108079Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0109514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0110936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0112362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0113766Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0115157Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0116556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0117964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0119378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0120923Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0122356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0123864Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0125249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0126643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0128044Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0129420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0130811Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0132255Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0133654Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0135067Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0136437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0137794Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0139163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0140527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0141906Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0143304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0144698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0146108Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0147485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0148855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0150530Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0151913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0153422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0154829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0156227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0157702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0159091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0160462Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0713742Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0715162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0716564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0717973Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0719377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0720785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0722171Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0723539Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0724917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0726300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0727699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0729098Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0730508Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0732158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0733561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0735041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0736413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0737800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0739199Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0740603Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0742011Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0743433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0744829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0746212Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0747611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0749161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0750578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0751988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0753406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0754826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0756216Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0757606Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0758991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0760378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0761907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0763325Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0764841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.0766264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.0767699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0769058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0770429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0771842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0773235Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0774627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0776025Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0777507Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0778890Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.0780253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.0781616Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1340385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1343177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1345961Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1347586Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1348987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1350522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1352075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1353456Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1354843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1356358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1357760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1359178Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.1360591Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.1361978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1363356Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1364736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1366129Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1367588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1368994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1370418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.1371909Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.1373290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1374667Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1376041Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1377423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1378824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1380234Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1381721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1383141Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1384531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1386012Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1387573Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1388954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1390357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1391760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1393169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1394592Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1395994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1397434Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1398815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1400211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1401608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1403030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1404445Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.1405855Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.1407262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1408636Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1410022Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1411548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1959385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1960833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1962394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.1963851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.1965249Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1966630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1967998Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1969381Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1970771Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1972242Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1973651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1975057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1976444Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1977806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1979175Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1980546Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1981938Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1983339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1984749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1986156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1987538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1989039Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1990422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1991884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1993287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.1994698Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.1996110Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.1997524Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.1998924Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2000300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2001688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2003083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2004489Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2005910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2014527Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.2016043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.2017452Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2018819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2020199Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2021589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2023116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2024974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2026522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2027957Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2029432Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2030801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2032187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2033583Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2034981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2595869Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2598193Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2601039Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2603876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2606566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2607971Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2609379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2610799Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2612309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2613730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.2615158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.2616566Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2617962Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2619360Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2620925Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2622354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2623880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2625302Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.2626774Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.2628164Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2629520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2630877Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2632229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2633598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2634993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2636377Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2637778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2639142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2640485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2641841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2643192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2644573Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2645964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2647343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2648741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2650420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2651827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2653300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2654676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2656065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2657472Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2658871Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.2660267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.2661640Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2663001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2664367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2665736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.2667167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.2668575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3200160Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3202759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3205275Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3207365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3208737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3210095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3211555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3213100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3214506Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3216040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3217405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3218757Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3220133Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3221490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3222861Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3224254Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3225654Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3227053Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3228427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3229791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3231163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3232538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3233925Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3235314Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3236730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3238153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3239521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3240878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3242331Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3243707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3245091Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3246564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3247954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3249533Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3250912Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3252325Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3253695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3255060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3256438Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3257832Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3259230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3260633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3262009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3263358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3264724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3266095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3267522Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3268908Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3270294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3849503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3852412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3855144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3857300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3858686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3860097Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3861519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3862927Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3864340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3865735Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3867115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3868498Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3869897Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3871306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3872716Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3874123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3875539Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3876937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3878322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3879710Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3881102Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3883405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3884822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3886234Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3887728Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3889113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3890493Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3891929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3893309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3894713Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3896118Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3897579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3899006Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3900408Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3901791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3903179Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3904574Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3905994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3907423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3908838Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3910260Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.3911663Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3913153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3914546Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3915939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3917417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.3918841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.3920266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.3921690Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.4407426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4408807Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4410156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4411582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4412950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4414321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4415699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4417082Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4418446Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4419782Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4421123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4422469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4423826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4425200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4426721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4428098Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4429457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4430911Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4432262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4433625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4434997Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4436381Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4437822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.4439192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.4440550Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4441895Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4443235Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4444605Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4445979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4447352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4448741Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4450370Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4451775Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4453128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4454476Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4455833Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4457340Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4458722Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4460215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4461604Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4462966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4464319Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4465677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4467088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4468460Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4469835Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4471227Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4472617Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4473988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4475350Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4952601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4955152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4957385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4958785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4960178Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.4961579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.4962955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4964456Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4965826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4967307Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4968685Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4970084Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4971579Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4972976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4974349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4975705Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4977100Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4978461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4979829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4981209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4982601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4983985Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4985354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4986700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4988043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4989405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4990768Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4992147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4993647Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4995043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4996485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.4997842Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.4999198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5000581Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5001965Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5003349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5004755Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5006156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5007584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5008945Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5010308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5011731Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5013114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5014510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5015918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5017330Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5018707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5020066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5021433Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5467758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5470351Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5472906Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5475700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5477657Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5479049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5480412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5481779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5483153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5484534Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5485926Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5487341Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5488739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5490138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5491585Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5492958Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5494345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5495748Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5497154Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5498564Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5499974Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5501451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5502829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5504207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5505668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5507067Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5508474Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5509889Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5511301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5512679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5514023Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5515364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5516749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5518131Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5519508Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5520887Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5522271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5523628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5524966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5526311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5527665Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5529070Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5530451Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5531975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5533362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5534837Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5536182Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5537538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5538905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5985517Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5987771Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5989516Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5991264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5992986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5994675Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5996379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.5998098Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.5999815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6001561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6003310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6005051Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6006774Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6008466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6010161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6011922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6013307Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6014789Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6016175Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6017614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6018987Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6020339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6021702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6023054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6024430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6025812Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6027199Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6028588Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6029960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6031322Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6032685Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6034054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6035445Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6036836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6038232Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6039633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6041099Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6042464Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6043905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6045270Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6046664Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6048095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6049670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6051083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6052857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6054531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6062993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6064420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6065790Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6496647Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6498106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6499488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6500852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6502186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6503536Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6504887Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6506246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6507800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6509186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6510570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6512061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6513412Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6514758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6516125Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6517493Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6518880Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6520278Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6521670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6523042Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6524394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6525742Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6527160Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6528539Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6529922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6531390Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6532785Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6534149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6535496Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6536930Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6538297Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6539672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6541128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6542517Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6543907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6545273Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6546614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6547968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6549484Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6550866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6552253Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6553634Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6555034Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6556400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6557819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6559186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6560555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.6561942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.6563348Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7005049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7006475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7009511Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7012344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7015273Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7017336Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7018718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7020116Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7021513Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7022918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7024290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7025630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7026992Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7028347Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7029731Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7031111Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7032491Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7033878Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7035234Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7036608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7037996Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7039359Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7040735Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7042192Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7043591Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7045081Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7046446Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7047806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7049333Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7050702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7052144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7053533Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7054928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7056331Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7057700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7059069Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7060437Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7061797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7063179Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7064570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7065960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7067427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7068808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7070167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7071656Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7073034Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7074584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7075994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7077440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7517092Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7518492Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7519852Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7521224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7522601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7523991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7525398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7526791Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7528197Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7529584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7530957Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7532441Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7533825Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7535218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7536627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7538080Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7539653Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7541055Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7542531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7543909Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7545290Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7546688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7548093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7549666Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7551088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7552461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7553801Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7555140Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7556485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7557840Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7559203Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7560576Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7561946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7563293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7564631Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7565961Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7567349Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7568819Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7570186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7571602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7573095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7574448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7575798Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7577144Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7578494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7579867Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7581248Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.7582633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.7584024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8038374Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8041127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8043816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8046510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8047908Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8049431Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8050811Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8052269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8053625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8054966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8056505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8057882Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8059354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8060729Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8062115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8063508Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8064865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8066208Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8067559Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8068905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8070271Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8071646Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8073024Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8074417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8075786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8077186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8078555Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8079922Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8081306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8082689Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8084094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8085570Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8086949Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8088375Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8089734Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8091106Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8092535Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8093921Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8095319Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8096720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8098089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8099441Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8100797Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8102162Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8103539Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8104915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8106310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8107753Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8109118Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8110471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8530209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8533068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8536092Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8537840Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8539339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8540731Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8542097Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8543466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8544827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8546198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8547584Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8548984Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8550532Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8551957Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8553343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8554707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8556072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8557448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8558832Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8560232Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8561637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8563046Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8564440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8565919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8567294Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8568672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8570159Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8571603Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8573003Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8574413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8575794Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8577159Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8578518Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8579886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8581269Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8582668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8584066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8585465Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8586881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8588283Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8589652Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8591039Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8592432Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8593830Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8595357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8596778Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8598167Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.8599622Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.8600991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9086338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9087758Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9089161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9090572Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9092066Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[2-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9093449Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9094800Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9096158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9097572Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9098942Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9100327Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9101718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9103115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9104486Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9105836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9107206Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9108711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9110084Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9111469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9112972Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9114361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9115746Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9117114Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9118479Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9119866Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9121245Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9122641Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9124049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.9125436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.9126846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9128234Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9129601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9130983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9132430Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9133824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9135229Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9136633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9138017Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9139463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9140828Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9142284Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9143671Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9145065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9146468Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9147881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9149425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9150792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9152161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9153534Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9642600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9644016Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9645419Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9646823Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9648218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9649738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9651121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9652593Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9653986Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9655398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9657004Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:16.9658418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:16.9661132Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9662512Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9663891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9665286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9666684Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9668107Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9669519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9670935Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9672335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9673695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9675061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9676457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9677835Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9679242Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9680643Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9682054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9683441Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9684806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9686170Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9687635Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9689023Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9690491Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9691970Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9693373Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9694769Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9696142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9697578Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9698964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9700361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9701770Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9703189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9704614Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9706007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9707379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9708756Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:16.9710142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:16.9711541Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0159811Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0161238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0162669Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0164218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0165600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0167147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0175417Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0176928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0178354Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0179764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0181198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0182598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0183968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0185357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0186744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0188136Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0189544Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0190953Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0192367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0193767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0195147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0196542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0197989Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0199389Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0200918Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0202348Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0203849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0205258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0206642Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0208032Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0209422Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0210832Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0212301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0213724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0215153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0216542Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0217898Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0219255Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0220620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0221988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0223369Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0224767Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0226177Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0227599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0228944Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0230392Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0231752Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0233200Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0234580Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0679928Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0681364Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0682750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0684117Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0685483Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0686857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0688244Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0689644Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0691050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0692536Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0693929Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0695300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0696677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0698059Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0699457Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0700854Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0702266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0703829Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0705224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0706712Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0708118Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0709490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0710886Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0712287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0713704Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0715113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0716505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0717872Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0719242Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0720617Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0722009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0723400Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0724806Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0726214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0727599Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0728975Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0730345Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0731787Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0733331Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0734739Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0736256Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0737683Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0739075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0740456Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0741841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0743231Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0744650Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.0746064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.0747525Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1176631Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1178104Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1179471Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1180834Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1182213Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1183594Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1184988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1186385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1187834Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1189215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1190721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1192086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1193453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1194938Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1196321Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1197729Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1199128Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1200508Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1201884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1203250Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1204630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1206032Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1207425Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1208839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1210251Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1211718Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1213094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1214473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1215854Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1217299Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1218696Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1220188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1221607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1222992Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1224439Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1225812Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1227187Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1228593Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1229995Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1231398Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1232817Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1234211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1235585Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1236964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1238343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1239738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1241138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1242541Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1243960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1683109Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1684506Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1685881Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1687407Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1688822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1690241Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1691865Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1693286Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1694691Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1696083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1697465Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1698868Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1700273Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1701688Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1703113Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1704541Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1705939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1707305Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1708676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1710061Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1711454Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1712846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1714258Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1715668Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1717226Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1718598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1719968Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1721420Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1722815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1724214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1725618Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1727029Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1728423Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1729805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1731243Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1732628Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1734022Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1735442Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1736848Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1738262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1739659Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1741034Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1742404Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1743788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1745195Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1746687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1748149Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.1749740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.1751262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2193207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2194605Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2195991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2197381Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2198788Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2200191Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2201601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2202993Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2204361Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2205738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2207124Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2208510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2209914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2211405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2212822Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2214224Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2215596Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2217138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2218538Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2219937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2221459Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2222876Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2224300Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2225705Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2227135Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2228521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2229910Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2231307Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2232726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2234152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2235573Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2236948Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2238287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2239630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2240978Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2242334Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2243700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2245076Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2246463Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2247898Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2249473Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2250944Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2252344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2253700Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2255075Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2256447Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2257890Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2259247Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2260598Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2705064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2707279Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2708662Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2710054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2711435Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2712836Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2714209Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2715556Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2716917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2718282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2719658Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2721230Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2722634Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2724131Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2725503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2726847Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2728205Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2729567Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2730939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2732389Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2733776Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2735185Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2736554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2737954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2739311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2740669Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2742038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2743421Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2744813Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2746205Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2747575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2748940Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2750589Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2751976Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2753475Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2754864Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2756260Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2757673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2759050Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2760418Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2761792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2763163Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2764554Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2765955Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2767362Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2768772Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2770158Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.2771582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.2772960Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3215627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3217060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3218461Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3219869Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3221439Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3222835Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3224311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3225677Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3227063Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3228455Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3229851Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3231259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3232670Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3234060Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3235436Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3236849Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3238262Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3239672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3241078Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3242502Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3243931Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3245318Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3246702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3248083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3249641Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3251214Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3252627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3254040Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3255601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3256992Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3258378Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3259765Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3261147Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3262552Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3263969Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3265387Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3266848Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3268264Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3269649Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3271025Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3272405Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3273808Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3275218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3276630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3278049Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3279453Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3280923Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3282310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3283699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3761853Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3763287Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3764715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3766139Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3767543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3768946Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3770344Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3771816Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3773246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3774779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3776263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3778001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-False-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3779498Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3780907Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3789183Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3790562Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3791927Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3793306Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3794854Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3796239Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3797603Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3799054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3800396Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3801751Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3803122Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3804505Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3805901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3807338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3808710Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3810072Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3811479Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3812848Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3814221Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3815602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3817005Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:17.3818394Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:17.3819765Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3821127Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3822488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3823858Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3825335Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3826727Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3828198Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3829597Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3830967Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3832339Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3833711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.3835089Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.3836466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4301485Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4302904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4304311Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4305687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4307031Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4308395Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4309759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4311134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4312519Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4313913Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4315309Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4316686Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4318282Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4319659Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4321142Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4322520Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4323923Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4325324Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-True] [32mPASSED[0m
2026-01-14T08:44:17.4326721Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype0-weight_only-False-False] [32mPASSED[0m
2026-01-14T08:44:17.4328111Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4329481Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4330843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4332292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4333687Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4335083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4336494Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4337905Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4339296Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4340651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4341999Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4343368Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4344745Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4346123Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4347651Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4349211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4350732Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4352088Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4353469Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4354831Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4356207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4357635Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4359038Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4360427Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4361802Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4363161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4364533Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4365911Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4367296Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4368715Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4807500Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4808943Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4810343Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4811792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4813152Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4814672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4816073Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4817569Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4818966Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4820379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4821760Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4823121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4824488Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4825856Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4827295Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4828691Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4830093Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4831501Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4832884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4834243Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4835608Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4836981Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4838365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4839765Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4841161Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4842571Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4844044Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4845416Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4846888Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4848303Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4849933Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4851401Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4852811Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4854231Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4855637Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4857037Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4858442Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4859827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4861218Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4862627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4864039Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4865448Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-256x128x512-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4866820Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4868156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4869503Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4870857Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4872215Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.4873730Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.4875115Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5305308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5306914Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5309623Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5312310Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5315014Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5317307Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5318679Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5320057Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5321444Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5322815Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5324171Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5325543Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5326901Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5328281Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5329673Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5331062Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5332523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5333893Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5335252Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5336611Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5338181Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5339561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5342499Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5343887Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5345291Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5346672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5348020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5349557Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5350936Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5352308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5353701Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5355087Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5356490Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5357917Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5359266Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5360627Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5361991Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5363370Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5364766Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5366156Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5367549Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5369052Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5370424Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5371951Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5373323Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5374720Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5376135Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5377535Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5378954Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5810699Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5812491Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5814217Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5815937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5817666Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5819426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5821180Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5822937Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-145x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5824672Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5826358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5828043Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5829738Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5831442Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5833308Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5834695Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5836175Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5837583Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5838930Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5840277Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5841630Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5842994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5844367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5845750Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5847131Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5848510Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5850017Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5851413Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5852779Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5854153Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5855541Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5856939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5858338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5859706Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5861065Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5862613Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5863980Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5865358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5866875Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5868304Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5869702Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5871068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5872428Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5873796Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5875169Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5876547Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5877941Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5879329Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5880736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.5882112Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.5883466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6319211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6320600Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6321977Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6323365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6324761Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6326329Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6327719Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6329086Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6330561Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6332008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6333392Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6334792Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6336213Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6337625Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6339008Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6340381Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6341749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6343130Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6344523Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6345915Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6347367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6348783Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x96x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6350384Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6351736Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6353094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6354462Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6355846Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6357352Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6358749Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6360301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6361661Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6363020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6364382Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6365737Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6367117Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6368504Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6369904Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6371353Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6372726Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6374094Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6375466Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6376843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6378293Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6379692Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6381092Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6382514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6383902Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6385259Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6386724Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6825641Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6828233Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6831438Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6834656Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6837620Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6839365Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6841083Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6842802Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6844531Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6846267Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6848015Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6849762Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6851232Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6852616Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6853983Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6855353Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6856727Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6858121Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6859516Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6860919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6862462Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6863861Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6865373Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6866754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6868138Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6869548Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6870950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6872367Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6873782Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6875168Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6876547Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6877979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6879358Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6880759Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6882166Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6883575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6885001Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-128x160x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6886376Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6887717Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6889064Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6890406Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6891906Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6893283Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6894740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6896120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6897478Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6898826Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.6900174Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.6901521Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7342112Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7343514Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7344884Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7346263Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7347623Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7349134Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7350486Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7351850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7353231Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7354602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7355988Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7357379Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7358744Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7360232Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7361582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7362939Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7364429Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7365804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7367188Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7368577Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7369934Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7371360Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7372706Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7374058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7375431Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7376805Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7378196Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7379587Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7380950Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7382301Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7383648Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7384996Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7386368Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7387804Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7389189Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7390676Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7392058Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7393489Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7394850Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7396211Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7397601Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7398994Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7400391Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7401793Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7403273Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7404827Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7406276Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7415009Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7416504Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7417900Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7849165Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7850602Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-64x64x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7852054Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7853414Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7854764Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7856120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7857671Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7859068Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7860569Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7861964Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7863338Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7864711Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7866078Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7867440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7868824Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7870207Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7871607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7873007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7874385Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7875754Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7877120Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7878495Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7879891Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7881288Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7882692Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7884095Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7885478Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7886919Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7888292Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7889746Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7891139Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7892607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7894020Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7895438Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-True-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7896839Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7898246Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7899615Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7900995Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7902388Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7903786Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7905201Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7906607Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7908051Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7909426Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7910803Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7912186Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7913582Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:17.7914979Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:17.7916467Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0486357Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-True-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0488440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0489843Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0491334Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0492740Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0494155Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0495575Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0497007Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0498442Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype0-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0499841Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0501238Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-True-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0502633Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0504030Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-dynamic-False-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0505440Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0506859Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-True-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0508279Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-True] [33mSKIPPED[0m
2026-01-14T08:44:18.0509707Z test/prototype/mx_formats/test_inference_workflow.py::test_inference_workflow_nvfp4[3-True-200x192x256-False-False-inpt_dtype1-weight_only-False-False] [33mSKIPPED[0m
2026-01-14T08:44:18.0510936Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_narrow_similar_to_vllm [32mPASSED[0m
2026-01-14T08:44:18.0512037Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_nvfp4_quantize_3d_param_similar_to_vllm [32mPASSED[0m
2026-01-14T08:44:18.0513198Z test/prototype/mx_formats/test_inference_workflow.py::VLLMIntegrationTestCase::test_slice_and_copy_similar_to_vllm [32mPASSED[0m
2026-01-14T08:44:18.0514064Z test/prototype/mx_formats/test_kernels.py::test_fp32 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:44:18.0514738Z test/prototype/mx_formats/test_kernels.py::test_bf16 [33mSKIPPED[0m (TODO d...)
2026-01-14T08:44:18.0515500Z test/prototype/mx_formats/test_kernels.py::test_fp16 [32mPASSED[0m
2026-01-14T08:44:18.0516107Z test/prototype/mx_formats/test_kernels.py::test_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:44:18.0516732Z test/prototype/mx_formats/test_kernels.py::test_float8_e5m2 [32mPASSED[0m
2026-01-14T08:44:18.0517473Z test/prototype/mx_formats/test_kernels.py::test_float4_e2m1_table [32mPASSED[0m
2026-01-14T08:44:18.0518130Z test/prototype/mx_formats/test_kernels.py::test_float6_e3m2_table [32mPASSED[0m
2026-01-14T08:44:18.0518780Z test/prototype/mx_formats/test_kernels.py::test_float6_e2m3_table [32mPASSED[0m
2026-01-14T08:44:18.0519399Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_0 [32mPASSED[0m
2026-01-14T08:44:18.0519983Z test/prototype/mx_formats/test_kernels.py::test_fp4_0_5 [32mPASSED[0m
2026-01-14T08:44:18.0520559Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_0 [32mPASSED[0m
2026-01-14T08:44:18.0521147Z test/prototype/mx_formats/test_kernels.py::test_fp4_1_5 [32mPASSED[0m
2026-01-14T08:44:18.0521718Z test/prototype/mx_formats/test_kernels.py::test_fp4_2_0 [32mPASSED[0m
2026-01-14T08:44:18.0522306Z test/prototype/mx_formats/test_kernels.py::test_fp4_3_0 [32mPASSED[0m
2026-01-14T08:44:18.0522889Z test/prototype/mx_formats/test_kernels.py::test_fp4_4_0 [32mPASSED[0m
2026-01-14T08:44:18.0523468Z test/prototype/mx_formats/test_kernels.py::test_fp4_6_0 [32mPASSED[0m
2026-01-14T08:44:18.0524084Z test/prototype/mx_formats/test_kernels.py::test_fp4_pack_unpack [32mPASSED[0m
2026-01-14T08:44:18.0524757Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:18.0525441Z test/prototype/mx_formats/test_kernels.py::test_fp6_values[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:18.0526164Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cpu] [32mPASSED[0m
2026-01-14T08:44:18.0526929Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[29.0-31-cuda] [32mPASSED[0m
2026-01-14T08:44:18.0527743Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cpu] [32mPASSED[0m
2026-01-14T08:44:18.0528492Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[26.0-30-cuda] [32mPASSED[0m
2026-01-14T08:44:18.0529254Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cpu] [32mPASSED[0m
2026-01-14T08:44:18.0530019Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.1251-2-cuda] [32mPASSED[0m
2026-01-14T08:44:18.0530785Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cpu] [32mPASSED[0m
2026-01-14T08:44:18.0531613Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.0314-1-cuda] [32mPASSED[0m
2026-01-14T08:44:18.0532364Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cpu] [32mPASSED[0m
2026-01-14T08:44:18.0533116Z test/prototype/mx_formats/test_kernels.py::test_fp6_e3m2_rounding[0.03-0-cuda] [32mPASSED[0m
2026-01-14T08:44:18.0534017Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0535057Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0536094Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0537118Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0538145Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0539168Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0540281Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0541314Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim1_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0542339Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0543448Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0544472Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0545502Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.FLOOR-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0546534Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0547619Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0548657Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0549946Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_randn[ScaleCalculationMode.RCEIL-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.0550947Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.FLOOR] [33mSKIPPED[0m
2026-01-14T08:44:18.0551912Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dim0_zeros[ScaleCalculationMode.RCEIL] [33mSKIPPED[0m
2026-01-14T08:44:18.0552841Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.0553747Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9966617Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.9967668Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9968561Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-128] [33mSKIPPED[0m
2026-01-14T08:44:18.9969462Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-128-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9970353Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-128] [33mSKIPPED[0m
2026-01-14T08:44:18.9971320Z test/prototype/mx_formats/test_kernels.py::test_triton_mxfp8_dequant_dim0[orig_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9972098Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape0] [32mPASSED[0m
2026-01-14T08:44:18.9972760Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape1] [32mPASSED[0m
2026-01-14T08:44:18.9973415Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape2] [32mPASSED[0m
2026-01-14T08:44:18.9974076Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape3] [32mPASSED[0m
2026-01-14T08:44:18.9974726Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape4] [32mPASSED[0m
2026-01-14T08:44:18.9975390Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape5] [32mPASSED[0m
2026-01-14T08:44:18.9976051Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape6] [32mPASSED[0m
2026-01-14T08:44:18.9976702Z test/prototype/mx_formats/test_kernels.py::test_rearrange[shape7] [32mPASSED[0m
2026-01-14T08:44:18.9977614Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9978734Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9980048Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9981183Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9982436Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9983569Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9984685Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9985800Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.FLOOR-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9986938Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9988052Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-32-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9989167Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9990303Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype0-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9991415Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9992534Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-32-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9993656Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-32] [33mSKIPPED[0m
2026-01-14T08:44:18.9994774Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim1_numerics[ScaleCalculationMode.RCEIL-input_dtype1-256-256] [33mSKIPPED[0m
2026-01-14T08:44:18.9995704Z test/prototype/mx_formats/test_kernels.py::test_cuda_mx_dim0_not_supported [33mSKIPPED[0m
2026-01-14T08:44:18.9996898Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:18.9998449Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0000004Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0001546Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0003095Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0004650Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.0006203Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0007759Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0009444Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0011243Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0012877Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.0014426Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0015966Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0017520Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0019063Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0020613Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.0022163Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0023706Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0025275Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0026831Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0028380Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.0029934Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0031478Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0033017Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0034566Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0036124Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.0610282Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.0613510Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.0616943Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.0618556Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.0620226Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0621795Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0623350Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0624920Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0626485Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0628053Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0629636Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0631206Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0632778Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0634347Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0635923Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0637481Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0639051Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0640624Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0642180Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0643758Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0645337Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0646904Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0648567Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0650419Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0652182Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0653753Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0655312Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0656889Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0658501Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0660073Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0661646Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0663226Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0664791Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0666369Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0667930Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0669463Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0671005Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0672550Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0674087Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0675637Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0677189Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.0678736Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.0680413Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.0681968Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.0683589Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.0685127Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3268889Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3270903Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3272445Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3273997Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3275551Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3277087Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3278637Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3280184Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3281723Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3283259Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3284799Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3286331Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3287870Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3289426Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3290974Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3292596Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3294314Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3295858Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3297512Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3299042Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3300572Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3302113Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3303634Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3305175Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3306714Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3308250Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3309793Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3311340Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3312876Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3314413Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3315951Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3317532Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3319072Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3320613Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3322154Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3323699Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3325355Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3326887Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3328515Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3330046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3331621Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3333154Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3334676Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3336215Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.3337748Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.3339276Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.3746653Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.3748260Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.3750050Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3751593Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3753144Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3754697Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3756238Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3757798Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3759364Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3760922Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3762627Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3764180Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3765840Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3767440Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3769174Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3770743Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3772376Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3773929Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3775489Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3777046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3778599Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3780162Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3781729Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3783273Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3784828Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3786391Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3787939Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3789500Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3791061Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3792619Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3794291Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3795848Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3797512Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3799046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3800574Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3802108Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3803632Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3805164Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3806702Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3808240Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3809778Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.3811374Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.3812910Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.3814434Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.3815959Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.3817543Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.6622944Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.6624568Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.6626105Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.6627644Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.6629393Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.6630942Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.6632584Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.6634112Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.6635645Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.6637187Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.6638706Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.6640243Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.6641791Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.6643324Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.6644864Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.6646396Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.CEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.6647929Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6649934Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6651655Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6653277Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6655013Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.6656650Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6658330Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6659988Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6669723Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6671301Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.6672953Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6674490Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6676024Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6677612Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6679154Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.6680682Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6682232Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6683776Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6685318Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6686868Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.6688408Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6689939Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6691530Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6693071Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6694596Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.6696135Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.6697682Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.6699215Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.6700851Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.6702401Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.7029521Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7031436Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7033004Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7034570Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7036134Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7037712Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7039288Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7040849Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7042413Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7043965Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7045522Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7047085Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7048626Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7050399Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7052003Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7053577Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7055155Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7056711Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7058488Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7060073Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7061629Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7063301Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7064862Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7066426Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7067995Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7069560Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7071137Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7072708Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7074289Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7075848Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7077408Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7078949Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7080477Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7082021Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7083553Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7085100Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7086654Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7088251Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7089889Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7091503Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7093036Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.7094680Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.7096214Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.7097736Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.7099263Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.7100801Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.9694748Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.9696327Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.9697883Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.9699418Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.9700952Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.9702493Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.9704026Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.9705567Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.9707094Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.9708637Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.9710183Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:19.9711719Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:19.9713429Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:19.9714984Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.EVEN-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:19.9716525Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9718191Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9719735Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9721286Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9722830Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9724375Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9725934Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9727485Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9729041Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9730602Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape0-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9732242Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9733793Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9735342Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9736884Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9738427Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9739974Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9741528Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9743089Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9744733Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9746278Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape1-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9747875Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9751294Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9752829Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9754375Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9755917Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-True-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9757461Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:19.9759013Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:19.9760558Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype2] [32mPASSED[0m
2026-01-14T08:44:19.9762108Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype3] [32mPASSED[0m
2026-01-14T08:44:19.9763656Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-input_shape2-False-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:19.9765205Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:19.9766774Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0105617Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0108139Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0109699Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0111284Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0112870Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0114442Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0116166Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0117753Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0119319Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0121003Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0122572Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0124144Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0125718Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0127296Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0128893Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0130475Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0132136Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0133719Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0135291Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0136863Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0138436Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0140015Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0141577Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0143153Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0144729Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0146297Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0147990Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0149795Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0151494Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0153046Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0154604Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0156154Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0157757Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0159314Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0160876Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0162436Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0163989Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0165546Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape0-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0167096Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0168693Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0170258Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0171859Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0173409Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0174968Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0176531Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0178138Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0615059Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0616644Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape1-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0618187Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0619847Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0621398Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0622947Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0624504Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-True-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0626059Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0627618Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0629178Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype2] [33mSKIPPED[0m
2026-01-14T08:44:20.0630737Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype3] [33mSKIPPED[0m
2026-01-14T08:44:20.0632305Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_vs_hp[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-input_shape2-False-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:20.0633645Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:44:20.0634814Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn0-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:44:20.0635957Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:44:20.0637100Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn1-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:44:20.0638247Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP8_CUBLAS] [33mSKIPPED[0m
2026-01-14T08:44:20.0639396Z test/prototype/mx_formats/test_mx_linear.py::test_linear_eager_emulated_vs_real_gemm[mkn2-MXLinearRecipeName.MXFP4_CUTLASS] [33mSKIPPED[0m
2026-01-14T08:44:20.0640327Z test/prototype/mx_formats/test_mx_linear.py::test_activation_checkpointing [32mPASSED[0m
2026-01-14T08:44:20.0641530Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0643108Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0644688Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0646329Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0647876Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0649691Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0651341Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0652871Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0654440Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0656027Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0657596Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0659156Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0660732Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0662300Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0663862Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0665425Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0666986Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0668624Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0670187Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0671728Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0673284Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0674841Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0676379Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0678045Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.FLOOR-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0679592Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0681335Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0682885Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0684424Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.0685982Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.0687571Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1286649Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1289244Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TORCH-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1292449Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1295597Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1298142Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1299697Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1301253Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1302815Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1304372Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1305912Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.TRITON-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1307465Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1309022Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1310567Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1312106Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-False-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1313817Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1315367Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_emulated-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1317009Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:20.1318539Z test/prototype/mx_formats/test_mx_linear.py::test_linear_compile[ScaleCalculationMode.RCEIL-MXFP8Dim1CastKernelChoice.CUDA-True-mxfp8_cublas-hp_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:20.1319588Z test/prototype/mx_formats/test_mx_linear.py::test_filter_fn [32mPASSED[0m
2026-01-14T08:44:20.1320257Z test/prototype/mx_formats/test_mx_linear.py::test_training_print_str [32mPASSED[0m
2026-01-14T08:44:20.1321030Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x128x128] [33mSKIPPED[0m
2026-01-14T08:44:20.1321852Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x256x256] [33mSKIPPED[0m
2026-01-14T08:44:20.1322663Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-384x384x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1323482Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-512x512x512] [33mSKIPPED[0m
2026-01-14T08:44:20.1324294Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-768x768x768] [33mSKIPPED[0m
2026-01-14T08:44:20.1325116Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:44:20.1325945Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:44:20.1326765Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-128x256x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1327591Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-256x384x512] [33mSKIPPED[0m
2026-01-14T08:44:20.1328431Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-129x256x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1329233Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp8-133x512x528] [33mSKIPPED[0m
2026-01-14T08:44:20.1330045Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x128x128] [33mSKIPPED[0m
2026-01-14T08:44:20.1330842Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x256x256] [33mSKIPPED[0m
2026-01-14T08:44:20.1331693Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-384x384x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1332494Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-512x512x512] [33mSKIPPED[0m
2026-01-14T08:44:20.1333294Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-768x768x768] [33mSKIPPED[0m
2026-01-14T08:44:20.1334107Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-1024x1024x1024] [33mSKIPPED[0m
2026-01-14T08:44:20.1334929Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-8192x8192x8192] [33mSKIPPED[0m
2026-01-14T08:44:20.1335745Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-128x256x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1336544Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-256x384x512] [33mSKIPPED[0m
2026-01-14T08:44:20.1337340Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-129x256x384] [33mSKIPPED[0m
2026-01-14T08:44:20.1338139Z test/prototype/mx_formats/test_mx_mm.py::test_matrix_multiplication[fp4-133x512x528] [33mSKIPPED[0m
2026-01-14T08:44:20.1338926Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[mxfp8] [33mSKIPPED[0m
2026-01-14T08:44:20.1339796Z test/prototype/mx_formats/test_mx_serialization.py::test_serialization[nvfp4] [33mSKIPPED[0m
2026-01-14T08:44:20.1340556Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:20.1341283Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:20.1342078Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:20.1342771Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:20.1343478Z test/prototype/mx_formats/test_mx_tensor.py::test_hello_world[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:20.1344376Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:44:20.1345405Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:44:20.1346433Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:44:20.1347445Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype0-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:44:20.1348473Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:44:20.1349662Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:44:20.1350684Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:44:20.1351694Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype1-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:44:20.1352703Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:44:20.1353717Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:44:20.1354718Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:44:20.1355713Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e2m3-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:44:20.1356716Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:44:20.1357744Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:44:20.1358751Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:44:20.1359735Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[fp6_e3m2-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:44:33.6517086Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.FLOOR] [32mPASSED[0m
2026-01-14T08:44:33.6518188Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.RCEIL] [32mPASSED[0m
2026-01-14T08:44:33.6519230Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.CEIL] [32mPASSED[0m
2026-01-14T08:44:33.6520260Z test/prototype/mx_formats/test_mx_tensor.py::test_realistic_numerics[elem_dtype4-ScaleCalculationMode.EVEN] [32mPASSED[0m
2026-01-14T08:44:33.6521121Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6521833Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6522537Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6523565Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6524280Z test/prototype/mx_formats/test_mx_tensor.py::test_all_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6524995Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6525878Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6526598Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6527288Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6528000Z test/prototype/mx_formats/test_mx_tensor.py::test_some_zeros[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6528671Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_rceil [32mPASSED[0m
2026-01-14T08:44:33.6529363Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6530129Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6530865Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6531691Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6532436Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_in[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6533187Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6533946Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6534691Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6535429Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6536170Z test/prototype/mx_formats/test_mx_tensor.py::test_exponent_nan_out[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6536885Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6537557Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6538223Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6538883Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6539539Z test/prototype/mx_formats/test_mx_tensor.py::test_ranks[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6540243Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6540973Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6541695Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e2m3] [33mSKIPPED[0m
2026-01-14T08:44:33.6542419Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-fp6_e3m2] [33mSKIPPED[0m
2026-01-14T08:44:33.6543150Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[1-elem_dtype4] [33mSKIPPED[0m
2026-01-14T08:44:33.6543887Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6544619Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6545337Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6546049Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6546758Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[4-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6547497Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6548319Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6549396Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6550129Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6551054Z test/prototype/mx_formats/test_mx_tensor.py::test_block_sizes[32-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6551773Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6552473Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6553164Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6553842Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6554531Z test/prototype/mx_formats/test_mx_tensor.py::test_transpose[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6555226Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.6555891Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.6556554Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6557201Z test/prototype/mx_formats/test_mx_tensor.py::test_view[fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6557857Z test/prototype/mx_formats/test_mx_tensor.py::test_view[elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6558483Z test/prototype/mx_formats/test_mx_tensor.py::test_clone [32mPASSED[0m
2026-01-14T08:44:33.6559290Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:33.6560296Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:33.6561276Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6562237Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6563211Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6564203Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:33.6565218Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:33.6566201Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6567160Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6568145Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[False-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6569132Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:33.6570122Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:33.6571105Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6572102Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6573068Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype0-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6574058Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:33.6575177Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:33.6576160Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e2m3] [32mPASSED[0m
2026-01-14T08:44:33.6577205Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-fp6_e3m2] [32mPASSED[0m
2026-01-14T08:44:33.6578171Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_from_mx_compile_numerics[True-hp_dtype1-elem_dtype4] [32mPASSED[0m
2026-01-14T08:44:33.6579034Z test/prototype/mx_formats/test_mx_tensor.py::test_to_mx_inductor_single_kernel [33mSKIPPED[0m
2026-01-14T08:44:33.6579732Z test/prototype/mx_formats/test_mx_tensor.py::test_index_select [32mPASSED[0m
2026-01-14T08:44:33.6580495Z test/prototype/mx_formats/test_mx_tensor.py::test_cast_to_float8_e4m3fn_saturation_behavior [33mSKIPPED[0m
2026-01-14T08:44:33.6589226Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape0] [32mPASSED[0m
2026-01-14T08:44:33.6590234Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape1] [32mPASSED[0m
2026-01-14T08:44:33.7617263Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape2] [32mPASSED[0m
2026-01-14T08:44:33.7619137Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape3] [32mPASSED[0m
2026-01-14T08:44:33.7620637Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape4] [32mPASSED[0m
2026-01-14T08:44:33.7621533Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[False-shape5] [32mPASSED[0m
2026-01-14T08:44:33.7622428Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape0] [32mPASSED[0m
2026-01-14T08:44:33.7623320Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape1] [32mPASSED[0m
2026-01-14T08:44:33.7624212Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape2] [32mPASSED[0m
2026-01-14T08:44:33.7625094Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape3] [32mPASSED[0m
2026-01-14T08:44:33.7625991Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape4] [32mPASSED[0m
2026-01-14T08:44:33.7626883Z test/prototype/mx_formats/test_mx_tensor.py::test_to_blocked_from_blocked_roundtrip[True-shape5] [32mPASSED[0m
2026-01-14T08:44:33.7627743Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-False] [32mPASSED[0m
2026-01-14T08:44:33.7628583Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape0-True] [32mPASSED[0m
2026-01-14T08:44:33.7629415Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-False] [32mPASSED[0m
2026-01-14T08:44:33.7630259Z test/prototype/mx_formats/test_mx_tensor.py::test_scale_shape_matches_qdata[shape1-True] [33mSKIPPED[0m
2026-01-14T08:44:33.7631082Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.7631882Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.7632679Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.7633456Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape0-True-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.7634253Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype0] [32mPASSED[0m
2026-01-14T08:44:33.7635051Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-False-elem_dtype1] [32mPASSED[0m
2026-01-14T08:44:33.7636013Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype0] [33mSKIPPED[0m
2026-01-14T08:44:33.7636815Z test/prototype/mx_formats/test_mx_tensor.py::test_swizzle[shape1-True-elem_dtype1] [33mSKIPPED[0m
2026-01-14T08:44:33.7637668Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype0-shape0-False] [32mPASSED[0m
2026-01-14T08:44:33.7638680Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype1-shape1-False] [32mPASSED[0m
2026-01-14T08:44:33.7639579Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype2-shape2-False] [32mPASSED[0m
2026-01-14T08:44:33.7640464Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype3-shape3-True] [32mPASSED[0m
2026-01-14T08:44:33.7641358Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_reconstruction[dtype4-shape4-False] [32mPASSED[0m
2026-01-14T08:44:33.7642281Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-False] [32mPASSED[0m
2026-01-14T08:44:33.7643236Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape0-True] [32mPASSED[0m
2026-01-14T08:44:33.7644181Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-False] [32mPASSED[0m
2026-01-14T08:44:33.7645124Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape1-True] [32mPASSED[0m
2026-01-14T08:44:33.7646069Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-False] [32mPASSED[0m
2026-01-14T08:44:33.7647009Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape2-True] [32mPASSED[0m
2026-01-14T08:44:33.7647956Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-False] [32mPASSED[0m
2026-01-14T08:44:33.7648902Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape3-True] [32mPASSED[0m
2026-01-14T08:44:33.7650011Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-False] [32mPASSED[0m
2026-01-14T08:44:33.7651009Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_construction[shape4-True] [32mPASSED[0m
2026-01-14T08:44:33.7652020Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[0:128]] [32mPASSED[0m
2026-01-14T08:44:33.7652968Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_rows[128:256]] [32mPASSED[0m
2026-01-14T08:44:33.7653907Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:64]] [32mPASSED[0m
2026-01-14T08:44:33.7654834Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[64:128]] [32mPASSED[0m
2026-01-14T08:44:33.7655831Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:128]_full_width] [32mPASSED[0m
2026-01-14T08:44:33.7656876Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:2048]_tp_first_half] [32mPASSED[0m
2026-01-14T08:44:33.7657945Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[2048:4096]_tp_second_half] [32mPASSED[0m
2026-01-14T08:44:33.7659004Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[0:1024]_quarter] [32mPASSED[0m
2026-01-14T08:44:33.7660016Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing[slice_cols[1024:2048]_quarter] [32mPASSED[0m
2026-01-14T08:44:33.7661036Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_end] [32mPASSED[0m
2026-01-14T08:44:33.7662054Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_row_start] [32mPASSED[0m
2026-01-14T08:44:33.7663182Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_32] [32mPASSED[0m
2026-01-14T08:44:33.7664199Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_start] [32mPASSED[0m
2026-01-14T08:44:33.7665207Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[misaligned_col_end] [32mPASSED[0m
2026-01-14T08:44:33.7666287Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_start] [32mPASSED[0m
2026-01-14T08:44:33.7667214Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_slicing_errors[odd_end] [32mPASSED[0m
2026-01-14T08:44:33.7668092Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_view_semantics [32mPASSED[0m
2026-01-14T08:44:33.7668939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_serialization [32mPASSED[0m
2026-01-14T08:44:33.7669800Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_swizzled_scales_get_scales_method [32mPASSED[0m
2026-01-14T08:44:33.7670772Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7671828Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7672886Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7673948Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7675013Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7676065Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7677119Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7678172Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7679246Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7680309Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7681374Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7682442Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7683509Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7902739Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7904090Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7905413Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7906726Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7908050Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7909513Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7910580Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7911647Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7912814Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7913878Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7914944Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7916008Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7917087Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7918149Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7919211Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7920270Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7921328Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7922381Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7923438Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7924492Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7925548Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7926597Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7927652Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7928709Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7929759Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7930820Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7932114Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7933425Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7934729Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7936033Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7937356Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7938756Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7940086Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7941302Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7942364Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7943429Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7944481Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7945549Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7946620Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7947677Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7948758Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7950164Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7951483Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7952813Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7954138Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7955467Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7956811Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7958137Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7959469Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7960789Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7962126Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7963455Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7964782Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7966117Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.7967478Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.7968802Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.7970254Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.7971586Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.7972654Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.7973835Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.7974902Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8192823Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8193932Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8195007Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8196084Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8197162Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8198228Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8199307Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8200381Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8201446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8202512Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8203588Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8204656Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8205727Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8206795Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8207874Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8208933Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8210010Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8211092Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8212247Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8213327Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8214552Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8215638Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8216715Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8217895Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[fp32-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8218967Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8220026Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8221130Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8222197Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8223252Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8224316Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8225372Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8226426Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8227502Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8228574Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8229640Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8230714Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8231778Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8232848Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8233918Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8234985Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8236052Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8237129Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8238201Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8239274Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8240340Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8241410Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8242564Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8243631Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8244787Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8245868Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8246927Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8248005Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8249229Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8250299Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8251400Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8252471Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8253538Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8254605Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8255662Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8256730Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8257785Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8258855Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8477468Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8479619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8481070Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8482138Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8483196Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8484275Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8485359Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8486433Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8487510Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8488749Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8489835Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-block_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8490908Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8492171Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8493236Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8494313Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8495380Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8496455Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8497517Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N64-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8498597Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8499680Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8500751Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8501839Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8502925Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8504005Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8505082Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N128-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8506159Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8507241Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8508319Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8509404Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8510493Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8511621Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8512701Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N256-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8513778Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8514855Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8515938Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8517130Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8518209Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8519374Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8520455Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N512-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8521531Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8522609Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8523688Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8524772Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8525842Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8526925Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8528008Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N32-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8529079Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8530161Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8531288Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8532363Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8533446Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8534519Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8535590Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N96-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8536669Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M128] [33mSKIPPED[0m
2026-01-14T08:44:33.8537746Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M256] [33mSKIPPED[0m
2026-01-14T08:44:33.8538831Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M512] [33mSKIPPED[0m
2026-01-14T08:44:33.8539914Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M1024] [33mSKIPPED[0m
2026-01-14T08:44:33.8541001Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M100] [33mSKIPPED[0m
2026-01-14T08:44:33.8542075Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M200] [33mSKIPPED[0m
2026-01-14T08:44:33.8543145Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_triton_nvfp4_quantize_equivalence[bf16-tensor_scale-N160-M384] [33mSKIPPED[0m
2026-01-14T08:44:33.8544388Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8727965Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8730632Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8731956Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8733197Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8734421Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8735677Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8736940Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8738179Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8739397Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8740630Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8741889Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8743140Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8744362Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8745616Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8746885Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8748124Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8749531Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8750791Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8752049Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8753311Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8754543Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8755804Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8757206Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8758460Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8759801Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8761106Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8762366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8763619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8764861Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8766124Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8767406Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8768659Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8769893Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8771144Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8772443Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8773689Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8774932Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8776185Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8777464Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8778713Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8779943Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8781190Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8782439Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8783678Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8784910Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8786270Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8787547Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8788880Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8790109Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8791418Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8792688Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8793944Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8795193Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8796455Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8981327Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8982604Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8983844Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8985095Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8986366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8987619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8988866Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8990139Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8991468Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[256x128x512-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8992711Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8993926Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8995160Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8996409Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.8997640Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.8999010Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9000272Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9001686Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9002920Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9004139Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9005389Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9006633Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9007867Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9009105Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9010363Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9011741Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9012992Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9014223Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9015460Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9016724Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9017973Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9019209Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9020482Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9021788Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9023041Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9024272Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9025512Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9026766Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9028105Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9029336Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9030658Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9031916Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[157x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9033158Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9034380Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9035609Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9036855Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9038096Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9039310Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9040545Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9041798Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9043035Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9044254Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9045473Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9046715Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9047945Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9231940Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9233205Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9234465Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9235696Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9236923Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9238164Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9240373Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9241635Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9243010Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9252049Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9253343Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9254615Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9255858Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9257102Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9258365Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9259616Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9260850Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9262108Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9263383Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x96x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9264632Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9265867Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9267106Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9268366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9269619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9270906Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9272169Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9273438Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9274681Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9276069Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9277313Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9278573Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9279931Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9281167Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9282417Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9283698Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9284939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9286178Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9287435Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9288698Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9289958Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9291250Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9292516Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9293806Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9295053Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9296290Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9297541Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9298801Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9300051Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9301346Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9302606Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9303877Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[128x160x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9305199Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9306409Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9307633Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9483720Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9484982Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9486205Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9487448Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9488693Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9489939Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9491143Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9492423Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9493669Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9494899Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9496127Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9497364Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9498619Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9499853Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9501077Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9502317Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9503574Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9504809Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9506035Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9507275Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9508688Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9509936Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9511150Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9512492Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9513745Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9514976Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9516213Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9517458Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9518712Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[64x64x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9519961Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9521239Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9522482Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9523740Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9524983Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9526223Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9527479Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9528741Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9529981Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9531349Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9532594Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9533852Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9535090Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9536325Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9537673Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9538944Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-True-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9540195Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9541600Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9542857Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9544124Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9545390Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9546635Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9547904Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:33.9549417Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype0-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:33.9550675Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0126886Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0128178Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0129436Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-True-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0130737Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0132033Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-dynamic-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0133284Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0134563Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_matmul_with_amax[200x192x256-False-inpt_dtype1-False-False-weight_only-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0135528Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_nvfp4_to_copy [32mPASSED[0m
2026-01-14T08:44:34.0136366Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0137349Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0138323Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0139292Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-False-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0140257Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0141365Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0142328Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0143278Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape0-True-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0144355Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0145323Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0146288Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0147249Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-False-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0148212Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0149385Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0150354Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0151319Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape1-True-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0152286Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0153247Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0154215Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0155191Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-False-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0156147Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0157111Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0158071Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0159021Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape2-True-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0159988Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0160956Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0161927Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0162895Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-False-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0163852Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0164824Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0165777Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0166732Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape3-True-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0167693Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0168783Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0169760Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0170721Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-False-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0171854Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-False] [32mPASSED[0m
2026-01-14T08:44:34.0172805Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-False-True] [32mPASSED[0m
2026-01-14T08:44:34.0173751Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-False] [33mSKIPPED[0m
2026-01-14T08:44:34.0174712Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_scale_shape_matches_qdata[shape4-True-True-True] [33mSKIPPED[0m
2026-01-14T08:44:34.0175568Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims0] [32mPASSED[0m
2026-01-14T08:44:34.0176324Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims1] [32mPASSED[0m
2026-01-14T08:44:34.0177077Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims2] [32mPASSED[0m
2026-01-14T08:44:34.0177834Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[True-dims3] [32mPASSED[0m
2026-01-14T08:44:34.0178594Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims0] [32mPASSED[0m
2026-01-14T08:44:34.0179353Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims1] [32mPASSED[0m
2026-01-14T08:44:34.0180107Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims2] [32mPASSED[0m
2026-01-14T08:44:34.0180865Z test/prototype/mx_formats/test_nvfp4_tensor.py::test_3d_transpose[False-dims3] [32mPASSED[0m
2026-01-14T08:44:34.0181825Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0182965Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0184082Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:44:34.0185203Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0186323Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0187436Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0188561Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0189681Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0190841Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:34.0192004Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config0_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1468299Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config1_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1469871Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config2_act_pre_scale_True [33mSKIPPED[0m
2026-01-14T08:44:40.1471700Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config3_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1472896Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config4_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1474083Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config5_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1475445Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config6_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1476623Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config7_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1477819Z test/prototype/safetensors/test_safetensors_support.py::TestSafeTensors::test_safetensors_sharded_config8_act_pre_scale_False [33mSKIPPED[0m
2026-01-14T08:44:40.1478895Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_metadata_torchao [33mSKIPPED[0m
2026-01-14T08:44:40.1479929Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata0 [33mSKIPPED[0m
2026-01-14T08:44:40.1481006Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata1 [33mSKIPPED[0m
2026-01-14T08:44:40.1482081Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata2 [33mSKIPPED[0m
2026-01-14T08:44:40.1483157Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata3 [33mSKIPPED[0m
2026-01-14T08:44:40.1484226Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata4 [33mSKIPPED[0m
2026-01-14T08:44:40.1485300Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata5 [33mSKIPPED[0m
2026-01-14T08:44:40.1486379Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata6 [33mSKIPPED[0m
2026-01-14T08:44:40.1487444Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata7 [33mSKIPPED[0m
2026-01-14T08:44:40.1488520Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata8 [33mSKIPPED[0m
2026-01-14T08:44:40.1489588Z test/prototype/safetensors/test_safetensors_utils.py::TestSafeTensorsUtils::test_not_metadata_torchao_metadata9 [33mSKIPPED[0m
2026-01-14T08:44:40.1490395Z test/prototype/test_awq.py::TestAWQ::test_awq_config [32mPASSED[0m
2026-01-14T08:44:40.1491092Z test/prototype/test_awq.py::TestAWQ::test_awq_functionality_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:44:40.1491965Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:44:40.1492773Z test/prototype/test_awq.py::TestAWQ::test_awq_loading_vllm_device_cpu_base_config0 [32mPASSED[0m
2026-01-14T08:44:40.1493642Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook [33mSKIPPED[0m
2026-01-14T08:44:40.1494642Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_choose_qparams_codebook_row_grouping [33mSKIPPED[0m
2026-01-14T08:44:40.1495688Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [33mSKIPPED[0m
2026-01-14T08:44:40.1496725Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [33mSKIPPED[0m
2026-01-14T08:44:40.1497829Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float_row_grouping [33mSKIPPED[0m
2026-01-14T08:44:40.1498791Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_export [33mSKIPPED[0m
2026-01-14T08:44:40.1499701Z test/prototype/test_codebook_coreml.py::TestCodebookQuantization::test_quantize_api [33mSKIPPED[0m
2026-01-14T08:44:40.1500590Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook [32mPASSED[0m
2026-01-14T08:44:40.1501556Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:44:40.1502673Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_codebook_quantized_tensor_from_float2 [32mPASSED[0m
2026-01-14T08:44:40.1503593Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:44:40.1504370Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_accuracy [33mSKIPPED[0m
2026-01-14T08:44:40.1505166Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T08:44:40.1506583Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1508461Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1510341Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1512193Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1514054Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1515900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1517762Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1519605Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1521458Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerAxis(axis=0), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1523421Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1525383Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1527325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1529358Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1531359Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1533426Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1535354Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1660616Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1663126Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=128), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1665067Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1667005Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1668930Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1670860Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1672787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1674706Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1676624Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1678544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1680463Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_Int4WeightOnlyEmbeddingQATQuantizer_{'granularity': PerGroup(group_size=32), 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1682718Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1685326Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1687927Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1690373Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1692863Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1695289Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1697741Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1700170Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1702596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1705033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1707469Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1709888Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1712371Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1714931Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1717350Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1719849Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1722276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1724695Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1727184Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1825263Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1827818Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1830342Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1832900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1835400Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1837913Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1840418Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1843079Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1845583Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1848187Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1851123Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1854412Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1857598Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1860092Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1862642Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1865150Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1867639Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1870142Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1872709Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1875345Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1877849Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1880458Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1882968Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1885470Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.1887974Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.1890476Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.1999175Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2001708Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2004202Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2006688Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2009168Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2011906Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2014443Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2017032Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2019513Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2021976Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2024412Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2026843Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2029284Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2031717Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2034188Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2036624Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2039050Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2041486Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2043988Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2046419Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2048920Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2051569Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2053984Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2056404Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2058823Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2061247Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2063667Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2163661Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2166226Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2168750Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2171489Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2174071Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2176688Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2179193Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2181712Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2184270Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2186778Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2189298Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2191807Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2194374Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2196884Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2199385Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2201883Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2204521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2207017Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2209603Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2212194Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2214701Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2217219Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2219720Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2222262Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2224775Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2227281Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2333326Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2335835Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2338498Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2340992Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2343633Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2346107Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2348581Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2351218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2353702Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2356168Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2358630Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2361067Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2363505Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2365930Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2368353Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2370891Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2373504Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2375922Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2378356Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2380782Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2383262Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2385675Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2388093Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2390521Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2392925Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2395340Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2397762Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2498037Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2500585Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2503215Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2505739Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2508248Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2510763Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2513282Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2515784Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2518300Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2520811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2523317Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2525818Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2528406Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2530911Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2533638Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2536128Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2538637Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2541161Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2543654Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2546163Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2548687Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2551376Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2553901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2556402Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2558900Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2561528Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2667280Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2669964Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2672544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2675048Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2677547Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2680052Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2682539Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2685033Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2687530Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2690014Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2692583Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2695260Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2697726Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2700271Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2702714Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2705149Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2707587Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2710024Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2712461Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2714902Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2717339Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2719771Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2722208Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2724637Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2728283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2730709Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2733274Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2838856Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2841318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2843808Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2846341Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2848856Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2851597Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2854154Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2856658Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2859174Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2861829Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2864332Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2866962Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2869470Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2871995Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2874514Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2877015Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2879503Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2882022Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2884535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2887024Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2889538Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2892242Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2894742Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2897325Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.2899823Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.2902324Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.2904820Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3015878Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3018410Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3020920Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3023475Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3025966Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3028460Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3030963Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3033682Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3036179Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3038827Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3041316Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3043834Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3046276Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3048717Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3051479Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3053915Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3056340Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3058773Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3061202Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3063742Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3066176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3069323Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3072460Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3075547Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3078635Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3081716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3084808Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3190039Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3192471Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3194953Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3197474Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3199988Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3202681Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3205187Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3207798Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3210295Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3212862Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3215369Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3217873Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3220361Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3222859Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3225356Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3227844Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3230329Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3232955Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3235448Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3238003Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3240495Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3242994Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3245495Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3247991Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3250634Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3253176Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3255668Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3364923Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3368137Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3371379Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3374187Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3376791Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3379283Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3381783Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3384329Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3386823Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3389318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3391814Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3394334Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3396791Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3399236Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3401684Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3404263Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3406697Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3409205Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3411694Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3414137Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3416574Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3419008Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3421431Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3423849Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3426254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3428665Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3431088Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3536410Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3539018Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3541621Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3544207Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3546742Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3549525Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3552058Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3554578Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3557106Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3559621Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3562160Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3564699Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3567221Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3569856Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3572503Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3575161Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3577677Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3580178Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3582744Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3585252Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3587926Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3590450Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3592970Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3595485Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3597993Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3600596Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3603114Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3705580Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3708132Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3710659Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3713201Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3715728Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3718254Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3720772Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3723354Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3725871Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3728405Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3730917Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3733723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3736318Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3738790Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3741268Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3743735Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3746199Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3748663Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3751363Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3753873Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3756331Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3758773Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3761218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3763832Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3766279Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3768819Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3771305Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3875672Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3878131Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3880608Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3883128Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3885644Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3888152Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3890654Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3893247Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3895761Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3898425Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3901125Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3903638Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3906167Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3908685Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3911188Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3913698Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3916197Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3918708Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3921208Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3923707Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3926223Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3928821Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3931410Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3934021Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.3936544Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.3939043Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.3941542Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4047072Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4049773Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4052406Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4054912Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4057411Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4059917Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4062611Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4065107Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4067706Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4070212Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4072758Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4075229Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4077685Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4080135Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4082647Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4085081Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4087523Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4089967Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4092487Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4095011Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4097457Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4099980Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4102418Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4104850Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4107286Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4109711Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4112137Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4216548Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4219016Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4221499Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4224032Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4226731Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4229257Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4231882Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4234442Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4236946Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4239459Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4241973Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4244528Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4247038Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4249716Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4252297Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4254811Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4257298Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4259929Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4262538Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4265030Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4267555Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4270066Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4272577Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4275084Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4277588Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4280096Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4282656Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4404665Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4409715Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4413604Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4416122Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4418726Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4421226Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4423723Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4426214Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4428713Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [33mSKIPPED[0m
2026-01-14T08:44:40.4431202Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [33mSKIPPED[0m
2026-01-14T08:44:40.4433742Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntXQuantizationAwareTrainingConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4436007Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4438046Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4440129Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4442274Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4444493Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4446602Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int1, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4448753Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4451041Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4453190Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4455315Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4457432Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4459557Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int2, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4461630Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4463728Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4465818Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4467933Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4470045Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4472159Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int3, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4474385Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4614650Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4616930Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4619061Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4621181Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4623299Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int4, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4625397Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4627450Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4629535Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4631666Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4633787Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4635901Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int5, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4647287Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4649703Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4651881Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4654162Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4656285Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4658498Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int6, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4660582Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4662676Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4664762Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4666875Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4668990Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4671091Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int7, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4673218Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4675257Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerAxis(axis=0), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4677339Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4679450Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=128), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4681559Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.ASYMMETRIC: 3>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4683800Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_identical_to_IntxWeightOnlyConfig_{'weight_dtype': torch.int8, 'granularity': PerGroup(group_size=32), 'mapping_type': <MappingType.SYMMETRIC: 1>, 'model_dtype': torch.float32} [33mSKIPPED[0m
2026-01-14T08:44:40.4685215Z test/prototype/test_embedding.py::TestEmbeddingQuantizer::test_shared_embedding [33mSKIPPED[0m
2026-01-14T08:44:40.4686381Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4687896Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4689325Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4938331Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4941270Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4943093Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4944531Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4945960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4947389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4948819Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4950420Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4951851Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4953281Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4954713Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4956141Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4957570Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4959006Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4960429Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4962044Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4963484Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4966062Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4967536Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4968965Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4970401Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4971905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4973340Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4974757Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4976174Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4977608Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4979021Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4980448Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4981875Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4983333Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4984796Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4986210Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4987631Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4989047Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4990462Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4991966Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.4993440Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.4994958Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.4996410Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.4997825Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.4999243Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5000661Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5002097Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5003545Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5004960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5006383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5253961Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5255468Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5256901Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5258318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5259739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5261165Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5262592Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5264020Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5265443Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5267017Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5268456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5269996Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5271414Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5272892Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5274317Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5275743Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5277167Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5278595Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5280020Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5281443Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5282865Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5284305Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5285719Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5287141Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5288574Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5289995Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5291509Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5292979Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5294386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5295883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5297299Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5298785Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5300239Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5301655Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5303122Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5304535Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5305944Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5307356Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5308767Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5310178Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5311589Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5313065Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5314469Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5315887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5317308Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5318716Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5570839Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5572985Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5575794Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5578881Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5581712Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5583474Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5584909Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5586352Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5587787Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5589225Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5590668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5592145Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5593581Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5595016Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5596447Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5597892Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5599328Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5600755Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5602204Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5603637Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5605069Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5606505Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5607942Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5609481Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5611342Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5612915Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5614342Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5615768Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5617199Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5618630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5620067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5621482Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5622903Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5624322Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5625739Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5627164Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5628580Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5629993Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5631416Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5632888Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5634308Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5635729Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5637149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5638649Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5640073Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5641572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5888664Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5891625Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5893243Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5894656Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5896078Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5897495Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5898906Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5900327Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5901747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5903226Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5904644Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5906060Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5907484Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5908898Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5910321Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5911738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5913151Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5914715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5916147Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5917676Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5919107Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5920530Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5921967Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5923401Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5924848Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5926274Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5927700Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5929129Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5930556Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5932040Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5933516Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5934943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5936376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5937801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5939233Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5940654Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5942064Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5943572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5944992Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5946478Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5947895Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.5949490Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.5950910Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.5952327Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.5953748Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.5955160Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6220483Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6221928Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6223389Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6224805Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6226224Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6227636Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6229056Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6230471Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6231887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6233310Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6234734Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6236320Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6237738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_bfloat16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6239210Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6240522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6241830Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6243136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6244443Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6245755Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6247061Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6248359Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_bfloat16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6249901Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6251254Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6252609Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6253905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6255197Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6256491Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6257790Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6259082Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float16_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6260383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6261670Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6262972Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6264386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_2_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6265681Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6266981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_False_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6268383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_128 [33mSKIPPED[0m
2026-01-14T08:44:40.6269670Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_fallback_path_float32_x_dim_3_bias_True_bs_4 [33mSKIPPED[0m
2026-01-14T08:44:40.6271028Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6272505Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6273935Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6275365Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6276782Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6278204Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6279635Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6281055Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6282484Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6283912Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6285329Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6537053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6540008Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6542441Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6543858Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6545271Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6547656Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6549272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6550812Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6552218Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6553630Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6555048Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6556458Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6557887Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6559300Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6560709Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6562120Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6563521Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6564919Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6566319Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6567719Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6569125Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6570527Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6571999Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6573456Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6574861Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6576375Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6577789Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6579328Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6580722Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6582136Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6583585Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6584985Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6586396Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6587801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6589198Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6590605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6592016Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6593414Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6594815Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6596232Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6597645Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6599055Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6600460Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6601863Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6603318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6604803Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6851500Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6854063Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6856632Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6859202Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6861784Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6863507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6864912Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6866318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6867728Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6869133Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6870540Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6871953Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6873361Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6874767Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6876171Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6877579Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6878995Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6880397Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6881802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6883319Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6884715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6886187Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6887581Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6888973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6890377Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6891830Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6893223Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6894612Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6896005Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6897398Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6898798Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6900192Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6901580Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6903022Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6904414Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6905802Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6907193Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6908582Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6909970Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6911454Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6912843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.6914307Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.6915701Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.6917100Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.6918520Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.6919934Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7170437Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7172284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7175115Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7177943Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7180771Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7182851Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7184261Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7185680Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7187102Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7188515Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7189935Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7191364Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7192834Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7194439Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7195870Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7197385Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7198820Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7200236Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7201660Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7203082Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7204504Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7205931Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7207350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7208761Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7210172Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7211665Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7213073Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7214489Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7215905Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7226084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7227513Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7228904Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7230301Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7231811Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7233208Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7234677Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7236070Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7237461Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7238867Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7240259Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7241660Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7243054Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7244447Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7245843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7247236Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7248636Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7485255Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7486736Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7488170Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7489587Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7491022Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7492522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7493939Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7495534Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7496982Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7498519Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7499948Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7501376Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7502795Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7504220Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7505653Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7507067Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7508499Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7509928Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7511346Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7512799Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7514216Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7515641Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7517063Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7518480Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7519908Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7521338Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7522746Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7524235Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7525654Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7527143Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7528548Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7529955Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7531418Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7532828Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7534241Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7535644Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7537052Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7538460Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7539868Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7541289Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7542694Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7544099Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7545507Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7546908Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7548325Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7549909Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7801191Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7803270Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7804687Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7806217Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7807617Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float16_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7809030Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7810451Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7811953Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7813383Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7814806Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7816232Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7817662Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7819084Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7820510Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7821939Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7823408Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7824841Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7826272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7827691Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7829128Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7830551Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7832055Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7833486Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7834981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7836399Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7837824Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7839248Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7840668Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7842106Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7843522Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7844945Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7846367Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7847782Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7849436Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7850863Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7852318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7853743Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7855146Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7856557Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7857955Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7859359Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.7860957Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.7862368Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.7863884Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.7865293Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.7866687Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8120382Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8122706Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8124120Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8125541Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8126951Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8128372Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8129782Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8131332Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8132746Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8134169Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8135590Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8137009Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8138435Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8139856Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8141267Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8142843Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8144264Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8145785Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8147204Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8148614Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8150214Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8151626Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8153041Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8154457Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8155873Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8157290Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8158709Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8160132Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8161546Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8162960Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8164386Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8165798Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8167216Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8168634Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8170036Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8171633Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8173053Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8174568Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8175973Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8177373Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8178785Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8180203Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8181609Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8183070Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8184469Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8185883Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8434396Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8435954Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8437359Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8438761Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8440163Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8441572Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8442984Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8444382Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8445784Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8447337Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8448747Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8450513Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8451981Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_2_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8453390Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8454821Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8456250Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8457674Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8459092Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8460506Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8461929Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8463350Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8464769Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8466189Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8467611Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8469029Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8470455Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8471880Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8473297Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8474718Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8476318Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8477742Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8479272Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8480695Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8482117Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8483588Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8485012Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8486436Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8487859Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8489268Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8490687Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8492167Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8493573Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8494980Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8496385Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8497801Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8499214Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8750736Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8752200Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8753599Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8755197Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8756605Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8758127Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8759531Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8760937Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8762348Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8763763Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8765172Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8766577Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8767987Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8769391Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8770800Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8772342Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8773748Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_False_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8775160Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8776616Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8778023Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8779439Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8780848Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8782249Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8783779Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8785189Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8786670Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8788074Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8789476Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8790886Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8792292Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8793699Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8795103Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8796517Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8797922Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8799333Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8800738Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8802149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8803593Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8805008Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8806406Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8807814Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.8809227Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_160_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.8810618Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.8812149Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.8813546Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.8815016Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.9127297Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity0_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.9129018Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.9130418Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.9131896Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.9133306Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.9134702Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity1_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.9136104Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.9137531Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.9138923Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.9140325Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.9141722Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity2_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.9143112Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.9144516Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.9145914Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.9147311Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.9148715Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity3_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.9150284Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:40.9151840Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:40.9153298Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity2 [33mSKIPPED[0m
2026-01-14T08:44:40.9154800Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity3 [33mSKIPPED[0m
2026-01-14T08:44:40.9156192Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_dynamic_float8_linear_float32_x_dim_3_bias_True_bs_1_x_granularity4_w_granularity4 [33mSKIPPED[0m
2026-01-14T08:44:40.9157352Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_bfloat16 [33mSKIPPED[0m
2026-01-14T08:44:40.9158265Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float16 [33mSKIPPED[0m
2026-01-14T08:44:40.9159183Z test/prototype/test_float8_opaque_tensor.py::TestFloat8OpaqueTensor::test_module_path_float32 [33mSKIPPED[0m
2026-01-14T08:44:40.9160035Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_choose_qparams_gguf [32mPASSED[0m
2026-01-14T08:44:40.9160892Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_gguf_quantized_tensor_from_float [32mPASSED[0m
2026-01-14T08:44:40.9161718Z test/prototype/test_gguf_quant.py::TestGGUFQuantization::test_quantize_api [32mPASSED[0m
2026-01-14T08:44:40.9162757Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_00 [33mSKIPPED[0m
2026-01-14T08:44:40.9163952Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_01 [33mSKIPPED[0m
2026-01-14T08:44:40.9165149Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_02 [33mSKIPPED[0m
2026-01-14T08:44:40.9166342Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_03 [33mSKIPPED[0m
2026-01-14T08:44:40.9167535Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_04 [33mSKIPPED[0m
2026-01-14T08:44:40.9168724Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_05 [33mSKIPPED[0m
2026-01-14T08:44:40.9169912Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_06 [33mSKIPPED[0m
2026-01-14T08:44:40.9171101Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_07 [33mSKIPPED[0m
2026-01-14T08:44:40.9172425Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_08 [33mSKIPPED[0m
2026-01-14T08:44:40.9173614Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_09 [33mSKIPPED[0m
2026-01-14T08:44:40.9174800Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_10 [33mSKIPPED[0m
2026-01-14T08:44:40.9175988Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_11 [33mSKIPPED[0m
2026-01-14T08:44:40.9177173Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_12 [33mSKIPPED[0m
2026-01-14T08:44:40.9178355Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_13 [33mSKIPPED[0m
2026-01-14T08:44:40.9179543Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_14 [33mSKIPPED[0m
2026-01-14T08:44:40.9180822Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_e2e_accuracy_vs_reference_15 [33mSKIPPED[0m
2026-01-14T08:44:40.9182001Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_00 [33mSKIPPED[0m
2026-01-14T08:44:40.9183292Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_01 [33mSKIPPED[0m
2026-01-14T08:44:40.9184441Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_02 [33mSKIPPED[0m
2026-01-14T08:44:40.9185585Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_03 [33mSKIPPED[0m
2026-01-14T08:44:40.9186730Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_04 [33mSKIPPED[0m
2026-01-14T08:44:40.9187873Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_05 [33mSKIPPED[0m
2026-01-14T08:44:40.9189020Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_06 [33mSKIPPED[0m
2026-01-14T08:44:40.9190171Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_07 [33mSKIPPED[0m
2026-01-14T08:44:40.9191308Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_08 [33mSKIPPED[0m
2026-01-14T08:44:40.9192501Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_09 [33mSKIPPED[0m
2026-01-14T08:44:40.9193644Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_10 [33mSKIPPED[0m
2026-01-14T08:44:50.5738208Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_11 [33mSKIPPED[0m
2026-01-14T08:44:50.5739734Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_12 [33mSKIPPED[0m
2026-01-14T08:44:50.5741225Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_13 [33mSKIPPED[0m
2026-01-14T08:44:50.5742734Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_14 [33mSKIPPED[0m
2026-01-14T08:44:50.5744210Z test/prototype/test_groupwise_lowbit_weight_lut_quantizer.py::TestGroupwiseLowbitWeightLut::test_export_compile_aoti_15 [33mSKIPPED[0m
2026-01-14T08:44:50.5745611Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5746899Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_activation_prescaling_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5748272Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5749926Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5751356Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5752785Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5754210Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5755622Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5757519Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5769725Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5773412Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5774861Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5776246Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5777622Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5779022Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5780410Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5781805Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5783189Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5784566Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5785957Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes0_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5787360Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5788787Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5790195Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5791597Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5793003Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5794414Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5795823Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5797230Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5798621Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5800011Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5801405Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5802787Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5804341Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5805784Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5807170Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5808659Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5810047Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5811500Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes1_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5812935Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5814400Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5815826Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5817257Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5818671Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5820091Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_bfloat16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5821511Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5822923Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5824339Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5825747Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5827154Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5828569Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float16_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5829973Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5831396Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_128_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5832798Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:50.5834209Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:50.5835628Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:56.9495385Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_linear_sizes2_float32_group_size_64_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:56.9496823Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:56.9498728Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_bfloat16_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:56.9499997Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:56.9501232Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float16_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:56.9502660Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_False [32mPASSED[0m
2026-01-14T08:44:56.9503901Z test/prototype/test_int4_opaque_tensor.py::TestInt4OpaqueTensor::test_module_path_float32_use_hqq_True [32mPASSED[0m
2026-01-14T08:44:56.9505091Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9506245Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9507396Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9508537Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9509686Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9510825Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9511970Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9513121Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9514249Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9515391Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9516583Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9517731Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9518892Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9520032Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9521169Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9522307Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9523452Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9524598Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9525728Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9526881Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9528021Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9529163Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9530307Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9531605Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9532846Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9533981Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9535121Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9536348Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9537479Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9538622Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9539750Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9540893Z test/prototype/test_int8_lut_tensor.py::test_parq_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9541991Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9543025Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9544068Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9545104Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9546158Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9547205Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9548235Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9549513Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9550560Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9551602Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9552645Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9553670Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9554711Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9555730Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9556754Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9557795Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9558814Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9559839Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9560867Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9561896Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9562926Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9563952Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9564980Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9566140Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9567188Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9568222Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9569368Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9570398Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9571513Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9572549Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9573578Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:44:56.9574611Z test/prototype/test_int8_lut_tensor.py::test_export[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:44:56.9575743Z test/prototype/test_mixed_precision.py::TestWeightOnlyQuantNaive::test_quantization_intNwo [32mPASSED[0m
2026-01-14T08:44:56.9576781Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace [32mPASSED[0m
2026-01-14T08:44:56.9577748Z test/prototype/test_parametrization.py::TestFakeSparsity::test_masking_logic [32mPASSED[0m
2026-01-14T08:44:56.9578758Z test/prototype/test_parametrization.py::TestFakeSparsity::test_state_dict_preserved [32mPASSED[0m
2026-01-14T08:44:56.9579798Z test/prototype/test_parametrization.py::TestFakeSparsity::test_weights_parametrized [32mPASSED[0m
2026-01-14T08:44:57.4818946Z test/prototype/test_paretoq.py::TestParetoQ::test_quantize_functions [32mPASSED[0m
2026-01-14T08:44:57.4819833Z test/prototype/test_paretoq.py::TestParetoQ::test_quantized_linear [32mPASSED[0m
2026-01-14T08:44:57.4821064Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4822258Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4823448Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4824626Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4825813Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4826994Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4828168Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4829344Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_0_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4830535Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4831717Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4832927Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4834099Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4835447Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4836685Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4837998Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4839171Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_1_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4840357Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4841550Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4842733Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4843919Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4845103Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4846282Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4847452Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4848637Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_2_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4850024Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4851275Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4852472Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4853656Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_False_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4854830Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4856022Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_False_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4857197Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_False [32mPASSED[0m
2026-01-14T08:44:57.4858372Z test/prototype/test_parq.py::TestPARQuantization::test_parq_train_loop_b_4_unif_quant_True_hard_prox_True_per_group_quantizer_True [32mPASSED[0m
2026-01-14T08:44:57.4859357Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_e2e [33mSKIPPED[0m
2026-01-14T08:44:57.4860222Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_256 [33mSKIPPED[0m
2026-01-14T08:44:57.4861121Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_int4_weight_only_group_size_32 [33mSKIPPED[0m
2026-01-14T08:44:57.4862031Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4863070Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_2_group_size_512 [32mPASSED[0m
2026-01-14T08:44:57.4863990Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4865003Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_3_group_size_512 [32mPASSED[0m
2026-01-14T08:44:57.4865954Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4866881Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_4_group_size_512 [32mPASSED[0m
2026-01-14T08:44:57.4867781Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4868695Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_b_8_group_size_512 [32mPASSED[0m
2026-01-14T08:44:57.4869573Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_2 [32mPASSED[0m
2026-01-14T08:44:57.4870408Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_3 [32mPASSED[0m
2026-01-14T08:44:57.4871245Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_4 [32mPASSED[0m
2026-01-14T08:44:57.4872071Z test/prototype/test_parq.py::TestUnifTorchaoQuantizer::test_intx_weight_only_e2e_b_8 [32mPASSED[0m
2026-01-14T08:44:57.4872923Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only [32mPASSED[0m
2026-01-14T08:44:57.4873801Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_e2e [32mPASSED[0m
2026-01-14T08:44:57.4874763Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_parq_equivalent [32mPASSED[0m
2026-01-14T08:44:57.4875775Z test/prototype/test_parq.py::TestStretchedUnifTorchaoQuantizer::test_intx_weight_only_tied_embed_linear [32mPASSED[0m
2026-01-14T08:44:57.4876940Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:57.4878245Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4879538Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:57.4880828Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4882114Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:44:57.4883397Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_2_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:44:57.4884694Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6907110Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6908655Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6909963Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6911256Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6912878Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_3_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6914184Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6915632Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6916927Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6918233Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6919526Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6920819Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_4_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6922109Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6923410Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_bfloat16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6924704Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6925989Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float16_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6927338Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_128 [32mPASSED[0m
2026-01-14T08:44:59.6928633Z test/prototype/test_parq.py::TestInt8DynamicActivationTorchaoQuantizer::test_int8_dynamic_activation_intx_e2e_b_8_float32_group_size_32 [32mPASSED[0m
2026-01-14T08:44:59.6929714Z test/prototype/test_parq.py::TestTorchAoConfigIntegration::test_tied_weights_quantization [32mPASSED[0m
2026-01-14T08:44:59.6930751Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:59.6931984Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_creation_and_attributes_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:59.6933269Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6934654Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6936026Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6937455Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6938831Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6940198Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6941660Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6943034Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6944400Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6945849Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6947218Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6948586Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6950380Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6951732Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6953101Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T08:44:59.6954456Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T08:44:59.6955724Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity0 [33mSKIPPED[0m
2026-01-14T08:44:59.6956932Z test/prototype/test_prototype_float8_tensor.py::TestFloat8StaticActivation::test_static_activation_float8_weight_granularity1 [33mSKIPPED[0m
2026-01-14T08:44:59.6958020Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_False [33mSKIPPED[0m
2026-01-14T08:44:59.6958996Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_bitnet_training_compile_True [33mSKIPPED[0m
2026-01-14T08:44:59.6960148Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6961441Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6962729Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6964021Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6965306Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6966601Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6967889Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6969168Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_False_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6970576Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6971918Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config0_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6973196Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_False [32mPASSED[0m
2026-01-14T08:44:59.6974590Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config1_module_swap_True [32mPASSED[0m
2026-01-14T08:44:59.6975868Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_False [32mPASSED[0m
2026-01-14T08:46:39.0214589Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config2_module_swap_True [32mPASSED[0m
2026-01-14T08:46:39.0216680Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_False [32mPASSED[0m
2026-01-14T08:46:39.0218017Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_mixed_precision_training_compile_True_config3_module_swap_True [32mPASSED[0m
2026-01-14T08:46:39.0219175Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0220197Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_stochastic_rounding_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0221332Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0222558Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0223777Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0224978Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0226191Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0227399Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0228656Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0229862Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0231070Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0232286Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0233498Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0234709Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_compile_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0235935Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0237180Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0238892Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0240147Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims0_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0241567Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0242818Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0244057Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0245311Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims1_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0246560Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0247800Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0249241Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0250495Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_correctness_leading_dims2_bias_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0251743Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0252901Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_False_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0254044Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cpu [32mPASSED[0m
2026-01-14T08:46:39.0255177Z test/prototype/test_quantized_training.py::TestQuantizedTraining::test_int8_weight_only_training_compile_True_device_cuda [32mPASSED[0m
2026-01-14T08:46:39.0256450Z test/prototype/test_quantized_training.py::TestFSDP2::test_fsdp2_correctness I0114 08:45:43.374000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 36274
2026-01-14T08:46:39.0257641Z I0114 08:45:43.375000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 36275
2026-01-14T08:46:39.0258234Z dist init r=0, world=2
2026-01-14T08:46:39.0258462Z dist init r=1, world=2
2026-01-14T08:46:39.0259416Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:46:39.0260451Z   warnings.warn(  # warn only once
2026-01-14T08:46:39.0261441Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:46:39.0262440Z   warnings.warn(  # warn only once
2026-01-14T08:46:39.0263422Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:46:39.0264413Z   warnings.warn(  # warn only once
2026-01-14T08:46:39.0265520Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T08:46:39.0266517Z   warnings.warn(  # warn only once
2026-01-14T08:46:39.0266813Z [32mPASSED[0m
2026-01-14T08:46:39.0267669Z test/prototype/test_quantized_training.py::TestFSDP2::test_precompute_bitnet_scale I0114 08:46:34.252000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 37105
2026-01-14T08:46:39.0268980Z I0114 08:46:34.254000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 37106
2026-01-14T08:46:39.0269574Z dist init r=1, world=2
2026-01-14T08:46:39.0269798Z dist init r=0, world=2
2026-01-14T08:46:39.0270054Z [32mPASSED[0m
2026-01-14T08:46:39.0270501Z test/prototype/test_scheduler.py::TestScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:46:39.0271191Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler [32mPASSED[0m
2026-01-14T08:46:39.0271894Z test/prototype/test_scheduler.py::TestScheduler::test_order_of_steps [32mPASSED[0m
2026-01-14T08:46:39.0272540Z test/prototype/test_scheduler.py::TestScheduler::test_step [32mPASSED[0m
2026-01-14T08:46:39.0273206Z test/prototype/test_scheduler.py::TestCubicScheduler::test_constructor [32mPASSED[0m
2026-01-14T08:46:39.0273902Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step [32mPASSED[0m
2026-01-14T08:46:39.0274675Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_observer_insertion_base_config0 [32mPASSED[0m
2026-01-14T08:46:39.0275553Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_prepare_for_loading_base_config0 [32mPASSED[0m
2026-01-14T08:46:39.0276558Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:46:39.0277689Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_5_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:46:39.0278821Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T08:46:39.0279948Z test/prototype/test_smoothquant.py::TestSmoothQuant::test_smoothquant_accuracy_alpha_0_75_base_config0_device_cuda_bfloat16 [32mPASSED[0m
2026-01-14T08:46:39.0280868Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:46:39.0281574Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_convert [32mPASSED[0m
2026-01-14T08:46:43.1495833Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:46:43.1497539Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params1 [32mPASSED[0m
2026-01-14T08:46:43.1499242Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params2 [32mPASSED[0m
2026-01-14T08:46:43.1500222Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_mask_squash_with_params3 [32mPASSED[0m
2026-01-14T08:46:43.1501032Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_prepare_config [32mPASSED[0m
2026-01-14T08:46:43.1501772Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_state_dict [32mPASSED[0m
2026-01-14T08:46:43.1502509Z test/prototype/test_sparsifier.py::TestBaseSparsifier::test_step [32mPASSED[0m
2026-01-14T08:46:43.1503271Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:46:43.1504077Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:46:43.1504861Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:46:43.1505657Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:46:43.1506462Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step [32mPASSED[0m
2026-01-14T08:46:43.1507493Z test/prototype/test_sparsifier.py::TestWeightNormSparsifier::test_step_2_of_4 [32mPASSED[0m
2026-01-14T08:46:43.1508340Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:46:43.1509188Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_mask_squash [32mPASSED[0m
2026-01-14T08:46:43.1510130Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_prepare [32mPASSED[0m
2026-01-14T08:46:43.1510990Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_sparsity_levels [32mPASSED[0m
2026-01-14T08:46:43.1511822Z test/prototype/test_sparsifier.py::TestNearlyDiagonalSparsifier::test_step [32mPASSED[0m
2026-01-14T08:46:43.1512646Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module [32mPASSED[0m
2026-01-14T08:46:43.1513529Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_fail [32mPASSED[0m
2026-01-14T08:46:43.1514463Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_fqn_to_module_for_tensors [32mPASSED[0m
2026-01-14T08:46:43.1515442Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn [32mPASSED[0m
2026-01-14T08:46:43.1516435Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_get_arg_info_from_tensor_fqn_fail [32mPASSED[0m
2026-01-14T08:46:43.1517369Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn [32mPASSED[0m
2026-01-14T08:46:43.1518263Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_fail [32mPASSED[0m
2026-01-14T08:46:43.1519150Z test/prototype/test_sparsity_utils.py::TestSparsityUtilFunctions::test_module_to_fqn_root [32mPASSED[0m
2026-01-14T08:46:43.1520173Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_lstm_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:46:43.1521166Z test/prototype/test_structured_sparsifier.py::TestSaliencyPruner::test_saliency_pruner_update_mask [32mPASSED[0m
2026-01-14T08:46:43.1522134Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1523092Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_constructor [32mPASSED[0m
2026-01-14T08:46:43.1524033Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1524982Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prepare_linear [32mPASSED[0m
2026-01-14T08:46:43.1526041Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_activation_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1535362Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_bias_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1536697Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1537984Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_padding_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1539299Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_conv2d_pool_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1540617Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_activation_linear [32mPASSED[0m
2026-01-14T08:46:43.1541936Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_bias_linear [32mPASSED[0m
2026-01-14T08:46:43.1543198Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_linear_linear [32mPASSED[0m
2026-01-14T08:46:43.1544561Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:46:43.1546056Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_layernorm_linear_single_layer [32mPASSED[0m
2026-01-14T08:46:43.1547189Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_multiple_layer [32mPASSED[0m
2026-01-14T08:46:43.1548355Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_prune_lstm_linear_single_layer [32mPASSED[0m
2026-01-14T08:46:43.1549740Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_conv2d [32mPASSED[0m
2026-01-14T08:46:43.1550666Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_step_linear [32mPASSED[0m
2026-01-14T08:46:43.1551539Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_compute_distance [32mPASSED[0m
2026-01-14T08:46:43.1552346Z test/prototype/test_structured_sparsifier.py::TestFPGMPruner::test_update_mask [32mPASSED[0m
2026-01-14T08:46:43.1553248Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1554214Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1555159Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1556151Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1557100Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1558055Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1559019Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1559969Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1560918Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1561863Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1562825Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1563778Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1564721Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1565671Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1566624Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1567563Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim0-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1568513Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1569463Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1570414Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1571413Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1572352Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1573438Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1574394Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1575346Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:43.1576412Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:43.1577361Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9466051Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9467052Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9468018Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9468981Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9469951Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9470955Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim1-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9471920Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9472871Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9473831Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9474794Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-1-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9475746Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9476702Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9477656Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9478611Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-2-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9479577Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9480580Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9481562Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9482523Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-3-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9483480Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9484444Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity0-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9485394Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype0] [33mSKIPPED[0m
2026-01-14T08:46:45.9486577Z test/prototype/test_tensor_conversion.py::test_aarch64_conversion[lead_dim2-4-granularity1-dtype1] [33mSKIPPED[0m
2026-01-14T08:46:45.9487630Z test/prototype/test_tensor_conversion.py::test_int4_tensor_conversion [33mSKIPPED[0m
2026-01-14T08:46:45.9488755Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_attention_block [33mSKIPPED[0m
2026-01-14T08:46:45.9490268Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d [33mSKIPPED[0m
2026-01-14T08:46:45.9491659Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:46:45.9493115Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:46:45.9494449Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:46:45.9495801Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_filter_linear_recipe [33mSKIPPED[0m
2026-01-14T08:46:45.9497083Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear [33mSKIPPED[0m
2026-01-14T08:46:45.9498332Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary [33mSKIPPED[0m
2026-01-14T08:46:45.9499657Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic [33mSKIPPED[0m
2026-01-14T08:46:45.9501041Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_dynamic_qat [33mSKIPPED[0m
2026-01-14T08:46:45.9502405Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_linear_unary_qat [33mSKIPPED[0m
2026-01-14T08:46:45.9503697Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d [33mSKIPPED[0m
2026-01-14T08:46:45.9504993Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary [33mSKIPPED[0m
2026-01-14T08:46:45.9506318Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_conv2d_binary2 [33mSKIPPED[0m
2026-01-14T08:46:45.9507699Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_qat_dynamic_quant_linear [33mSKIPPED[0m
2026-01-14T08:46:45.9509170Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case1 [33mSKIPPED[0m
2026-01-14T08:46:45.9510765Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_case2 [33mSKIPPED[0m
2026-01-14T08:46:45.9512387Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_and_module_type_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:46:45.9513904Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig [33mSKIPPED[0m
2026-01-14T08:46:45.9515411Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_for_dynamic_quant [33mSKIPPED[0m
2026-01-14T08:46:45.9517006Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_qconfig_with_underscores [33mSKIPPED[0m
2026-01-14T08:46:45.9518539Z test/quantization/pt2e/test_arm_inductor_quantizer.py::TestQuantizePT2EArmInductor::test_set_module_name_with_mixed_configs [33mSKIPPED[0m
2026-01-14T08:46:45.9519901Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_avgpool_use_different_qconfig [32mPASSED[0m
2026-01-14T08:46:45.9521097Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_add_quant_duplicate_dq [32mPASSED[0m
2026-01-14T08:46:45.9522281Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_no_need_for_duplicate_dq [32mPASSED[0m
2026-01-14T08:46:45.9523428Z test/quantization/pt2e/test_duplicate_dq.py::TestDuplicateDQPass::test_simple_duplicate_dq [32mPASSED[0m
2026-01-14T08:46:45.9524488Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu [32mPASSED[0m
2026-01-14T08:46:45.9526048Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu W0114 08:46:45.733000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3138] Failed to reduce inequalities: 1/2
2026-01-14T08:46:45.9527205Z [32mPASSED[0m
2026-01-14T08:46:45.9528351Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict W0114 08:46:45.908000 1007 site-packages/torch/fx/experimental/symbolic_shapes.py:3138] Failed to reduce inequalities: 1/2
2026-01-14T08:46:45.9529711Z [32mPASSED[0m
2026-01-14T08:46:45.9530500Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_calculate_qparams [32mPASSED[0m
2026-01-14T08:46:45.9531935Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_disable_range_learning [32mPASSED[0m
2026-01-14T08:46:45.9533248Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_observer [32mPASSED[0m
2026-01-14T08:46:45.9534579Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_enable_range_learning [32mPASSED[0m
2026-01-14T08:46:45.9535894Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_error_conditions [32mPASSED[0m
2026-01-14T08:46:45.9537279Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_and_observer_control [32mPASSED[0m
2026-01-14T08:46:45.9538656Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_fake_quant_control [32mPASSED[0m
2026-01-14T08:46:45.9540024Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_fake_quant_disabled [32mPASSED[0m
2026-01-14T08:46:45.9541416Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_learning_enabled [32mPASSED[0m
2026-01-14T08:46:45.9542797Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_forward_observer_enabled [32mPASSED[0m
2026-01-14T08:46:45.9544122Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_gradient_scaling [32mPASSED[0m
2026-01-14T08:46:45.9545465Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_channel [32mPASSED[0m
2026-01-14T08:46:45.9546874Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_initialization_per_tensor [32mPASSED[0m
2026-01-14T08:47:11.2132391Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_backward_per_tensor [32mPASSED[0m
2026-01-14T08:47:11.2133880Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_learnable_forward_per_tensor [32mPASSED[0m
2026-01-14T08:47:11.2135310Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_per_channel_quantization [32mPASSED[0m
2026-01-14T08:47:11.2136696Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_state_persistence [32mPASSED[0m
2026-01-14T08:47:11.2138056Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantize::test_symmetric_quantization [32mPASSED[0m
2026-01-14T08:47:11.2139506Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_device_compatibility [32mPASSED[0m
2026-01-14T08:47:11.2141082Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_integration_with_linear_layer [32mPASSED[0m
2026-01-14T08:47:11.2142679Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_multiple_fake_quant_modules [32mPASSED[0m
2026-01-14T08:47:11.2144342Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_optimizer_updates_scale_and_zero_point [32mPASSED[0m
2026-01-14T08:47:11.2146227Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeIntegration::test_training_mode_switching [32mPASSED[0m
2026-01-14T08:47:11.2147825Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_numerical_consistency_per_tensor [32mPASSED[0m
2026-01-14T08:47:11.2149710Z test/quantization/pt2e/test_learnable_fake_quantize.py::TestLearnableFakeQuantizeComparison::test_serialization [32mPASSED[0m
2026-01-14T08:47:11.2151050Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq [33mSKIPPED[0m
2026-01-14T08:47:11.2152345Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_dq_no_static_q [32mPASSED[0m
2026-01-14T08:47:11.2153642Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_for_two_dq [32mPASSED[0m
2026-01-14T08:47:11.2154990Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_metadata_porting_with_no_quant_inbetween [32mPASSED[0m
2026-01-14T08:47:11.2156277Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting [32mPASSED[0m
2026-01-14T08:47:11.2157384Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_no_metadata_porting_through_unknown_ops [32mPASSED[0m
2026-01-14T08:47:11.2158424Z test/quantization/pt2e/test_metadata_porting.py::TestMetaDataPorting::test_simple_metadata_porting [32mPASSED[0m
2026-01-14T08:47:11.2159429Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_added_node_gets_unique_id [32mPASSED[0m
2026-01-14T08:47:11.2160417Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_control_flow [33mSKIPPED[0m
2026-01-14T08:47:11.2161384Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_copy_preserve_handle [32mPASSED[0m
2026-01-14T08:47:11.2162401Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_deepcopy_preserve_handle [32mPASSED[0m
2026-01-14T08:47:11.2163483Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_prepare_for_propagation_comparison [32mPASSED[0m
2026-01-14T08:47:11.2164552Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_re_export_preserve_handle [32mPASSED[0m
2026-01-14T08:47:11.2165675Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_map_handle_to_new_nodes [32mPASSED[0m
2026-01-14T08:47:11.2166819Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_run_decompositions_same_handle_id [32mPASSED[0m
2026-01-14T08:47:11.2167798Z test/quantization/pt2e/test_numeric_debugger.py::TestNumericDebuggerInfra::test_simple [32mPASSED[0m
2026-01-14T08:47:11.2168730Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval [32mPASSED[0m
2026-01-14T08:47:11.2169752Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_exported_model_train_eval_idempotent [32mPASSED[0m
2026-01-14T08:47:11.2170733Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing [32mPASSED[0m
2026-01-14T08:47:11.2171820Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_allow_implicit_sharing_with_shared_input_edge [32mPASSED[0m
2026-01-14T08:47:11.2172780Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_chunked_bn_fusion [32mPASSED[0m
2026-01-14T08:47:11.2174784Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_linear_conv [W114 08:47:11.687775102 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2177730Z [W114 08:47:11.687809352 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2180233Z [W114 08:47:11.687822173 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2182625Z [W114 08:47:11.687840193 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2185021Z [W114 08:47:11.687863163 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2187425Z [W114 08:47:11.687871633 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2189827Z [W114 08:47:11.687888753 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2192215Z [W114 08:47:11.687896033 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2194621Z [W114 08:47:11.687937014 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2197028Z [W114 08:47:11.687953274 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:47:11.2199422Z [W114 08:47:11.687960904 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0265755Z [W114 08:47:11.687975424 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0269480Z [W114 08:47:11.687993405 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0272587Z [W114 08:47:11.688007835 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0275874Z [W114 08:47:11.688046255 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0278968Z [W114 08:47:11.688056865 PyInterpreter.cpp:265] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)
2026-01-14T08:48:03.0280938Z [32mPASSED[0m
2026-01-14T08:48:03.0281693Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_throw [32mPASSED[0m
2026-01-14T08:48:03.0283015Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_composable_quantizer_transform_for_annotation [32mPASSED[0m
2026-01-14T08:48:03.0284258Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_folding_pass [32mPASSED[0m
2026-01-14T08:48:03.0285445Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_constant_prop_preserve_metadata [32mPASSED[0m
2026-01-14T08:48:03.0286580Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv3d_bn_relu [32mPASSED[0m
2026-01-14T08:48:03.0287658Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_padding_bn_relu [32mPASSED[0m
2026-01-14T08:48:03.0288789Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose3d_bn_relu [32mPASSED[0m
2026-01-14T08:48:03.0289921Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:48:03.0291005Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec [32mPASSED[0m
2026-01-14T08:48:03.0292236Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_derived_qspec_per_channel [32mPASSED[0m
2026-01-14T08:48:03.0293359Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_disallow_eval_train [32mPASSED[0m
2026-01-14T08:48:03.0294480Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_dont_fold_other_constant [32mPASSED[0m
2026-01-14T08:48:03.0295693Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization [32mPASSED[0m
2026-01-14T08:48:03.0296870Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer [32mPASSED[0m
2026-01-14T08:48:03.0298055Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_observer_dedup [32mPASSED[0m
2026-01-14T08:48:03.0299253Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_ptq [32mPASSED[0m
2026-01-14T08:48:03.0300401Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fixed_qparams_qspec_qat [32mPASSED[0m
2026-01-14T08:48:03.0301564Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_all_ops_before_quantize [32mPASSED[0m
2026-01-14T08:48:03.0302669Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize [32mPASSED[0m
2026-01-14T08:48:03.0303774Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_fold_quantize_per_channel [32mPASSED[0m
2026-01-14T08:48:03.0305033Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_groupwise_per_channel_quant [32mPASSED[0m
2026-01-14T08:48:03.0306205Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_input_edge_sanity_check [32mPASSED[0m
2026-01-14T08:48:03.0307370Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_max_pool2d_quantizer [32mPASSED[0m
2026-01-14T08:48:03.0308551Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported [32mPASSED[0m
2026-01-14T08:48:03.0309713Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cpu [32mPASSED[0m
2026-01-14T08:48:03.0310953Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_bn_device_cuda [32mPASSED[0m
2026-01-14T08:48:03.0312165Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout [32mPASSED[0m
2026-01-14T08:48:03.0313406Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_move_exported_model_dropout_inplace [32mPASSED[0m
2026-01-14T08:48:03.0314670Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_multi_users_without_output_observer [32mPASSED[0m
2026-01-14T08:48:03.0315828Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_observer_callback [32mPASSED[0m
2026-01-14T08:48:03.0316953Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_prepare_obs_or_fq_callback [32mPASSED[0m
2026-01-14T08:48:03.0318119Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_preserve_nn_module_stack [32mPASSED[0m
2026-01-14T08:48:03.0319372Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:48:03.0320691Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_float8_e5m2 [32mPASSED[0m
2026-01-14T08:48:03.0321978Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_bfloat16_int16 [32mPASSED[0m
2026-01-14T08:48:03.0323269Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e4m3fn [32mPASSED[0m
2026-01-14T08:48:03.0324579Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_float8_e5m2 [32mPASSED[0m
2026-01-14T08:48:03.0325854Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantization_dtype_float32_int16 [32mPASSED[0m
2026-01-14T08:48:03.0326939Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_quantize_in_place_ops input_act1 is a node
2026-01-14T08:48:03.0327686Z [32mPASSED[0m
2026-01-14T08:48:03.0328306Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant [32mPASSED[0m
2026-01-14T08:48:03.0329977Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load W0114 08:48:02.555000 1007 site-packages/torch/export/pt2_archive/_package.py:586] Expect archive file to be a file ending in .pt2, or is a buffer. Instead got {/tmp/tmp3xpc1cwv}
2026-01-14T08:48:03.0332074Z W0114 08:48:02.566000 1007 site-packages/torch/export/pt2_archive/_package.py:943] Unable to load package. f must be a buffer or a file ending in .pt2. Instead got {/tmp/tmp3xpc1cwv}
2026-01-14T08:48:03.0333104Z [32mPASSED[0m
2026-01-14T08:48:03.0333766Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec [32mPASSED[0m
2026-01-14T08:48:03.0334867Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity [32mPASSED[0m
2026-01-14T08:48:03.0336066Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_shared_qspec_transitivity_case_2 [32mPASSED[0m
2026-01-14T08:48:03.0337240Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_simple_quantizer [32mPASSED[0m
2026-01-14T08:48:03.0338259Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_speed [32mPASSED[0m
2026-01-14T08:48:03.0339418Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_transform_for_annotation [32mPASSED[0m
2026-01-14T08:48:03.0340632Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_wo_annotate_conv_output_quantizer [32mPASSED[0m
2026-01-14T08:48:03.0341998Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_channel_group_quantization prepared model: GraphModule(
2026-01-14T08:48:03.0342896Z   (linear): Module()
2026-01-14T08:48:03.0343283Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:48:03.0343866Z   (activation_post_process_0): AffineQuantizedMinMaxObserver()
2026-01-14T08:48:03.0344323Z   (_guards_fn): GuardsFn()
2026-01-14T08:48:03.0344600Z )
2026-01-14T08:48:03.0344719Z 
2026-01-14T08:48:03.0344725Z 
2026-01-14T08:48:03.0344729Z 
2026-01-14T08:48:03.0344838Z def forward(self, x):
2026-01-14T08:48:03.0345189Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:48:03.0345640Z     linear_weight = self.linear.weight
2026-01-14T08:48:03.0346263Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:48:03.0346920Z     linear_bias = self.linear.bias
2026-01-14T08:48:03.0347361Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:48:03.0347906Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:48:51.9759063Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:48:51.9761542Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:48:51.9761997Z     
2026-01-14T08:48:51.9762373Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:48:51.9762865Z quantized model GraphModule(
2026-01-14T08:48:51.9763177Z   (linear): Module()
2026-01-14T08:48:51.9763618Z   (_guards_fn): GuardsFn()
2026-01-14T08:48:51.9763940Z )
2026-01-14T08:48:51.9764068Z 
2026-01-14T08:48:51.9764073Z 
2026-01-14T08:48:51.9764078Z 
2026-01-14T08:48:51.9764185Z def forward(self, x):
2026-01-14T08:48:51.9764551Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:48:51.9764992Z     _scale0 = self._scale0
2026-01-14T08:48:51.9765331Z     _zero_point0 = self._zero_point0
2026-01-14T08:48:51.9765686Z     quantize_affine = self._frozen_param0
2026-01-14T08:48:51.9766826Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:48:51.9767967Z     linear_bias = self.linear.bias
2026-01-14T08:48:51.9768291Z     _scale1 = self._scale1
2026-01-14T08:48:51.9768600Z     _zero_point1 = self._zero_point1
2026-01-14T08:48:51.9769259Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255)
2026-01-14T08:48:51.9770732Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), _scale1, _zero_point1, torch.uint8, 0, 255, output_dtype = torch.float32);  quantize_affine_1 = _scale1 = _zero_point1 = None
2026-01-14T08:48:51.9772070Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:48:51.9773044Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:48:51.9774044Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:48:51.9774456Z     
2026-01-14T08:48:51.9774798Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:48:51.9775473Z [32mPASSED[0m
2026-01-14T08:48:51.9776428Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_affine_act_per_channel_weights [32mPASSED[0m
2026-01-14T08:48:51.9778281Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2EAffineQuantization::test_dynamic_per_tok_act_per_group_weights prepared model: GraphModule(
2026-01-14T08:48:51.9779230Z   (linear): Module()
2026-01-14T08:48:51.9779623Z   (activation_post_process_1): AffineQuantizedMinMaxObserver()
2026-01-14T08:48:51.9782104Z   (activation_post_process_0): AffineQuantizedPlaceholderObserver()
2026-01-14T08:48:51.9782592Z   (_guards_fn): GuardsFn()
2026-01-14T08:48:51.9782873Z )
2026-01-14T08:48:51.9782995Z 
2026-01-14T08:48:51.9783000Z 
2026-01-14T08:48:51.9783005Z 
2026-01-14T08:48:51.9783108Z def forward(self, x):
2026-01-14T08:48:51.9783464Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:48:51.9783897Z     linear_weight = self.linear.weight
2026-01-14T08:48:51.9784516Z     activation_post_process_1 = self.activation_post_process_1(linear_weight);  linear_weight = None
2026-01-14T08:48:51.9785162Z     linear_bias = self.linear.bias
2026-01-14T08:48:51.9785609Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:48:51.9786138Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:48:51.9787238Z     linear = torch.ops.aten.linear.default(activation_post_process_0, activation_post_process_1, linear_bias);  activation_post_process_0 = activation_post_process_1 = linear_bias = None
2026-01-14T08:48:51.9788383Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:48:51.9788790Z     
2026-01-14T08:48:51.9789148Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:48:51.9789627Z quantized model GraphModule(
2026-01-14T08:48:51.9789927Z   (linear): Module()
2026-01-14T08:48:51.9790199Z   (_guards_fn): GuardsFn()
2026-01-14T08:48:51.9790472Z )
2026-01-14T08:48:51.9790592Z 
2026-01-14T08:48:51.9790597Z 
2026-01-14T08:48:51.9790609Z 
2026-01-14T08:48:51.9790716Z def forward(self, x):
2026-01-14T08:48:51.9791062Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:48:51.9791484Z     _scale0 = self._scale0
2026-01-14T08:48:51.9791779Z     _zero_point0 = self._zero_point0
2026-01-14T08:48:51.9792134Z     quantize_affine = self._frozen_param0
2026-01-14T08:48:51.9793281Z     dequantize_affine = torch.ops.torchao.dequantize_affine(quantize_affine, (1, 128), _scale0, _zero_point0, torch.int8, -127, 127, output_dtype = torch.float32);  quantize_affine = _scale0 = _zero_point0 = None
2026-01-14T08:48:51.9794417Z     linear_bias = self.linear.bias
2026-01-14T08:48:51.9795162Z     choose_qparams_affine = torch.ops.torchao.choose_qparams_affine(x, 'SYMMETRIC', (1, 128), torch.int8, -128, 127, None, None, None)
2026-01-14T08:48:51.9796014Z     getitem = choose_qparams_affine[0]
2026-01-14T08:48:51.9796517Z     getitem_1 = choose_qparams_affine[1];  choose_qparams_affine = None
2026-01-14T08:48:51.9797206Z     quantize_affine_1 = torch.ops.torchao.quantize_affine(x, (1, 128), getitem, getitem_1, torch.int8, -128, 127)
2026-01-14T08:48:51.9798349Z     dequantize_affine_1 = torch.ops.torchao.dequantize_affine(quantize_affine_1, (1, 128), getitem, getitem_1, torch.int8, -128, 127, output_dtype = torch.float32);  quantize_affine_1 = getitem = getitem_1 = None
2026-01-14T08:48:51.9799299Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:48:51.9800067Z     linear = torch.ops.aten.linear.default(dequantize_affine_1, dequantize_affine, linear_bias);  dequantize_affine_1 = dequantize_affine = linear_bias = None
2026-01-14T08:48:51.9800861Z     return pytree.tree_unflatten((linear,), self._out_spec)
2026-01-14T08:48:51.9801197Z     
2026-01-14T08:48:51.9801482Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:48:51.9801903Z [32mPASSED[0m
2026-01-14T08:48:51.9802558Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_fold_bn_erases_bn_node [33mSKIPPED[0m
2026-01-14T08:48:51.9803658Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_bias_derived_qspec [33mSKIPPED[0m
2026-01-14T08:48:51.9804822Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion [33mSKIPPED[0m
2026-01-14T08:48:51.9805872Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:48:51.9807047Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_literal_args [33mSKIPPED[0m
2026-01-14T08:48:51.9808163Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:48:51.9809300Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_per_channel_weight_bias [33mSKIPPED[0m
2026-01-14T08:48:51.9810405Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion [33mSKIPPED[0m
2026-01-14T08:48:51.9811570Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_cuda [33mSKIPPED[0m
2026-01-14T08:48:51.9812702Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_bn_relu_fusion_no_conv_bias [33mSKIPPED[0m
2026-01-14T08:48:51.9813773Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_no_bias [33mSKIPPED[0m
2026-01-14T08:48:51.9814794Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn [33mSKIPPED[0m
2026-01-14T08:48:51.9815856Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_conv_transpose_bn_relu [33mSKIPPED[0m
2026-01-14T08:48:51.9816903Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_inplace_add_relu [33mSKIPPED[0m
2026-01-14T08:48:51.9818005Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_per_channel_weight_custom_dtype [33mSKIPPED[0m
2026-01-14T08:48:51.9819132Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_preserve_source_fn_stack [33mSKIPPED[0m
2026-01-14T08:48:51.9820196Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn_Base::test_qat_update_shared_qspec [33mSKIPPED[0m
2026-01-14T08:48:51.9821235Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:48:51.9822275Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:48:51.9823244Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:48:51.9823863Z   (conv): Module()
2026-01-14T08:48:51.9824066Z   (bn): Module()
2026-01-14T08:48:51.9824373Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:48:51.9825404Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:48:51.9826623Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:48:51.9827174Z   )
2026-01-14T08:48:51.9827359Z   (_guards_fn): GuardsFn()
2026-01-14T08:48:51.9827696Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:48:51.9828786Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:48:51.9830311Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:48:51.9831005Z   )
2026-01-14T08:48:51.9831283Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:48:51.9832308Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:12.4917656Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:49:12.4927932Z   )
2026-01-14T08:49:12.4928188Z )
2026-01-14T08:49:12.4928317Z 
2026-01-14T08:49:12.4928322Z 
2026-01-14T08:49:12.4928330Z 
2026-01-14T08:49:12.4928437Z def forward(self, x):
2026-01-14T08:49:12.4928842Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:12.4929281Z     conv_weight = self.conv.weight
2026-01-14T08:49:12.4929627Z     conv_bias = self.conv.bias
2026-01-14T08:49:12.4929970Z     bn_weight = self.bn.weight
2026-01-14T08:49:12.4930278Z     bn_bias = self.bn.bias
2026-01-14T08:49:12.4930601Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:49:12.4930971Z     bn_running_var = self.bn.running_var
2026-01-14T08:49:12.4931543Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:12.4932079Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:49:12.4932618Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:12.4933291Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:12.4934000Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:49:12.4934505Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:49:12.4935031Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:49:12.4935603Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:49:12.4936251Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:49:12.4937001Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:49:12.4937828Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:49:12.4939173Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:49:12.4940385Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:49:12.4941085Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:49:12.4941845Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:49:12.4942574Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:49:12.4943804Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:49:12.4945121Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:49:12.4945902Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:49:12.4946411Z     
2026-01-14T08:49:12.4946757Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:12.4947237Z model fx: GraphModule(
2026-01-14T08:49:12.4947637Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:12.4948937Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:12.4951041Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:49:12.4951738Z   )
2026-01-14T08:49:12.4951954Z   (conv): ConvBn1d(
2026-01-14T08:49:12.4952232Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:49:12.4952778Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:49:12.4953569Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:12.4954919Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0017, 0.0019, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:49:12.4956767Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2148, -0.0992, -0.2048]), max_val=tensor([0.0771, 0.2459, 0.3011]))
2026-01-14T08:49:12.4957641Z     )
2026-01-14T08:49:12.4957852Z   )
2026-01-14T08:49:12.4958204Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:12.4959503Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:12.4961125Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4139440059661865)
2026-01-14T08:49:12.4961677Z   )
2026-01-14T08:49:12.4961844Z )
2026-01-14T08:49:12.4961942Z 
2026-01-14T08:49:12.4961946Z 
2026-01-14T08:49:12.4961958Z 
2026-01-14T08:49:12.4962045Z def forward(self, x):
2026-01-14T08:49:12.4962403Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:49:12.4963013Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:49:12.4963578Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:49:12.4964029Z     return activation_post_process_1
2026-01-14T08:49:12.4964299Z     
2026-01-14T08:49:12.4964579Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:12.4964969Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:49:12.4965201Z          [0., 0., 0.],
2026-01-14T08:49:12.4965452Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:49:12.4965759Z converted model pt2e: GraphModule(
2026-01-14T08:49:12.4966032Z   (conv): Module()
2026-01-14T08:49:12.4966236Z   (bn): Module()
2026-01-14T08:49:12.4966450Z   (_guards_fn): GuardsFn()
2026-01-14T08:49:12.4966684Z )
2026-01-14T08:49:12.4966786Z 
2026-01-14T08:49:12.4966790Z 
2026-01-14T08:49:12.4966794Z 
2026-01-14T08:49:12.4966882Z def forward(self, x):
2026-01-14T08:49:12.4967177Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:12.4967523Z     conv_bias = self.conv.bias
2026-01-14T08:49:12.4967834Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:12.4968541Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:49:12.4969828Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:12.4970804Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:12.4971409Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:12.4971906Z     _scale_0 = self._scale_0
2026-01-14T08:49:12.4972160Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:49:12.4972475Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:49:12.4973514Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:49:12.4974971Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:49:12.4976262Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011089790612459183, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:49:12.4977726Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:49:12.4978793Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:49:12.4979223Z     
2026-01-14T08:49:12.4979505Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:12.4979901Z onverted model fx: GraphModule(
2026-01-14T08:49:12.4980286Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:49:12.4980672Z )
2026-01-14T08:49:12.4980775Z 
2026-01-14T08:49:12.4980779Z 
2026-01-14T08:49:12.4980783Z 
2026-01-14T08:49:12.4980877Z def forward(self, x):
2026-01-14T08:49:12.4981512Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:49:12.4982866Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:12.4983951Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:49:12.4984859Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011089790612459183, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:49:12.4986221Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011089790612459183, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:49:12.4987158Z     return dequantize_per_tensor_default_1
2026-01-14T08:49:12.4987444Z     
2026-01-14T08:49:12.4987726Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:12.4988111Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:49:12.4988360Z          [0., 0., 0.],
2026-01-14T08:49:12.4988570Z          [0., 0., 0.]]])
2026-01-14T08:49:12.4988803Z model pt2e: GraphModule(
2026-01-14T08:49:12.4989050Z   (conv): Module()
2026-01-14T08:49:12.4989261Z   (bn): Module()
2026-01-14T08:49:12.4989560Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:12.4990593Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:12.4991794Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:49:12.4992330Z   )
2026-01-14T08:49:12.4992522Z   (_guards_fn): GuardsFn()
2026-01-14T08:49:12.4992859Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:12.4993891Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:49:12.4995105Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:49:12.4995644Z   )
2026-01-14T08:49:39.3003407Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:39.3004884Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:39.3006113Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:49:39.3006853Z   )
2026-01-14T08:49:39.3007022Z )
2026-01-14T08:49:39.3007117Z 
2026-01-14T08:49:39.3007122Z 
2026-01-14T08:49:39.3007126Z 
2026-01-14T08:49:39.3007215Z def forward(self, x):
2026-01-14T08:49:39.3007513Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:39.3007861Z     conv_weight = self.conv.weight
2026-01-14T08:49:39.3008170Z     conv_bias = self.conv.bias
2026-01-14T08:49:39.3008431Z     bn_weight = self.bn.weight
2026-01-14T08:49:39.3008679Z     bn_bias = self.bn.bias
2026-01-14T08:49:39.3008940Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:49:39.3009239Z     bn_running_var = self.bn.running_var
2026-01-14T08:49:39.3009589Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:39.3010007Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:49:39.3010438Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:39.3010987Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:39.3011652Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:49:39.3012063Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:49:39.3012485Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:49:39.3012942Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:49:39.3013457Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:49:39.3014058Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:49:39.3014713Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:49:39.3015759Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:49:39.3016719Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:49:39.3017276Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:49:39.3017884Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:49:39.3018468Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:49:39.3019438Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:49:39.3020483Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:49:39.3021109Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:49:39.3021522Z     
2026-01-14T08:49:39.3021817Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:39.3022205Z model fx: GraphModule(
2026-01-14T08:49:39.3022538Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:39.3023564Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:39.3024773Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:49:39.3025311Z   )
2026-01-14T08:49:39.3025486Z   (conv): ConvBn1d(
2026-01-14T08:49:39.3025715Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:49:39.3026231Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:49:39.3026728Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:39.3027729Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:49:39.3029070Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.214811772108078, max_val=0.30109599232673645)
2026-01-14T08:49:39.3029615Z     )
2026-01-14T08:49:39.3029785Z   )
2026-01-14T08:49:39.3030062Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:39.3031082Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0111]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:39.3032290Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4139524698257446, max_val=1.4138529300689697)
2026-01-14T08:49:39.3032831Z   )
2026-01-14T08:49:39.3032997Z )
2026-01-14T08:49:39.3033092Z 
2026-01-14T08:49:39.3033096Z 
2026-01-14T08:49:39.3033105Z 
2026-01-14T08:49:39.3033197Z def forward(self, x):
2026-01-14T08:49:39.3033548Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:49:39.3034102Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:49:39.3034661Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:49:39.3035105Z     return activation_post_process_1
2026-01-14T08:49:39.3035371Z     
2026-01-14T08:49:39.3035646Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:39.3036026Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:49:39.3036256Z          [0., 0., 0.],
2026-01-14T08:49:39.3036505Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:49:39.3036809Z converted model pt2e: GraphModule(
2026-01-14T08:49:39.3037077Z   (conv): Module()
2026-01-14T08:49:39.3037277Z   (bn): Module()
2026-01-14T08:49:39.3037491Z   (_guards_fn): GuardsFn()
2026-01-14T08:49:39.3037714Z )
2026-01-14T08:49:39.3037816Z 
2026-01-14T08:49:39.3037819Z 
2026-01-14T08:49:39.3037823Z 
2026-01-14T08:49:39.3037908Z def forward(self, x):
2026-01-14T08:49:39.3038195Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:39.3038536Z     conv_bias = self.conv.bias
2026-01-14T08:49:39.3038839Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:39.3039593Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:49:39.3040880Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:39.3041857Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:39.3042396Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:39.3042927Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:49:39.3043754Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002370834583416581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:49:39.3045104Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:49:39.3046379Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.01108943298459053, 0, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:49:39.3047844Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:49:39.3048915Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:49:39.3049611Z     
2026-01-14T08:49:39.3049893Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:39.3050284Z onverted model fx: GraphModule(
2026-01-14T08:49:39.3050658Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:49:39.3051052Z )
2026-01-14T08:49:39.3051196Z 
2026-01-14T08:49:39.3051200Z 
2026-01-14T08:49:39.3051204Z 
2026-01-14T08:49:39.3051290Z def forward(self, x):
2026-01-14T08:49:39.3051936Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:49:39.3053253Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:39.3054318Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:49:39.3055216Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01108943298459053, 0, -128, 127, torch.int8);  conv = None
2026-01-14T08:49:39.3056563Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01108943298459053, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:49:39.3057493Z     return dequantize_per_tensor_default_1
2026-01-14T08:49:39.3057771Z     
2026-01-14T08:49:39.3058048Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:39.3058427Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:49:39.3058664Z          [0., 0., 0.],
2026-01-14T08:49:39.3058876Z          [0., 0., 0.]]])
2026-01-14T08:49:39.3059321Z [32mPASSED[0m
2026-01-14T08:49:39.3059911Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:49:39.3060558Z   (conv): Module()
2026-01-14T08:49:39.3060755Z   (bn): Module()
2026-01-14T08:49:39.3061063Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:39.3062298Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:39.3063712Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:49:39.3064252Z   )
2026-01-14T08:49:39.3064439Z   (_guards_fn): GuardsFn()
2026-01-14T08:49:39.3064781Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:56.7588693Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:49:56.7591008Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:49:56.7591818Z   )
2026-01-14T08:49:56.7592107Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:56.7593664Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:56.7595098Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:49:56.7595782Z   )
2026-01-14T08:49:56.7595956Z )
2026-01-14T08:49:56.7596053Z 
2026-01-14T08:49:56.7596058Z 
2026-01-14T08:49:56.7596062Z 
2026-01-14T08:49:56.7596149Z def forward(self, x):
2026-01-14T08:49:56.7596451Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:56.7596808Z     conv_weight = self.conv.weight
2026-01-14T08:49:56.7597087Z     conv_bias = self.conv.bias
2026-01-14T08:49:56.7597356Z     bn_weight = self.bn.weight
2026-01-14T08:49:56.7597606Z     bn_bias = self.bn.bias
2026-01-14T08:49:56.7597868Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:49:56.7598169Z     bn_running_var = self.bn.running_var
2026-01-14T08:49:56.7598516Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:56.7598934Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:49:56.7599365Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:56.7599911Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:56.7600479Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:49:56.7600886Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:49:56.7601306Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:49:56.7601761Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:49:56.7602276Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:49:56.7602870Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:49:56.7603524Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:49:56.7604567Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:49:56.7605512Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:49:56.7606075Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:49:56.7606686Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:49:56.7607268Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:49:56.7608238Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:49:56.7609276Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:49:56.7609897Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:49:56.7610310Z     
2026-01-14T08:49:56.7610606Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:56.7610989Z model fx: GraphModule(
2026-01-14T08:49:56.7611443Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:56.7612692Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:56.7614173Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:49:56.7614720Z   )
2026-01-14T08:49:56.7614905Z   (conv): ConvBn1d(
2026-01-14T08:49:56.7615232Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:49:56.7615660Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:49:56.7616166Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:56.7617454Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:49:56.7620805Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:49:56.7621614Z     )
2026-01-14T08:49:56.7621794Z   )
2026-01-14T08:49:56.7622089Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:49:56.7623393Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:49:56.7624834Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3958139419555664, max_val=1.4123148918151855)
2026-01-14T08:49:56.7625381Z   )
2026-01-14T08:49:56.7625553Z )
2026-01-14T08:49:56.7625659Z 
2026-01-14T08:49:56.7625663Z 
2026-01-14T08:49:56.7625667Z 
2026-01-14T08:49:56.7625757Z def forward(self, x):
2026-01-14T08:49:56.7626117Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:49:56.7626681Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:49:56.7627258Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:49:56.7627702Z     return activation_post_process_1
2026-01-14T08:49:56.7627980Z     
2026-01-14T08:49:56.7628266Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:56.7628657Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:49:56.7628896Z          [0., 0., 0.],
2026-01-14T08:49:56.7629178Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:49:56.7629542Z converted model pt2e: GraphModule(
2026-01-14T08:49:56.7629812Z   (conv): Module()
2026-01-14T08:49:56.7630024Z   (bn): Module()
2026-01-14T08:49:56.7630237Z   (_guards_fn): GuardsFn()
2026-01-14T08:49:56.7630473Z )
2026-01-14T08:49:56.7630574Z 
2026-01-14T08:49:56.7630578Z 
2026-01-14T08:49:56.7630582Z 
2026-01-14T08:49:56.7630670Z def forward(self, x):
2026-01-14T08:49:56.7630967Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:49:56.7631315Z     conv_bias = self.conv.bias
2026-01-14T08:49:56.7631631Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:49:56.7632350Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:49:56.7633635Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:56.7634610Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:49:56.7635158Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:49:56.7635664Z     _scale_0 = self._scale_0
2026-01-14T08:49:56.7635935Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:49:56.7636248Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:49:56.7637202Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:49:56.7638753Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:49:56.7640062Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011012271046638489, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:49:56.7641545Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:49:56.7642632Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:49:56.7643118Z     
2026-01-14T08:49:56.7643408Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:49:56.7643809Z onverted model fx: GraphModule(
2026-01-14T08:49:56.7644201Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:49:56.7644586Z )
2026-01-14T08:49:56.7644686Z 
2026-01-14T08:49:56.7644690Z 
2026-01-14T08:49:56.7644694Z 
2026-01-14T08:49:56.7644791Z def forward(self, x):
2026-01-14T08:49:56.7645436Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:49:56.7646761Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:49:56.7647843Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:49:56.7648752Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011012271046638489, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:49:56.7650445Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011012271046638489, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:50:17.3130179Z     return dequantize_per_tensor_default_1
2026-01-14T08:50:17.3134026Z     
2026-01-14T08:50:17.3135214Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:17.3136182Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:50:17.3136665Z          [0., 0., 0.],
2026-01-14T08:50:17.3137118Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:50:17.3137526Z model pt2e: GraphModule(
2026-01-14T08:50:17.3137767Z   (conv): Module()
2026-01-14T08:50:17.3137976Z   (bn): Module()
2026-01-14T08:50:17.3138280Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3139539Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:17.3141031Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:50:17.3141565Z   )
2026-01-14T08:50:17.3141759Z   (_guards_fn): GuardsFn()
2026-01-14T08:50:17.3142090Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3143335Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:50:17.3144766Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:50:17.3145306Z   )
2026-01-14T08:50:17.3145852Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3147084Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:17.3148634Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:50:17.3149358Z   )
2026-01-14T08:50:17.3149525Z )
2026-01-14T08:50:17.3149629Z 
2026-01-14T08:50:17.3149633Z 
2026-01-14T08:50:17.3149637Z 
2026-01-14T08:50:17.3149721Z def forward(self, x):
2026-01-14T08:50:17.3150016Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:50:17.3150367Z     conv_weight = self.conv.weight
2026-01-14T08:50:17.3150651Z     conv_bias = self.conv.bias
2026-01-14T08:50:17.3150907Z     bn_weight = self.bn.weight
2026-01-14T08:50:17.3151162Z     bn_bias = self.bn.bias
2026-01-14T08:50:17.3151427Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:50:17.3151734Z     bn_running_var = self.bn.running_var
2026-01-14T08:50:17.3152066Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:50:17.3152492Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:50:17.3152922Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:50:17.3153460Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:50:17.3154027Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:50:17.3154431Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:50:17.3154857Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:50:17.3155307Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:50:17.3155839Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:50:17.3156437Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:50:17.3157083Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:50:17.3158127Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:50:17.3166634Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:50:17.3167238Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:50:17.3167880Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:50:17.3168463Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:50:17.3169448Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:50:17.3170492Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:50:17.3171114Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:50:17.3171623Z     
2026-01-14T08:50:17.3171912Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:17.3172298Z model fx: GraphModule(
2026-01-14T08:50:17.3172625Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3173875Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:17.3175475Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:50:17.3176017Z   )
2026-01-14T08:50:17.3176208Z   (conv): ConvBn1d(
2026-01-14T08:50:17.3176434Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:50:17.3176864Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:50:17.3177469Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3178700Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:50:17.3180194Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:50:17.3180740Z     )
2026-01-14T08:50:17.3180924Z   )
2026-01-14T08:50:17.3181214Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:17.3182458Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0110], device='cuda:0'), zero_point=tensor([-1], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:17.3183886Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3977917432785034, max_val=1.4123148918151855)
2026-01-14T08:50:17.3184424Z   )
2026-01-14T08:50:17.3184601Z )
2026-01-14T08:50:17.3184702Z 
2026-01-14T08:50:17.3184706Z 
2026-01-14T08:50:17.3184710Z 
2026-01-14T08:50:17.3184808Z def forward(self, x):
2026-01-14T08:50:17.3185169Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:50:17.3185729Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:50:17.3186297Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:50:17.3186747Z     return activation_post_process_1
2026-01-14T08:50:17.3187008Z     
2026-01-14T08:50:17.3187301Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:17.3187726Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:50:17.3187973Z          [0., 0., 0.],
2026-01-14T08:50:17.3188255Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:50:17.3188601Z converted model pt2e: GraphModule(
2026-01-14T08:50:17.3188872Z   (conv): Module()
2026-01-14T08:50:17.3189074Z   (bn): Module()
2026-01-14T08:50:17.3189289Z   (_guards_fn): GuardsFn()
2026-01-14T08:50:17.3189517Z )
2026-01-14T08:50:17.3189623Z 
2026-01-14T08:50:17.3189627Z 
2026-01-14T08:50:17.3189631Z 
2026-01-14T08:50:17.3189715Z def forward(self, x):
2026-01-14T08:50:17.3190003Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:50:17.3190350Z     conv_bias = self.conv.bias
2026-01-14T08:50:17.3190665Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:50:17.3191368Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:50:17.3192654Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:50:17.3193620Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:50:17.3194171Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:50:17.3194697Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:50:17.3195528Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:50:17.3196963Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:50:17.3198301Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011020027101039886, -1, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:50:17.3199771Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:50:17.3200855Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:50:17.3201279Z     
2026-01-14T08:50:17.3201571Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:17.3201961Z onverted model fx: GraphModule(
2026-01-14T08:50:17.3202351Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:50:17.3202745Z )
2026-01-14T08:50:17.3202845Z 
2026-01-14T08:50:17.3202849Z 
2026-01-14T08:50:17.3202853Z 
2026-01-14T08:50:17.3202939Z def forward(self, x):
2026-01-14T08:50:17.3203585Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:50:44.0100836Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:50:44.0102892Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:50:44.0104116Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011020027101039886, -1, -128, 127, torch.int8);  conv = None
2026-01-14T08:50:44.0105907Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011020027101039886, -1, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:50:44.0107123Z     return dequantize_per_tensor_default_1
2026-01-14T08:50:44.0107463Z     
2026-01-14T08:50:44.0107821Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:44.0108313Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:50:44.0108610Z          [0., 0., 0.],
2026-01-14T08:50:44.0108882Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:50:44.0109452Z [32mPASSED[0m
2026-01-14T08:50:44.0110237Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T08:50:44.0111094Z   (conv): Module()
2026-01-14T08:50:44.0111348Z   (bn): Module()
2026-01-14T08:50:44.0111713Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0113026Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:44.0114567Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:50:44.0115257Z   )
2026-01-14T08:50:44.0115483Z   (_guards_fn): GuardsFn()
2026-01-14T08:50:44.0115903Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0117296Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:50:44.0119109Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:50:44.0119986Z   )
2026-01-14T08:50:44.0120599Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0121923Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:44.0123690Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:50:44.0124367Z   )
2026-01-14T08:50:44.0124580Z )
2026-01-14T08:50:44.0124698Z 
2026-01-14T08:50:44.0124711Z 
2026-01-14T08:50:44.0124716Z 
2026-01-14T08:50:44.0124819Z def forward(self, x):
2026-01-14T08:50:44.0125171Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:50:44.0125606Z     conv_weight = self.conv.weight
2026-01-14T08:50:44.0125948Z     conv_bias = self.conv.bias
2026-01-14T08:50:44.0126256Z     bn_weight = self.bn.weight
2026-01-14T08:50:44.0126565Z     bn_bias = self.bn.bias
2026-01-14T08:50:44.0126885Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:50:44.0127258Z     bn_running_var = self.bn.running_var
2026-01-14T08:50:44.0127669Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:50:44.0128196Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:50:44.0128730Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:50:44.0129405Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:50:44.0130105Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:50:44.0130595Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:50:44.0131122Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:50:44.0131802Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:50:44.0132444Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:50:44.0133186Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:50:44.0134007Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:50:44.0135363Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:50:44.0136580Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:50:44.0137279Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:50:44.0138025Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:50:44.0138754Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:50:44.0139991Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:50:44.0141293Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:50:44.0142077Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:50:44.0142578Z     
2026-01-14T08:50:44.0142931Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:44.0143404Z model fx: GraphModule(
2026-01-14T08:50:44.0143795Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0145097Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:44.0146729Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:50:44.0147414Z   )
2026-01-14T08:50:44.0147627Z   (conv): ConvBn1d(
2026-01-14T08:50:44.0147940Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:50:44.0148509Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:50:44.0149443Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0150718Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:50:44.0152156Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:50:44.0152847Z     )
2026-01-14T08:50:44.0153024Z   )
2026-01-14T08:50:44.0153305Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:50:44.0154335Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:50:44.0155543Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9784814715385437, max_val=2.047511577606201)
2026-01-14T08:50:44.0156082Z   )
2026-01-14T08:50:44.0156245Z )
2026-01-14T08:50:44.0156348Z 
2026-01-14T08:50:44.0156352Z 
2026-01-14T08:50:44.0156356Z 
2026-01-14T08:50:44.0156441Z def forward(self, x):
2026-01-14T08:50:44.0156801Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:50:44.0157348Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:50:44.0157921Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:50:44.0158363Z     return activation_post_process_1
2026-01-14T08:50:44.0158634Z     
2026-01-14T08:50:44.0158921Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:50:44.0159303Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:50:44.0159579Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:50:44.0159873Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:50:44.0160216Z converted model pt2e: GraphModule(
2026-01-14T08:50:44.0160477Z   (conv): Module()
2026-01-14T08:50:44.0160690Z   (bn): Module()
2026-01-14T08:50:44.0160896Z   (_guards_fn): GuardsFn()
2026-01-14T08:50:44.0161123Z )
2026-01-14T08:50:44.0161222Z 
2026-01-14T08:50:44.0161226Z 
2026-01-14T08:50:44.0161229Z 
2026-01-14T08:50:44.0161324Z def forward(self, x):
2026-01-14T08:50:44.0161610Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:50:44.0161956Z     conv_bias = self.conv.bias
2026-01-14T08:50:44.0162256Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:50:44.0162965Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8)
2026-01-14T08:50:44.0164245Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:50:44.0165210Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:50:44.0165754Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:50:44.0166244Z     _scale_0 = self._scale_0
2026-01-14T08:50:44.0166503Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:50:44.0166804Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:50:44.0167901Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:50:44.0169382Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:50:44.0170684Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011866639368236065, -46, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:04.5637154Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:04.5639053Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:51:04.5639644Z     
2026-01-14T08:51:04.5640008Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:04.5640498Z onverted model fx: GraphModule(
2026-01-14T08:51:04.5641054Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:51:04.5641593Z )
2026-01-14T08:51:04.5641713Z 
2026-01-14T08:51:04.5641725Z 
2026-01-14T08:51:04.5641730Z 
2026-01-14T08:51:04.5641837Z def forward(self, x):
2026-01-14T08:51:04.5642662Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:51:04.5644391Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:04.5645770Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:04.5646920Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011866639368236065, -46, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:04.5648744Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011866639368236065, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:04.5650194Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:04.5650541Z     
2026-01-14T08:51:04.5650895Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:04.5651447Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:04.5651786Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:04.5652089Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:51:04.5652417Z model pt2e: GraphModule(
2026-01-14T08:51:04.5652699Z   (conv): Module()
2026-01-14T08:51:04.5652946Z   (bn): Module()
2026-01-14T08:51:04.5653325Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5654624Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:04.5656176Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:51:04.5656855Z   )
2026-01-14T08:51:04.5657091Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:04.5657491Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5658801Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:04.5660362Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:51:04.5661049Z   )
2026-01-14T08:51:04.5661388Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5662930Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:04.5664487Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:51:04.5665374Z   )
2026-01-14T08:51:04.5665574Z )
2026-01-14T08:51:04.5665700Z 
2026-01-14T08:51:04.5665706Z 
2026-01-14T08:51:04.5665711Z 
2026-01-14T08:51:04.5665814Z def forward(self, x):
2026-01-14T08:51:04.5666162Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:04.5666600Z     conv_weight = self.conv.weight
2026-01-14T08:51:04.5666946Z     conv_bias = self.conv.bias
2026-01-14T08:51:04.5667255Z     bn_weight = self.bn.weight
2026-01-14T08:51:04.5667572Z     bn_bias = self.bn.bias
2026-01-14T08:51:04.5667883Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:04.5668272Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:04.5668681Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:04.5669203Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:51:04.5669732Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:04.5670420Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:04.5671122Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:04.5671613Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:04.5672134Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:04.5672690Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:04.5673335Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:04.5674066Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:04.5674891Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:04.5676254Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2], [4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:51:04.5677471Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:04.5678218Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:04.5678965Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:51:04.5679694Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:04.5680926Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:04.5682232Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:04.5683014Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:04.5683512Z     
2026-01-14T08:51:04.5683868Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:04.5684345Z model fx: GraphModule(
2026-01-14T08:51:04.5684734Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5686042Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([57], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:04.5687582Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.611703872680664, max_val=0.6104744076728821)
2026-01-14T08:51:04.5688264Z   )
2026-01-14T08:51:04.5688476Z   (conv): ConvBn1d(
2026-01-14T08:51:04.5688884Z     3, 3, kernel_size=(3,), stride=(2,), padding=(4,)
2026-01-14T08:51:04.5689454Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:04.5690067Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5692857Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:04.5694090Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31192728877067566, max_val=0.23078496754169464)
2026-01-14T08:51:04.5694648Z     )
2026-01-14T08:51:04.5694823Z   )
2026-01-14T08:51:04.5695096Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:04.5696133Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0119]), zero_point=tensor([-44], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:04.5697339Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9980934262275696, max_val=2.047511577606201)
2026-01-14T08:51:04.5697878Z   )
2026-01-14T08:51:04.5698047Z )
2026-01-14T08:51:04.5698154Z 
2026-01-14T08:51:04.5698159Z 
2026-01-14T08:51:04.5698163Z 
2026-01-14T08:51:04.5698247Z def forward(self, x):
2026-01-14T08:51:04.5698612Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:04.5699164Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:04.5699731Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:04.5700170Z     return activation_post_process_1
2026-01-14T08:51:04.5700434Z     
2026-01-14T08:51:04.5700715Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:04.5701097Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:04.5701371Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:04.5701663Z          [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:04.5701996Z converted model pt2e: GraphModule(
2026-01-14T08:51:04.5702256Z   (conv): Module()
2026-01-14T08:51:04.5702471Z   (bn): Module()
2026-01-14T08:51:04.5702681Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:04.5702908Z )
2026-01-14T08:51:04.5703006Z 
2026-01-14T08:51:04.5703010Z 
2026-01-14T08:51:04.5703014Z 
2026-01-14T08:51:04.5703105Z def forward(self, x):
2026-01-14T08:51:04.5703387Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:04.5703733Z     conv_bias = self.conv.bias
2026-01-14T08:51:04.5704038Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:04.5704745Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8)
2026-01-14T08:51:04.5706026Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:04.5706994Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:04.5707545Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:04.5708068Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:51:04.5708907Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0024561204481869936, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:51:33.1233676Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2], [4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:51:33.1235389Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.011943548917770386, -44, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:33.1236819Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:51:33.1238067Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:51:33.1238503Z     
2026-01-14T08:51:33.1238793Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:33.1239187Z onverted model fx: GraphModule(
2026-01-14T08:51:33.1239625Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(2,), padding=(4,))
2026-01-14T08:51:33.1240057Z )
2026-01-14T08:51:33.1240158Z 
2026-01-14T08:51:33.1240835Z 
2026-01-14T08:51:33.1240855Z 
2026-01-14T08:51:33.1240953Z def forward(self, x):
2026-01-14T08:51:33.1241615Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008714424446225166, 57, -128, 127, torch.int8);  x = None
2026-01-14T08:51:33.1242941Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008714424446225166, 57, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:33.1244057Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:33.1244969Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.011943548917770386, -44, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:33.1246352Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.011943548917770386, -44, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:33.1247298Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:33.1247574Z     
2026-01-14T08:51:33.1247870Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:33.1248249Z diff: tensor([[[0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:33.1248523Z          [0., 0., 0., 0., 0., 0.],
2026-01-14T08:51:33.1248784Z          [0., 0., 0., 0., 0., 0.]]])
2026-01-14T08:51:33.1249514Z [32mPASSED[0m
2026-01-14T08:51:33.1250369Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:51:33.1251134Z   (conv): Module()
2026-01-14T08:51:33.1251401Z   (bn): Module()
2026-01-14T08:51:33.1251703Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1252742Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:33.1253966Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:51:33.1254500Z   )
2026-01-14T08:51:33.1254692Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:33.1255024Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1256117Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:33.1257547Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:51:33.1258222Z   )
2026-01-14T08:51:33.1258504Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1259673Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:33.1260872Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:51:33.1261407Z   )
2026-01-14T08:51:33.1261691Z )
2026-01-14T08:51:33.1261794Z 
2026-01-14T08:51:33.1261799Z 
2026-01-14T08:51:33.1261803Z 
2026-01-14T08:51:33.1261888Z def forward(self, x):
2026-01-14T08:51:33.1262175Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:33.1262526Z     conv_weight = self.conv.weight
2026-01-14T08:51:33.1262806Z     bn_weight = self.bn.weight
2026-01-14T08:51:33.1263057Z     bn_bias = self.bn.bias
2026-01-14T08:51:33.1263319Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:33.1263613Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:33.1263949Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:33.1264374Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:51:33.1264806Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:33.1265345Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:33.1265912Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:33.1266324Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:33.1266744Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:33.1267203Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:33.1267716Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:33.1268307Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:33.1269192Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:51:33.1270072Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:33.1270661Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:33.1271653Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:33.1272689Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:33.1273313Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:33.1273708Z     
2026-01-14T08:51:33.1273998Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:33.1274372Z model fx: GraphModule(
2026-01-14T08:51:33.1274703Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1275733Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:33.1276940Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:51:33.1277486Z   )
2026-01-14T08:51:33.1277666Z   (conv): ConvBn1d(
2026-01-14T08:51:33.1277915Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:51:33.1278359Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:33.1278852Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1279919Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0020, 0.0022]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:33.1281432Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618]), max_val=tensor([0.1970, 0.2308, 0.2775]))
2026-01-14T08:51:33.1290523Z     )
2026-01-14T08:51:33.1290736Z   )
2026-01-14T08:51:33.1291029Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:33.1292233Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:33.1293452Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:51:33.1293993Z   )
2026-01-14T08:51:33.1294157Z )
2026-01-14T08:51:33.1294252Z 
2026-01-14T08:51:33.1294256Z 
2026-01-14T08:51:33.1294260Z 
2026-01-14T08:51:33.1294352Z def forward(self, x):
2026-01-14T08:51:33.1294710Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:33.1295270Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:33.1295830Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:33.1296278Z     return activation_post_process_1
2026-01-14T08:51:33.1296553Z     
2026-01-14T08:51:33.1296832Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:33.1297219Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:33.1297450Z          [0., 0., 0.],
2026-01-14T08:51:33.1297664Z          [0., 0., 0.]],
2026-01-14T08:51:33.1297799Z 
2026-01-14T08:51:33.1297876Z         [[0., 0., 0.],
2026-01-14T08:51:33.1298088Z          [0., 0., 0.],
2026-01-14T08:51:33.1298287Z          [0., 0., 0.]],
2026-01-14T08:51:33.1298429Z 
2026-01-14T08:51:33.1298503Z         [[0., 0., 0.],
2026-01-14T08:51:33.1298712Z          [0., 0., 0.],
2026-01-14T08:51:33.1298945Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:33.1299270Z converted model pt2e: GraphModule(
2026-01-14T08:51:33.1299530Z   (conv): Module()
2026-01-14T08:51:33.1299736Z   (bn): Module()
2026-01-14T08:51:33.1299940Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:33.1300170Z )
2026-01-14T08:51:33.1300268Z 
2026-01-14T08:51:33.1300272Z 
2026-01-14T08:51:33.1300280Z 
2026-01-14T08:51:33.1300362Z def forward(self, x):
2026-01-14T08:51:33.1300653Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:33.1301050Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:33.1301757Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T08:51:33.1303042Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:33.1304002Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:33.1304547Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:33.1305048Z     _scale_0 = self._scale_0
2026-01-14T08:51:53.9991496Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:51:53.9991883Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:51:53.9992862Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:51:53.9993854Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:51:53.9994765Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:51:53.9996392Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:53.9997806Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:53.9999051Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:51:53.9999512Z     
2026-01-14T08:51:53.9999799Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:54.0000369Z onverted model fx: GraphModule(
2026-01-14T08:51:54.0000889Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:54.0001400Z )
2026-01-14T08:51:54.0001529Z 
2026-01-14T08:51:54.0001534Z 
2026-01-14T08:51:54.0001539Z 
2026-01-14T08:51:54.0001656Z def forward(self, x):
2026-01-14T08:51:54.0002435Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:51:54.0003855Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:54.0005073Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:54.0006005Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:54.0007467Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:54.0008410Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:54.0008691Z     
2026-01-14T08:51:54.0008990Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:54.0009378Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:54.0009624Z          [0., 0., 0.],
2026-01-14T08:51:54.0009840Z          [0., 0., 0.]],
2026-01-14T08:51:54.0009978Z 
2026-01-14T08:51:54.0010055Z         [[0., 0., 0.],
2026-01-14T08:51:54.0010271Z          [0., 0., 0.],
2026-01-14T08:51:54.0010478Z          [0., 0., 0.]],
2026-01-14T08:51:54.0010618Z 
2026-01-14T08:51:54.0010705Z         [[0., 0., 0.],
2026-01-14T08:51:54.0010915Z          [0., 0., 0.],
2026-01-14T08:51:54.0011130Z          [0., 0., 0.]]])
2026-01-14T08:51:54.0011456Z model pt2e: GraphModule(
2026-01-14T08:51:54.0011696Z   (conv): Module()
2026-01-14T08:51:54.0011899Z   (bn): Module()
2026-01-14T08:51:54.0012211Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0013251Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:54.0014481Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:51:54.0015032Z   )
2026-01-14T08:51:54.0015222Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:54.0015570Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0016612Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:54.0017828Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:51:54.0018383Z   )
2026-01-14T08:51:54.0018662Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0019855Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:54.0021062Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:51:54.0021679Z   )
2026-01-14T08:51:54.0021859Z )
2026-01-14T08:51:54.0021958Z 
2026-01-14T08:51:54.0021962Z 
2026-01-14T08:51:54.0021966Z 
2026-01-14T08:51:54.0022050Z def forward(self, x):
2026-01-14T08:51:54.0022349Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:54.0022703Z     conv_weight = self.conv.weight
2026-01-14T08:51:54.0022990Z     bn_weight = self.bn.weight
2026-01-14T08:51:54.0023252Z     bn_bias = self.bn.bias
2026-01-14T08:51:54.0023510Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:51:54.0023820Z     bn_running_var = self.bn.running_var
2026-01-14T08:51:54.0024154Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:54.0024585Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:51:54.0025011Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:54.0025565Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:54.0026130Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:51:54.0026540Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:54.0026961Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:51:54.0027423Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:54.0027947Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:51:54.0028540Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:51:54.0029443Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:51:54.0030315Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:54.0030878Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:51:54.0031881Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:51:54.0032915Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:51:54.0033541Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:51:54.0033940Z     
2026-01-14T08:51:54.0034233Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:54.0034609Z model fx: GraphModule(
2026-01-14T08:51:54.0034943Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0035972Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:54.0037187Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:51:54.0037732Z   )
2026-01-14T08:51:54.0037912Z   (conv): ConvBn1d(
2026-01-14T08:51:54.0038162Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:51:54.0038610Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:51:54.0039106Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0040211Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:51:54.0041439Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:51:54.0041989Z     )
2026-01-14T08:51:54.0042160Z   )
2026-01-14T08:51:54.0042522Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:54.0043548Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:54.0044747Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9912875890731812, max_val=1.733071208000183)
2026-01-14T08:51:54.0045292Z   )
2026-01-14T08:51:54.0045460Z )
2026-01-14T08:51:54.0045560Z 
2026-01-14T08:51:54.0045564Z 
2026-01-14T08:51:54.0045568Z 
2026-01-14T08:51:54.0045655Z def forward(self, x):
2026-01-14T08:51:54.0046016Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:51:54.0046565Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:51:54.0047135Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:51:54.0047583Z     return activation_post_process_1
2026-01-14T08:51:54.0047847Z     
2026-01-14T08:51:54.0048130Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:54.0048513Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:54.0048751Z          [0., 0., 0.],
2026-01-14T08:51:54.0048960Z          [0., 0., 0.]],
2026-01-14T08:51:54.0049294Z 
2026-01-14T08:51:54.0049379Z         [[0., 0., 0.],
2026-01-14T08:51:54.0049590Z          [0., 0., 0.],
2026-01-14T08:51:54.0049805Z          [0., 0., 0.]],
2026-01-14T08:51:54.0049942Z 
2026-01-14T08:51:54.0050019Z         [[0., 0., 0.],
2026-01-14T08:51:54.0050230Z          [0., 0., 0.],
2026-01-14T08:51:54.0050471Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:51:54.0050787Z converted model pt2e: GraphModule(
2026-01-14T08:51:54.0051052Z   (conv): Module()
2026-01-14T08:51:54.0051300Z   (bn): Module()
2026-01-14T08:51:54.0051517Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:54.0051737Z )
2026-01-14T08:51:54.0051833Z 
2026-01-14T08:51:54.0051842Z 
2026-01-14T08:51:54.0051846Z 
2026-01-14T08:51:54.0051936Z def forward(self, x):
2026-01-14T08:51:54.0052219Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:54.0052619Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:51:54.0053320Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T08:51:54.0054609Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:57.1948548Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:57.1949638Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:51:57.1950314Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:51:57.1951407Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:51:57.1952492Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:51:57.1953610Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:51:57.1955337Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.014605328440666199, 8, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:51:57.1958395Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:51:57.1959798Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:51:57.1960485Z     
2026-01-14T08:51:57.1960840Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:57.1961320Z onverted model fx: GraphModule(
2026-01-14T08:51:57.1961794Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:51:57.1962268Z )
2026-01-14T08:51:57.1962389Z 
2026-01-14T08:51:57.1962400Z 
2026-01-14T08:51:57.1962405Z 
2026-01-14T08:51:57.1962509Z def forward(self, x):
2026-01-14T08:51:57.1963321Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:51:57.1965051Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:51:57.1966434Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:51:57.1967681Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014605328440666199, 8, -128, 127, torch.int8);  conv = None
2026-01-14T08:51:57.1969140Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014605328440666199, 8, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:51:57.1970094Z     return dequantize_per_tensor_default_1
2026-01-14T08:51:57.1970372Z     
2026-01-14T08:51:57.1970658Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:51:57.1971043Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:51:57.1971463Z          [0., 0., 0.],
2026-01-14T08:51:57.1971701Z          [0., 0., 0.]],
2026-01-14T08:51:57.1971849Z 
2026-01-14T08:51:57.1971926Z         [[0., 0., 0.],
2026-01-14T08:51:57.1972155Z          [0., 0., 0.],
2026-01-14T08:51:57.1972364Z          [0., 0., 0.]],
2026-01-14T08:51:57.1972517Z 
2026-01-14T08:51:57.1972596Z         [[0., 0., 0.],
2026-01-14T08:51:57.1972805Z          [0., 0., 0.],
2026-01-14T08:51:57.1973024Z          [0., 0., 0.]]])
2026-01-14T08:51:57.1973268Z model pt2e: GraphModule(
2026-01-14T08:51:57.1973500Z   (conv1): Module()
2026-01-14T08:51:57.1973711Z   (bn1): Module()
2026-01-14T08:51:57.1973913Z   (conv2): Module()
2026-01-14T08:51:57.1974122Z   (bn2): Module()
2026-01-14T08:51:57.1974431Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:57.1975482Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:57.1976728Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:51:57.1977275Z   )
2026-01-14T08:51:57.1977471Z   (_guards_fn): GuardsFn()
2026-01-14T08:51:57.1977816Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:57.1978929Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:57.1980372Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:51:57.1981069Z   )
2026-01-14T08:51:57.1981357Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:57.1982558Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:51:57.1984002Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:51:57.1984775Z   )
2026-01-14T08:51:57.1985055Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:57.1986096Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:57.1987304Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:51:57.1987847Z   )
2026-01-14T08:51:57.1988137Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:51:57.1989172Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:51:57.1990445Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:51:57.1990987Z   )
2026-01-14T08:51:57.1991163Z )
2026-01-14T08:51:57.1991263Z 
2026-01-14T08:51:57.1991267Z 
2026-01-14T08:51:57.1991271Z 
2026-01-14T08:51:57.1991358Z def forward(self, x):
2026-01-14T08:51:57.1991663Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:51:57.1992024Z     conv1_weight = self.conv1.weight
2026-01-14T08:51:57.1992315Z     bn1_weight = self.bn1.weight
2026-01-14T08:51:57.1992589Z     bn1_bias = self.bn1.bias
2026-01-14T08:51:57.1992847Z     conv2_weight = self.conv2.weight
2026-01-14T08:51:57.1993143Z     conv2_bias = self.conv2.bias
2026-01-14T08:51:57.1993408Z     bn2_weight = self.bn2.weight
2026-01-14T08:51:57.1993677Z     bn2_bias = self.bn2.bias
2026-01-14T08:51:57.1993950Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:51:57.1994268Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:51:57.1994632Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:51:57.1994994Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:51:57.1995313Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:51:57.1995660Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:51:57.1996094Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:51:57.1996525Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:51:57.1997080Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:51:57.1997820Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:51:57.1998404Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:51:57.1998822Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:51:57.1999254Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:51:57.1999726Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:51:57.2000261Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:51:57.2000867Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:51:57.2001541Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:51:57.2002135Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:51:57.2002570Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:51:57.2003118Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:51:57.2003609Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:51:57.2004169Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:51:57.2004942Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:51:57.2005858Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:51:57.2006743Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:51:57.2007323Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:51:57.2008366Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:51:57.2009447Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:51:57.2010479Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:51:57.2011560Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:51:57.2012131Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:51:57.2012755Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:51:57.2013351Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:51:57.2014363Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:52:13.1609784Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:52:13.1610455Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:52:13.1610892Z     
2026-01-14T08:52:13.1611188Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:13.1611644Z model fx: GraphModule(
2026-01-14T08:52:13.1611974Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:13.1613011Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:13.1614338Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:52:13.1614875Z   )
2026-01-14T08:52:13.1615069Z   (conv1): ConvBn1d(
2026-01-14T08:52:13.1615321Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:52:13.1615774Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:13.1616268Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:13.1617340Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0023]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:13.1618777Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3233, -0.3086, -0.2979]), max_val=tensor([0.3026, 0.1712, 0.2405]))
2026-01-14T08:52:13.1619463Z     )
2026-01-14T08:52:13.1619641Z   )
2026-01-14T08:52:13.1619915Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:13.1621213Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:13.1622418Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.805302619934082, max_val=2.310788631439209)
2026-01-14T08:52:13.1623085Z   )
2026-01-14T08:52:13.1623288Z   (conv2): ConvBn1d(
2026-01-14T08:52:13.1623518Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:52:13.1623930Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:13.1624424Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:13.1625482Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:52:13.1626920Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2878, -0.2584, -0.3162]), max_val=tensor([0.2745, 0.3315, 0.3105]))
2026-01-14T08:52:13.1627611Z     )
2026-01-14T08:52:13.1627779Z   )
2026-01-14T08:52:13.1628060Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:13.1629088Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:13.1630296Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1982380151748657, max_val=1.4133442640304565)
2026-01-14T08:52:13.1630837Z   )
2026-01-14T08:52:13.1631002Z )
2026-01-14T08:52:13.1631098Z 
2026-01-14T08:52:13.1631102Z 
2026-01-14T08:52:13.1631107Z 
2026-01-14T08:52:13.1631199Z def forward(self, x):
2026-01-14T08:52:13.1631557Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:52:13.1632118Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:52:13.1632691Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:52:13.1633267Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:52:13.1633852Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:52:13.1634294Z     return activation_post_process_2
2026-01-14T08:52:13.1634558Z     
2026-01-14T08:52:13.1634833Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:13.1635206Z diff: tensor([[[0.],
2026-01-14T08:52:13.1635415Z          [0.],
2026-01-14T08:52:13.1635609Z          [0.]],
2026-01-14T08:52:13.1635726Z 
2026-01-14T08:52:13.1635802Z         [[0.],
2026-01-14T08:52:13.1635994Z          [0.],
2026-01-14T08:52:13.1636181Z          [0.]],
2026-01-14T08:52:13.1636307Z 
2026-01-14T08:52:13.1636384Z         [[0.],
2026-01-14T08:52:13.1636576Z          [0.],
2026-01-14T08:52:13.1636781Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:52:13.1637083Z converted model pt2e: GraphModule(
2026-01-14T08:52:13.1637340Z   (conv1): Module()
2026-01-14T08:52:13.1637546Z   (bn1): Module()
2026-01-14T08:52:13.1637745Z   (conv2): Module()
2026-01-14T08:52:13.1637954Z   (bn2): Module()
2026-01-14T08:52:13.1638158Z   (_guards_fn): GuardsFn()
2026-01-14T08:52:13.1638388Z )
2026-01-14T08:52:13.1638484Z 
2026-01-14T08:52:13.1638488Z 
2026-01-14T08:52:13.1638492Z 
2026-01-14T08:52:13.1638588Z def forward(self, x):
2026-01-14T08:52:13.1638870Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:13.1639222Z     conv2_bias = self.conv2.bias
2026-01-14T08:52:13.1639535Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:52:13.1639926Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:52:13.1640720Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T08:52:13.1642011Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:13.1643054Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:52:13.1643601Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:52:13.1644373Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:52:13.1644877Z     _scale_0 = self._scale_0
2026-01-14T08:52:13.1645136Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:52:13.1645418Z     _scale_1 = self._scale_1
2026-01-14T08:52:13.1645667Z     _zero_point_1 = self._zero_point_1
2026-01-14T08:52:13.1645988Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T08:52:13.1646951Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T08:52:13.1647934Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:52:13.1648841Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T08:52:13.1650875Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:52:13.1652332Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:13.1653287Z     quantize_per_channel = self._frozen_param1
2026-01-14T08:52:13.1654227Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:52:13.1655709Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T08:52:13.1657016Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.010241499170660973, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:52:13.1658409Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:52:13.1659485Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:52:13.1659905Z     
2026-01-14T08:52:13.1660190Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:13.1660574Z onverted model fx: GraphModule(
2026-01-14T08:52:13.1660957Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:52:13.1661466Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:52:13.1661846Z )
2026-01-14T08:52:13.1661944Z 
2026-01-14T08:52:13.1661948Z 
2026-01-14T08:52:13.1661952Z 
2026-01-14T08:52:13.1662042Z def forward(self, x):
2026-01-14T08:52:13.1662680Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:52:13.1664157Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:52:13.1665247Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:52:13.1666162Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016141533851623535, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:52:13.1667649Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016141533851623535, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:52:13.1668751Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:52:13.1669679Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.010241499170660973, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:52:13.1671055Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010241499170660973, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:52:18.3342167Z     return dequantize_per_tensor_default_2
2026-01-14T08:52:18.3342546Z     
2026-01-14T08:52:18.3342927Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:18.3343397Z diff: tensor([[[0.],
2026-01-14T08:52:18.3343653Z          [0.],
2026-01-14T08:52:18.3352204Z          [0.]],
2026-01-14T08:52:18.3352366Z 
2026-01-14T08:52:18.3352448Z         [[0.],
2026-01-14T08:52:18.3352652Z          [0.],
2026-01-14T08:52:18.3352838Z          [0.]],
2026-01-14T08:52:18.3352963Z 
2026-01-14T08:52:18.3353036Z         [[0.],
2026-01-14T08:52:18.3353227Z          [0.],
2026-01-14T08:52:18.3353407Z          [0.]]])
2026-01-14T08:52:18.3353623Z model pt2e: GraphModule(
2026-01-14T08:52:18.3353859Z   (conv1): Module()
2026-01-14T08:52:18.3354068Z   (bn1): Module()
2026-01-14T08:52:18.3354276Z   (conv2): Module()
2026-01-14T08:52:18.3354483Z   (bn2): Module()
2026-01-14T08:52:18.3354786Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3355835Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:18.3357088Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:52:18.3357628Z   )
2026-01-14T08:52:18.3357827Z   (_guards_fn): GuardsFn()
2026-01-14T08:52:18.3358167Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3359196Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:18.3360419Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:52:18.3360962Z   )
2026-01-14T08:52:18.3361243Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3362276Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:18.3363473Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:52:18.3364010Z   )
2026-01-14T08:52:18.3364282Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3365602Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:18.3366811Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:52:18.3367340Z   )
2026-01-14T08:52:18.3367619Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3368775Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:18.3369986Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:52:18.3370527Z   )
2026-01-14T08:52:18.3370695Z )
2026-01-14T08:52:18.3370795Z 
2026-01-14T08:52:18.3370800Z 
2026-01-14T08:52:18.3370804Z 
2026-01-14T08:52:18.3370895Z def forward(self, x):
2026-01-14T08:52:18.3371183Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:52:18.3371689Z     conv1_weight = self.conv1.weight
2026-01-14T08:52:18.3371978Z     bn1_weight = self.bn1.weight
2026-01-14T08:52:18.3372240Z     bn1_bias = self.bn1.bias
2026-01-14T08:52:18.3372486Z     conv2_weight = self.conv2.weight
2026-01-14T08:52:18.3372762Z     conv2_bias = self.conv2.bias
2026-01-14T08:52:18.3373029Z     bn2_weight = self.bn2.weight
2026-01-14T08:52:18.3373283Z     bn2_bias = self.bn2.bias
2026-01-14T08:52:18.3373553Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T08:52:18.3373854Z     bn1_running_var = self.bn1.running_var
2026-01-14T08:52:18.3374199Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:52:18.3374553Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T08:52:18.3374906Z     bn2_running_var = self.bn2.running_var
2026-01-14T08:52:18.3375241Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:52:18.3375669Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:52:18.3376108Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:52:18.3376648Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:52:18.3377371Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:52:18.3377950Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T08:52:18.3378363Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:52:18.3378786Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T08:52:18.3379247Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:52:18.3379777Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T08:52:18.3380367Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T08:52:18.3381030Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:52:18.3381618Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T08:52:18.3382047Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T08:52:18.3382509Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T08:52:18.3382991Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1])
2026-01-14T08:52:18.3383553Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T08:52:18.3384175Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T08:52:18.3385089Z     conv1d_3 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:52:18.3385974Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1]);  div_2 = None
2026-01-14T08:52:18.3386631Z     div_3 = torch.ops.aten.div.Tensor(conv1d_3, reshape_4);  conv1d_3 = reshape_4 = None
2026-01-14T08:52:18.3387670Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T08:52:18.3388812Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T08:52:18.3389838Z     conv1d_2 = torch.ops.aten.conv1d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T08:52:18.3390782Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:52:18.3391337Z     div_1 = torch.ops.aten.div.Tensor(conv1d_2, reshape_1);  conv1d_2 = reshape_1 = None
2026-01-14T08:52:18.3391950Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1]);  conv2_bias = None
2026-01-14T08:52:18.3392540Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:52:18.3393538Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T08:52:18.3394604Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T08:52:18.3395219Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T08:52:18.3395623Z     
2026-01-14T08:52:18.3395905Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:52:18.3396289Z model fx: GraphModule(
2026-01-14T08:52:18.3396615Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3397651Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([14], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:18.3398870Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1280412673950195, max_val=1.6863642930984497)
2026-01-14T08:52:18.3399413Z   )
2026-01-14T08:52:18.3399601Z   (conv1): ConvBn1d(
2026-01-14T08:52:18.3399855Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:52:18.3400311Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:18.3400805Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3401807Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:18.3403030Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232710361480713, max_val=0.30256387591362)
2026-01-14T08:52:18.3403562Z     )
2026-01-14T08:52:18.3403737Z   )
2026-01-14T08:52:18.3404011Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3405091Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-16], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:52:18.3406307Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.807204008102417, max_val=2.3096539974212646)
2026-01-14T08:52:18.3406830Z   )
2026-01-14T08:52:18.3407009Z   (conv2): ConvBn1d(
2026-01-14T08:52:18.3407233Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:52:18.3407651Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:52:18.3408141Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:52:18.3409238Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:52:18.3410471Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3161814510822296, max_val=0.33154603838920593)
2026-01-14T08:52:18.3411091Z     )
2026-01-14T08:52:18.3411359Z   )
2026-01-14T08:52:18.3411632Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:05.1613870Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0102]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:05.1615160Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2001533508300781, max_val=1.4126498699188232)
2026-01-14T08:53:05.1615714Z   )
2026-01-14T08:53:05.1615900Z )
2026-01-14T08:53:05.1616001Z 
2026-01-14T08:53:05.1616006Z 
2026-01-14T08:53:05.1616010Z 
2026-01-14T08:53:05.1616132Z def forward(self, x):
2026-01-14T08:53:05.1616508Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:05.1617095Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:05.1617688Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T08:53:05.1618304Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:53:05.1618887Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T08:53:05.1619350Z     return activation_post_process_2
2026-01-14T08:53:05.1619622Z     
2026-01-14T08:53:05.1619918Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:05.1620314Z diff: tensor([[[0.],
2026-01-14T08:53:05.1620532Z          [0.],
2026-01-14T08:53:05.1620742Z          [0.]],
2026-01-14T08:53:05.1620870Z 
2026-01-14T08:53:05.1620948Z         [[0.],
2026-01-14T08:53:05.1621162Z          [0.],
2026-01-14T08:53:05.1621362Z          [0.]],
2026-01-14T08:53:05.1621499Z 
2026-01-14T08:53:05.1621578Z         [[0.],
2026-01-14T08:53:05.1621785Z          [0.],
2026-01-14T08:53:05.1622003Z          [0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:05.1622327Z converted model pt2e: GraphModule(
2026-01-14T08:53:05.1622606Z   (conv1): Module()
2026-01-14T08:53:05.1622818Z   (bn1): Module()
2026-01-14T08:53:05.1623026Z   (conv2): Module()
2026-01-14T08:53:05.1623241Z   (bn2): Module()
2026-01-14T08:53:05.1623457Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:05.1623704Z )
2026-01-14T08:53:05.1623808Z 
2026-01-14T08:53:05.1623812Z 
2026-01-14T08:53:05.1623816Z 
2026-01-14T08:53:05.1623903Z def forward(self, x):
2026-01-14T08:53:05.1624208Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:05.1624583Z     conv2_bias = self.conv2.bias
2026-01-14T08:53:05.1624908Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T08:53:05.1625320Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T08:53:05.1626077Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8)
2026-01-14T08:53:05.1627784Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:05.1629206Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:53:05.1629826Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T08:53:05.1630651Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T08:53:05.1631206Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T08:53:05.1632386Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.0025454412680119276, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T08:53:05.1633278Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T08:53:05.1634190Z     conv1d_5 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T08:53:05.1635701Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_5, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1d_5 = None
2026-01-14T08:53:05.1637116Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:53:05.1638070Z     quantize_per_tensor = self._frozen_param1
2026-01-14T08:53:05.1638921Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0026105986908078194, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:53:05.1640303Z     conv1d_4 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T08:53:05.1641612Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_4, 0.01024628710001707, -11, -128, 127, torch.int8);  conv1d_4 = None
2026-01-14T08:53:05.1643008Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T08:53:05.1644102Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T08:53:05.1644531Z     
2026-01-14T08:53:05.1644876Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:05.1645300Z onverted model fx: GraphModule(
2026-01-14T08:53:05.1645694Z   (conv1): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:05.1646212Z   (conv2): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:05.1646608Z )
2026-01-14T08:53:05.1646709Z 
2026-01-14T08:53:05.1646714Z 
2026-01-14T08:53:05.1646717Z 
2026-01-14T08:53:05.1646821Z def forward(self, x):
2026-01-14T08:53:05.1647469Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.014958452433347702, 14, -128, 127, torch.int8);  x = None
2026-01-14T08:53:05.1648796Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.014958452433347702, 14, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:05.1650116Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:05.1651053Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.016144542023539543, -16, -128, 127, torch.int8);  conv1 = None
2026-01-14T08:53:05.1652510Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016144542023539543, -16, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:05.1653625Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:53:05.1654564Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.01024628710001707, -11, -128, 127, torch.int8);  conv2 = None
2026-01-14T08:53:05.1655950Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01024628710001707, -11, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:05.1657018Z     return dequantize_per_tensor_default_2
2026-01-14T08:53:05.1657317Z     
2026-01-14T08:53:05.1657608Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:05.1658005Z diff: tensor([[[0.],
2026-01-14T08:53:05.1658230Z          [0.],
2026-01-14T08:53:05.1658538Z          [0.]],
2026-01-14T08:53:05.1658657Z 
2026-01-14T08:53:05.1658739Z         [[0.],
2026-01-14T08:53:05.1658936Z          [0.],
2026-01-14T08:53:05.1659137Z          [0.]],
2026-01-14T08:53:05.1659260Z 
2026-01-14T08:53:05.1659336Z         [[0.],
2026-01-14T08:53:05.1659536Z          [0.],
2026-01-14T08:53:05.1659725Z          [0.]]])
2026-01-14T08:53:05.1660147Z [32mPASSED[0m
2026-01-14T08:53:05.1660858Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T08:53:05.1661887Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T08:53:05.1662538Z   (conv): Module()
2026-01-14T08:53:05.1662747Z   (bn): Module()
2026-01-14T08:53:05.1663064Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:05.1664091Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:05.1665367Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:53:05.1665920Z   )
2026-01-14T08:53:05.1666118Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:05.1666474Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:05.1667582Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:05.1669025Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:53:05.1669720Z   )
2026-01-14T08:53:05.1670007Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:05.1671056Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:05.1672208Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:53:05.1672711Z   )
2026-01-14T08:53:05.1672876Z )
2026-01-14T08:53:05.1672980Z 
2026-01-14T08:53:05.1672984Z 
2026-01-14T08:53:05.1672988Z 
2026-01-14T08:53:05.1673073Z def forward(self, x):
2026-01-14T08:53:05.1673373Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:05.1673724Z     conv_weight = self.conv.weight
2026-01-14T08:53:05.1674017Z     conv_bias = self.conv.bias
2026-01-14T08:53:05.1674280Z     bn_weight = self.bn.weight
2026-01-14T08:53:05.1674549Z     bn_bias = self.bn.bias
2026-01-14T08:53:05.1674813Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:05.1675140Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:05.1675475Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:05.1675896Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:53:05.1676321Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:53:05.1676861Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:05.1677416Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:05.1677824Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:05.1678375Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:24.2960860Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:24.2961580Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:24.2962325Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:24.2963482Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:24.2964822Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:53:24.2966025Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:24.2966721Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:24.2967503Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:53:24.2968227Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:24.2969484Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:24.2970743Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:24.2971540Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:53:24.2972249Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:24.2972748Z     
2026-01-14T08:53:24.2973102Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:24.2973573Z model fx: GraphModule(
2026-01-14T08:53:24.2973968Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.2975268Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:24.2976806Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:53:24.2977494Z   )
2026-01-14T08:53:24.2977719Z   (conv): ConvBnReLU1d(
2026-01-14T08:53:24.2978018Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:53:24.2978539Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:24.2979142Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.2980497Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:24.2982329Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2845, -0.3289, -0.3229]), max_val=tensor([0.2989, 0.2870, 0.2939]))
2026-01-14T08:53:24.2983210Z     )
2026-01-14T08:53:24.2983426Z   )
2026-01-14T08:53:24.2983767Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.2985089Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:24.2986560Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:53:24.2987171Z   )
2026-01-14T08:53:24.2987376Z )
2026-01-14T08:53:24.2987503Z 
2026-01-14T08:53:24.2987508Z 
2026-01-14T08:53:24.2987513Z 
2026-01-14T08:53:24.2987619Z def forward(self, x):
2026-01-14T08:53:24.2988322Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:24.2989017Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:24.2989794Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:24.2990349Z     return activation_post_process_1
2026-01-14T08:53:24.2990774Z     
2026-01-14T08:53:24.2991122Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:24.2991591Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:24.2991884Z          [0., 0., 0.],
2026-01-14T08:53:24.2992172Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:24.2992556Z converted model pt2e: GraphModule(
2026-01-14T08:53:24.2992877Z   (conv): Module()
2026-01-14T08:53:24.2993126Z   (bn): Module()
2026-01-14T08:53:24.2993384Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:24.2993665Z )
2026-01-14T08:53:24.2993783Z 
2026-01-14T08:53:24.2993788Z 
2026-01-14T08:53:24.2993793Z 
2026-01-14T08:53:24.2993904Z def forward(self, x):
2026-01-14T08:53:24.2994259Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:24.2994688Z     conv_bias = self.conv.bias
2026-01-14T08:53:24.2995057Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:24.2995949Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:53:24.2997604Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:24.2998842Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:53:24.2999523Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:24.3000136Z     _scale_0 = self._scale_0
2026-01-14T08:53:24.3000456Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:53:24.3000832Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:53:24.3002036Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:53:24.3003915Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:53:24.3004832Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:53:24.3005653Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:53:24.3007039Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:24.3008120Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:53:24.3008553Z     
2026-01-14T08:53:24.3008845Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:24.3009239Z onverted model fx: GraphModule(
2026-01-14T08:53:24.3009506Z   (conv): ConvReLU1d(
2026-01-14T08:53:24.3009836Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:24.3010216Z     (1): ReLU()
2026-01-14T08:53:24.3010408Z   )
2026-01-14T08:53:24.3010594Z )
2026-01-14T08:53:24.3010697Z 
2026-01-14T08:53:24.3010701Z 
2026-01-14T08:53:24.3010705Z 
2026-01-14T08:53:24.3010792Z def forward(self, x):
2026-01-14T08:53:24.3011499Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:53:24.3012908Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:24.3013979Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:24.3014900Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:24.3016359Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:24.3017306Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:24.3017590Z     
2026-01-14T08:53:24.3017874Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:24.3018262Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:24.3018491Z          [0., 0., 0.],
2026-01-14T08:53:24.3018719Z          [0., 0., 0.]]])
2026-01-14T08:53:24.3018953Z model pt2e: GraphModule(
2026-01-14T08:53:24.3019182Z   (conv): Module()
2026-01-14T08:53:24.3019386Z   (bn): Module()
2026-01-14T08:53:24.3019714Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.3020768Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:24.3021968Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:53:24.3022505Z   )
2026-01-14T08:53:24.3022697Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:24.3023029Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.3024071Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:24.3025286Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:53:24.3025830Z   )
2026-01-14T08:53:24.3026111Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:24.3027148Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:24.3028300Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:53:24.3028780Z   )
2026-01-14T08:53:24.3028954Z )
2026-01-14T08:53:24.3029053Z 
2026-01-14T08:53:24.3029057Z 
2026-01-14T08:53:24.3029061Z 
2026-01-14T08:53:24.3029147Z def forward(self, x):
2026-01-14T08:53:24.3029450Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:24.3029805Z     conv_weight = self.conv.weight
2026-01-14T08:53:24.3030080Z     conv_bias = self.conv.bias
2026-01-14T08:53:24.3030344Z     bn_weight = self.bn.weight
2026-01-14T08:53:24.3030593Z     bn_bias = self.bn.bias
2026-01-14T08:53:24.3030866Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:53:24.3031168Z     bn_running_var = self.bn.running_var
2026-01-14T08:53:24.3031508Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:51.7099330Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:53:51.7101628Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:53:51.7102199Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:51.7102794Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:53:51.7103202Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:53:51.7103862Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:53:51.7104324Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:53:51.7104850Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:53:51.7105583Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:53:51.7106241Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:53:51.7107293Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:53:51.7108248Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:53:51.7108818Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:53:51.7109430Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:53:51.7110019Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:53:51.7110991Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:53:51.7111953Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:53:51.7119576Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:53:51.7120193Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:53:51.7120609Z     
2026-01-14T08:53:51.7120904Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:51.7121302Z model fx: GraphModule(
2026-01-14T08:53:51.7121642Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:51.7122703Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:51.7123930Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:53:51.7124479Z   )
2026-01-14T08:53:51.7124679Z   (conv): ConvBnReLU1d(
2026-01-14T08:53:51.7124931Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:53:51.7125373Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:53:51.7125876Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:51.7126897Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:53:51.7128143Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3289433717727661, max_val=0.29890719056129456)
2026-01-14T08:53:51.7128698Z     )
2026-01-14T08:53:51.7128886Z   )
2026-01-14T08:53:51.7129172Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:51.7130221Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0055]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:51.7131478Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.413901925086975)
2026-01-14T08:53:51.7132151Z   )
2026-01-14T08:53:51.7132385Z )
2026-01-14T08:53:51.7132522Z 
2026-01-14T08:53:51.7132528Z 
2026-01-14T08:53:51.7132534Z 
2026-01-14T08:53:51.7132656Z def forward(self, x):
2026-01-14T08:53:51.7133188Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:53:51.7133879Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:53:51.7134453Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:53:51.7134902Z     return activation_post_process_1
2026-01-14T08:53:51.7135277Z     
2026-01-14T08:53:51.7135623Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:51.7136055Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:51.7136366Z          [0., 0., 0.],
2026-01-14T08:53:51.7136705Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:53:51.7137069Z converted model pt2e: GraphModule(
2026-01-14T08:53:51.7137332Z   (conv): Module()
2026-01-14T08:53:51.7137542Z   (bn): Module()
2026-01-14T08:53:51.7137757Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:51.7137982Z )
2026-01-14T08:53:51.7138080Z 
2026-01-14T08:53:51.7138084Z 
2026-01-14T08:53:51.7138088Z 
2026-01-14T08:53:51.7138177Z def forward(self, x):
2026-01-14T08:53:51.7138472Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:53:51.7138825Z     conv_bias = self.conv.bias
2026-01-14T08:53:51.7139128Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:53:51.7139843Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:53:51.7141138Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:51.7142096Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:53:51.7142645Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:53:51.7143162Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:53:51.7143999Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002590105403214693, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:53:51.7145346Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:53:51.7146249Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:53:51.7147077Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005544713232666254, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:53:51.7148468Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:53:51.7149764Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:53:51.7150196Z     
2026-01-14T08:53:51.7150482Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:51.7150877Z onverted model fx: GraphModule(
2026-01-14T08:53:51.7151132Z   (conv): ConvReLU1d(
2026-01-14T08:53:51.7151470Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:53:51.7151847Z     (1): ReLU()
2026-01-14T08:53:51.7152043Z   )
2026-01-14T08:53:51.7152216Z )
2026-01-14T08:53:51.7152312Z 
2026-01-14T08:53:51.7152316Z 
2026-01-14T08:53:51.7152320Z 
2026-01-14T08:53:51.7152407Z def forward(self, x):
2026-01-14T08:53:51.7153051Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:53:51.7154358Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:53:51.7155634Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:53:51.7156567Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005544713232666254, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:53:51.7157941Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005544713232666254, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:53:51.7159008Z     return dequantize_per_tensor_default_1
2026-01-14T08:53:51.7159290Z     
2026-01-14T08:53:51.7159577Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:53:51.7159964Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:53:51.7160198Z          [0., 0., 0.],
2026-01-14T08:53:51.7160413Z          [0., 0., 0.]]])
2026-01-14T08:53:51.7160846Z [32mPASSED[0m
2026-01-14T08:53:51.7161471Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:53:51.7162126Z   (conv): Module()
2026-01-14T08:53:51.7162340Z   (bn): Module()
2026-01-14T08:53:51.7162639Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:51.7163881Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:53:51.7165307Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:53:51.7165889Z   )
2026-01-14T08:53:51.7166081Z   (_guards_fn): GuardsFn()
2026-01-14T08:53:51.7166416Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:53:51.7167736Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:53:51.7169489Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:53:51.7170281Z   )
2026-01-14T08:53:51.7170567Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.8664147Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.8665601Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:54:12.8666130Z   )
2026-01-14T08:54:12.8666303Z )
2026-01-14T08:54:12.8666412Z 
2026-01-14T08:54:12.8666417Z 
2026-01-14T08:54:12.8666421Z 
2026-01-14T08:54:12.8666508Z def forward(self, x):
2026-01-14T08:54:12.8666807Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:12.8667185Z     conv_weight = self.conv.weight
2026-01-14T08:54:12.8667474Z     conv_bias = self.conv.bias
2026-01-14T08:54:12.8667733Z     bn_weight = self.bn.weight
2026-01-14T08:54:12.8667992Z     bn_bias = self.bn.bias
2026-01-14T08:54:12.8668252Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:12.8668562Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:12.8668899Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:12.8669327Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:54:12.8669760Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:12.8670549Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:12.8671124Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:12.8671529Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:12.8671964Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:12.8672560Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:12.8673083Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:12.8673682Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:12.8674328Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:54:12.8675383Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:54:12.8676345Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:12.8676912Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:54:12.8677528Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:54:12.8678116Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:54:12.8679090Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:54:12.8680032Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:54:12.8680587Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:54:12.8681156Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:54:12.8681558Z     
2026-01-14T08:54:12.8681852Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.8682227Z model fx: GraphModule(
2026-01-14T08:54:12.8682564Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.8683799Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.8685224Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:12.8685763Z   )
2026-01-14T08:54:12.8685949Z   (conv): ConvBnReLU1d(
2026-01-14T08:54:12.8686194Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:54:12.8686613Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:12.8687296Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.8689001Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022, 0.0020, 0.0022], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:12.8690988Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2799, -0.2557, -0.2618], device='cuda:0'), max_val=tensor([0.1970, 0.2308, 0.2775], device='cuda:0'))
2026-01-14T08:54:12.8691876Z     )
2026-01-14T08:54:12.8692044Z   )
2026-01-14T08:54:12.8692329Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:12.8693689Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:12.8695058Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:54:12.8695552Z   )
2026-01-14T08:54:12.8695802Z )
2026-01-14T08:54:12.8695905Z 
2026-01-14T08:54:12.8695910Z 
2026-01-14T08:54:12.8695914Z 
2026-01-14T08:54:12.8695997Z def forward(self, x):
2026-01-14T08:54:12.8696355Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:12.8696903Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:12.8697477Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:54:12.8697913Z     return activation_post_process_1
2026-01-14T08:54:12.8698184Z     
2026-01-14T08:54:12.8698462Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.8698862Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:12.8699106Z          [0., 0., 0.],
2026-01-14T08:54:12.8699376Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:54:12.8699730Z converted model pt2e: GraphModule(
2026-01-14T08:54:12.8700002Z   (conv): Module()
2026-01-14T08:54:12.8700214Z   (bn): Module()
2026-01-14T08:54:12.8700425Z   (_guards_fn): GuardsFn()
2026-01-14T08:54:12.8700653Z )
2026-01-14T08:54:12.8700754Z 
2026-01-14T08:54:12.8700758Z 
2026-01-14T08:54:12.8700762Z 
2026-01-14T08:54:12.8700848Z def forward(self, x):
2026-01-14T08:54:12.8701143Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:12.8701492Z     conv_bias = self.conv.bias
2026-01-14T08:54:12.8701800Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:12.8702503Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:54:12.8703785Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:12.8704757Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:12.8705311Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:12.8705798Z     _scale_0 = self._scale_0
2026-01-14T08:54:12.8706067Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:54:12.8706374Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:54:12.8707316Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:54:12.8708780Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:54:12.8709686Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:54:12.8710505Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:54:12.8711876Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:12.8712959Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:54:12.8713384Z     
2026-01-14T08:54:12.8713665Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.8714053Z onverted model fx: GraphModule(
2026-01-14T08:54:12.8714310Z   (conv): ConvReLU1d(
2026-01-14T08:54:12.8714731Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:12.8715100Z     (1): ReLU()
2026-01-14T08:54:12.8715293Z   )
2026-01-14T08:54:12.8715460Z )
2026-01-14T08:54:12.8715561Z 
2026-01-14T08:54:12.8715565Z 
2026-01-14T08:54:12.8715569Z 
2026-01-14T08:54:12.8715651Z def forward(self, x):
2026-01-14T08:54:12.8716379Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:54:12.8717685Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:12.8718753Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:12.8719664Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:54:12.8721097Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:12.8722047Z     return dequantize_per_tensor_default_1
2026-01-14T08:54:12.8722336Z     
2026-01-14T08:54:12.8722618Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:12.8723008Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:12.8723246Z          [0., 0., 0.],
2026-01-14T08:54:12.8723468Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:54:12.8723749Z model pt2e: GraphModule(
2026-01-14T08:54:12.8723976Z   (conv): Module()
2026-01-14T08:54:12.8724183Z   (bn): Module()
2026-01-14T08:54:12.8724480Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8634341Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:30.8636074Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:30.8636754Z   )
2026-01-14T08:54:30.8636949Z   (_guards_fn): GuardsFn()
2026-01-14T08:54:30.8637291Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8638619Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:30.8640216Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:54:30.8640762Z   )
2026-01-14T08:54:30.8641062Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8642308Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:30.8643766Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:54:30.8644404Z   )
2026-01-14T08:54:30.8644576Z )
2026-01-14T08:54:30.8644674Z 
2026-01-14T08:54:30.8644679Z 
2026-01-14T08:54:30.8644692Z 
2026-01-14T08:54:30.8644782Z def forward(self, x):
2026-01-14T08:54:30.8645076Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:30.8645438Z     conv_weight = self.conv.weight
2026-01-14T08:54:30.8645717Z     conv_bias = self.conv.bias
2026-01-14T08:54:30.8645979Z     bn_weight = self.bn.weight
2026-01-14T08:54:30.8646486Z     bn_bias = self.bn.bias
2026-01-14T08:54:30.8646757Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:30.8647070Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:30.8647406Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:30.8647973Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:54:30.8648401Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:30.8648947Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:30.8649805Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:30.8650217Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:30.8650647Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:30.8651104Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:30.8651702Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:30.8652301Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:30.8652959Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:54:30.8654024Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:54:30.8654972Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:30.8655539Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:54:30.8656141Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:54:30.8656728Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:54:30.8657709Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:54:30.8658657Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:54:30.8659215Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:54:30.8659777Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:54:30.8660185Z     
2026-01-14T08:54:30.8660471Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:30.8660861Z model fx: GraphModule(
2026-01-14T08:54:30.8661195Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8662442Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0104], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:30.8663869Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:30.8664405Z   )
2026-01-14T08:54:30.8664600Z   (conv): ConvBnReLU1d(
2026-01-14T08:54:30.8664853Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:54:30.8665278Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:30.8665781Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8667005Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0022], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:54:30.8668579Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799264192581177, max_val=0.27745386958122253)
2026-01-14T08:54:30.8669136Z     )
2026-01-14T08:54:30.8669311Z   )
2026-01-14T08:54:30.8669596Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:30.8670842Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0055], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:30.8672328Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.4123148918151855)
2026-01-14T08:54:30.8672827Z   )
2026-01-14T08:54:30.8673001Z )
2026-01-14T08:54:30.8673100Z 
2026-01-14T08:54:30.8673129Z 
2026-01-14T08:54:30.8673133Z 
2026-01-14T08:54:30.8673218Z def forward(self, x):
2026-01-14T08:54:30.8673568Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:30.8674133Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:30.8674707Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:54:30.8675185Z     return activation_post_process_1
2026-01-14T08:54:30.8675453Z     
2026-01-14T08:54:30.8675735Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:30.8676113Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:30.8676344Z          [0., 0., 0.],
2026-01-14T08:54:30.8676621Z          [0., 0., 0.]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T08:54:30.8676967Z converted model pt2e: GraphModule(
2026-01-14T08:54:30.8677232Z   (conv): Module()
2026-01-14T08:54:30.8677440Z   (bn): Module()
2026-01-14T08:54:30.8677643Z   (_guards_fn): GuardsFn()
2026-01-14T08:54:30.8677871Z )
2026-01-14T08:54:30.8677971Z 
2026-01-14T08:54:30.8677975Z 
2026-01-14T08:54:30.8677979Z 
2026-01-14T08:54:30.8678065Z def forward(self, x):
2026-01-14T08:54:30.8678364Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:30.8678705Z     conv_bias = self.conv.bias
2026-01-14T08:54:30.8679009Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:30.8679712Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8)
2026-01-14T08:54:30.8680991Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:30.8681950Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:30.8682488Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:30.8683015Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:54:30.8683850Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002204145072028041, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:54:30.8685240Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:54:30.8686143Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:54:30.8686956Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.005538490135222673, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:54:30.8688335Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:54:30.8689413Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:54:30.8689835Z     
2026-01-14T08:54:30.8690208Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:30.8690593Z onverted model fx: GraphModule(
2026-01-14T08:54:30.8690854Z   (conv): ConvReLU1d(
2026-01-14T08:54:30.8691186Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:30.8691707Z     (1): ReLU()
2026-01-14T08:54:30.8691899Z   )
2026-01-14T08:54:30.8692066Z )
2026-01-14T08:54:30.8692163Z 
2026-01-14T08:54:30.8692167Z 
2026-01-14T08:54:30.8692177Z 
2026-01-14T08:54:30.8692263Z def forward(self, x):
2026-01-14T08:54:30.8692896Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933931648731, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:54:30.8694206Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933931648731, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:30.8695284Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:54:58.3114650Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.005538490135222673, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:54:58.3116473Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.005538490135222673, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:58.3117706Z     return dequantize_per_tensor_default_1
2026-01-14T08:54:58.3118057Z     
2026-01-14T08:54:58.3118402Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:58.3118881Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:58.3119164Z          [0., 0., 0.],
2026-01-14T08:54:58.3119440Z          [0., 0., 0.]]], device='cuda:0')
2026-01-14T08:54:58.3120014Z [32mPASSED[0m
2026-01-14T08:54:58.3120826Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T08:54:58.3121698Z   (conv): Module()
2026-01-14T08:54:58.3121940Z   (bn): Module()
2026-01-14T08:54:58.3122311Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3123603Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:58.3125190Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:58.3125874Z   )
2026-01-14T08:54:58.3126096Z   (_guards_fn): GuardsFn()
2026-01-14T08:54:58.3126505Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3127897Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:58.3129706Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:54:58.3130580Z   )
2026-01-14T08:54:58.3130914Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3132334Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:58.3133811Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:54:58.3134424Z   )
2026-01-14T08:54:58.3134632Z )
2026-01-14T08:54:58.3134750Z 
2026-01-14T08:54:58.3134755Z 
2026-01-14T08:54:58.3134760Z 
2026-01-14T08:54:58.3134864Z def forward(self, x):
2026-01-14T08:54:58.3137161Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:58.3137614Z     conv_weight = self.conv.weight
2026-01-14T08:54:58.3137949Z     bn_weight = self.bn.weight
2026-01-14T08:54:58.3138264Z     bn_bias = self.bn.bias
2026-01-14T08:54:58.3138575Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:54:58.3139151Z     bn_running_var = self.bn.running_var
2026-01-14T08:54:58.3139560Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:58.3140084Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:54:58.3140608Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:58.3141283Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:58.3141980Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:54:58.3142467Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:54:58.3142997Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:54:58.3143547Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:54:58.3144188Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:54:58.3144918Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:54:58.3146061Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:54:58.3147167Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:54:58.3147858Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:54:58.3149357Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:54:58.3150559Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:54:58.3151243Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:54:58.3151951Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:54:58.3152452Z     
2026-01-14T08:54:58.3152802Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:58.3153268Z model fx: GraphModule(
2026-01-14T08:54:58.3153666Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3154961Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:58.3156501Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:54:58.3157186Z   )
2026-01-14T08:54:58.3157407Z   (conv): ConvBnReLU1d(
2026-01-14T08:54:58.3157728Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:54:58.3158278Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:54:58.3167088Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3168525Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026, 0.0026, 0.0025]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:54:58.3170209Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3276, -0.3045, -0.2418]), max_val=tensor([0.2760, 0.3298, 0.3101]))
2026-01-14T08:54:58.3170889Z     )
2026-01-14T08:54:58.3171063Z   )
2026-01-14T08:54:58.3171411Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:54:58.3172626Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:54:58.3173801Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3778926134109497)
2026-01-14T08:54:58.3174394Z   )
2026-01-14T08:54:58.3174561Z )
2026-01-14T08:54:58.3174656Z 
2026-01-14T08:54:58.3174661Z 
2026-01-14T08:54:58.3174665Z 
2026-01-14T08:54:58.3174747Z def forward(self, x):
2026-01-14T08:54:58.3175110Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:54:58.3175659Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:54:58.3176229Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:54:58.3176678Z     return activation_post_process_1
2026-01-14T08:54:58.3176934Z     
2026-01-14T08:54:58.3177225Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:58.3177598Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:54:58.3177837Z          [0., 0., 0.],
2026-01-14T08:54:58.3178075Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:54:58.3178395Z converted model pt2e: GraphModule(
2026-01-14T08:54:58.3178655Z   (conv): Module()
2026-01-14T08:54:58.3178860Z   (bn): Module()
2026-01-14T08:54:58.3179076Z   (_guards_fn): GuardsFn()
2026-01-14T08:54:58.3179295Z )
2026-01-14T08:54:58.3179394Z 
2026-01-14T08:54:58.3179398Z 
2026-01-14T08:54:58.3179402Z 
2026-01-14T08:54:58.3179490Z def forward(self, x):
2026-01-14T08:54:58.3179773Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:54:58.3180167Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:54:58.3180916Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:54:58.3182205Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:54:58.3183175Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:54:58.3183718Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:54:58.3184211Z     _scale_0 = self._scale_0
2026-01-14T08:54:58.3184463Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:54:58.3184770Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:54:58.3185718Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:54:58.3186659Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:54:58.3187550Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T08:54:58.3188507Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:54:58.3189340Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0054035005159676075, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:54:58.3190722Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:54:58.3191849Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:54:58.3192276Z     
2026-01-14T08:54:58.3192553Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:54:58.3192938Z onverted model fx: GraphModule(
2026-01-14T08:54:58.3193282Z   (conv): ConvReLU1d(
2026-01-14T08:54:58.3193608Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:54:58.3193980Z     (1): ReLU()
2026-01-14T08:54:58.3194166Z   )
2026-01-14T08:54:58.3194336Z )
2026-01-14T08:54:58.3194431Z 
2026-01-14T08:54:58.3194512Z 
2026-01-14T08:54:58.3194516Z 
2026-01-14T08:54:58.3194602Z def forward(self, x):
2026-01-14T08:55:19.5811469Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:19.5812852Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:19.5814232Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:19.5815616Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0054035005159676075, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:19.5817230Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0054035005159676075, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:19.5818197Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:19.5818486Z     
2026-01-14T08:55:19.5818784Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.5819170Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:19.5819417Z          [0., 0., 0.],
2026-01-14T08:55:19.5819627Z          [0., 0., 0.]]])
2026-01-14T08:55:19.5819868Z model pt2e: GraphModule(
2026-01-14T08:55:19.5820105Z   (conv): Module()
2026-01-14T08:55:19.5820320Z   (bn): Module()
2026-01-14T08:55:19.5820715Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5821953Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.5823181Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:19.5823728Z   )
2026-01-14T08:55:19.5823922Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:19.5824264Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5825295Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:19.5826524Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:55:19.5827073Z   )
2026-01-14T08:55:19.5827354Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5828385Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.5829543Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:55:19.5830038Z   )
2026-01-14T08:55:19.5830205Z )
2026-01-14T08:55:19.5830313Z 
2026-01-14T08:55:19.5830317Z 
2026-01-14T08:55:19.5830321Z 
2026-01-14T08:55:19.5830406Z def forward(self, x):
2026-01-14T08:55:19.5830704Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:19.5831057Z     conv_weight = self.conv.weight
2026-01-14T08:55:19.5831340Z     bn_weight = self.bn.weight
2026-01-14T08:55:19.5831593Z     bn_bias = self.bn.bias
2026-01-14T08:55:19.5831859Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:55:19.5832451Z     bn_running_var = self.bn.running_var
2026-01-14T08:55:19.5832800Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:19.5833229Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:55:19.5833660Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:19.5834354Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:19.5834926Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:55:19.5835378Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:55:19.5835804Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:55:19.5836268Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:55:19.5836780Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:55:19.5837378Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:55:19.5838273Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:55:19.5839142Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:55:19.5839708Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:55:19.5840702Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:55:19.5841654Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:55:19.5842198Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:19.5842758Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:19.5843166Z     
2026-01-14T08:55:19.5843456Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.5843834Z model fx: GraphModule(
2026-01-14T08:55:19.5844160Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5845184Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.5846390Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:19.5846924Z   )
2026-01-14T08:55:19.5847108Z   (conv): ConvBnReLU1d(
2026-01-14T08:55:19.5847366Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:55:19.5847822Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:55:19.5848311Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5857397Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:19.5858666Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.32764676213264465, max_val=0.3298276662826538)
2026-01-14T08:55:19.5859212Z     )
2026-01-14T08:55:19.5859390Z   )
2026-01-14T08:55:19.5859665Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:19.5860695Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0054]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:19.5861854Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.3749419450759888)
2026-01-14T08:55:19.5862336Z   )
2026-01-14T08:55:19.5862702Z )
2026-01-14T08:55:19.5862802Z 
2026-01-14T08:55:19.5862806Z 
2026-01-14T08:55:19.5862810Z 
2026-01-14T08:55:19.5862896Z def forward(self, x):
2026-01-14T08:55:19.5863252Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:19.5863796Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:19.5864508Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:19.5864952Z     return activation_post_process_1
2026-01-14T08:55:19.5865210Z     
2026-01-14T08:55:19.5865496Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.5865873Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:19.5866115Z          [0., 0., 0.],
2026-01-14T08:55:19.5866352Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:19.5866664Z converted model pt2e: GraphModule(
2026-01-14T08:55:19.5866923Z   (conv): Module()
2026-01-14T08:55:19.5867132Z   (bn): Module()
2026-01-14T08:55:19.5867347Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:19.5867567Z )
2026-01-14T08:55:19.5867665Z 
2026-01-14T08:55:19.5867669Z 
2026-01-14T08:55:19.5867673Z 
2026-01-14T08:55:19.5867760Z def forward(self, x):
2026-01-14T08:55:19.5868045Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:19.5868448Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:55:19.5869148Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:55:19.5870428Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:19.5871393Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:19.5871938Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:55:19.5872459Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:55:19.5873280Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002597068203613162, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:55:19.5874126Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T08:55:19.5875005Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T08:55:19.5875956Z     relu = torch.ops.aten.relu.default(conv1d_2);  conv1d_2 = None
2026-01-14T08:55:19.5876785Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0053919292986392975, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:19.5878175Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:55:19.5879254Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:55:19.5879683Z     
2026-01-14T08:55:19.5879970Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:19.5880364Z onverted model fx: GraphModule(
2026-01-14T08:55:19.5880619Z   (conv): ConvReLU1d(
2026-01-14T08:55:19.5880952Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:55:19.5881328Z     (1): ReLU()
2026-01-14T08:55:19.5881514Z   )
2026-01-14T08:55:19.5881684Z )
2026-01-14T08:55:19.5881781Z 
2026-01-14T08:55:19.5881785Z 
2026-01-14T08:55:19.5881789Z 
2026-01-14T08:55:19.5881875Z def forward(self, x):
2026-01-14T08:55:22.7175930Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:22.7178428Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:22.7179518Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:22.7180567Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0053919292986392975, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:22.7181959Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0053919292986392975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:22.7182915Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:22.7183199Z     
2026-01-14T08:55:22.7183491Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:22.7183905Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:22.7184239Z          [0., 0., 0.],
2026-01-14T08:55:22.7184482Z          [0., 0., 0.]]])
2026-01-14T08:55:22.7184931Z [32mPASSED[0m
2026-01-14T08:55:22.7185690Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T08:55:22.7186437Z   (conv): Module()
2026-01-14T08:55:22.7186896Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7188305Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:22.7189762Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:55:22.7190459Z   )
2026-01-14T08:55:22.7190747Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7191774Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:22.7192986Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:22.7193534Z   )
2026-01-14T08:55:22.7193722Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:22.7194060Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7195097Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:22.7196260Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:55:22.7196754Z   )
2026-01-14T08:55:22.7196927Z )
2026-01-14T08:55:22.7197030Z 
2026-01-14T08:55:22.7197034Z 
2026-01-14T08:55:22.7197038Z 
2026-01-14T08:55:22.7197131Z def forward(self, x):
2026-01-14T08:55:22.7197426Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:22.7197791Z     conv_weight = self.conv.weight
2026-01-14T08:55:22.7198264Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:55:22.7198837Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:55:22.7199266Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:22.7200037Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:55:22.7200839Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:55:22.7201451Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:22.7202012Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:22.7202412Z     
2026-01-14T08:55:22.7202698Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:22.7203158Z model fx: GraphModule(
2026-01-14T08:55:22.7203487Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7204510Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:22.7205714Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:22.7206246Z   )
2026-01-14T08:55:22.7206430Z   (conv): ConvReLU1d(
2026-01-14T08:55:22.7206683Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:55:22.7207063Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7208131Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024, 0.0022, 0.0021]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:22.7209565Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3119, -0.2799, -0.2618]), max_val=tensor([0.1970, 0.1855, 0.2308]))
2026-01-14T08:55:22.7210252Z     )
2026-01-14T08:55:22.7210422Z   )
2026-01-14T08:55:22.7210698Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:22.7211833Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0038]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:22.7213001Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9578298330307007)
2026-01-14T08:55:22.7213493Z   )
2026-01-14T08:55:22.7213658Z )
﻿2026-01-14T08:55:22.7218656Z 
2026-01-14T08:55:22.7218661Z 
2026-01-14T08:55:22.7218665Z 
2026-01-14T08:55:22.7218762Z def forward(self, x):
2026-01-14T08:55:22.7219137Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:22.7219703Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:22.7220272Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:22.7220725Z     return activation_post_process_1
2026-01-14T08:55:22.7220990Z     
2026-01-14T08:55:22.7221285Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:22.7221674Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:22.7221914Z          [0., 0., 0.],
2026-01-14T08:55:22.7222163Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:22.7222480Z converted model pt2e: GraphModule(
2026-01-14T08:55:22.7222757Z   (conv): Module()
2026-01-14T08:55:22.7222974Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:22.7223219Z )
2026-01-14T08:55:22.7223326Z 
2026-01-14T08:55:22.7223330Z 
2026-01-14T08:55:22.7223334Z 
2026-01-14T08:55:22.7223423Z def forward(self, x):
2026-01-14T08:55:22.7223715Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:22.7224055Z     _scale_0 = self._scale_0
2026-01-14T08:55:22.7224318Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:55:22.7224646Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:55:22.7225726Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:55:22.7227276Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:55:22.7228558Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:22.7229567Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:22.7230414Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:55:22.7231291Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:55:22.7232117Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0037561955396085978, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:22.7233516Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:22.7234608Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:55:22.7235048Z     
2026-01-14T08:55:22.7235337Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:22.7235736Z onverted model fx: GraphModule(
2026-01-14T08:55:22.7235997Z   (conv): ConvReLU1d(
2026-01-14T08:55:22.7236372Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:55:22.7236789Z     (1): ReLU()
2026-01-14T08:55:22.7236986Z   )
2026-01-14T08:55:22.7237161Z )
2026-01-14T08:55:22.7237269Z 
2026-01-14T08:55:22.7237273Z 
2026-01-14T08:55:22.7237277Z 
2026-01-14T08:55:22.7237363Z def forward(self, x):
2026-01-14T08:55:22.7238012Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:22.7239332Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:22.7240511Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:22.7241428Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0037561955396085978, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:22.7242825Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0037561955396085978, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:22.7243788Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:22.7244068Z     
2026-01-14T08:55:22.7244362Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:22.7244749Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:22.7244997Z          [0., 0., 0.],
2026-01-14T08:55:22.7245218Z          [0., 0., 0.]]])
2026-01-14T08:55:24.3878298Z model pt2e: GraphModule(
2026-01-14T08:55:24.3878753Z   (conv): Module()
2026-01-14T08:55:24.3879184Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3880483Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:24.3881725Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:55:24.3882267Z   )
2026-01-14T08:55:24.3882549Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3883913Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:24.3885550Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:24.3886310Z   )
2026-01-14T08:55:24.3886670Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:24.3887025Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3888062Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:24.3889314Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:55:24.3889958Z   )
2026-01-14T08:55:24.3890144Z )
2026-01-14T08:55:24.3890278Z 
2026-01-14T08:55:24.3890284Z 
2026-01-14T08:55:24.3890289Z 
2026-01-14T08:55:24.3890410Z def forward(self, x):
2026-01-14T08:55:24.3890824Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:24.3891179Z     conv_weight = self.conv.weight
2026-01-14T08:55:24.3891964Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:55:24.3892660Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:55:24.3893182Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:24.3893965Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:55:24.3905038Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:55:24.3905568Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:55:24.3906133Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:24.3906544Z     
2026-01-14T08:55:24.3906844Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:24.3907220Z model fx: GraphModule(
2026-01-14T08:55:24.3907546Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3908749Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:24.3909961Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:24.3910499Z   )
2026-01-14T08:55:24.3910679Z   (conv): ConvReLU1d(
2026-01-14T08:55:24.3910936Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:55:24.3911299Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3912308Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:24.3913528Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3119288384914398, max_val=0.23078612983226776)
2026-01-14T08:55:24.3914079Z     )
2026-01-14T08:55:24.3914248Z   )
2026-01-14T08:55:24.3914519Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3915547Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0037]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:24.3916697Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9556508660316467)
2026-01-14T08:55:24.3917186Z   )
2026-01-14T08:55:24.3917345Z )
2026-01-14T08:55:24.3917450Z 
2026-01-14T08:55:24.3917455Z 
2026-01-14T08:55:24.3917459Z 
2026-01-14T08:55:24.3917543Z def forward(self, x):
2026-01-14T08:55:24.3917991Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:24.3918540Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:24.3919110Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:24.3919596Z     return activation_post_process_1
2026-01-14T08:55:24.3919862Z     
2026-01-14T08:55:24.3920138Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:24.3920518Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:24.3920757Z          [0., 0., 0.],
2026-01-14T08:55:24.3920994Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:24.3921304Z converted model pt2e: GraphModule(
2026-01-14T08:55:24.3921564Z   (conv): Module()
2026-01-14T08:55:24.3921782Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:24.3922003Z )
2026-01-14T08:55:24.3922105Z 
2026-01-14T08:55:24.3922109Z 
2026-01-14T08:55:24.3922113Z 
2026-01-14T08:55:24.3922202Z def forward(self, x):
2026-01-14T08:55:24.3922490Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:24.3922880Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:55:24.3923846Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0024561325553804636, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:24.3925131Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:55:24.3926430Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:24.3927411Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:24.3928266Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:55:24.3929143Z     relu = torch.ops.aten.relu.default(conv1d);  conv1d = None
2026-01-14T08:55:24.3930003Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003747650422155857, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:55:24.3931498Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:55:24.3932598Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:55:24.3933021Z     
2026-01-14T08:55:24.3933309Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:24.3933693Z onverted model fx: GraphModule(
2026-01-14T08:55:24.3933958Z   (conv): ConvReLU1d(
2026-01-14T08:55:24.3934326Z     (0): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:55:24.3934748Z     (1): ReLU()
2026-01-14T08:55:24.3934946Z   )
2026-01-14T08:55:24.3935117Z )
2026-01-14T08:55:24.3935213Z 
2026-01-14T08:55:24.3935220Z 
2026-01-14T08:55:24.3935223Z 
2026-01-14T08:55:24.3935319Z def forward(self, x):
2026-01-14T08:55:24.3935963Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:24.3937287Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:24.3938367Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:24.3939372Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003747650422155857, -128, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:24.3940761Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003747650422155857, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:24.3941761Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:24.3942038Z     
2026-01-14T08:55:24.3942328Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:24.3942703Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:24.3942938Z          [0., 0., 0.],
2026-01-14T08:55:24.3943144Z          [0., 0., 0.]]])
2026-01-14T08:55:24.3943373Z model pt2e: GraphModule(
2026-01-14T08:55:24.3943598Z   (conv): Module()
2026-01-14T08:55:24.3943905Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3945012Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:24.3946502Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:55:24.3947193Z   )
2026-01-14T08:55:24.3947467Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3948493Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:24.3949968Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:24.3950500Z   )
2026-01-14T08:55:24.3950691Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:24.3951026Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:24.3952051Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0559795Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:55:26.0560526Z   )
2026-01-14T08:55:26.0560709Z )
2026-01-14T08:55:26.0560822Z 
2026-01-14T08:55:26.0560827Z 
2026-01-14T08:55:26.0560833Z 
2026-01-14T08:55:26.0560926Z def forward(self, x):
2026-01-14T08:55:26.0561306Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:26.0561678Z     conv_weight = self.conv.weight
2026-01-14T08:55:26.0562245Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:55:26.0562899Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:55:26.0563378Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:26.0564239Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:55:26.0565229Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:55:26.0565900Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:26.0566329Z     
2026-01-14T08:55:26.0566676Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:26.0567059Z model fx: GraphModule(
2026-01-14T08:55:26.0567471Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0568817Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0570252Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:26.0570879Z   )
2026-01-14T08:55:26.0571059Z   (conv): Conv1d(
2026-01-14T08:55:26.0571404Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:55:26.0571992Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0573169Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022, 0.0025, 0.0024]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:55:26.0574811Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2203, -0.3233, -0.3086]), max_val=tensor([0.2796, 0.3026, 0.2405]))
2026-01-14T08:55:26.0575588Z     )
2026-01-14T08:55:26.0575778Z   )
2026-01-14T08:55:26.0576118Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0577274Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-25], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0578590Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8935509324073792, max_val=1.3209781646728516)
2026-01-14T08:55:26.0579213Z   )
2026-01-14T08:55:26.0579386Z )
2026-01-14T08:55:26.0579500Z 
2026-01-14T08:55:26.0579506Z 
2026-01-14T08:55:26.0579512Z 
2026-01-14T08:55:26.0579631Z def forward(self, x):
2026-01-14T08:55:26.0580025Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:55:26.0580659Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:55:26.0581244Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:55:26.0581770Z     return activation_post_process_1
2026-01-14T08:55:26.0582038Z     
2026-01-14T08:55:26.0582409Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:26.0583911Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:26.0584226Z          [0., 0., 0.],
2026-01-14T08:55:26.0584466Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:55:26.0584793Z converted model pt2e: GraphModule(
2026-01-14T08:55:26.0585130Z   (conv): Module()
2026-01-14T08:55:26.0585352Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:26.0585576Z )
2026-01-14T08:55:26.0585695Z 
2026-01-14T08:55:26.0585701Z 
2026-01-14T08:55:26.0585706Z 
2026-01-14T08:55:26.0585825Z def forward(self, x):
2026-01-14T08:55:26.0586154Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:26.0586492Z     _scale_0 = self._scale_0
2026-01-14T08:55:26.0586764Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:55:26.0587167Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:55:26.0588272Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:55:26.0589760Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:55:26.0591151Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:26.0592128Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:26.0592978Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T08:55:26.0594369Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008684427477419376, -25, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:55:26.0595903Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:26.0597053Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:55:26.0597485Z     
2026-01-14T08:55:26.0597778Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:26.0598177Z onverted model fx: GraphModule(
2026-01-14T08:55:26.0598604Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:55:26.0599029Z )
2026-01-14T08:55:26.0599130Z 
2026-01-14T08:55:26.0599142Z 
2026-01-14T08:55:26.0599147Z 
2026-01-14T08:55:26.0599232Z def forward(self, x):
2026-01-14T08:55:26.0599879Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:55:26.0601208Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:55:26.0602396Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:55:26.0603301Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008684427477419376, -25, -128, 127, torch.int8);  conv = None
2026-01-14T08:55:26.0604678Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008684427477419376, -25, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:55:26.0605625Z     return dequantize_per_tensor_default_1
2026-01-14T08:55:26.0605900Z     
2026-01-14T08:55:26.0606194Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:26.0606572Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:55:26.0606879Z          [0., 0., 0.],
2026-01-14T08:55:26.0607094Z          [0., 0., 0.]]])
2026-01-14T08:55:26.0607334Z model pt2e: GraphModule(
2026-01-14T08:55:26.0607569Z   (conv): Module()
2026-01-14T08:55:26.0607886Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0608931Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:55:26.0610153Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:55:26.0610709Z   )
2026-01-14T08:55:26.0610987Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0612102Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0613313Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:26.0613847Z   )
2026-01-14T08:55:26.0614036Z   (_guards_fn): GuardsFn()
2026-01-14T08:55:26.0614370Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0615503Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0616716Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:55:26.0617282Z   )
2026-01-14T08:55:26.0617468Z )
2026-01-14T08:55:26.0617664Z 
2026-01-14T08:55:26.0617669Z 
2026-01-14T08:55:26.0617673Z 
2026-01-14T08:55:26.0617759Z def forward(self, x):
2026-01-14T08:55:26.0618055Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:55:26.0618427Z     conv_weight = self.conv.weight
2026-01-14T08:55:26.0618941Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:55:26.0619515Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:55:26.0619941Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:55:26.0620711Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T08:55:26.0621591Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:55:26.0622162Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:55:26.0622571Z     
2026-01-14T08:55:26.0622859Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:55:26.0623235Z model fx: GraphModule(
2026-01-14T08:55:26.0623572Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:55:26.0624595Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:55:26.0625800Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:55:26.0626341Z   )
2026-01-14T08:55:26.0626532Z   (conv): Conv1d(
2026-01-14T08:56:50.5716495Z     3, 3, kernel_size=(3,), stride=(1,), bias=False
2026-01-14T08:56:50.5716892Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5717929Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:50.5719390Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3232726454734802, max_val=0.30256539583206177)
2026-01-14T08:56:50.5719952Z     )
2026-01-14T08:56:50.5720123Z   )
2026-01-14T08:56:50.5720407Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5721444Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0087]), zero_point=tensor([-26], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:50.5722652Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.887858510017395, max_val=1.3209781646728516)
2026-01-14T08:56:50.5723183Z   )
2026-01-14T08:56:50.5723349Z )
2026-01-14T08:56:50.5723446Z 
2026-01-14T08:56:50.5723451Z 
2026-01-14T08:56:50.5723459Z 
2026-01-14T08:56:50.5723549Z def forward(self, x):
2026-01-14T08:56:50.5723897Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:50.5724450Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:56:50.5725008Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:50.5725449Z     return activation_post_process_1
2026-01-14T08:56:50.5725704Z     
2026-01-14T08:56:50.5725989Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:50.5726369Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:50.5726600Z          [0., 0., 0.],
2026-01-14T08:56:50.5726841Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:50.5727178Z converted model pt2e: GraphModule(
2026-01-14T08:56:50.5727433Z   (conv): Module()
2026-01-14T08:56:50.5727647Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:50.5727862Z )
2026-01-14T08:56:50.5727957Z 
2026-01-14T08:56:50.5728225Z 
2026-01-14T08:56:50.5728237Z 
2026-01-14T08:56:50.5728322Z def forward(self, x):
2026-01-14T08:56:50.5728601Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:50.5728990Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:56:50.5730026Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002545453840866685, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:50.5731523Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:56:50.5732829Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:50.5733800Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:50.5734660Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:56:50.5735917Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.008662103675305843, -26, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:56:50.5737297Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:50.5738374Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:50.5738794Z     
2026-01-14T08:56:50.5739071Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:50.5739460Z onverted model fx: GraphModule(
2026-01-14T08:56:50.5739873Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,), bias=False)
2026-01-14T08:56:50.5740293Z )
2026-01-14T08:56:50.5740388Z 
2026-01-14T08:56:50.5740393Z 
2026-01-14T08:56:50.5740397Z 
2026-01-14T08:56:50.5740535Z def forward(self, x):
2026-01-14T08:56:50.5741182Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:56:50.5742501Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:50.5743565Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:56:50.5744467Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008662103675305843, -26, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:50.5745842Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008662103675305843, -26, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:50.5746784Z     return dequantize_per_tensor_default_1
2026-01-14T08:56:50.5747058Z     
2026-01-14T08:56:50.5747337Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:50.5747716Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:56:50.5747944Z          [0., 0., 0.],
2026-01-14T08:56:50.5748154Z          [0., 0., 0.]]])
2026-01-14T08:56:50.5748600Z [32mPASSED[0m
2026-01-14T08:56:50.5749418Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T08:56:50.5751042Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T08:56:50.5752163Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T08:56:50.5752797Z   (conv): Module()
2026-01-14T08:56:50.5753104Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5754159Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:50.5755508Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:56:50.5756095Z   )
2026-01-14T08:56:50.5756426Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5757444Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:50.5758651Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:56:50.5759188Z   )
2026-01-14T08:56:50.5759374Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:50.5759720Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5760737Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:50.5761945Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:56:50.5762493Z   )
2026-01-14T08:56:50.5762766Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5763799Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:50.5764946Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:56:50.5765552Z   )
2026-01-14T08:56:50.5765730Z )
2026-01-14T08:56:50.5765827Z 
2026-01-14T08:56:50.5765832Z 
2026-01-14T08:56:50.5765836Z 
2026-01-14T08:56:50.5765919Z def forward(self, x):
2026-01-14T08:56:50.5766212Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:50.5766556Z     conv_weight = self.conv.weight
2026-01-14T08:56:50.5767025Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:50.5767510Z     conv_bias = self.conv.bias
2026-01-14T08:56:50.5767858Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:56:50.5768284Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:50.5769034Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:56:50.5769889Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:56:50.5770735Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:56:50.5771569Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:56:50.5772058Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:56:50.5772622Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:56:50.5773025Z     
2026-01-14T08:56:50.5773308Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:50.5773683Z model fx: GraphModule(
2026-01-14T08:56:50.5774006Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5775121Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:50.5776332Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:56:50.5776902Z   )
2026-01-14T08:56:50.5777084Z   (conv): Conv1d(
2026-01-14T08:56:50.5777297Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:56:50.5777640Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:50.5778650Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:56:52.3168351Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2457]), max_val=tensor([-0.2457]))
2026-01-14T08:56:52.3168972Z     )
2026-01-14T08:56:52.3169157Z   )
2026-01-14T08:56:52.3169468Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3170756Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.3172144Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:56:52.3172687Z   )
2026-01-14T08:56:52.3172884Z   (relu): ReLU(inplace=True)
2026-01-14T08:56:52.3173227Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3174259Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.3175451Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:56:52.3175940Z   )
2026-01-14T08:56:52.3176248Z )
2026-01-14T08:56:52.3176343Z 
2026-01-14T08:56:52.3176348Z 
2026-01-14T08:56:52.3176351Z 
2026-01-14T08:56:52.3176449Z def forward(self, x):
2026-01-14T08:56:52.3176805Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:56:52.3177262Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:56:52.3177708Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:56:52.3178439Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:56:52.3179042Z     relu = self.relu(add);  add = None
2026-01-14T08:56:52.3179462Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:56:52.3179908Z     return activation_post_process_2
2026-01-14T08:56:52.3180173Z     
2026-01-14T08:56:52.3180466Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.3180893Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:56:52.3181244Z converted model pt2e: GraphModule(
2026-01-14T08:56:52.3181521Z   (conv): Module()
2026-01-14T08:56:52.3181730Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:52.3181957Z )
2026-01-14T08:56:52.3182056Z 
2026-01-14T08:56:52.3182060Z 
2026-01-14T08:56:52.3182064Z 
2026-01-14T08:56:52.3182149Z def forward(self, x):
2026-01-14T08:56:52.3182441Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:52.3182777Z     _scale_0 = self._scale_0
2026-01-14T08:56:52.3183133Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:56:52.3183569Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T08:56:52.3185020Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T08:56:52.3186157Z     conv_bias = self.conv.bias
2026-01-14T08:56:52.3186791Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:56:52.3188023Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:56:52.3189431Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:52.3190395Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:52.3191345Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T08:56:52.3192687Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:56:52.3194078Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:52.3195495Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T08:56:52.3196335Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:56:52.3197141Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:56:52.3198529Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:52.3199704Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:56:52.3200144Z     
2026-01-14T08:56:52.3200431Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.3200823Z onverted model fx: GraphModule(
2026-01-14T08:56:52.3201196Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:56:52.3201608Z   (relu): ReLU(inplace=True)
2026-01-14T08:56:52.3201837Z )
2026-01-14T08:56:52.3201942Z 
2026-01-14T08:56:52.3201946Z 
2026-01-14T08:56:52.3201949Z 
2026-01-14T08:56:52.3202033Z def forward(self, x):
2026-01-14T08:56:52.3202687Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:56:52.3203993Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:56:52.3204946Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:56:52.3205719Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:56:52.3207081Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:56:52.3208386Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:56:52.3209138Z     relu = self.relu(add);  add = None
2026-01-14T08:56:52.3209870Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:56:52.3220006Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:56:52.3221138Z     return dequantize_per_tensor_default_2
2026-01-14T08:56:52.3221420Z     
2026-01-14T08:56:52.3221717Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:56:52.3222091Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:56:52.3222347Z model pt2e: GraphModule(
2026-01-14T08:56:52.3222576Z   (conv): Module()
2026-01-14T08:56:52.3222882Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3223930Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:56:52.3225165Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:56:52.3225718Z   )
2026-01-14T08:56:52.3225988Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3227059Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.3228256Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:56:52.3228781Z   )
2026-01-14T08:56:52.3228972Z   (_guards_fn): GuardsFn()
2026-01-14T08:56:52.3229308Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3230325Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.3231598Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:56:52.3232131Z   )
2026-01-14T08:56:52.3232409Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:56:52.3233427Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:56:52.3234575Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:56:52.3235061Z   )
2026-01-14T08:56:52.3235222Z )
2026-01-14T08:56:52.3235319Z 
2026-01-14T08:56:52.3235323Z 
2026-01-14T08:56:52.3235327Z 
2026-01-14T08:56:52.3235416Z def forward(self, x):
2026-01-14T08:56:52.3235701Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:56:52.3236057Z     conv_weight = self.conv.weight
2026-01-14T08:56:52.3236521Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T08:56:52.3237010Z     conv_bias = self.conv.bias
2026-01-14T08:56:52.3237354Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:56:52.3237776Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:56:52.3238527Z     conv1d = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T08:57:35.5860930Z     activation_post_process_2 = self.activation_post_process_2(conv1d);  conv1d = None
2026-01-14T08:57:35.5862449Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T08:57:35.5863575Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:57:35.5864202Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T08:57:35.5865175Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:57:35.5865696Z     
2026-01-14T08:57:35.5866016Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:35.5866427Z model fx: GraphModule(
2026-01-14T08:57:35.5866761Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:35.5867794Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0089]), zero_point=tensor([41], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:35.5869083Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.498010516166687, max_val=0.7672448754310608)
2026-01-14T08:57:35.5869624Z   )
2026-01-14T08:57:35.5869808Z   (conv): Conv1d(
2026-01-14T08:57:35.5870036Z     1, 1, kernel_size=(1,), stride=(1,)
2026-01-14T08:57:35.5870379Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:35.5871401Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0010]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:35.5872644Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24565386772155762, max_val=-0.24565386772155762)
2026-01-14T08:57:35.5873207Z     )
2026-01-14T08:57:35.5873390Z   )
2026-01-14T08:57:35.5873669Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:35.5874727Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:35.5876377Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3805955946445465, max_val=0.17587313055992126)
2026-01-14T08:57:35.5877119Z   )
2026-01-14T08:57:35.5877407Z   (relu): ReLU(inplace=True)
2026-01-14T08:57:35.5877955Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:35.5879285Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:35.5880715Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.3842603862285614)
2026-01-14T08:57:35.5881302Z   )
2026-01-14T08:57:35.5881487Z )
2026-01-14T08:57:35.5881591Z 
2026-01-14T08:57:35.5881595Z 
2026-01-14T08:57:35.5881598Z 
2026-01-14T08:57:35.5881696Z def forward(self, x):
2026-01-14T08:57:35.5882112Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:35.5882639Z     conv = self.conv(activation_post_process_0)
2026-01-14T08:57:35.5883101Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:57:35.5883855Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T08:57:35.5884458Z     relu = self.relu(add);  add = None
2026-01-14T08:57:35.5884892Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T08:57:35.5885343Z     return activation_post_process_2
2026-01-14T08:57:35.5885610Z     
2026-01-14T08:57:35.5885890Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:35.5886320Z diff: tensor([[[0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:57:35.5886781Z converted model pt2e: GraphModule(
2026-01-14T08:57:35.5887050Z   (conv): Module()
2026-01-14T08:57:35.5887270Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:35.5887490Z )
2026-01-14T08:57:35.5887586Z 
2026-01-14T08:57:35.5887600Z 
2026-01-14T08:57:35.5887604Z 
2026-01-14T08:57:35.5887689Z def forward(self, x):
2026-01-14T08:57:35.5888025Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:35.5888408Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T08:57:35.5889371Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0019342823652550578, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:35.5890285Z     conv_bias = self.conv.bias
2026-01-14T08:57:35.5890923Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:57:35.5892222Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8)
2026-01-14T08:57:35.5893637Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:35.5894622Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:35.5895551Z     conv1d = torch.ops.aten.conv1d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T08:57:35.5896886Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv1d = None
2026-01-14T08:57:35.5898277Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:35.5899690Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T08:57:35.5900596Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T08:57:35.5901403Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T08:57:35.5902785Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:57:35.5903865Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:57:35.5904293Z     
2026-01-14T08:57:35.5904577Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:35.5904972Z onverted model fx: GraphModule(
2026-01-14T08:57:35.5905346Z   (conv): QuantizedConv1d(Reference)(1, 1, kernel_size=(1,), stride=(1,))
2026-01-14T08:57:35.5905751Z   (relu): ReLU(inplace=True)
2026-01-14T08:57:35.5905986Z )
2026-01-14T08:57:35.5906088Z 
2026-01-14T08:57:35.5906092Z 
2026-01-14T08:57:35.5906096Z 
2026-01-14T08:57:35.5906178Z def forward(self, x):
2026-01-14T08:57:35.5906825Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.008883354254066944, 41, -128, 127, torch.int8);  x = None
2026-01-14T08:57:35.5908132Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.008883354254066944, 41, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:35.5909076Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T08:57:35.5909927Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.0021822303533554077, 46, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:35.5911291Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.0021822303533554077, 46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:35.5912629Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T08:57:35.5913293Z     relu = self.relu(add);  add = None
2026-01-14T08:57:35.5914023Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.0015069034416228533, -128, -128, 127, torch.int8);  relu = None
2026-01-14T08:57:35.5915407Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.0015069034416228533, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:35.5916355Z     return dequantize_per_tensor_default_2
2026-01-14T08:57:35.5916675Z     
2026-01-14T08:57:35.5916958Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:35.5917350Z diff: tensor([[[0., 0., 0.]]])
2026-01-14T08:57:35.5917811Z [32mPASSED[0m
2026-01-14T08:57:35.5918521Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T08:57:35.5919618Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T08:57:35.5920591Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T08:57:35.5921223Z   (conv): Module()
2026-01-14T08:57:35.5921425Z   (bn): Module()
2026-01-14T08:57:35.5921737Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:35.5922758Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:35.5924045Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:35.5924581Z   )
2026-01-14T08:57:35.5924765Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:35.5925102Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3914025Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:54.3915944Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:57:54.3916823Z   )
2026-01-14T08:57:54.3917162Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3918480Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:54.3920023Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:57:54.3920704Z   )
2026-01-14T08:57:54.3921052Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3922340Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:54.3924170Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:57:54.3924851Z   )
2026-01-14T08:57:54.3925061Z )
2026-01-14T08:57:54.3925183Z 
2026-01-14T08:57:54.3925188Z 
2026-01-14T08:57:54.3925193Z 
2026-01-14T08:57:54.3925303Z def forward(self, x):
2026-01-14T08:57:54.3925747Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:54.3926189Z     conv_weight = self.conv.weight
2026-01-14T08:57:54.3926526Z     conv_bias = self.conv.bias
2026-01-14T08:57:54.3926845Z     bn_weight = self.bn.weight
2026-01-14T08:57:54.3927151Z     bn_bias = self.bn.bias
2026-01-14T08:57:54.3927475Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:57:54.3927844Z     bn_running_var = self.bn.running_var
2026-01-14T08:57:54.3928261Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:54.3928787Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:57:54.3929326Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:54.3930005Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:54.3930706Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:57:54.3931208Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:57:54.3931836Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:57:54.3932418Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:57:54.3933061Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:57:54.3933795Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:57:54.3934613Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:57:54.3935971Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:57:54.3937166Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:57:54.3938001Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:57:54.3938768Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:57:54.3939488Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:57:54.3940715Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:57:54.3942023Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:57:54.3943020Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:57:54.3943972Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:57:54.3944711Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:57:54.3945218Z     
2026-01-14T08:57:54.3945565Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:54.3946033Z model fx: GraphModule(
2026-01-14T08:57:54.3946430Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3947728Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:54.3949493Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:54.3950171Z   )
2026-01-14T08:57:54.3950387Z   (conv): ConvBn1d(
2026-01-14T08:57:54.3950784Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:57:54.3951305Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:57:54.3951912Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3953267Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025, 0.0024, 0.0026]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:57:54.3955155Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.3156, -0.1982, -0.3261]), max_val=tensor([0.2827, 0.2978, 0.2359]))
2026-01-14T08:57:54.3956018Z     )
2026-01-14T08:57:54.3956224Z   )
2026-01-14T08:57:54.3956558Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3957871Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:54.3959409Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:57:54.3960087Z   )
2026-01-14T08:57:54.3960400Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:57:54.3960888Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:54.3962187Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:54.3963722Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3043057918548584, max_val=1.399786114692688)
2026-01-14T08:57:54.3964391Z   )
2026-01-14T08:57:54.3964594Z )
2026-01-14T08:57:54.3964709Z 
2026-01-14T08:57:54.3964715Z 
2026-01-14T08:57:54.3964726Z 
2026-01-14T08:57:54.3964826Z def forward(self, x):
2026-01-14T08:57:54.3965264Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:57:54.3966054Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:57:54.3966761Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:57:54.3967471Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:57:54.3968096Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:57:54.3968563Z     return activation_post_process_2
2026-01-14T08:57:54.3968817Z     
2026-01-14T08:57:54.3969099Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:54.3969478Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:54.3969705Z          [0., 0., 0.],
2026-01-14T08:57:54.3969944Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:57:54.3970255Z converted model pt2e: GraphModule(
2026-01-14T08:57:54.3970519Z   (conv): Module()
2026-01-14T08:57:54.3970715Z   (bn): Module()
2026-01-14T08:57:54.3970929Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:54.3971147Z )
2026-01-14T08:57:54.3971249Z 
2026-01-14T08:57:54.3971255Z 
2026-01-14T08:57:54.3971259Z 
2026-01-14T08:57:54.3971393Z def forward(self, x):
2026-01-14T08:57:54.3971687Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:54.3972030Z     conv_bias = self.conv.bias
2026-01-14T08:57:54.3972332Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:54.3973032Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:57:54.3974408Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:54.3975364Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:54.3975907Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:54.3976405Z     _scale_0 = self._scale_0
2026-01-14T08:57:54.3976699Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:57:54.3977007Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:57:54.3977941Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:57:54.3979399Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:57:54.3980694Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010604282841086388, -5, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:57:54.3982078Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:54.3983337Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T08:57:54.3984428Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:57:57.5538354Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:57.5539796Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:57:57.5540333Z     
2026-01-14T08:57:57.5540687Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:57.5541344Z onverted model fx: GraphModule(
2026-01-14T08:57:57.5541817Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:57:57.5542359Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:57:57.5542727Z )
2026-01-14T08:57:57.5542848Z 
2026-01-14T08:57:57.5542853Z 
2026-01-14T08:57:57.5542858Z 
2026-01-14T08:57:57.5542972Z def forward(self, x):
2026-01-14T08:57:57.5543780Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:57:57.5545471Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:57:57.5546842Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:57:57.5547994Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010604282841086388, -5, -128, 127, torch.int8);  conv = None
2026-01-14T08:57:57.5550097Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:57:57.5551560Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:57:57.5552815Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010604282841086388, -5, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:57:57.5556783Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010604282841086388, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:57:57.5558008Z     return dequantize_per_tensor_default_2
2026-01-14T08:57:57.5558379Z     
2026-01-14T08:57:57.5558750Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:57.5559354Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:57:57.5559644Z          [0., 0., 0.],
2026-01-14T08:57:57.5559858Z          [0., 0., 0.]]])
2026-01-14T08:57:57.5560087Z model pt2e: GraphModule(
2026-01-14T08:57:57.5560326Z   (conv): Module()
2026-01-14T08:57:57.5560531Z   (bn): Module()
2026-01-14T08:57:57.5560835Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5561861Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5563075Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:57.5563618Z   )
2026-01-14T08:57:57.5563808Z   (_guards_fn): GuardsFn()
2026-01-14T08:57:57.5564154Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5565188Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:57.5566392Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:57:57.5566938Z   )
2026-01-14T08:57:57.5567218Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5568243Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5569445Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:57:57.5570052Z   )
2026-01-14T08:57:57.5570337Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5571440Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5572640Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:57:57.5573180Z   )
2026-01-14T08:57:57.5573353Z )
2026-01-14T08:57:57.5573452Z 
2026-01-14T08:57:57.5573463Z 
2026-01-14T08:57:57.5573468Z 
2026-01-14T08:57:57.5573554Z def forward(self, x):
2026-01-14T08:57:57.5573847Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:57:57.5574216Z     conv_weight = self.conv.weight
2026-01-14T08:57:57.5574500Z     conv_bias = self.conv.bias
2026-01-14T08:57:57.5574758Z     bn_weight = self.bn.weight
2026-01-14T08:57:57.5575017Z     bn_bias = self.bn.bias
2026-01-14T08:57:57.5575278Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:57:57.5575591Z     bn_running_var = self.bn.running_var
2026-01-14T08:57:57.5575928Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:57:57.5576350Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:57:57.5576777Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:57:57.5577317Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:57:57.5577882Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:57:57.5578284Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:57:57.5578806Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:57:57.5579259Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1])
2026-01-14T08:57:57.5579780Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:57:57.5580371Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:57:57.5581065Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:57:57.5582112Z     conv1d_1 = torch.ops.aten.conv1d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:57:57.5583052Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1]);  div = None
2026-01-14T08:57:57.5583615Z     div_1 = torch.ops.aten.div.Tensor(conv1d_1, reshape_1);  conv1d_1 = reshape_1 = None
2026-01-14T08:57:57.5584216Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1]);  conv_bias = None
2026-01-14T08:57:57.5584805Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:57:57.5585774Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:57:57.5586806Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:57:57.5587594Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T08:57:57.5588341Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T08:57:57.5588939Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T08:57:57.5589343Z     
2026-01-14T08:57:57.5589626Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:57:57.5590009Z model fx: GraphModule(
2026-01-14T08:57:57.5590330Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5591363Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0104]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5592625Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3264806270599365, max_val=1.318617343902588)
2026-01-14T08:57:57.5593158Z   )
2026-01-14T08:57:57.5593347Z   (conv): ConvBn1d(
2026-01-14T08:57:57.5593575Z     3, 3, kernel_size=(3,), stride=(1,)
2026-01-14T08:57:57.5594000Z     (bn): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:57:57.5594493Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5595510Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:57:57.5596734Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3261372148990631, max_val=0.297783762216568)
2026-01-14T08:57:57.5597277Z     )
2026-01-14T08:57:57.5597460Z   )
2026-01-14T08:57:57.5597739Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5598770Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5599974Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:57:57.5600508Z   )
2026-01-14T08:57:57.5600733Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:57:57.5601226Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:57:57.5602258Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0106]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:57:57.5603503Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3146827220916748, max_val=1.399786114692688)
2026-01-14T08:57:57.5604040Z   )
2026-01-14T08:57:57.5604221Z )
2026-01-14T08:57:57.5604319Z 
2026-01-14T08:57:57.5604323Z 
2026-01-14T08:57:57.5604327Z 
2026-01-14T08:57:57.5604416Z def forward(self, x):
2026-01-14T08:57:57.5604777Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:05.0357021Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:05.0357779Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:05.0358557Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T08:59:05.0359359Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T08:59:05.0359963Z     return activation_post_process_2
2026-01-14T08:59:05.0360285Z     
2026-01-14T08:59:05.0360657Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:05.0361129Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:05.0361422Z          [0., 0., 0.],
2026-01-14T08:59:05.0371015Z          [0., 0., 0.]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:05.0371536Z converted model pt2e: GraphModule(
2026-01-14T08:59:05.0371868Z   (conv): Module()
2026-01-14T08:59:05.0372147Z   (bn): Module()
2026-01-14T08:59:05.0372399Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:05.0372669Z )
2026-01-14T08:59:05.0372794Z 
2026-01-14T08:59:05.0372799Z 
2026-01-14T08:59:05.0372804Z 
2026-01-14T08:59:05.0372904Z def forward(self, x):
2026-01-14T08:59:05.0373268Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:05.0373690Z     conv_bias = self.conv.bias
2026-01-14T08:59:05.0374064Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:05.0375172Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8)
2026-01-14T08:59:05.0376880Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:05.0378119Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:05.0378790Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:05.0379436Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:59:05.0380490Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.002568009542301297, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:59:05.0382208Z     conv1d_2 = torch.ops.aten.conv1d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:59:05.0383857Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1d_2, 0.010644976049661636, -4, -128, 127, torch.int8);  conv1d_2 = None
2026-01-14T08:59:05.0385645Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:05.0387250Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T08:59:05.0388848Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:59:05.0390645Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T08:59:05.0392104Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T08:59:05.0392634Z     
2026-01-14T08:59:05.0392983Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:05.0393465Z onverted model fx: GraphModule(
2026-01-14T08:59:05.0393925Z   (conv): QuantizedConv1d(Reference)(3, 3, kernel_size=(3,), stride=(1,))
2026-01-14T08:59:05.0394461Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T08:59:05.0394836Z )
2026-01-14T08:59:05.0394972Z 
2026-01-14T08:59:05.0394978Z 
2026-01-14T08:59:05.0394983Z 
2026-01-14T08:59:05.0395092Z def forward(self, x):
2026-01-14T08:59:05.0396017Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.010372933000326157, 0, -128, 127, torch.int8);  x = None
2026-01-14T08:59:05.0397347Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.010372933000326157, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:05.0398428Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:05.0399327Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.010644976049661636, -4, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:05.0400694Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:05.0401843Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T08:59:05.0402816Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.010644976049661636, -4, -128, 127, torch.int8);  hardtanh = None
2026-01-14T08:59:05.0404264Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.010644976049661636, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:05.0405207Z     return dequantize_per_tensor_default_2
2026-01-14T08:59:05.0405478Z     
2026-01-14T08:59:05.0405764Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:05.0406137Z diff: tensor([[[0., 0., 0.],
2026-01-14T08:59:05.0406379Z          [0., 0., 0.],
2026-01-14T08:59:05.0406584Z          [0., 0., 0.]]])
2026-01-14T08:59:05.0407027Z [32mPASSED[0m
2026-01-14T08:59:05.0407696Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node [32mPASSED[0m
2026-01-14T08:59:05.0408767Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec [32mPASSED[0m
2026-01-14T08:59:05.0409755Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion model pt2e: GraphModule(
2026-01-14T08:59:05.0410369Z   (conv): Module()
2026-01-14T08:59:05.0410576Z   (bn): Module()
2026-01-14T08:59:05.0410880Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:05.0411977Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:05.0413189Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:59:05.0413716Z   )
2026-01-14T08:59:05.0413901Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:05.0414323Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:05.0415418Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:05.0416935Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T08:59:05.0417613Z   )
2026-01-14T08:59:05.0417896Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:05.0418914Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:05.0420122Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T08:59:05.0420658Z   )
2026-01-14T08:59:05.0420821Z )
2026-01-14T08:59:05.0420914Z 
2026-01-14T08:59:05.0420921Z 
2026-01-14T08:59:05.0420925Z 
2026-01-14T08:59:05.0421011Z def forward(self, x):
2026-01-14T08:59:05.0421299Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:05.0421646Z     conv_weight = self.conv.weight
2026-01-14T08:59:05.0421917Z     conv_bias = self.conv.bias
2026-01-14T08:59:05.0422173Z     bn_weight = self.bn.weight
2026-01-14T08:59:05.0422418Z     bn_bias = self.bn.bias
2026-01-14T08:59:05.0422672Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:05.0422976Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:05.0423304Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:05.0423722Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:59:05.0424142Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:05.0424695Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:05.0425248Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:05.0425706Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:59:05.0426135Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:59:05.0426589Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:59:05.0427115Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:59:05.0427702Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:59:05.0428352Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:59:05.0429395Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:59:05.0430346Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:59:05.0430923Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:59:05.0431542Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:59:05.0432136Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:05.0433106Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:27.3922221Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:27.3923041Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:59:27.3923555Z     
2026-01-14T08:59:27.3924201Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.3924686Z model fx: GraphModule(
2026-01-14T08:59:27.3925084Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3926412Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.3928063Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:59:27.3928737Z   )
2026-01-14T08:59:27.3928956Z   (conv): ConvBn2d(
2026-01-14T08:59:27.3929232Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:59:27.3929767Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:27.3930412Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3931895Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:27.3933747Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1894, -0.1850, -0.1857]), max_val=tensor([0.1520, 0.1622, 0.1895]))
2026-01-14T08:59:27.3934623Z     )
2026-01-14T08:59:27.3934827Z   )
2026-01-14T08:59:27.3935165Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3936461Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.3938001Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9920659065246582, max_val=2.112386465072632)
2026-01-14T08:59:27.3938687Z   )
2026-01-14T08:59:27.3938886Z )
2026-01-14T08:59:27.3939004Z 
2026-01-14T08:59:27.3939009Z 
2026-01-14T08:59:27.3939020Z 
2026-01-14T08:59:27.3939229Z def forward(self, x):
2026-01-14T08:59:27.3939665Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:27.3940365Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:27.3941129Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:27.3941679Z     return activation_post_process_1
2026-01-14T08:59:27.3942005Z     
2026-01-14T08:59:27.3942346Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.3942828Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:59:27.3943117Z           [0., 0., 0.],
2026-01-14T08:59:27.3943379Z           [0., 0., 0.]],
2026-01-14T08:59:27.3943551Z 
2026-01-14T08:59:27.3943643Z          [[0., 0., 0.],
2026-01-14T08:59:27.3943905Z           [0., 0., 0.],
2026-01-14T08:59:27.3944156Z           [0., 0., 0.]],
2026-01-14T08:59:27.3944332Z 
2026-01-14T08:59:27.3944424Z          [[0., 0., 0.],
2026-01-14T08:59:27.3944680Z           [0., 0., 0.],
2026-01-14T08:59:27.3944972Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:27.3945371Z converted model pt2e: GraphModule(
2026-01-14T08:59:27.3945688Z   (conv): Module()
2026-01-14T08:59:27.3945935Z   (bn): Module()
2026-01-14T08:59:27.3946186Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:27.3946460Z )
2026-01-14T08:59:27.3946583Z 
2026-01-14T08:59:27.3946588Z 
2026-01-14T08:59:27.3946593Z 
2026-01-14T08:59:27.3946694Z def forward(self, x):
2026-01-14T08:59:27.3947046Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:27.3947479Z     conv_bias = self.conv.bias
2026-01-14T08:59:27.3948272Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T08:59:27.3950311Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:27.3951558Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:27.3952042Z     _scale_0 = self._scale_0
2026-01-14T08:59:27.3952359Z     _zero_point_0 = self._zero_point_0
2026-01-14T08:59:27.3952730Z     quantize_per_channel = self._frozen_param0
2026-01-14T08:59:27.3953946Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T08:59:27.3955821Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T08:59:27.3957486Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01609589159488678, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:59:27.3959267Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:27.3960687Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T08:59:27.3961260Z     
2026-01-14T08:59:27.3961623Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.3962137Z onverted model fx: GraphModule(
2026-01-14T08:59:27.3962536Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:59:27.3962930Z )
2026-01-14T08:59:27.3963030Z 
2026-01-14T08:59:27.3963034Z 
2026-01-14T08:59:27.3963044Z 
2026-01-14T08:59:27.3963129Z def forward(self, x):
2026-01-14T08:59:27.3963779Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:59:27.3965093Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:27.3966246Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:27.3967141Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01609589159488678, -4, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:27.3968496Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01609589159488678, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:27.3969434Z     return dequantize_per_tensor_default_1
2026-01-14T08:59:27.3969709Z     
2026-01-14T08:59:27.3969993Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:27.3970368Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:59:27.3970612Z           [0., 0., 0.],
2026-01-14T08:59:27.3970823Z           [0., 0., 0.]],
2026-01-14T08:59:27.3970973Z 
2026-01-14T08:59:27.3971051Z          [[0., 0., 0.],
2026-01-14T08:59:27.3971308Z           [0., 0., 0.],
2026-01-14T08:59:27.3971536Z           [0., 0., 0.]],
2026-01-14T08:59:27.3971689Z 
2026-01-14T08:59:27.3971773Z          [[0., 0., 0.],
2026-01-14T08:59:27.3971992Z           [0., 0., 0.],
2026-01-14T08:59:27.3972221Z           [0., 0., 0.]]]])
2026-01-14T08:59:27.3972476Z model pt2e: GraphModule(
2026-01-14T08:59:27.3972729Z   (conv): Module()
2026-01-14T08:59:27.3972944Z   (bn): Module()
2026-01-14T08:59:27.3973281Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3974640Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.3976148Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:59:27.3976840Z   )
2026-01-14T08:59:27.3977034Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:27.3977412Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3978686Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:27.3980219Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T08:59:27.3980894Z   )
2026-01-14T08:59:27.3981178Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:27.3982196Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:27.3983406Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T08:59:27.3983947Z   )
2026-01-14T08:59:27.3984118Z )
2026-01-14T08:59:27.3984212Z 
2026-01-14T08:59:27.3984216Z 
2026-01-14T08:59:27.3984220Z 
2026-01-14T08:59:27.3984312Z def forward(self, x):
2026-01-14T08:59:27.3984599Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:27.3984952Z     conv_weight = self.conv.weight
2026-01-14T08:59:27.3985222Z     conv_bias = self.conv.bias
2026-01-14T08:59:27.3985481Z     bn_weight = self.bn.weight
2026-01-14T08:59:27.3985734Z     bn_bias = self.bn.bias
2026-01-14T08:59:27.3985996Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:27.3986305Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:27.3986646Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:27.3987069Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:59:27.3987543Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:27.3988097Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:27.3988658Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:27.3989070Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T08:59:27.3989499Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T08:59:27.3989970Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T08:59:27.3990505Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T08:59:27.3991103Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T08:59:27.3991763Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T08:59:27.3992810Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T08:59:27.3993772Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T08:59:53.1643994Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T08:59:53.1644651Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T08:59:53.1645248Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T08:59:53.1646491Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T08:59:53.1647529Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T08:59:53.1648166Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T08:59:53.1648652Z     
2026-01-14T08:59:53.1648939Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.1649591Z model fx: GraphModule(
2026-01-14T08:59:53.1649916Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1650952Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.1652254Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:59:53.1652785Z   )
2026-01-14T08:59:53.1652981Z   (conv): ConvBn2d(
2026-01-14T08:59:53.1653211Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T08:59:53.1653671Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T08:59:53.1654173Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1655181Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T08:59:53.1656418Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18937721848487854, max_val=0.18946029245853424)
2026-01-14T08:59:53.1656967Z     )
2026-01-14T08:59:53.1657139Z   )
2026-01-14T08:59:53.1657421Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1658442Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0161]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.1659646Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9922423362731934, max_val=2.1162424087524414)
2026-01-14T08:59:53.1660288Z   )
2026-01-14T08:59:53.1660463Z )
2026-01-14T08:59:53.1660560Z 
2026-01-14T08:59:53.1660565Z 
2026-01-14T08:59:53.1660568Z 
2026-01-14T08:59:53.1660664Z def forward(self, x):
2026-01-14T08:59:53.1661020Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T08:59:53.1661572Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T08:59:53.1662130Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T08:59:53.1662573Z     return activation_post_process_1
2026-01-14T08:59:53.1662838Z     
2026-01-14T08:59:53.1663118Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.1663506Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:59:53.1663743Z           [0., 0., 0.],
2026-01-14T08:59:53.1663960Z           [0., 0., 0.]],
2026-01-14T08:59:53.1664098Z 
2026-01-14T08:59:53.1664180Z          [[0., 0., 0.],
2026-01-14T08:59:53.1664390Z           [0., 0., 0.],
2026-01-14T08:59:53.1664595Z           [0., 0., 0.]],
2026-01-14T08:59:53.1664751Z 
2026-01-14T08:59:53.1664831Z          [[0., 0., 0.],
2026-01-14T08:59:53.1665039Z           [0., 0., 0.],
2026-01-14T08:59:53.1665281Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T08:59:53.1665600Z converted model pt2e: GraphModule(
2026-01-14T08:59:53.1665862Z   (conv): Module()
2026-01-14T08:59:53.1666069Z   (bn): Module()
2026-01-14T08:59:53.1666276Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:53.1666510Z )
2026-01-14T08:59:53.1666605Z 
2026-01-14T08:59:53.1666609Z 
2026-01-14T08:59:53.1666613Z 
2026-01-14T08:59:53.1666698Z def forward(self, x):
2026-01-14T08:59:53.1667002Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:53.1667485Z     conv_bias = self.conv.bias
2026-01-14T08:59:53.1668126Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T08:59:53.1669426Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:53.1670448Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:53.1670820Z     quantize_per_tensor = self._frozen_param0
2026-01-14T08:59:53.1671669Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014918133383616805, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T08:59:53.1673024Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T08:59:53.1674317Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01611170545220375, -4, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T08:59:53.1675710Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T08:59:53.1676782Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T08:59:53.1677211Z     
2026-01-14T08:59:53.1677492Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.1677884Z onverted model fx: GraphModule(
2026-01-14T08:59:53.1678265Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T08:59:53.1678665Z )
2026-01-14T08:59:53.1678760Z 
2026-01-14T08:59:53.1678764Z 
2026-01-14T08:59:53.1678768Z 
2026-01-14T08:59:53.1678863Z def forward(self, x):
2026-01-14T08:59:53.1679509Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T08:59:53.1680875Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T08:59:53.1681949Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T08:59:53.1682848Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01611170545220375, -4, -128, 127, torch.int8);  conv = None
2026-01-14T08:59:53.1684204Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01611170545220375, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T08:59:53.1685139Z     return dequantize_per_tensor_default_1
2026-01-14T08:59:53.1685416Z     
2026-01-14T08:59:53.1685691Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T08:59:53.1686076Z diff: tensor([[[[0., 0., 0.],
2026-01-14T08:59:53.1686326Z           [0., 0., 0.],
2026-01-14T08:59:53.1686562Z           [0., 0., 0.]],
2026-01-14T08:59:53.1686722Z 
2026-01-14T08:59:53.1686801Z          [[0., 0., 0.],
2026-01-14T08:59:53.1687007Z           [0., 0., 0.],
2026-01-14T08:59:53.1687214Z           [0., 0., 0.]],
2026-01-14T08:59:53.1687353Z 
2026-01-14T08:59:53.1687428Z          [[0., 0., 0.],
2026-01-14T08:59:53.1687635Z           [0., 0., 0.],
2026-01-14T08:59:53.1687843Z           [0., 0., 0.]]]])
2026-01-14T08:59:53.1688304Z [32mPASSED[0m
2026-01-14T08:59:53.1688904Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_cuda model pt2e: GraphModule(
2026-01-14T08:59:53.1689537Z   (conv): Module()
2026-01-14T08:59:53.1689831Z   (bn): Module()
2026-01-14T08:59:53.1690132Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1691442Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.1692904Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T08:59:53.1693433Z   )
2026-01-14T08:59:53.1693619Z   (_guards_fn): GuardsFn()
2026-01-14T08:59:53.1693947Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1695261Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T08:59:53.1697004Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T08:59:53.1697787Z   )
2026-01-14T08:59:53.1698060Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T08:59:53.1699288Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T08:59:53.1700696Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T08:59:53.1701236Z   )
2026-01-14T08:59:53.1701403Z )
2026-01-14T08:59:53.1701498Z 
2026-01-14T08:59:53.1701508Z 
2026-01-14T08:59:53.1701512Z 
2026-01-14T08:59:53.1701604Z def forward(self, x):
2026-01-14T08:59:53.1701887Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T08:59:53.1702285Z     conv_weight = self.conv.weight
2026-01-14T08:59:53.1702556Z     conv_bias = self.conv.bias
2026-01-14T08:59:53.1702811Z     bn_weight = self.bn.weight
2026-01-14T08:59:53.1703063Z     bn_bias = self.bn.bias
2026-01-14T08:59:53.1703314Z     bn_running_mean = self.bn.running_mean
2026-01-14T08:59:53.1703622Z     bn_running_var = self.bn.running_var
2026-01-14T08:59:53.1703950Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T08:59:53.1704366Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T08:59:53.1704786Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T08:59:53.1705328Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T08:59:53.1705886Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T08:59:53.1706294Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:15.5213076Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:15.5213619Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:15.5214163Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:15.5214769Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:15.5215422Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:15.5216699Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:15.5218057Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:15.5219175Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:15.5219805Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:15.5220401Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:15.5221477Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:15.5222516Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:15.5223140Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:15.5223551Z     
2026-01-14T09:00:15.5223835Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:15.5224222Z model fx: GraphModule(
2026-01-14T09:00:15.5224553Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:15.5225813Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:15.5227258Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:15.5227791Z   )
2026-01-14T09:00:15.5228002Z   (conv): ConvBn2d(
2026-01-14T09:00:15.5228241Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:15.5228667Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:15.5229159Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:15.5230450Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:00:15.5232373Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:00:15.5233171Z     )
2026-01-14T09:00:15.5233339Z   )
2026-01-14T09:00:15.5233619Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:15.5234843Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0165], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:15.5236263Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1394810676574707, max_val=2.0564441680908203)
2026-01-14T09:00:15.5236817Z   )
2026-01-14T09:00:15.5236982Z )
2026-01-14T09:00:15.5237079Z 
2026-01-14T09:00:15.5237087Z 
2026-01-14T09:00:15.5237091Z 
2026-01-14T09:00:15.5237184Z def forward(self, x):
2026-01-14T09:00:15.5237539Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:15.5246217Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:15.5246861Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:15.5247305Z     return activation_post_process_1
2026-01-14T09:00:15.5247570Z     
2026-01-14T09:00:15.5247851Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:15.5248240Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:15.5248483Z           [0., 0., 0.],
2026-01-14T09:00:15.5248703Z           [0., 0., 0.]],
2026-01-14T09:00:15.5248847Z 
2026-01-14T09:00:15.5249326Z          [[0., 0., 0.],
2026-01-14T09:00:15.5249582Z           [0., 0., 0.],
2026-01-14T09:00:15.5249794Z           [0., 0., 0.]],
2026-01-14T09:00:15.5249933Z 
2026-01-14T09:00:15.5250013Z          [[0., 0., 0.],
2026-01-14T09:00:15.5250225Z           [0., 0., 0.],
2026-01-14T09:00:15.5250569Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:00:15.5250925Z converted model pt2e: GraphModule(
2026-01-14T09:00:15.5251191Z   (conv): Module()
2026-01-14T09:00:15.5251498Z   (bn): Module()
2026-01-14T09:00:15.5251710Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:15.5251929Z )
2026-01-14T09:00:15.5252028Z 
2026-01-14T09:00:15.5252033Z 
2026-01-14T09:00:15.5252037Z 
2026-01-14T09:00:15.5252130Z def forward(self, x):
2026-01-14T09:00:15.5252415Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:15.5252765Z     conv_bias = self.conv.bias
2026-01-14T09:00:15.5253405Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:00:15.5254697Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:15.5255666Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:15.5255997Z     _scale_0 = self._scale_0
2026-01-14T09:00:15.5256262Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:00:15.5256566Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:00:15.5257514Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:00:15.5258977Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:00:15.5260258Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016454609110951424, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:15.5261732Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:15.5262804Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:00:15.5263228Z     
2026-01-14T09:00:15.5263521Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:15.5263904Z onverted model fx: GraphModule(
2026-01-14T09:00:15.5264295Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:15.5264680Z )
2026-01-14T09:00:15.5264784Z 
2026-01-14T09:00:15.5264788Z 
2026-01-14T09:00:15.5264792Z 
2026-01-14T09:00:15.5264882Z def forward(self, x):
2026-01-14T09:00:15.5265533Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:15.5266849Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:15.5267926Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:15.5268828Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016454609110951424, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:15.5270178Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016454609110951424, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:15.5271230Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:15.5271504Z     
2026-01-14T09:00:15.5271794Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:15.5272173Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:15.5272421Z           [0., 0., 0.],
2026-01-14T09:00:15.5272690Z           [0., 0., 0.]],
2026-01-14T09:00:15.5272833Z 
2026-01-14T09:00:15.5272909Z          [[0., 0., 0.],
2026-01-14T09:00:15.5273124Z           [0., 0., 0.],
2026-01-14T09:00:15.5273328Z           [0., 0., 0.]],
2026-01-14T09:00:15.5273477Z 
2026-01-14T09:00:15.5273550Z          [[0., 0., 0.],
2026-01-14T09:00:15.5273753Z           [0., 0., 0.],
2026-01-14T09:00:15.5273983Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:00:15.5274259Z model pt2e: GraphModule(
2026-01-14T09:00:15.5274496Z   (conv): Module()
2026-01-14T09:00:15.5274693Z   (bn): Module()
2026-01-14T09:00:15.5274997Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:15.5276244Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:15.5277655Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:15.5278193Z   )
2026-01-14T09:00:15.5278376Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:15.5278716Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:15.5279961Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:15.5281389Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:00:15.5281941Z   )
2026-01-14T09:00:15.5282259Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:44.2035995Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:44.2037978Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:00:44.2038682Z   )
2026-01-14T09:00:44.2038888Z )
2026-01-14T09:00:44.2039018Z 
2026-01-14T09:00:44.2039023Z 
2026-01-14T09:00:44.2039028Z 
2026-01-14T09:00:44.2039136Z def forward(self, x):
2026-01-14T09:00:44.2039496Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:44.2039950Z     conv_weight = self.conv.weight
2026-01-14T09:00:44.2040316Z     conv_bias = self.conv.bias
2026-01-14T09:00:44.2040632Z     bn_weight = self.bn.weight
2026-01-14T09:00:44.2040953Z     bn_bias = self.bn.bias
2026-01-14T09:00:44.2041268Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:00:44.2041657Z     bn_running_var = self.bn.running_var
2026-01-14T09:00:44.2042115Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:00:44.2042641Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:00:44.2043186Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:44.2043859Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:00:44.2044567Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:00:44.2045061Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:00:44.2045591Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:00:44.2048051Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:00:44.2048732Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:00:44.2049666Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:00:44.2050595Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:00:44.2052030Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:00:44.2053233Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:00:44.2053936Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:00:44.2054696Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:00:44.2055442Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:00:44.2056655Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:00:44.2057973Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:00:44.2058756Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:00:44.2059254Z     
2026-01-14T09:00:44.2059603Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:44.2060074Z model fx: GraphModule(
2026-01-14T09:00:44.2060469Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:44.2062057Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:44.2063988Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:00:44.2064675Z   )
2026-01-14T09:00:44.2064887Z   (conv): ConvBn2d(
2026-01-14T09:00:44.2065168Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:00:44.2065697Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:00:44.2066305Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:44.2067860Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:00:44.2069712Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:00:44.2070403Z     )
2026-01-14T09:00:44.2070616Z   )
2026-01-14T09:00:44.2070950Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:00:44.2072532Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0164], device='cuda:0'), zero_point=tensor([2], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:00:44.2074334Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.137371778488159, max_val=2.0522286891937256)
2026-01-14T09:00:44.2075016Z   )
2026-01-14T09:00:44.2075229Z )
2026-01-14T09:00:44.2075351Z 
2026-01-14T09:00:44.2075356Z 
2026-01-14T09:00:44.2075360Z 
2026-01-14T09:00:44.2075463Z def forward(self, x):
2026-01-14T09:00:44.2076036Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:00:44.2076773Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:00:44.2077538Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:00:44.2078084Z     return activation_post_process_1
2026-01-14T09:00:44.2078341Z     
2026-01-14T09:00:44.2078621Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:44.2079006Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:44.2079245Z           [0., 0., 0.],
2026-01-14T09:00:44.2079455Z           [0., 0., 0.]],
2026-01-14T09:00:44.2079601Z 
2026-01-14T09:00:44.2079677Z          [[0., 0., 0.],
2026-01-14T09:00:44.2079885Z           [0., 0., 0.],
2026-01-14T09:00:44.2080099Z           [0., 0., 0.]],
2026-01-14T09:00:44.2080237Z 
2026-01-14T09:00:44.2080314Z          [[0., 0., 0.],
2026-01-14T09:00:44.2080523Z           [0., 0., 0.],
2026-01-14T09:00:44.2080809Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:00:44.2081156Z converted model pt2e: GraphModule(
2026-01-14T09:00:44.2081426Z   (conv): Module()
2026-01-14T09:00:44.2081624Z   (bn): Module()
2026-01-14T09:00:44.2081842Z   (_guards_fn): GuardsFn()
2026-01-14T09:00:44.2082063Z )
2026-01-14T09:00:44.2082170Z 
2026-01-14T09:00:44.2082174Z 
2026-01-14T09:00:44.2082178Z 
2026-01-14T09:00:44.2082261Z def forward(self, x):
2026-01-14T09:00:44.2082543Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:00:44.2082895Z     conv_bias = self.conv.bias
2026-01-14T09:00:44.2083534Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:00:44.2084816Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:44.2085790Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:00:44.2086151Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:00:44.2086990Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:00:44.2088397Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:00:44.2089670Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.016429806128144264, 2, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:00:44.2091056Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:00:44.2092217Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:00:44.2092640Z     
2026-01-14T09:00:44.2092927Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:44.2093315Z onverted model fx: GraphModule(
2026-01-14T09:00:44.2093707Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:00:44.2094094Z )
2026-01-14T09:00:44.2094199Z 
2026-01-14T09:00:44.2094203Z 
2026-01-14T09:00:44.2094206Z 
2026-01-14T09:00:44.2094293Z def forward(self, x):
2026-01-14T09:00:44.2094939Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:00:44.2096252Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:00:44.2097407Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:00:44.2098313Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.016429806128144264, 2, -128, 127, torch.int8);  conv = None
2026-01-14T09:00:44.2099703Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.016429806128144264, 2, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:00:44.2100644Z     return dequantize_per_tensor_default_1
2026-01-14T09:00:44.2100918Z     
2026-01-14T09:00:44.2101205Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:00:44.2101587Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:00:44.2101827Z           [0., 0., 0.],
2026-01-14T09:00:44.2102043Z           [0., 0., 0.]],
2026-01-14T09:00:44.2102183Z 
2026-01-14T09:00:44.2102260Z          [[0., 0., 0.],
2026-01-14T09:00:44.2102479Z           [0., 0., 0.],
2026-01-14T09:00:44.2102686Z           [0., 0., 0.]],
2026-01-14T09:00:44.2102836Z 
2026-01-14T09:00:44.2102913Z          [[0., 0., 0.],
2026-01-14T09:00:44.2103114Z           [0., 0., 0.],
2026-01-14T09:00:44.2103352Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:00:44.2103836Z [32mPASSED[0m
2026-01-14T09:00:44.2104466Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_literal_args model pt2e: GraphModule(
2026-01-14T09:00:44.2105146Z   (conv): Module()
2026-01-14T09:00:44.2105357Z   (bn): Module()
2026-01-14T09:00:44.2105657Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3555485Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:00.3557218Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:00.3558042Z   )
2026-01-14T09:01:00.3558311Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:00.3558788Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3560557Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:00.3562675Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:00.3563754Z   )
2026-01-14T09:01:00.3564149Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3565252Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:00.3566459Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:00.3567000Z   )
2026-01-14T09:01:00.3567169Z )
2026-01-14T09:01:00.3567271Z 
2026-01-14T09:01:00.3567275Z 
2026-01-14T09:01:00.3567284Z 
2026-01-14T09:01:00.3567373Z def forward(self, x):
2026-01-14T09:01:00.3567666Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:00.3568025Z     conv_weight = self.conv.weight
2026-01-14T09:01:00.3568304Z     conv_bias = self.conv.bias
2026-01-14T09:01:00.3568568Z     bn_weight = self.bn.weight
2026-01-14T09:01:00.3568827Z     bn_bias = self.bn.bias
2026-01-14T09:01:00.3569088Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:00.3569398Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:00.3569733Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:00.3570363Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:00.3570794Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:00.3571480Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:00.3572130Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:00.3572536Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:00.3572965Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:00.3573425Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:00.3573955Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:00.3574548Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:00.3575203Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:00.3576289Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:00.3577267Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:00.3577841Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:00.3578455Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:00.3579053Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:00.3580029Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:00.3581061Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:00.3581683Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:00.3582082Z     
2026-01-14T09:01:00.3582423Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:00.3582800Z model fx: GraphModule(
2026-01-14T09:01:00.3583130Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3584169Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:00.3585378Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:00.3585918Z   )
2026-01-14T09:01:00.3586097Z   (conv): ConvBn2d(
2026-01-14T09:01:00.3586370Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:01:00.3586849Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:00.3587343Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3588421Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:00.3589856Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1897, -0.1774, -0.1913]), max_val=tensor([0.1806, 0.1870, 0.1478]))
2026-01-14T09:01:00.3590550Z     )
2026-01-14T09:01:00.3590727Z   )
2026-01-14T09:01:00.3591001Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:00.3592171Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0279]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:00.3593372Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.481316328048706, max_val=3.622279405593872)
2026-01-14T09:01:00.3593910Z   )
2026-01-14T09:01:00.3594080Z )
2026-01-14T09:01:00.3594186Z 
2026-01-14T09:01:00.3594234Z 
2026-01-14T09:01:00.3594238Z 
2026-01-14T09:01:00.3594326Z def forward(self, x):
2026-01-14T09:01:00.3594687Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:00.3595238Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:00.3595807Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:00.3596244Z     return activation_post_process_1
2026-01-14T09:01:00.3596510Z     
2026-01-14T09:01:00.3596793Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:00.3597186Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3597474Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3597727Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3597981Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3598231Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3598485Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:00.3598659Z 
2026-01-14T09:01:00.3598741Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3598996Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3599242Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3599494Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3599743Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3599989Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:00.3600161Z 
2026-01-14T09:01:00.3600251Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3600495Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3600744Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3600989Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3601271Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:00.3601593Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:00.3601937Z converted model pt2e: GraphModule(
2026-01-14T09:01:00.3602260Z   (conv): Module()
2026-01-14T09:01:00.3602463Z   (bn): Module()
2026-01-14T09:01:00.3602681Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:00.3602908Z )
2026-01-14T09:01:00.3603008Z 
2026-01-14T09:01:00.3603017Z 
2026-01-14T09:01:00.3603021Z 
2026-01-14T09:01:00.3603108Z def forward(self, x):
2026-01-14T09:01:00.3603398Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:00.3603746Z     conv_bias = self.conv.bias
2026-01-14T09:01:00.3604389Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8)
2026-01-14T09:01:00.3605683Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:00.3606652Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:00.3606984Z     _scale_0 = self._scale_0
2026-01-14T09:01:00.3607253Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:00.3607562Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:01:00.3608519Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:00.3610008Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:01:00.3611456Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.027857238426804543, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:00.3612857Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:00.3613936Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:01:00.3614401Z     
2026-01-14T09:01:00.3614690Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:00.3615075Z onverted model fx: GraphModule(
2026-01-14T09:01:00.3615518Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:01:00.3615971Z )
2026-01-14T09:01:00.3616069Z 
2026-01-14T09:01:00.3616073Z 
2026-01-14T09:01:00.3616077Z 
2026-01-14T09:01:00.3616163Z def forward(self, x):
2026-01-14T09:01:00.3616817Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:22.8166048Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:22.8167474Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:22.8168644Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.027857238426804543, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:22.8170410Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.027857238426804543, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:22.8171734Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:22.8172075Z     
2026-01-14T09:01:22.8172428Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:22.8173007Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8173357Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8173662Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8174151Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8174456Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8174761Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:22.8174975Z 
2026-01-14T09:01:22.8175082Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8175380Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8175686Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8175985Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8176320Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8176643Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:22.8176863Z 
2026-01-14T09:01:22.8176961Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8177262Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8177580Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8177886Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8178227Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8178543Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:01:22.8178871Z model pt2e: GraphModule(
2026-01-14T09:01:22.8179160Z   (conv): Module()
2026-01-14T09:01:22.8179407Z   (bn): Module()
2026-01-14T09:01:22.8179770Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8181082Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:22.8182639Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:22.8183314Z   )
2026-01-14T09:01:22.8183546Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:22.8185621Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8186948Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:22.8188597Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:01:22.8189291Z   )
2026-01-14T09:01:22.8189636Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8190924Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:22.8192457Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:01:22.8193131Z   )
2026-01-14T09:01:22.8193337Z )
2026-01-14T09:01:22.8193463Z 
2026-01-14T09:01:22.8193469Z 
2026-01-14T09:01:22.8193474Z 
2026-01-14T09:01:22.8193583Z def forward(self, x):
2026-01-14T09:01:22.8193935Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:22.8194373Z     conv_weight = self.conv.weight
2026-01-14T09:01:22.8194710Z     conv_bias = self.conv.bias
2026-01-14T09:01:22.8195027Z     bn_weight = self.bn.weight
2026-01-14T09:01:22.8195329Z     bn_bias = self.bn.bias
2026-01-14T09:01:22.8195644Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:22.8196015Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:22.8196437Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:22.8196964Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:22.8197489Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:22.8198167Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:22.8198868Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:22.8199366Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:22.8199936Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:22.8200508Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:22.8201160Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:22.8201905Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:22.8202728Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:01:22.8204108Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like, [2, 2], [4, 4]);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:01:22.8205355Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:22.8216254Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:22.8217071Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:01:22.8217822Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:01:22.8219046Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:22.8220398Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:22.8221251Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:22.8221724Z     
2026-01-14T09:01:22.8222013Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:22.8222507Z model fx: GraphModule(
2026-01-14T09:01:22.8222841Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8223880Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0165]), zero_point=tensor([-18], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:22.8225138Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8076945543289185, max_val=2.388113498687744)
2026-01-14T09:01:22.8225677Z   )
2026-01-14T09:01:22.8225849Z   (conv): ConvBn2d(
2026-01-14T09:01:22.8226125Z     3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4)
2026-01-14T09:01:22.8226593Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:22.8227140Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8228150Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:22.8229375Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19127479195594788, max_val=0.1870359182357788)
2026-01-14T09:01:22.8229931Z     )
2026-01-14T09:01:22.8230105Z   )
2026-01-14T09:01:22.8230382Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:22.8231413Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0278]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:22.8232611Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4796082973480225, max_val=3.620413064956665)
2026-01-14T09:01:22.8233148Z   )
2026-01-14T09:01:22.8233316Z )
2026-01-14T09:01:22.8233423Z 
2026-01-14T09:01:22.8233427Z 
2026-01-14T09:01:22.8233431Z 
2026-01-14T09:01:22.8233519Z def forward(self, x):
2026-01-14T09:01:22.8233878Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:22.8234474Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:22.8235047Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:22.8235485Z     return activation_post_process_1
2026-01-14T09:01:22.8235748Z     
2026-01-14T09:01:22.8236024Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:22.8236408Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8236680Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8236931Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8237185Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8237426Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8237676Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:22.8237844Z 
2026-01-14T09:01:22.8237927Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8238175Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8238412Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8238661Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8238901Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8239155Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:22.8239322Z 
2026-01-14T09:01:22.8239407Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8239646Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8239892Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8240130Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8240378Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:22.8240669Z           [0., 0., 0., 0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:22.8241012Z converted model pt2e: GraphModule(
2026-01-14T09:01:22.8241268Z   (conv): Module()
2026-01-14T09:01:22.8241468Z   (bn): Module()
2026-01-14T09:01:22.8241676Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:22.8241987Z )
2026-01-14T09:01:22.8242083Z 
2026-01-14T09:01:22.8242087Z 
2026-01-14T09:01:22.8242091Z 
2026-01-14T09:01:22.8242185Z def forward(self, x):
2026-01-14T09:01:22.8242471Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:22.8242856Z     conv_bias = self.conv.bias
2026-01-14T09:01:22.8243493Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8)
2026-01-14T09:01:22.8244789Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:22.8245760Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:22.8246115Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:01:32.3007285Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0015061007579788566, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:01:32.3009191Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias, [2, 2], [4, 4]);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:01:32.3010885Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.02784322015941143, -3, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:32.3012797Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:01:32.3014186Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:01:32.3014719Z     
2026-01-14T09:01:32.3015080Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:32.3015572Z onverted model fx: GraphModule(
2026-01-14T09:01:32.3016126Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(4, 4))
2026-01-14T09:01:32.3016892Z )
2026-01-14T09:01:32.3017029Z 
2026-01-14T09:01:32.3017035Z 
2026-01-14T09:01:32.3017044Z 
2026-01-14T09:01:32.3017150Z def forward(self, x):
2026-01-14T09:01:32.3017985Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.016454149037599564, -18, -128, 127, torch.int8);  x = None
2026-01-14T09:01:32.3019695Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.016454149037599564, -18, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:32.3021084Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:32.3022242Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.02784322015941143, -3, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:32.3024020Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.02784322015941143, -3, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:32.3025237Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:32.3025517Z     
2026-01-14T09:01:32.3025814Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:32.3026213Z diff: tensor([[[[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3026489Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3026748Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3027001Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3027259Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3027510Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:32.3027691Z 
2026-01-14T09:01:32.3027775Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3028188Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3028449Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3028704Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3028951Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3029203Z           [0., 0., 0., 0., 0., 0.]],
2026-01-14T09:01:32.3029460Z 
2026-01-14T09:01:32.3029545Z          [[0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3029788Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3030042Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3030293Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3030538Z           [0., 0., 0., 0., 0., 0.],
2026-01-14T09:01:32.3030793Z           [0., 0., 0., 0., 0., 0.]]]])
2026-01-14T09:01:32.3031257Z [32mPASSED[0m
2026-01-14T09:01:32.3031896Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:01:32.3032561Z   (conv): Module()
2026-01-14T09:01:32.3032779Z   (bn): Module()
2026-01-14T09:01:32.3033086Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3034129Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:32.3035356Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:01:32.3035903Z   )
2026-01-14T09:01:32.3036099Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:32.3036433Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3037527Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:32.3039011Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:01:32.3039744Z   )
2026-01-14T09:01:32.3040023Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3041047Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:32.3042253Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:01:32.3042786Z   )
2026-01-14T09:01:32.3042950Z )
2026-01-14T09:01:32.3043046Z 
2026-01-14T09:01:32.3043057Z 
2026-01-14T09:01:32.3043061Z 
2026-01-14T09:01:32.3043146Z def forward(self, x):
2026-01-14T09:01:32.3043434Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:32.3043792Z     conv_weight = self.conv.weight
2026-01-14T09:01:32.3044075Z     bn_weight = self.bn.weight
2026-01-14T09:01:32.3044329Z     bn_bias = self.bn.bias
2026-01-14T09:01:32.3044593Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:32.3044897Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:32.3045236Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:32.3045653Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:32.3046084Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:32.3046623Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:32.3047190Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:32.3047594Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:32.3048012Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:32.3048564Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:32.3049466Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:32.3050062Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:32.3050958Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:01:32.3051970Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:32.3052546Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:32.3053534Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:32.3054576Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:32.3055198Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:32.3055600Z     
2026-01-14T09:01:32.3055891Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:32.3056267Z model fx: GraphModule(
2026-01-14T09:01:32.3056603Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3057632Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:32.3058903Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:01:32.3059447Z   )
2026-01-14T09:01:32.3059624Z   (conv): ConvBn2d(
2026-01-14T09:01:32.3059892Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:01:32.3060352Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:32.3060848Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3061983Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:01:32.3063419Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:01:32.3064108Z     )
2026-01-14T09:01:32.3064281Z   )
2026-01-14T09:01:32.3064567Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:32.3065594Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:32.3066795Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1459269523620605, max_val=2.376943349838257)
2026-01-14T09:01:32.3067336Z   )
2026-01-14T09:01:32.3067500Z )
2026-01-14T09:01:32.3067596Z 
2026-01-14T09:01:32.3067609Z 
2026-01-14T09:01:32.3067614Z 
2026-01-14T09:01:32.3067699Z def forward(self, x):
2026-01-14T09:01:32.3068050Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:01:32.3068603Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:01:32.3069170Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:01:32.3069605Z     return activation_post_process_1
2026-01-14T09:01:32.3069870Z     
2026-01-14T09:01:32.3070151Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:32.3070532Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:32.3070767Z           [0., 0., 0.],
2026-01-14T09:01:32.3071104Z           [0., 0., 0.]],
2026-01-14T09:01:32.3071246Z 
2026-01-14T09:01:32.3071322Z          [[0., 0., 0.],
2026-01-14T09:01:32.3071534Z           [0., 0., 0.],
2026-01-14T09:01:32.3071747Z           [0., 0., 0.]],
2026-01-14T09:01:32.3071890Z 
2026-01-14T09:01:32.3072010Z          [[0., 0., 0.],
2026-01-14T09:01:32.3072220Z           [0., 0., 0.],
2026-01-14T09:01:32.3072426Z           [0., 0., 0.]]],
2026-01-14T09:01:32.3072573Z 
2026-01-14T09:01:32.3072582Z 
2026-01-14T09:01:32.3072656Z         [[[0., 0., 0.],
2026-01-14T09:01:32.3072866Z           [0., 0., 0.],
2026-01-14T09:01:54.6679668Z           [0., 0., 0.]],
2026-01-14T09:01:54.6679983Z 
2026-01-14T09:01:54.6680080Z          [[0., 0., 0.],
2026-01-14T09:01:54.6680338Z           [0., 0., 0.],
2026-01-14T09:01:54.6680606Z           [0., 0., 0.]],
2026-01-14T09:01:54.6680779Z 
2026-01-14T09:01:54.6680879Z          [[0., 0., 0.],
2026-01-14T09:01:54.6681131Z           [0., 0., 0.],
2026-01-14T09:01:54.6681421Z           [0., 0., 0.]]],
2026-01-14T09:01:54.6681603Z 
2026-01-14T09:01:54.6681608Z 
2026-01-14T09:01:54.6681703Z         [[[0., 0., 0.],
2026-01-14T09:01:54.6681961Z           [0., 0., 0.],
2026-01-14T09:01:54.6682222Z           [0., 0., 0.]],
2026-01-14T09:01:54.6682402Z 
2026-01-14T09:01:54.6682511Z          [[0., 0., 0.],
2026-01-14T09:01:54.6682760Z           [0., 0., 0.],
2026-01-14T09:01:54.6683076Z           [0., 0., 0.]],
2026-01-14T09:01:54.6683256Z 
2026-01-14T09:01:54.6683357Z          [[0., 0., 0.],
2026-01-14T09:01:54.6683606Z           [0., 0., 0.],
2026-01-14T09:01:54.6683906Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:01:54.6684301Z converted model pt2e: GraphModule(
2026-01-14T09:01:54.6684633Z   (conv): Module()
2026-01-14T09:01:54.6684876Z   (bn): Module()
2026-01-14T09:01:54.6685138Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:54.6685408Z )
2026-01-14T09:01:54.6685534Z 
2026-01-14T09:01:54.6685539Z 
2026-01-14T09:01:54.6685544Z 
2026-01-14T09:01:54.6685645Z def forward(self, x):
2026-01-14T09:01:54.6686011Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:54.6686933Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:01:54.6688831Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:54.6690063Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:54.6690485Z     _scale_0 = self._scale_0
2026-01-14T09:01:54.6690806Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:01:54.6691180Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:01:54.6692510Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:01:54.6693718Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:01:54.6694850Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:01:54.6696618Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01773674599826336, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:01:54.6698405Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:54.6699765Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:01:54.6700305Z     
2026-01-14T09:01:54.6700648Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:54.6701323Z onverted model fx: GraphModule(
2026-01-14T09:01:54.6701804Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:01:54.6702303Z )
2026-01-14T09:01:54.6702421Z 
2026-01-14T09:01:54.6702426Z 
2026-01-14T09:01:54.6702431Z 
2026-01-14T09:01:54.6702622Z def forward(self, x):
2026-01-14T09:01:54.6703464Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:01:54.6705179Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:01:54.6706557Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:01:54.6707700Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01773674599826336, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:01:54.6709493Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01773674599826336, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:01:54.6710442Z     return dequantize_per_tensor_default_1
2026-01-14T09:01:54.6710723Z     
2026-01-14T09:01:54.6711003Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:54.6711397Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:01:54.6711641Z           [0., 0., 0.],
2026-01-14T09:01:54.6711853Z           [0., 0., 0.]],
2026-01-14T09:01:54.6711996Z 
2026-01-14T09:01:54.6712080Z          [[0., 0., 0.],
2026-01-14T09:01:54.6712287Z           [0., 0., 0.],
2026-01-14T09:01:54.6712502Z           [0., 0., 0.]],
2026-01-14T09:01:54.6712643Z 
2026-01-14T09:01:54.6712718Z          [[0., 0., 0.],
2026-01-14T09:01:54.6712928Z           [0., 0., 0.],
2026-01-14T09:01:54.6713146Z           [0., 0., 0.]]],
2026-01-14T09:01:54.6713301Z 
2026-01-14T09:01:54.6713305Z 
2026-01-14T09:01:54.6713383Z         [[[0., 0., 0.],
2026-01-14T09:01:54.6713598Z           [0., 0., 0.],
2026-01-14T09:01:54.6713862Z           [0., 0., 0.]],
2026-01-14T09:01:54.6714002Z 
2026-01-14T09:01:54.6714090Z          [[0., 0., 0.],
2026-01-14T09:01:54.6714296Z           [0., 0., 0.],
2026-01-14T09:01:54.6714509Z           [0., 0., 0.]],
2026-01-14T09:01:54.6714648Z 
2026-01-14T09:01:54.6714726Z          [[0., 0., 0.],
2026-01-14T09:01:54.6714934Z           [0., 0., 0.],
2026-01-14T09:01:54.6715137Z           [0., 0., 0.]]],
2026-01-14T09:01:54.6715290Z 
2026-01-14T09:01:54.6715294Z 
2026-01-14T09:01:54.6715371Z         [[[0., 0., 0.],
2026-01-14T09:01:54.6715583Z           [0., 0., 0.],
2026-01-14T09:01:54.6715788Z           [0., 0., 0.]],
2026-01-14T09:01:54.6715926Z 
2026-01-14T09:01:54.6716009Z          [[0., 0., 0.],
2026-01-14T09:01:54.6716210Z           [0., 0., 0.],
2026-01-14T09:01:54.6716425Z           [0., 0., 0.]],
2026-01-14T09:01:54.6716568Z 
2026-01-14T09:01:54.6716645Z          [[0., 0., 0.],
2026-01-14T09:01:54.6716853Z           [0., 0., 0.],
2026-01-14T09:01:54.6717068Z           [0., 0., 0.]]]])
2026-01-14T09:01:54.6717302Z model pt2e: GraphModule(
2026-01-14T09:01:54.6717536Z   (conv): Module()
2026-01-14T09:01:54.6717738Z   (bn): Module()
2026-01-14T09:01:54.6718042Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:54.6719071Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:54.6720320Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:01:54.6720865Z   )
2026-01-14T09:01:54.6721051Z   (_guards_fn): GuardsFn()
2026-01-14T09:01:54.6721509Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:54.6722541Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:54.6723819Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:01:54.6724371Z   )
2026-01-14T09:01:54.6724647Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:54.6725677Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:54.6726874Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:01:54.6727410Z   )
2026-01-14T09:01:54.6727582Z )
2026-01-14T09:01:54.6727686Z 
2026-01-14T09:01:54.6727690Z 
2026-01-14T09:01:54.6727694Z 
2026-01-14T09:01:54.6727779Z def forward(self, x):
2026-01-14T09:01:54.6728073Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:01:54.6728426Z     conv_weight = self.conv.weight
2026-01-14T09:01:54.6728710Z     bn_weight = self.bn.weight
2026-01-14T09:01:54.6728963Z     bn_bias = self.bn.bias
2026-01-14T09:01:54.6729228Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:01:54.6729527Z     bn_running_var = self.bn.running_var
2026-01-14T09:01:54.6729873Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:01:54.6730297Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:01:54.6730727Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:01:54.6731273Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:01:54.6731968Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:01:54.6732378Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:01:54.6732801Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:01:54.6733329Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:01:54.6733863Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:01:54.6734450Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:01:54.6735345Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:01:54.6736222Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:01:54.6736790Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:01:54.6737786Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:01:54.6738816Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:01:54.6739438Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:01:54.6739834Z     
2026-01-14T09:01:54.6740121Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:01:54.6740500Z model fx: GraphModule(
2026-01-14T09:01:54.6740830Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:54.6741857Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:01:54.6743153Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:01:54.6743701Z   )
2026-01-14T09:01:54.6743878Z   (conv): ConvBn2d(
2026-01-14T09:01:54.6744134Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:01:54.6744593Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:01:54.6745125Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:01:54.6746135Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:01:54.6747359Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:01:54.6747911Z     )
2026-01-14T09:01:54.6748093Z   )
2026-01-14T09:01:54.6748369Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0032014Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0177]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:14.0033655Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1475415229797363, max_val=2.368046283721924)
2026-01-14T09:02:14.0034347Z   )
2026-01-14T09:02:14.0034560Z )
2026-01-14T09:02:14.0034677Z 
2026-01-14T09:02:14.0034682Z 
2026-01-14T09:02:14.0034687Z 
2026-01-14T09:02:14.0034800Z def forward(self, x):
2026-01-14T09:02:14.0035239Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:14.0035933Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:14.0036638Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:02:14.0037205Z     return activation_post_process_1
2026-01-14T09:02:14.0037528Z     
2026-01-14T09:02:14.0037941Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:14.0038456Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:14.0038942Z           [0., 0., 0.],
2026-01-14T09:02:14.0039208Z           [0., 0., 0.]],
2026-01-14T09:02:14.0039381Z 
2026-01-14T09:02:14.0039491Z          [[0., 0., 0.],
2026-01-14T09:02:14.0039752Z           [0., 0., 0.],
2026-01-14T09:02:14.0040024Z           [0., 0., 0.]],
2026-01-14T09:02:14.0040195Z 
2026-01-14T09:02:14.0040288Z          [[0., 0., 0.],
2026-01-14T09:02:14.0040551Z           [0., 0., 0.],
2026-01-14T09:02:14.0040805Z           [0., 0., 0.]]],
2026-01-14T09:02:14.0040989Z 
2026-01-14T09:02:14.0040994Z 
2026-01-14T09:02:14.0041088Z         [[[0., 0., 0.],
2026-01-14T09:02:14.0041349Z           [0., 0., 0.],
2026-01-14T09:02:14.0041605Z           [0., 0., 0.]],
2026-01-14T09:02:14.0041775Z 
2026-01-14T09:02:14.0041878Z          [[0., 0., 0.],
2026-01-14T09:02:14.0042132Z           [0., 0., 0.],
2026-01-14T09:02:14.0042400Z           [0., 0., 0.]],
2026-01-14T09:02:14.0042570Z 
2026-01-14T09:02:14.0042661Z          [[0., 0., 0.],
2026-01-14T09:02:14.0042921Z           [0., 0., 0.],
2026-01-14T09:02:14.0043175Z           [0., 0., 0.]]],
2026-01-14T09:02:14.0043356Z 
2026-01-14T09:02:14.0043360Z 
2026-01-14T09:02:14.0043457Z         [[[0., 0., 0.],
2026-01-14T09:02:14.0043712Z           [0., 0., 0.],
2026-01-14T09:02:14.0043967Z           [0., 0., 0.]],
2026-01-14T09:02:14.0044137Z 
2026-01-14T09:02:14.0044246Z          [[0., 0., 0.],
2026-01-14T09:02:14.0044494Z           [0., 0., 0.],
2026-01-14T09:02:14.0044754Z           [0., 0., 0.]],
2026-01-14T09:02:14.0044925Z 
2026-01-14T09:02:14.0045016Z          [[0., 0., 0.],
2026-01-14T09:02:14.0045280Z           [0., 0., 0.],
2026-01-14T09:02:14.0045579Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:14.0045990Z converted model pt2e: GraphModule(
2026-01-14T09:02:14.0046321Z   (conv): Module()
2026-01-14T09:02:14.0046566Z   (bn): Module()
2026-01-14T09:02:14.0047015Z   (_guards_fn): GuardsFn()
2026-01-14T09:02:14.0047293Z )
2026-01-14T09:02:14.0047413Z 
2026-01-14T09:02:14.0047417Z 
2026-01-14T09:02:14.0047430Z 
2026-01-14T09:02:14.0047542Z def forward(self, x):
2026-01-14T09:02:14.0047898Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:14.0048904Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:02:14.0050761Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:14.0052110Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:02:14.0052564Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:02:14.0053641Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:02:14.0054733Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:02:14.0055925Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:02:14.0066116Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.01770818792283535, -7, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:02:14.0067524Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:14.0072084Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:14.0072559Z     
2026-01-14T09:02:14.0072861Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:14.0073268Z onverted model fx: GraphModule(
2026-01-14T09:02:14.0073670Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:14.0074164Z )
2026-01-14T09:02:14.0074266Z 
2026-01-14T09:02:14.0074274Z 
2026-01-14T09:02:14.0074277Z 
2026-01-14T09:02:14.0074366Z def forward(self, x):
2026-01-14T09:02:14.0075031Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:14.0076370Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:14.0077447Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:14.0078387Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.01770818792283535, -7, -128, 127, torch.int8);  conv = None
2026-01-14T09:02:14.0079756Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01770818792283535, -7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:14.0080711Z     return dequantize_per_tensor_default_1
2026-01-14T09:02:14.0081003Z     
2026-01-14T09:02:14.0081291Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:14.0081685Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:02:14.0081930Z           [0., 0., 0.],
2026-01-14T09:02:14.0082157Z           [0., 0., 0.]],
2026-01-14T09:02:14.0082306Z 
2026-01-14T09:02:14.0082387Z          [[0., 0., 0.],
2026-01-14T09:02:14.0082609Z           [0., 0., 0.],
2026-01-14T09:02:14.0082833Z           [0., 0., 0.]],
2026-01-14T09:02:14.0082977Z 
2026-01-14T09:02:14.0083059Z          [[0., 0., 0.],
2026-01-14T09:02:14.0083349Z           [0., 0., 0.],
2026-01-14T09:02:14.0083572Z           [0., 0., 0.]]],
2026-01-14T09:02:14.0083720Z 
2026-01-14T09:02:14.0083734Z 
2026-01-14T09:02:14.0083814Z         [[[0., 0., 0.],
2026-01-14T09:02:14.0084031Z           [0., 0., 0.],
2026-01-14T09:02:14.0084252Z           [0., 0., 0.]],
2026-01-14T09:02:14.0084456Z 
2026-01-14T09:02:14.0084538Z          [[0., 0., 0.],
2026-01-14T09:02:14.0084761Z           [0., 0., 0.],
2026-01-14T09:02:14.0084981Z           [0., 0., 0.]],
2026-01-14T09:02:14.0085124Z 
2026-01-14T09:02:14.0085202Z          [[0., 0., 0.],
2026-01-14T09:02:14.0085420Z           [0., 0., 0.],
2026-01-14T09:02:14.0085634Z           [0., 0., 0.]]],
2026-01-14T09:02:14.0085789Z 
2026-01-14T09:02:14.0085793Z 
2026-01-14T09:02:14.0085872Z         [[[0., 0., 0.],
2026-01-14T09:02:14.0086084Z           [0., 0., 0.],
2026-01-14T09:02:14.0086304Z           [0., 0., 0.]],
2026-01-14T09:02:14.0086448Z 
2026-01-14T09:02:14.0086534Z          [[0., 0., 0.],
2026-01-14T09:02:14.0086746Z           [0., 0., 0.],
2026-01-14T09:02:14.0086967Z           [0., 0., 0.]],
2026-01-14T09:02:14.0087111Z 
2026-01-14T09:02:14.0087189Z          [[0., 0., 0.],
2026-01-14T09:02:14.0087406Z           [0., 0., 0.],
2026-01-14T09:02:14.0087626Z           [0., 0., 0.]]]])
2026-01-14T09:02:14.0087870Z model pt2e: GraphModule(
2026-01-14T09:02:14.0088108Z   (conv1): Module()
2026-01-14T09:02:14.0088320Z   (bn1): Module()
2026-01-14T09:02:14.0088522Z   (conv2): Module()
2026-01-14T09:02:14.0088732Z   (bn2): Module()
2026-01-14T09:02:14.0089038Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0090083Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:14.0091456Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:14.0092010Z   )
2026-01-14T09:02:14.0092211Z   (_guards_fn): GuardsFn()
2026-01-14T09:02:14.0092550Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0093715Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:14.0095154Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:02:14.0095844Z   )
2026-01-14T09:02:14.0096134Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0097239Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:14.0098670Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:14.0099369Z   )
2026-01-14T09:02:14.0099651Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0100687Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:14.0101902Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:14.0102443Z   )
2026-01-14T09:02:14.0102733Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:14.0103806Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:14.0105021Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:02:14.0105572Z   )
2026-01-14T09:02:14.0105786Z )
2026-01-14T09:02:14.0105887Z 
2026-01-14T09:02:14.0105891Z 
2026-01-14T09:02:14.0105895Z 
2026-01-14T09:02:14.0105996Z def forward(self, x):
2026-01-14T09:02:14.0106292Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:14.0106657Z     conv1_weight = self.conv1.weight
2026-01-14T09:02:14.0106951Z     bn1_weight = self.bn1.weight
2026-01-14T09:02:14.0107230Z     bn1_bias = self.bn1.bias
2026-01-14T09:02:14.0107489Z     conv2_weight = self.conv2.weight
2026-01-14T09:02:14.0107781Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:14.0108056Z     bn2_weight = self.bn2.weight
2026-01-14T09:02:14.0108323Z     bn2_bias = self.bn2.bias
2026-01-14T09:02:14.0108606Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:02:14.0108922Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:02:14.0109287Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:02:14.0109652Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:02:14.0109973Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:02:14.0110322Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:02:14.0110762Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:02:14.0111202Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:02:14.0111752Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:02:14.0112486Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:02:33.3576150Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:02:33.3576601Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:33.3577047Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:02:33.3577510Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:33.3578140Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:02:33.3578741Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:02:33.3579397Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:02:33.3579987Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:02:33.3580413Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:02:33.3580871Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:02:33.3581357Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:02:33.3581931Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:02:33.3582556Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:02:33.3583451Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:33.3584354Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:02:33.3584931Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:02:33.3585964Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:02:33.3587042Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:02:33.3588143Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:02:33.3589092Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:33.3589736Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:02:33.3590362Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:02:33.3590958Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:02:33.3591955Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:02:33.3593013Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:02:33.3593637Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:02:33.3594043Z     
2026-01-14T09:02:33.3594324Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:33.3594702Z model fx: GraphModule(
2026-01-14T09:02:33.3595026Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:33.3596058Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:33.3597286Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:33.3597821Z   )
2026-01-14T09:02:33.3598003Z   (conv1): ConvBn2d(
2026-01-14T09:02:33.3598314Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:02:33.3598787Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:33.3599272Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:33.3600334Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:33.3601843Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:02:33.3602527Z     )
2026-01-14T09:02:33.3602693Z   )
2026-01-14T09:02:33.3602967Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:33.3603996Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:33.3605206Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7323514223098755, max_val=2.7138354778289795)
2026-01-14T09:02:33.3605740Z   )
2026-01-14T09:02:33.3605917Z   (conv2): ConvBn2d(
2026-01-14T09:02:33.3606149Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:02:33.3606572Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:02:33.3607060Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:33.3608119Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:02:33.3609552Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1921, -0.1899, -0.1895]), max_val=tensor([0.1769, 0.1726, 0.1697]))
2026-01-14T09:02:33.3610236Z     )
2026-01-14T09:02:33.3610451Z   )
2026-01-14T09:02:33.3610728Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:33.3611832Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:33.3613145Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4053945541381836, max_val=1.4082176685333252)
2026-01-14T09:02:33.3613684Z   )
2026-01-14T09:02:33.3613846Z )
2026-01-14T09:02:33.3613941Z 
2026-01-14T09:02:33.3613946Z 
2026-01-14T09:02:33.3613949Z 
2026-01-14T09:02:33.3614039Z def forward(self, x):
2026-01-14T09:02:33.3614388Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:02:33.3614951Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:02:33.3615527Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:02:33.3616105Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:02:33.3616680Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:02:33.3617120Z     return activation_post_process_2
2026-01-14T09:02:33.3617382Z     
2026-01-14T09:02:33.3617658Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:33.3618029Z diff: tensor([[[[0.]],
2026-01-14T09:02:33.3618171Z 
2026-01-14T09:02:33.3618244Z          [[0.]],
2026-01-14T09:02:33.3618371Z 
2026-01-14T09:02:33.3618445Z          [[0.]]],
2026-01-14T09:02:33.3618562Z 
2026-01-14T09:02:33.3618566Z 
2026-01-14T09:02:33.3618644Z         [[[0.]],
2026-01-14T09:02:33.3618759Z 
2026-01-14T09:02:33.3618831Z          [[0.]],
2026-01-14T09:02:33.3618946Z 
2026-01-14T09:02:33.3619080Z          [[0.]]],
2026-01-14T09:02:33.3619197Z 
2026-01-14T09:02:33.3619201Z 
2026-01-14T09:02:33.3619277Z         [[[0.]],
2026-01-14T09:02:33.3619398Z 
2026-01-14T09:02:33.3619472Z          [[0.]],
2026-01-14T09:02:33.3619588Z 
2026-01-14T09:02:33.3619687Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:02:33.3620027Z converted model pt2e: GraphModule(
2026-01-14T09:02:33.3620297Z   (conv1): Module()
2026-01-14T09:02:33.3620497Z   (bn1): Module()
2026-01-14T09:02:33.3620695Z   (conv2): Module()
2026-01-14T09:02:33.3620894Z   (bn2): Module()
2026-01-14T09:02:33.3621104Z   (_guards_fn): GuardsFn()
2026-01-14T09:02:33.3621322Z )
2026-01-14T09:02:33.3621422Z 
2026-01-14T09:02:33.3621426Z 
2026-01-14T09:02:33.3621430Z 
2026-01-14T09:02:33.3621513Z def forward(self, x):
2026-01-14T09:02:33.3621794Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:33.3622143Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:33.3622791Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:02:33.3624076Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:33.3625042Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:02:33.3625379Z     _scale_0 = self._scale_0
2026-01-14T09:02:33.3625640Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:02:33.3625915Z     _scale_1 = self._scale_1
2026-01-14T09:02:33.3626159Z     _zero_point_1 = self._zero_point_1
2026-01-14T09:02:33.3626463Z     quantize_per_channel_1 = self._frozen_param0
2026-01-14T09:02:33.3627426Z     dequantize_per_channel_1 = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_1, _scale_1, _zero_point_1, 0, -127, 127, torch.int8);  quantize_per_channel_1 = _scale_1 = _zero_point_1 = None
2026-01-14T09:02:33.3628399Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:02:33.3629355Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel_1 = conv1_weight_bias = None
2026-01-14T09:02:33.3630724Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.01743602752685547, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:02:33.3632155Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:33.3633096Z     quantize_per_channel = self._frozen_param1
2026-01-14T09:02:33.3634037Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:02:33.3635520Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_channel, conv2_bias);  dequantize_per_tensor_default_1 = dequantize_per_channel = conv2_bias = None
2026-01-14T09:02:36.6124168Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:02:36.6126690Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:36.6128528Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:02:36.6129254Z     
2026-01-14T09:02:36.6129712Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:36.6130379Z onverted model fx: GraphModule(
2026-01-14T09:02:36.6131568Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:36.6132508Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:02:36.6133225Z )
2026-01-14T09:02:36.6133379Z 
2026-01-14T09:02:36.6133554Z 
2026-01-14T09:02:36.6133560Z 
2026-01-14T09:02:36.6133701Z def forward(self, x):
2026-01-14T09:02:36.6134789Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:02:36.6137054Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:02:36.6138914Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:02:36.6140492Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.01743602752685547, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:02:36.6142712Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01743602752685547, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:02:36.6144582Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:02:36.6146111Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011033773422241211, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:02:36.6148303Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011033773422241211, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:02:36.6150094Z     return dequantize_per_tensor_default_2
2026-01-14T09:02:36.6150547Z     
2026-01-14T09:02:36.6151001Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:02:36.6151822Z diff: tensor([[[[0.]],
2026-01-14T09:02:36.6152059Z 
2026-01-14T09:02:36.6152170Z          [[0.]],
2026-01-14T09:02:36.6152371Z 
2026-01-14T09:02:36.6152493Z          [[0.]]],
2026-01-14T09:02:36.6152690Z 
2026-01-14T09:02:36.6152697Z 
2026-01-14T09:02:36.6152944Z         [[[0.]],
2026-01-14T09:02:36.6153137Z 
2026-01-14T09:02:36.6153247Z          [[0.]],
2026-01-14T09:02:36.6153419Z 
2026-01-14T09:02:36.6153532Z          [[0.]]],
2026-01-14T09:02:36.6153713Z 
2026-01-14T09:02:36.6153720Z 
2026-01-14T09:02:36.6153820Z         [[[0.]],
2026-01-14T09:02:36.6154015Z 
2026-01-14T09:02:36.6154131Z          [[0.]],
2026-01-14T09:02:36.6154328Z 
2026-01-14T09:02:36.6154444Z          [[0.]]]])
2026-01-14T09:02:36.6154799Z model pt2e: GraphModule(
2026-01-14T09:02:36.6155179Z   (conv1): Module()
2026-01-14T09:02:36.6155479Z   (bn1): Module()
2026-01-14T09:02:36.6155798Z   (conv2): Module()
2026-01-14T09:02:36.6156124Z   (bn2): Module()
2026-01-14T09:02:36.6156623Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:36.6158371Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:36.6160561Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:02:36.6161510Z   )
2026-01-14T09:02:36.6161804Z   (_guards_fn): GuardsFn()
2026-01-14T09:02:36.6162371Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:36.6164174Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:36.6166446Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:02:36.6167387Z   )
2026-01-14T09:02:36.6167813Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:36.6169554Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:02:36.6171866Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:02:36.6172839Z   )
2026-01-14T09:02:36.6173295Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:36.6174978Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:36.6176880Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:02:36.6177752Z   )
2026-01-14T09:02:36.6178201Z   (activation_post_process_4): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:02:36.6179865Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:02:36.6181899Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:02:36.6182831Z   )
2026-01-14T09:02:36.6183074Z )
2026-01-14T09:02:36.6183214Z 
2026-01-14T09:02:36.6183228Z 
2026-01-14T09:02:36.6183234Z 
2026-01-14T09:02:36.6183355Z def forward(self, x):
2026-01-14T09:02:36.6183795Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:02:36.6184373Z     conv1_weight = self.conv1.weight
2026-01-14T09:02:36.6184779Z     bn1_weight = self.bn1.weight
2026-01-14T09:02:36.6185281Z     bn1_bias = self.bn1.bias
2026-01-14T09:02:36.6185703Z     conv2_weight = self.conv2.weight
2026-01-14T09:02:36.6186143Z     conv2_bias = self.conv2.bias
2026-01-14T09:02:36.6186550Z     bn2_weight = self.bn2.weight
2026-01-14T09:02:36.6186918Z     bn2_bias = self.bn2.bias
2026-01-14T09:02:36.6187454Z     bn1_running_mean = self.bn1.running_mean
2026-01-14T09:02:36.6187949Z     bn1_running_var = self.bn1.running_var
2026-01-14T09:02:36.6188514Z     bn1_num_batches_tracked = self.bn1.num_batches_tracked
2026-01-14T09:02:36.6189059Z     bn2_running_mean = self.bn2.running_mean
2026-01-14T09:02:36.6189569Z     bn2_running_var = self.bn2.running_var
2026-01-14T09:02:36.6190128Z     bn2_num_batches_tracked = self.bn2.num_batches_tracked
2026-01-14T09:02:36.6190775Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:02:36.6191431Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:02:36.6192269Z     add_ = torch.ops.aten.add_.Tensor(bn1_num_batches_tracked, 1);  bn1_num_batches_tracked = add_ = None
2026-01-14T09:02:36.6193439Z     add__1 = torch.ops.aten.add_.Tensor(bn2_num_batches_tracked, 1);  bn2_num_batches_tracked = add__1 = None
2026-01-14T09:02:36.6194302Z     add = torch.ops.aten.add.Tensor(bn2_running_var, 1e-05)
2026-01-14T09:02:36.6194889Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:02:36.6195565Z     div = torch.ops.aten.div.Tensor(bn2_weight, sqrt);  sqrt = None
2026-01-14T09:02:36.6196314Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:02:36.6197218Z     mul = torch.ops.aten.mul.Tensor(conv2_weight, reshape);  conv2_weight = reshape = None
2026-01-14T09:02:36.6198197Z     activation_post_process_3 = self.activation_post_process_3(mul);  mul = None
2026-01-14T09:02:36.6199258Z     zeros_like = torch.ops.aten.zeros_like.default(conv2_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:02:36.6200423Z     add_2 = torch.ops.aten.add.Tensor(bn1_running_var, 1e-05)
2026-01-14T09:02:36.6201128Z     sqrt_1 = torch.ops.aten.sqrt.default(add_2);  add_2 = None
2026-01-14T09:02:36.6201844Z     div_2 = torch.ops.aten.div.Tensor(bn1_weight, sqrt_1);  sqrt_1 = None
2026-01-14T09:02:36.6202675Z     reshape_3 = torch.ops.aten.reshape.default(div_2, [-1, 1, 1, 1])
2026-01-14T09:02:36.6203544Z     mul_1 = torch.ops.aten.mul.Tensor(conv1_weight, reshape_3);  conv1_weight = reshape_3 = None
2026-01-14T09:02:36.6204454Z     activation_post_process_1 = self.activation_post_process_1(mul_1);  mul_1 = None
2026-01-14T09:02:36.6205855Z     conv2d_3 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:02:36.6207287Z     reshape_4 = torch.ops.aten.reshape.default(div_2, [1, -1, 1, 1]);  div_2 = None
2026-01-14T09:02:36.6208202Z     div_3 = torch.ops.aten.div.Tensor(conv2d_3, reshape_4);  conv2d_3 = reshape_4 = None
2026-01-14T09:02:36.6209903Z     batch_norm_3 = torch.ops.aten.batch_norm.default(div_3, bn1_weight, bn1_bias, bn1_running_mean, bn1_running_var, True, 0.1, 1e-05, True);  div_3 = bn1_weight = bn1_bias = bn1_running_mean = bn1_running_var = None
2026-01-14T09:02:36.6211692Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_3);  batch_norm_3 = None
2026-01-14T09:02:36.6213192Z     conv2d_2 = torch.ops.aten.conv2d.default(activation_post_process_2, activation_post_process_3, zeros_like);  activation_post_process_2 = activation_post_process_3 = zeros_like = None
2026-01-14T09:02:36.6214777Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:02:36.6215692Z     div_1 = torch.ops.aten.div.Tensor(conv2d_2, reshape_1);  conv2d_2 = reshape_1 = None
2026-01-14T09:02:36.6216664Z     reshape_2 = torch.ops.aten.reshape.default(conv2_bias, [1, -1, 1, 1]);  conv2_bias = None
2026-01-14T09:02:36.6217605Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:02:36.6219301Z     batch_norm_2 = torch.ops.aten.batch_norm.default(add_1, bn2_weight, bn2_bias, bn2_running_mean, bn2_running_var, True, 0.1, 1e-05, True);  add_1 = bn2_weight = bn2_bias = bn2_running_mean = bn2_running_var = None
2026-01-14T09:02:36.6221060Z     activation_post_process_4 = self.activation_post_process_4(batch_norm_2);  batch_norm_2 = None
2026-01-14T09:02:36.6222178Z     return pytree.tree_unflatten((activation_post_process_4,), self._out_spec)
2026-01-14T09:02:36.6222822Z     
2026-01-14T09:03:23.2275989Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:23.2278937Z model fx: GraphModule(
2026-01-14T09:03:23.2279450Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:23.2280814Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0189]), zero_point=tensor([-17], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:23.2282421Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0985729694366455, max_val=2.7226178646087646)
2026-01-14T09:03:23.2283111Z   )
2026-01-14T09:03:23.2283343Z   (conv1): ConvBn2d(
2026-01-14T09:03:23.2283684Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:03:23.2284255Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:23.2284873Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:23.2286146Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:23.2287718Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212442636489868, max_val=0.18097376823425293)
2026-01-14T09:03:23.2288419Z     )
2026-01-14T09:03:23.2288846Z   )
2026-01-14T09:03:23.2289205Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:23.2290495Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0174]), zero_point=tensor([-29], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:23.2292234Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7288155555725098, max_val=2.7138354778289795)
2026-01-14T09:03:23.2292924Z   )
2026-01-14T09:03:23.2293140Z   (conv2): ConvBn2d(
2026-01-14T09:03:23.2293431Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:03:23.2293950Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:23.2294560Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:23.2295819Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:03:23.2297369Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1921343356370926, max_val=0.1768510341644287)
2026-01-14T09:03:23.2298063Z     )
2026-01-14T09:03:23.2298272Z   )
2026-01-14T09:03:23.2298612Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:23.2299893Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0110]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:23.2301416Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4025696516036987, max_val=1.4086220264434814)
2026-01-14T09:03:23.2302092Z   )
2026-01-14T09:03:23.2302293Z )
2026-01-14T09:03:23.2302412Z 
2026-01-14T09:03:23.2302417Z 
2026-01-14T09:03:23.2302422Z 
2026-01-14T09:03:23.2302538Z def forward(self, x):
2026-01-14T09:03:23.2303085Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:23.2303789Z     conv1 = self.conv1(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:23.2304516Z     activation_post_process_1 = self.activation_post_process_1(conv1);  conv1 = None
2026-01-14T09:03:23.2305333Z     conv2 = self.conv2(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:03:23.2306054Z     activation_post_process_2 = self.activation_post_process_2(conv2);  conv2 = None
2026-01-14T09:03:23.2306610Z     return activation_post_process_2
2026-01-14T09:03:23.2306947Z     
2026-01-14T09:03:23.2307289Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:23.2307754Z diff: tensor([[[[0.]],
2026-01-14T09:03:23.2307927Z 
2026-01-14T09:03:23.2308022Z          [[0.]],
2026-01-14T09:03:23.2308178Z 
2026-01-14T09:03:23.2308270Z          [[0.]]],
2026-01-14T09:03:23.2308417Z 
2026-01-14T09:03:23.2308422Z 
2026-01-14T09:03:23.2308524Z         [[[0.]],
2026-01-14T09:03:23.2308670Z 
2026-01-14T09:03:23.2308762Z          [[0.]],
2026-01-14T09:03:23.2308904Z 
2026-01-14T09:03:23.2309005Z          [[0.]]],
2026-01-14T09:03:23.2309152Z 
2026-01-14T09:03:23.2309159Z 
2026-01-14T09:03:23.2309250Z         [[[0.]],
2026-01-14T09:03:23.2309400Z 
2026-01-14T09:03:23.2309495Z          [[0.]],
2026-01-14T09:03:23.2309640Z 
2026-01-14T09:03:23.2309771Z          [[0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:23.2310137Z converted model pt2e: GraphModule(
2026-01-14T09:03:23.2310465Z   (conv1): Module()
2026-01-14T09:03:23.2310711Z   (bn1): Module()
2026-01-14T09:03:23.2310958Z   (conv2): Module()
2026-01-14T09:03:23.2311205Z   (bn2): Module()
2026-01-14T09:03:23.2311464Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:23.2311736Z )
2026-01-14T09:03:23.2311862Z 
2026-01-14T09:03:23.2311867Z 
2026-01-14T09:03:23.2311872Z 
2026-01-14T09:03:23.2311979Z def forward(self, x):
2026-01-14T09:03:23.2312407Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:23.2312878Z     conv2_bias = self.conv2.bias
2026-01-14T09:03:23.2313778Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8)
2026-01-14T09:03:23.2315124Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:23.2316104Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:23.2316469Z     quantize_per_tensor_1 = self._frozen_param0
2026-01-14T09:03:23.2317334Z     dequantize_per_tensor_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.001512790797278285, 0, -127, 127, torch.int8);  quantize_per_tensor_1 = None
2026-01-14T09:03:23.2318203Z     conv1_weight_bias = self.conv1.weight_bias
2026-01-14T09:03:23.2319116Z     conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_1, conv1_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor_1 = conv1_weight_bias = None
2026-01-14T09:03:23.2320482Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_5, 0.017422160133719444, -29, -128, 127, torch.int8);  conv2d_5 = None
2026-01-14T09:03:23.2321889Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:03:23.2322842Z     quantize_per_tensor = self._frozen_param1
2026-01-14T09:03:23.2323679Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001512868795543909, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:03:23.2325097Z     conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_tensor, conv2_bias);  dequantize_per_tensor_default_3 = dequantize_per_tensor = conv2_bias = None
2026-01-14T09:03:23.2326401Z     quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2d_4 = None
2026-01-14T09:03:23.2327838Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None
2026-01-14T09:03:23.2328913Z     return pytree.tree_unflatten((dequantize_per_tensor_default_4,), self._out_spec)
2026-01-14T09:03:23.2329346Z     
2026-01-14T09:03:23.2329642Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:23.2330039Z onverted model fx: GraphModule(
2026-01-14T09:03:23.2330423Z   (conv1): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:23.2330964Z   (conv2): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:23.2331448Z )
2026-01-14T09:03:23.2331547Z 
2026-01-14T09:03:23.2331550Z 
2026-01-14T09:03:23.2331554Z 
2026-01-14T09:03:23.2331641Z def forward(self, x):
2026-01-14T09:03:23.2332292Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01890663057565689, -17, -128, 127, torch.int8);  x = None
2026-01-14T09:03:23.2333664Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01890663057565689, -17, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:23.2334753Z     conv1 = self.conv1(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:23.2335681Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv1, 0.017422160133719444, -29, -128, 127, torch.int8);  conv1 = None
2026-01-14T09:03:23.2337110Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.017422160133719444, -29, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:23.2339813Z     conv2 = self.conv2(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:03:23.2340749Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2, 0.011024280451238155, -1, -128, 127, torch.int8);  conv2 = None
2026-01-14T09:03:23.2342117Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.011024280451238155, -1, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:03:23.2343061Z     return dequantize_per_tensor_default_2
2026-01-14T09:03:23.2343341Z     
2026-01-14T09:03:23.2343636Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:23.2344016Z diff: tensor([[[[0.]],
2026-01-14T09:03:23.2344158Z 
2026-01-14T09:03:23.2344232Z          [[0.]],
2026-01-14T09:03:23.2344351Z 
2026-01-14T09:03:23.2344429Z          [[0.]]],
2026-01-14T09:03:23.2344548Z 
2026-01-14T09:03:23.2344552Z 
2026-01-14T09:03:23.2344628Z         [[[0.]],
2026-01-14T09:03:23.2344750Z 
2026-01-14T09:03:23.2344823Z          [[0.]],
2026-01-14T09:03:23.2344943Z 
2026-01-14T09:03:23.2345018Z          [[0.]]],
2026-01-14T09:03:23.2345141Z 
2026-01-14T09:03:23.2345145Z 
2026-01-14T09:03:23.2345217Z         [[[0.]],
2026-01-14T09:03:23.2345333Z 
2026-01-14T09:03:23.2345415Z          [[0.]],
2026-01-14T09:03:23.2345529Z 
2026-01-14T09:03:23.2345605Z          [[0.]]]])
2026-01-14T09:03:23.2346017Z [32mPASSED[0m
2026-01-14T09:03:23.2346727Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias [32mPASSED[0m
2026-01-14T09:03:23.2347747Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion model pt2e: GraphModule(
2026-01-14T09:03:23.2348442Z   (conv): Module()
2026-01-14T09:03:23.2348643Z   (bn): Module()
2026-01-14T09:03:23.2348952Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6864113Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:42.6865921Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:42.6866608Z   )
2026-01-14T09:03:42.6866842Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:42.6867258Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6868661Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:42.6870498Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:03:42.6871380Z   )
2026-01-14T09:03:42.6871716Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6873038Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:42.6874519Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:03:42.6875138Z   )
2026-01-14T09:03:42.6875350Z )
2026-01-14T09:03:42.6875470Z 
2026-01-14T09:03:42.6875475Z 
2026-01-14T09:03:42.6875479Z 
2026-01-14T09:03:42.6875583Z def forward(self, x):
2026-01-14T09:03:42.6876059Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:42.6876494Z     conv_weight = self.conv.weight
2026-01-14T09:03:42.6876833Z     conv_bias = self.conv.bias
2026-01-14T09:03:42.6877142Z     bn_weight = self.bn.weight
2026-01-14T09:03:42.6877587Z     bn_bias = self.bn.bias
2026-01-14T09:03:42.6877910Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:03:42.6878282Z     bn_running_var = self.bn.running_var
2026-01-14T09:03:42.6878702Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:03:42.6879220Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:03:42.6879751Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:42.6880426Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:03:42.6881129Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:03:42.6881628Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:03:42.6882149Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:03:42.6882719Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:03:42.6883366Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:03:42.6884122Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:03:42.6884942Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:03:42.6886282Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:03:42.6887491Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:03:42.6888193Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:03:42.6889110Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:03:42.6889850Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:03:42.6891070Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:03:42.6892417Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:03:42.6893097Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:03:42.6893807Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:03:42.6894305Z     
2026-01-14T09:03:42.6894657Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:42.6895130Z model fx: GraphModule(
2026-01-14T09:03:42.6895526Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6896837Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:42.6898379Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:03:42.6899062Z   )
2026-01-14T09:03:42.6899281Z   (conv): ConvBnReLU2d(
2026-01-14T09:03:42.6899605Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:03:42.6900134Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:03:42.6900753Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6902164Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0014, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:03:42.6904012Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1835, -0.1822, -0.1883]), max_val=tensor([0.1799, 0.1856, 0.1719]))
2026-01-14T09:03:42.6904932Z     )
2026-01-14T09:03:42.6905135Z   )
2026-01-14T09:03:42.6905477Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:03:42.6906782Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:03:42.6908318Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2505061626434326)
2026-01-14T09:03:42.6908928Z   )
2026-01-14T09:03:42.6909137Z )
2026-01-14T09:03:42.6909257Z 
2026-01-14T09:03:42.6909262Z 
2026-01-14T09:03:42.6909267Z 
2026-01-14T09:03:42.6909377Z def forward(self, x):
2026-01-14T09:03:42.6909814Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:03:42.6910504Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:03:42.6911215Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:03:42.6911776Z     return activation_post_process_1
2026-01-14T09:03:42.6912100Z     
2026-01-14T09:03:42.6912450Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:42.6912926Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:03:42.6913214Z           [0., 0., 0.],
2026-01-14T09:03:42.6913481Z           [0., 0., 0.]],
2026-01-14T09:03:42.6913653Z 
2026-01-14T09:03:42.6913745Z          [[0., 0., 0.],
2026-01-14T09:03:42.6914007Z           [0., 0., 0.],
2026-01-14T09:03:42.6914259Z           [0., 0., 0.]],
2026-01-14T09:03:42.6914438Z 
2026-01-14T09:03:42.6914530Z          [[0., 0., 0.],
2026-01-14T09:03:42.6914783Z           [0., 0., 0.],
2026-01-14T09:03:42.6915086Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:03:42.6915536Z converted model pt2e: GraphModule(
2026-01-14T09:03:42.6915864Z   (conv): Module()
2026-01-14T09:03:42.6916130Z   (bn): Module()
2026-01-14T09:03:42.6916335Z   (_guards_fn): GuardsFn()
2026-01-14T09:03:42.6916565Z )
2026-01-14T09:03:42.6916662Z 
2026-01-14T09:03:42.6916666Z 
2026-01-14T09:03:42.6916721Z 
2026-01-14T09:03:42.6916809Z def forward(self, x):
2026-01-14T09:03:42.6917100Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:03:42.6917440Z     conv_bias = self.conv.bias
2026-01-14T09:03:42.6918072Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:03:42.6919359Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:42.6920319Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:03:42.6920662Z     _scale_0 = self._scale_0
2026-01-14T09:03:42.6920915Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:03:42.6921226Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:03:42.6922175Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:03:42.6923635Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:03:42.6924551Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:03:42.6925422Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004903945606201887, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:03:42.6926812Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:03:42.6927937Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:03:42.6928361Z     
2026-01-14T09:03:42.6928649Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:03:42.6929037Z onverted model fx: GraphModule(
2026-01-14T09:03:42.6929298Z   (conv): ConvReLU2d(
2026-01-14T09:03:42.6929641Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:03:42.6930023Z     (1): ReLU()
2026-01-14T09:03:42.6930221Z   )
2026-01-14T09:03:42.6930390Z )
2026-01-14T09:03:42.6930485Z 
2026-01-14T09:03:42.6930495Z 
2026-01-14T09:03:42.6930499Z 
2026-01-14T09:03:42.6930582Z def forward(self, x):
2026-01-14T09:03:42.6931226Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:03:42.6932605Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:03:42.6933689Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:03:42.6934596Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004903945606201887, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:02.0342274Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004903945606201887, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:02.0343562Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:02.0343911Z     
2026-01-14T09:04:02.0344467Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:02.0344951Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:02.0345249Z           [0., 0., 0.],
2026-01-14T09:04:02.0345528Z           [0., 0., 0.]],
2026-01-14T09:04:02.0345708Z 
2026-01-14T09:04:02.0345803Z          [[0., 0., 0.],
2026-01-14T09:04:02.0346187Z           [0., 0., 0.],
2026-01-14T09:04:02.0346446Z           [0., 0., 0.]],
2026-01-14T09:04:02.0346618Z 
2026-01-14T09:04:02.0346711Z          [[0., 0., 0.],
2026-01-14T09:04:02.0346969Z           [0., 0., 0.],
2026-01-14T09:04:02.0347227Z           [0., 0., 0.]]]])
2026-01-14T09:04:02.0347510Z model pt2e: GraphModule(
2026-01-14T09:04:02.0347795Z   (conv): Module()
2026-01-14T09:04:02.0348034Z   (bn): Module()
2026-01-14T09:04:02.0348402Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0349938Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:02.0351488Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:02.0352168Z   )
2026-01-14T09:04:02.0352391Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:02.0352801Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0354093Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:02.0355632Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:04:02.0356313Z   )
2026-01-14T09:04:02.0356646Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0358076Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:02.0359614Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:04:02.0360232Z   )
2026-01-14T09:04:02.0360435Z )
2026-01-14T09:04:02.0360565Z 
2026-01-14T09:04:02.0360570Z 
2026-01-14T09:04:02.0360575Z 
2026-01-14T09:04:02.0360678Z def forward(self, x):
2026-01-14T09:04:02.0361032Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:02.0361459Z     conv_weight = self.conv.weight
2026-01-14T09:04:02.0361796Z     conv_bias = self.conv.bias
2026-01-14T09:04:02.0362104Z     bn_weight = self.bn.weight
2026-01-14T09:04:02.0362409Z     bn_bias = self.bn.bias
2026-01-14T09:04:02.0362716Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:02.0363097Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:02.0363515Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:02.0364038Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:04:02.0364563Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:02.0365231Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:02.0365926Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:02.0366417Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:02.0366942Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:02.0367497Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:02.0368153Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:02.0368892Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:02.0369767Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:02.0371101Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:02.0372503Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:02.0373210Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:02.0373975Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:02.0374706Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:02.0375926Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:02.0377119Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:02.0377797Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:02.0378508Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:02.0379007Z     
2026-01-14T09:04:02.0379356Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:02.0379821Z model fx: GraphModule(
2026-01-14T09:04:02.0380216Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0381519Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:02.0383117Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:02.0383796Z   )
2026-01-14T09:04:02.0384018Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:02.0384321Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:02.0384841Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:02.0385500Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0386778Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:02.0388322Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.1882954239845276, max_val=0.1855725795030594)
2026-01-14T09:04:02.0389009Z     )
2026-01-14T09:04:02.0389216Z   )
2026-01-14T09:04:02.0389553Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:02.0390845Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0049]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:02.0392304Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.2396948337554932)
2026-01-14T09:04:02.0392919Z   )
2026-01-14T09:04:02.0393128Z )
2026-01-14T09:04:02.0393251Z 
2026-01-14T09:04:02.0393257Z 
2026-01-14T09:04:02.0393285Z 
2026-01-14T09:04:02.0393388Z def forward(self, x):
2026-01-14T09:04:02.0393823Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:02.0394505Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:02.0395216Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:02.0395823Z     return activation_post_process_1
2026-01-14T09:04:02.0396167Z     
2026-01-14T09:04:02.0396530Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:02.0396983Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:02.0397226Z           [0., 0., 0.],
2026-01-14T09:04:02.0397438Z           [0., 0., 0.]],
2026-01-14T09:04:02.0397582Z 
2026-01-14T09:04:02.0397668Z          [[0., 0., 0.],
2026-01-14T09:04:02.0397884Z           [0., 0., 0.],
2026-01-14T09:04:02.0398097Z           [0., 0., 0.]],
2026-01-14T09:04:02.0398279Z 
2026-01-14T09:04:02.0398354Z          [[0., 0., 0.],
2026-01-14T09:04:02.0398567Z           [0., 0., 0.],
2026-01-14T09:04:02.0398804Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:04:02.0399125Z converted model pt2e: GraphModule(
2026-01-14T09:04:02.0399386Z   (conv): Module()
2026-01-14T09:04:02.0399596Z   (bn): Module()
2026-01-14T09:04:02.0399807Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:02.0400028Z )
2026-01-14T09:04:02.0400126Z 
2026-01-14T09:04:02.0400129Z 
2026-01-14T09:04:02.0400133Z 
2026-01-14T09:04:02.0400223Z def forward(self, x):
2026-01-14T09:04:02.0400508Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:02.0400862Z     conv_bias = self.conv.bias
2026-01-14T09:04:02.0401498Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:04:02.0402792Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:02.0403768Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:02.0404131Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:04:02.0404971Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014826410915702581, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:04:02.0406379Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:04:02.0407282Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:02.0408111Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.004861548542976379, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:02.0409536Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:04:02.0410624Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:04:02.0411052Z     
2026-01-14T09:04:02.0411414Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:02.0411804Z onverted model fx: GraphModule(
2026-01-14T09:04:02.0412056Z   (conv): ConvReLU2d(
2026-01-14T09:04:02.0412402Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:02.0412785Z     (1): ReLU()
2026-01-14T09:04:02.0412978Z   )
2026-01-14T09:04:02.0413144Z )
2026-01-14T09:04:02.0413242Z 
2026-01-14T09:04:02.0413246Z 
2026-01-14T09:04:02.0413252Z 
2026-01-14T09:04:02.0413335Z def forward(self, x):
2026-01-14T09:04:02.0413982Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:31.2166514Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:31.2167670Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:31.2168651Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.004861548542976379, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:31.2170225Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.004861548542976379, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:31.2171190Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:31.2171621Z     
2026-01-14T09:04:31.2171908Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:31.2181180Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:31.2181528Z           [0., 0., 0.],
2026-01-14T09:04:31.2181843Z           [0., 0., 0.]],
2026-01-14T09:04:31.2182002Z 
2026-01-14T09:04:31.2182083Z          [[0., 0., 0.],
2026-01-14T09:04:31.2182301Z           [0., 0., 0.],
2026-01-14T09:04:31.2182508Z           [0., 0., 0.]],
2026-01-14T09:04:31.2182659Z 
2026-01-14T09:04:31.2182737Z          [[0., 0., 0.],
2026-01-14T09:04:31.2182950Z           [0., 0., 0.],
2026-01-14T09:04:31.2183168Z           [0., 0., 0.]]]])
2026-01-14T09:04:31.2183619Z [32mPASSED[0m
2026-01-14T09:04:31.2184237Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_cuda model pt2e: GraphModule(
2026-01-14T09:04:31.2184909Z   (conv): Module()
2026-01-14T09:04:31.2185117Z   (bn): Module()
2026-01-14T09:04:31.2185424Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2186680Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:31.2188099Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:31.2188636Z   )
2026-01-14T09:04:31.2188821Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:31.2189337Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2190660Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:31.2192510Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:04:31.2193304Z   )
2026-01-14T09:04:31.2193580Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2194830Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:31.2196203Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:04:31.2196687Z   )
2026-01-14T09:04:31.2196860Z )
2026-01-14T09:04:31.2196962Z 
2026-01-14T09:04:31.2196966Z 
2026-01-14T09:04:31.2196970Z 
2026-01-14T09:04:31.2197065Z def forward(self, x):
2026-01-14T09:04:31.2197357Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:31.2197710Z     conv_weight = self.conv.weight
2026-01-14T09:04:31.2197986Z     conv_bias = self.conv.bias
2026-01-14T09:04:31.2198254Z     bn_weight = self.bn.weight
2026-01-14T09:04:31.2198507Z     bn_bias = self.bn.bias
2026-01-14T09:04:31.2198773Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:31.2199078Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:31.2199421Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:31.2199846Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:04:31.2200338Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:31.2200892Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:31.2201454Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:31.2201866Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:31.2202336Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:31.2202806Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:31.2203333Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:31.2203928Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:31.2204583Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:31.2205638Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:31.2206595Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:31.2207165Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:31.2207792Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:31.2208394Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:31.2209367Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:31.2210320Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:31.2210912Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:31.2211570Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:31.2211980Z     
2026-01-14T09:04:31.2212268Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:31.2212699Z model fx: GraphModule(
2026-01-14T09:04:31.2213031Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2214287Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:31.2215712Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:31.2216241Z   )
2026-01-14T09:04:31.2216433Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:31.2216685Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:31.2217122Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:31.2217612Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2218906Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015, 0.0015, 0.0014], device='cuda:0'), zero_point=tensor([0, 0, 0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:04:31.2220666Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787], device='cuda:0'), max_val=tensor([0.1824, 0.1870, 0.1478], device='cuda:0'))
2026-01-14T09:04:31.2221457Z     )
2026-01-14T09:04:31.2221635Z   )
2026-01-14T09:04:31.2221908Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:31.2223216Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0081], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:31.2224593Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0564441680908203)
2026-01-14T09:04:31.2225122Z   )
2026-01-14T09:04:31.2225299Z )
2026-01-14T09:04:31.2225395Z 
2026-01-14T09:04:31.2225399Z 
2026-01-14T09:04:31.2225403Z 
2026-01-14T09:04:31.2225495Z def forward(self, x):
2026-01-14T09:04:31.2225849Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:31.2226405Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:31.2226972Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:31.2227420Z     return activation_post_process_1
2026-01-14T09:04:31.2227682Z     
2026-01-14T09:04:31.2227978Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:31.2228358Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:31.2228632Z           [0., 0., 0.],
2026-01-14T09:04:31.2228884Z           [0., 0., 0.]],
2026-01-14T09:04:31.2229027Z 
2026-01-14T09:04:31.2229106Z          [[0., 0., 0.],
2026-01-14T09:04:31.2229325Z           [0., 0., 0.],
2026-01-14T09:04:31.2229534Z           [0., 0., 0.]],
2026-01-14T09:04:31.2229684Z 
2026-01-14T09:04:31.2229761Z          [[0., 0., 0.],
2026-01-14T09:04:31.2229968Z           [0., 0., 0.],
2026-01-14T09:04:31.2230255Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:04:31.2230608Z converted model pt2e: GraphModule(
2026-01-14T09:04:31.2230887Z   (conv): Module()
2026-01-14T09:04:31.2231100Z   (bn): Module()
2026-01-14T09:04:31.2231308Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:31.2231540Z )
2026-01-14T09:04:31.2231639Z 
2026-01-14T09:04:31.2231693Z 
2026-01-14T09:04:31.2231697Z 
2026-01-14T09:04:31.2231784Z def forward(self, x):
2026-01-14T09:04:31.2232083Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:31.2232427Z     conv_bias = self.conv.bias
2026-01-14T09:04:31.2233109Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:04:31.2234402Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:31.2235356Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:31.2235697Z     _scale_0 = self._scale_0
2026-01-14T09:04:31.2235959Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:04:31.2236267Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:04:34.4288358Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:04:34.4290298Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:04:34.4291244Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:04:34.4292146Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.008064487017691135, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:04:34.4293525Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:34.4294613Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:04:34.4295046Z     
2026-01-14T09:04:34.4295471Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:34.4295872Z onverted model fx: GraphModule(
2026-01-14T09:04:34.4296132Z   (conv): ConvReLU2d(
2026-01-14T09:04:34.4296481Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:04:34.4296927Z     (1): ReLU()
2026-01-14T09:04:34.4297127Z   )
2026-01-14T09:04:34.4297297Z )
2026-01-14T09:04:34.4297403Z 
2026-01-14T09:04:34.4297407Z 
2026-01-14T09:04:34.4297411Z 
2026-01-14T09:04:34.4297501Z def forward(self, x):
2026-01-14T09:04:34.4298162Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:04:34.4299535Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:04:34.4300626Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:04:34.4301540Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.008064487017691135, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:04:34.4302923Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.008064487017691135, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:04:34.4303886Z     return dequantize_per_tensor_default_1
2026-01-14T09:04:34.4304162Z     
2026-01-14T09:04:34.4304450Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:34.4304835Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:34.4305079Z           [0., 0., 0.],
2026-01-14T09:04:34.4305298Z           [0., 0., 0.]],
2026-01-14T09:04:34.4305440Z 
2026-01-14T09:04:34.4305594Z          [[0., 0., 0.],
2026-01-14T09:04:34.4305814Z           [0., 0., 0.],
2026-01-14T09:04:34.4306031Z           [0., 0., 0.]],
2026-01-14T09:04:34.4306180Z 
2026-01-14T09:04:34.4306261Z          [[0., 0., 0.],
2026-01-14T09:04:34.4306466Z           [0., 0., 0.],
2026-01-14T09:04:34.4306764Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:04:34.4307049Z model pt2e: GraphModule(
2026-01-14T09:04:34.4307294Z   (conv): Module()
2026-01-14T09:04:34.4307511Z   (bn): Module()
2026-01-14T09:04:34.4307814Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4309060Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:34.4310482Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:34.4311024Z   )
2026-01-14T09:04:34.4311215Z   (_guards_fn): GuardsFn()
2026-01-14T09:04:34.4311558Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4312805Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:34.4314239Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:04:34.4314789Z   )
2026-01-14T09:04:34.4315098Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4316416Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:34.4317785Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:04:34.4318286Z   )
2026-01-14T09:04:34.4318454Z )
2026-01-14T09:04:34.4318553Z 
2026-01-14T09:04:34.4318606Z 
2026-01-14T09:04:34.4318610Z 
2026-01-14T09:04:34.4318696Z def forward(self, x):
2026-01-14T09:04:34.4318987Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:04:34.4319356Z     conv_weight = self.conv.weight
2026-01-14T09:04:34.4319671Z     conv_bias = self.conv.bias
2026-01-14T09:04:34.4319932Z     bn_weight = self.bn.weight
2026-01-14T09:04:34.4320191Z     bn_bias = self.bn.bias
2026-01-14T09:04:34.4320444Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:04:34.4320755Z     bn_running_var = self.bn.running_var
2026-01-14T09:04:34.4321093Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:04:34.4321519Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:04:34.4321946Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:04:34.4322487Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:04:34.4323050Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:04:34.4323458Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:04:34.4323885Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:04:34.4324342Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:04:34.4324870Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:04:34.4325455Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:04:34.4326155Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:04:34.4327208Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:04:34.4328151Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:04:34.4328763Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:04:34.4329428Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:04:34.4330029Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:04:34.4331004Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:04:34.4332005Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:04:34.4332556Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:04:34.4333113Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:04:34.4333518Z     
2026-01-14T09:04:34.4333807Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:34.4334184Z model fx: GraphModule(
2026-01-14T09:04:34.4334511Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4335756Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0183], device='cuda:0'), zero_point=tensor([10], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:34.4337171Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:04:34.4337703Z   )
2026-01-14T09:04:34.4337888Z   (conv): ConvBnReLU2d(
2026-01-14T09:04:34.4338190Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:04:34.4338616Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:04:34.4339116Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4340330Z       fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0015], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:04:34.4341816Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965020775794983, max_val=0.1870359182357788)
2026-01-14T09:04:34.4342365Z     )
2026-01-14T09:04:34.4342535Z   )
2026-01-14T09:04:34.4342817Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:04:34.4344068Z     fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([0.0080], device='cuda:0'), zero_point=tensor([-128], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:04:34.4345443Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.0522286891937256)
2026-01-14T09:04:34.4345938Z   )
2026-01-14T09:04:34.4346103Z )
2026-01-14T09:04:34.4346209Z 
2026-01-14T09:04:34.4346213Z 
2026-01-14T09:04:34.4346217Z 
2026-01-14T09:04:34.4346302Z def forward(self, x):
2026-01-14T09:04:34.4346655Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:04:34.4347213Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:04:34.4347781Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:04:34.4348217Z     return activation_post_process_1
2026-01-14T09:04:34.4348526Z     
2026-01-14T09:04:34.4348811Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:04:34.4349422Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:04:34.4349657Z           [0., 0., 0.],
2026-01-14T09:04:34.4349875Z           [0., 0., 0.]],
2026-01-14T09:04:34.4350093Z 
2026-01-14T09:05:03.5180454Z          [[0., 0., 0.],
2026-01-14T09:05:03.5183855Z           [0., 0., 0.],
2026-01-14T09:05:03.5184158Z           [0., 0., 0.]],
2026-01-14T09:05:03.5184460Z 
2026-01-14T09:05:03.5184628Z          [[0., 0., 0.],
2026-01-14T09:05:03.5184918Z           [0., 0., 0.],
2026-01-14T09:05:03.5185277Z           [0., 0., 0.]]]], device='cuda:0', grad_fn=<SubBackward0>)
2026-01-14T09:05:03.5185735Z converted model pt2e: GraphModule(
2026-01-14T09:05:03.5186057Z   (conv): Module()
2026-01-14T09:05:03.5186307Z   (bn): Module()
2026-01-14T09:05:03.5186561Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:03.5186899Z )
2026-01-14T09:05:03.5187019Z 
2026-01-14T09:05:03.5187059Z 
2026-01-14T09:05:03.5187255Z 
2026-01-14T09:05:03.5187388Z def forward(self, x):
2026-01-14T09:05:03.5187783Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:03.5188218Z     conv_bias = self.conv.bias
2026-01-14T09:05:03.5189024Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:03.5190714Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:03.5191953Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:03.5192407Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:05:03.5193488Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014933086931705475, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:05:03.5195542Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:05:03.5196700Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:03.5197743Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.00804795604199171, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:03.5199697Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:03.5200942Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:03.5201378Z     
2026-01-14T09:05:03.5201663Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:03.5202062Z onverted model fx: GraphModule(
2026-01-14T09:05:03.5202316Z   (conv): ConvReLU2d(
2026-01-14T09:05:03.5202667Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:03.5203047Z     (1): ReLU()
2026-01-14T09:05:03.5203240Z   )
2026-01-14T09:05:03.5203409Z )
2026-01-14T09:05:03.5203515Z 
2026-01-14T09:05:03.5203519Z 
2026-01-14T09:05:03.5203524Z 
2026-01-14T09:05:03.5203612Z def forward(self, x):
2026-01-14T09:05:03.5204258Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:03.5205570Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:03.5206643Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:03.5207662Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.00804795604199171, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:03.5209029Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.00804795604199171, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:03.5210056Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:03.5210334Z     
2026-01-14T09:05:03.5210618Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:03.5211008Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:03.5211248Z           [0., 0., 0.],
2026-01-14T09:05:03.5211531Z           [0., 0., 0.]],
2026-01-14T09:05:03.5211675Z 
2026-01-14T09:05:03.5211756Z          [[0., 0., 0.],
2026-01-14T09:05:03.5211968Z           [0., 0., 0.],
2026-01-14T09:05:03.5212173Z           [0., 0., 0.]],
2026-01-14T09:05:03.5212318Z 
2026-01-14T09:05:03.5212397Z          [[0., 0., 0.],
2026-01-14T09:05:03.5212602Z           [0., 0., 0.],
2026-01-14T09:05:03.5212836Z           [0., 0., 0.]]]], device='cuda:0')
2026-01-14T09:05:03.5213324Z [32mPASSED[0m
2026-01-14T09:05:03.5213996Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_relu_fusion_no_conv_bias model pt2e: GraphModule(
2026-01-14T09:05:03.5214690Z   (conv): Module()
2026-01-14T09:05:03.5214891Z   (bn): Module()
2026-01-14T09:05:03.5215195Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5216228Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:03.5217473Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:03.5218009Z   )
2026-01-14T09:05:03.5218205Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:03.5218589Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5219689Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:03.5221161Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:05:03.5221850Z   )
2026-01-14T09:05:03.5222140Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5223160Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:03.5224311Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:05:03.5224791Z   )
2026-01-14T09:05:03.5224969Z )
2026-01-14T09:05:03.5225068Z 
2026-01-14T09:05:03.5225072Z 
2026-01-14T09:05:03.5225075Z 
2026-01-14T09:05:03.5225165Z def forward(self, x):
2026-01-14T09:05:03.5225459Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:03.5225818Z     conv_weight = self.conv.weight
2026-01-14T09:05:03.5226098Z     bn_weight = self.bn.weight
2026-01-14T09:05:03.5226356Z     bn_bias = self.bn.bias
2026-01-14T09:05:03.5226616Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:03.5226918Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:03.5227249Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:03.5227667Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:03.5228095Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:03.5228679Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:03.5229251Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:03.5229653Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:03.5230125Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:03.5230581Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:03.5231108Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:03.5231698Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:03.5232586Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:03.5233500Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:03.5234066Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:03.5235065Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:03.5236015Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:03.5236561Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:03.5237124Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:03.5237523Z     
2026-01-14T09:05:03.5237807Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:03.5238185Z model fx: GraphModule(
2026-01-14T09:05:03.5238508Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5239589Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:03.5240785Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:03.5241323Z   )
2026-01-14T09:05:03.5241502Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:03.5241818Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:03.5242274Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:03.5242767Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5243834Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:03.5245265Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1866, -0.1825, -0.1912]), max_val=tensor([0.1747, 0.1914, 0.1702]))
2026-01-14T09:05:03.5245952Z     )
2026-01-14T09:05:03.5246125Z   )
2026-01-14T09:05:03.5246400Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:03.5247444Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:03.5248599Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.984864354133606)
2026-01-14T09:05:03.5249347Z   )
2026-01-14T09:05:03.5249513Z )
2026-01-14T09:05:03.5249618Z 
2026-01-14T09:05:03.5249622Z 
2026-01-14T09:05:03.5249626Z 
2026-01-14T09:05:03.5249713Z def forward(self, x):
2026-01-14T09:05:22.9170909Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:22.9171867Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:22.9172480Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:22.9172931Z     return activation_post_process_1
2026-01-14T09:05:22.9173311Z     
2026-01-14T09:05:22.9173603Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:22.9174001Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:22.9174250Z           [0., 0., 0.],
2026-01-14T09:05:22.9174482Z           [0., 0., 0.]],
2026-01-14T09:05:22.9174629Z 
2026-01-14T09:05:22.9174711Z          [[0., 0., 0.],
2026-01-14T09:05:22.9174930Z           [0., 0., 0.],
2026-01-14T09:05:22.9175144Z           [0., 0., 0.]],
2026-01-14T09:05:22.9175293Z 
2026-01-14T09:05:22.9175377Z          [[0., 0., 0.],
2026-01-14T09:05:22.9175599Z           [0., 0., 0.],
2026-01-14T09:05:22.9175883Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:22.9176214Z converted model pt2e: GraphModule(
2026-01-14T09:05:22.9176499Z   (conv): Module()
2026-01-14T09:05:22.9176710Z   (bn): Module()
2026-01-14T09:05:22.9176940Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:22.9177177Z )
2026-01-14T09:05:22.9177281Z 
2026-01-14T09:05:22.9177291Z 
2026-01-14T09:05:22.9177295Z 
2026-01-14T09:05:22.9177390Z def forward(self, x):
2026-01-14T09:05:22.9177686Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:22.9178436Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:22.9179744Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:22.9180776Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:22.9181128Z     _scale_0 = self._scale_0
2026-01-14T09:05:22.9181396Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:22.9181715Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:05:22.9182792Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:22.9183761Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:22.9184752Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_weight_bias = None
2026-01-14T09:05:22.9185725Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:22.9186564Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007783781737089157, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:22.9187975Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:22.9189075Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:22.9189518Z     
2026-01-14T09:05:22.9189815Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:22.9190222Z onverted model fx: GraphModule(
2026-01-14T09:05:22.9199514Z   (conv): ConvReLU2d(
2026-01-14T09:05:22.9199885Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:22.9200279Z     (1): ReLU()
2026-01-14T09:05:22.9200484Z   )
2026-01-14T09:05:22.9200654Z )
2026-01-14T09:05:22.9200755Z 
2026-01-14T09:05:22.9200759Z 
2026-01-14T09:05:22.9200775Z 
2026-01-14T09:05:22.9200867Z def forward(self, x):
2026-01-14T09:05:22.9201605Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:22.9202945Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:22.9204081Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:22.9204994Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007783781737089157, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:22.9206383Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007783781737089157, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:22.9207348Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:22.9207626Z     
2026-01-14T09:05:22.9207923Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:22.9208318Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:22.9208574Z           [0., 0., 0.],
2026-01-14T09:05:22.9208791Z           [0., 0., 0.]],
2026-01-14T09:05:22.9208941Z 
2026-01-14T09:05:22.9209025Z          [[0., 0., 0.],
2026-01-14T09:05:22.9209241Z           [0., 0., 0.],
2026-01-14T09:05:22.9209462Z           [0., 0., 0.]],
2026-01-14T09:05:22.9209605Z 
2026-01-14T09:05:22.9209690Z          [[0., 0., 0.],
2026-01-14T09:05:22.9209896Z           [0., 0., 0.],
2026-01-14T09:05:22.9210123Z           [0., 0., 0.]]]])
2026-01-14T09:05:22.9210362Z model pt2e: GraphModule(
2026-01-14T09:05:22.9210606Z   (conv): Module()
2026-01-14T09:05:22.9210810Z   (bn): Module()
2026-01-14T09:05:22.9211119Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:22.9212209Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:22.9213477Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:22.9214025Z   )
2026-01-14T09:05:22.9214215Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:22.9214564Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:22.9215642Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:22.9216872Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:05:22.9217429Z   )
2026-01-14T09:05:22.9217706Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:22.9218746Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:22.9219934Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:05:22.9220449Z   )
2026-01-14T09:05:22.9220629Z )
2026-01-14T09:05:22.9220728Z 
2026-01-14T09:05:22.9220735Z 
2026-01-14T09:05:22.9220740Z 
2026-01-14T09:05:22.9220826Z def forward(self, x):
2026-01-14T09:05:22.9221126Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:22.9221478Z     conv_weight = self.conv.weight
2026-01-14T09:05:22.9221768Z     bn_weight = self.bn.weight
2026-01-14T09:05:22.9222024Z     bn_bias = self.bn.bias
2026-01-14T09:05:22.9222293Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:05:22.9222608Z     bn_running_var = self.bn.running_var
2026-01-14T09:05:22.9222956Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:05:22.9223440Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:22.9223880Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:22.9224433Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:05:22.9225037Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:05:22.9225456Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:05:22.9225896Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:05:22.9226359Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:05:22.9226902Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:05:22.9227490Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:05:22.9228396Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, None);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:22.9229290Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:05:22.9229858Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:05:22.9230867Z     batch_norm_1 = torch.ops.aten.batch_norm.default(div_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  div_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:05:22.9231825Z     relu = torch.ops.aten.relu.default(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:05:22.9232379Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:22.9232950Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:22.9233349Z     
2026-01-14T09:05:22.9233642Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:22.9234021Z model fx: GraphModule(
2026-01-14T09:05:22.9234357Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:22.9235437Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:22.9236653Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:22.9237239Z   )
2026-01-14T09:05:22.9237421Z   (conv): ConvBnReLU2d(
2026-01-14T09:05:22.9237701Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:22.9238161Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:05:22.9238662Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:22.9239675Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:22.9240916Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19124282896518707, max_val=0.19141820073127747)
2026-01-14T09:05:22.9241476Z     )
2026-01-14T09:05:22.9241652Z   )
2026-01-14T09:05:22.9241941Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0924911Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0078]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:44.0926486Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9838534593582153)
2026-01-14T09:05:44.0927118Z   )
2026-01-14T09:05:44.0927323Z )
2026-01-14T09:05:44.0927443Z 
2026-01-14T09:05:44.0927458Z 
2026-01-14T09:05:44.0927463Z 
2026-01-14T09:05:44.0927569Z def forward(self, x):
2026-01-14T09:05:44.0928287Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:44.0929001Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:44.0929729Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:44.0930389Z     return activation_post_process_1
2026-01-14T09:05:44.0930727Z     
2026-01-14T09:05:44.0931068Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:44.0931646Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:44.0931937Z           [0., 0., 0.],
2026-01-14T09:05:44.0932209Z           [0., 0., 0.]],
2026-01-14T09:05:44.0932381Z 
2026-01-14T09:05:44.0932475Z          [[0., 0., 0.],
2026-01-14T09:05:44.0932740Z           [0., 0., 0.],
2026-01-14T09:05:44.0933004Z           [0., 0., 0.]],
2026-01-14T09:05:44.0933175Z 
2026-01-14T09:05:44.0933268Z          [[0., 0., 0.],
2026-01-14T09:05:44.0933528Z           [0., 0., 0.],
2026-01-14T09:05:44.0933827Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:44.0934223Z converted model pt2e: GraphModule(
2026-01-14T09:05:44.0934541Z   (conv): Module()
2026-01-14T09:05:44.0934793Z   (bn): Module()
2026-01-14T09:05:44.0935045Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:44.0935323Z )
2026-01-14T09:05:44.0935443Z 
2026-01-14T09:05:44.0935448Z 
2026-01-14T09:05:44.0935455Z 
2026-01-14T09:05:44.0935565Z def forward(self, x):
2026-01-14T09:05:44.0935914Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:44.0936833Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:44.0938481Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:44.0939720Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:44.0940340Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:05:44.0941395Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.001507229870185256, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:05:44.0942506Z     conv_weight_bias = self.conv.weight_bias
2026-01-14T09:05:44.0943751Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_weight_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_weight_bias = None
2026-01-14T09:05:44.0944716Z     relu = torch.ops.aten.relu.default(conv2d_2);  conv2d_2 = None
2026-01-14T09:05:44.0945550Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.007779817562550306, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:44.0946937Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:44.0948022Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:44.0948454Z     
2026-01-14T09:05:44.0948743Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:44.0949311Z onverted model fx: GraphModule(
2026-01-14T09:05:44.0949569Z   (conv): ConvReLU2d(
2026-01-14T09:05:44.0949918Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:05:44.0950301Z     (1): ReLU()
2026-01-14T09:05:44.0950495Z   )
2026-01-14T09:05:44.0950664Z )
2026-01-14T09:05:44.0950766Z 
2026-01-14T09:05:44.0950770Z 
2026-01-14T09:05:44.0950774Z 
2026-01-14T09:05:44.0950859Z def forward(self, x):
2026-01-14T09:05:44.0951582Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:44.0952909Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:44.0954046Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:44.0954955Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007779817562550306, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:44.0956336Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007779817562550306, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:44.0957287Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:44.0957567Z     
2026-01-14T09:05:44.0957853Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:44.0958234Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:44.0958482Z           [0., 0., 0.],
2026-01-14T09:05:44.0958698Z           [0., 0., 0.]],
2026-01-14T09:05:44.0958846Z 
2026-01-14T09:05:44.0958924Z          [[0., 0., 0.],
2026-01-14T09:05:44.0959138Z           [0., 0., 0.],
2026-01-14T09:05:44.0959345Z           [0., 0., 0.]],
2026-01-14T09:05:44.0959485Z 
2026-01-14T09:05:44.0959568Z          [[0., 0., 0.],
2026-01-14T09:05:44.0959776Z           [0., 0., 0.],
2026-01-14T09:05:44.0959989Z           [0., 0., 0.]]]])
2026-01-14T09:05:44.0960419Z [32mPASSED[0m
2026-01-14T09:05:44.0960992Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_no_bias model pt2e: GraphModule(
2026-01-14T09:05:44.0961606Z   (conv): Module()
2026-01-14T09:05:44.0961917Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0963093Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:44.0964517Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:05:44.0965205Z   )
2026-01-14T09:05:44.0965542Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0966571Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:44.0967771Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:44.0968298Z   )
2026-01-14T09:05:44.0968489Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:44.0968826Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0969862Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:44.0971013Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:05:44.0971545Z   )
2026-01-14T09:05:44.0971716Z )
2026-01-14T09:05:44.0971814Z 
2026-01-14T09:05:44.0971818Z 
2026-01-14T09:05:44.0971822Z 
2026-01-14T09:05:44.0971906Z def forward(self, x):
2026-01-14T09:05:44.0972203Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:44.0972549Z     conv_weight = self.conv.weight
2026-01-14T09:05:44.0973019Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:44.0973599Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:44.0974069Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:44.0974849Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:44.0975686Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:44.0976188Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:44.0976757Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:44.0977151Z     
2026-01-14T09:05:44.0977448Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:44.0977819Z model fx: GraphModule(
2026-01-14T09:05:44.0978146Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0979167Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:44.0980369Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:44.0980906Z   )
2026-01-14T09:05:44.0981086Z   (conv): ConvReLU2d(
2026-01-14T09:05:44.0981353Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:44.0981748Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0982812Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:44.0984249Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1860, -0.1897, -0.1787]), max_val=tensor([0.1824, 0.1870, 0.1478]))
2026-01-14T09:05:44.0984934Z     )
2026-01-14T09:05:44.0985107Z   )
2026-01-14T09:05:44.0985395Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:44.0986472Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:44.0987673Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5882599353790283)
2026-01-14T09:05:44.0988164Z   )
2026-01-14T09:05:44.0988328Z )
2026-01-14T09:05:44.0988425Z 
2026-01-14T09:05:44.0988429Z 
2026-01-14T09:05:44.0988433Z 
2026-01-14T09:05:44.0988530Z def forward(self, x):
2026-01-14T09:05:44.0988879Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:44.0989432Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:44.0989997Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:44.0990446Z     return activation_post_process_1
2026-01-14T09:05:44.0990718Z     
2026-01-14T09:05:44.0990999Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:44.0991377Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:44.0991613Z           [0., 0., 0.],
2026-01-14T09:05:46.0018822Z           [0., 0., 0.]],
2026-01-14T09:05:46.0019520Z 
2026-01-14T09:05:46.0019730Z          [[0., 0., 0.],
2026-01-14T09:05:46.0020008Z           [0., 0., 0.],
2026-01-14T09:05:46.0020329Z           [0., 0., 0.]],
2026-01-14T09:05:46.0020506Z 
2026-01-14T09:05:46.0020603Z          [[0., 0., 0.],
2026-01-14T09:05:46.0020864Z           [0., 0., 0.],
2026-01-14T09:05:46.0021160Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:46.0021558Z converted model pt2e: GraphModule(
2026-01-14T09:05:46.0021876Z   (conv): Module()
2026-01-14T09:05:46.0022138Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:46.0022412Z )
2026-01-14T09:05:46.0022536Z 
2026-01-14T09:05:46.0022710Z 
2026-01-14T09:05:46.0022716Z 
2026-01-14T09:05:46.0022825Z def forward(self, x):
2026-01-14T09:05:46.0023187Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:46.0023603Z     _scale_0 = self._scale_0
2026-01-14T09:05:46.0023919Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:46.0024450Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:05:46.0025859Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:46.0027665Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:46.0029320Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:46.0030564Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:46.0031645Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:05:46.0032755Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:46.0033790Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006228470243513584, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:46.0035565Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:46.0036964Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:46.0037506Z     
2026-01-14T09:05:46.0037939Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:46.0038430Z onverted model fx: GraphModule(
2026-01-14T09:05:46.0038741Z   (conv): ConvReLU2d(
2026-01-14T09:05:46.0039212Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:46.0039746Z     (1): ReLU()
2026-01-14T09:05:46.0040058Z   )
2026-01-14T09:05:46.0040270Z )
2026-01-14T09:05:46.0040389Z 
2026-01-14T09:05:46.0040394Z 
2026-01-14T09:05:46.0040398Z 
2026-01-14T09:05:46.0040500Z def forward(self, x):
2026-01-14T09:05:46.0041319Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:46.0043015Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:46.0044398Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:46.0045561Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006228470243513584, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:46.0047332Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006228470243513584, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:46.0048553Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:46.0048887Z     
2026-01-14T09:05:46.0049457Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:46.0049937Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:46.0050225Z           [0., 0., 0.],
2026-01-14T09:05:46.0050491Z           [0., 0., 0.]],
2026-01-14T09:05:46.0050665Z 
2026-01-14T09:05:46.0050758Z          [[0., 0., 0.],
2026-01-14T09:05:46.0051100Z           [0., 0., 0.],
2026-01-14T09:05:46.0051445Z           [0., 0., 0.]],
2026-01-14T09:05:46.0051627Z 
2026-01-14T09:05:46.0051721Z          [[0., 0., 0.],
2026-01-14T09:05:46.0051970Z           [0., 0., 0.],
2026-01-14T09:05:46.0052238Z           [0., 0., 0.]]]])
2026-01-14T09:05:46.0052641Z model pt2e: GraphModule(
2026-01-14T09:05:46.0052922Z   (conv): Module()
2026-01-14T09:05:46.0053307Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0054619Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:46.0056196Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:05:46.0056889Z   )
2026-01-14T09:05:46.0057231Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0058530Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:46.0060056Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:46.0060738Z   )
2026-01-14T09:05:46.0060960Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:46.0061367Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0062666Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:46.0064134Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:05:46.0064755Z   )
2026-01-14T09:05:46.0064993Z )
2026-01-14T09:05:46.0065134Z 
2026-01-14T09:05:46.0065139Z 
2026-01-14T09:05:46.0065211Z 
2026-01-14T09:05:46.0065315Z def forward(self, x):
2026-01-14T09:05:46.0065667Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:46.0066123Z     conv_weight = self.conv.weight
2026-01-14T09:05:46.0066708Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:46.0067493Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:46.0068024Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:46.0069003Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:46.0070014Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:46.0070636Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:05:46.0071341Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:46.0071850Z     
2026-01-14T09:05:46.0072196Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:46.0072671Z model fx: GraphModule(
2026-01-14T09:05:46.0073067Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0074365Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:46.0075980Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:46.0076653Z   )
2026-01-14T09:05:46.0076841Z   (conv): ConvReLU2d(
2026-01-14T09:05:46.0077103Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:46.0077562Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0078569Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:46.0081218Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18965116143226624, max_val=0.18703685700893402)
2026-01-14T09:05:46.0081778Z     )
2026-01-14T09:05:46.0081951Z   )
2026-01-14T09:05:46.0082229Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:46.0083259Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0062]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:46.0084412Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.5892566442489624)
2026-01-14T09:05:46.0084906Z   )
2026-01-14T09:05:46.0085075Z )
2026-01-14T09:05:46.0085176Z 
2026-01-14T09:05:46.0085180Z 
2026-01-14T09:05:46.0085186Z 
2026-01-14T09:05:46.0085274Z def forward(self, x):
2026-01-14T09:05:46.0085629Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:46.0086182Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:46.0086753Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:46.0087194Z     return activation_post_process_1
2026-01-14T09:05:46.0087456Z     
2026-01-14T09:05:46.0087737Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:46.0088116Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:46.0088354Z           [0., 0., 0.],
2026-01-14T09:05:46.0088572Z           [0., 0., 0.]],
2026-01-14T09:05:46.0088713Z 
2026-01-14T09:05:46.0088793Z          [[0., 0., 0.],
2026-01-14T09:05:46.0089000Z           [0., 0., 0.],
2026-01-14T09:05:46.0089215Z           [0., 0., 0.]],
2026-01-14T09:05:46.0089354Z 
2026-01-14T09:05:46.0089478Z          [[0., 0., 0.],
2026-01-14T09:05:46.0089695Z           [0., 0., 0.],
2026-01-14T09:05:46.0089936Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:46.0090255Z converted model pt2e: GraphModule(
2026-01-14T09:05:46.0090519Z   (conv): Module()
2026-01-14T09:05:46.0090735Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:46.0091001Z )
2026-01-14T09:05:46.0091097Z 
2026-01-14T09:05:46.0091104Z 
2026-01-14T09:05:46.0091107Z 
2026-01-14T09:05:46.0091190Z def forward(self, x):
2026-01-14T09:05:46.0091546Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:46.0091933Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:05:46.0092896Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0014933162601664662, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:46.0094194Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:47.6901214Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:47.6902543Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:47.6903624Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:05:47.6904739Z     relu = torch.ops.aten.relu.default(conv2d);  conv2d = None
2026-01-14T09:05:47.6905752Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.006232379004359245, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:05:47.6907659Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:47.6909046Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:47.6909650Z     
2026-01-14T09:05:47.6910004Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.6910483Z onverted model fx: GraphModule(
2026-01-14T09:05:47.6910805Z   (conv): ConvReLU2d(
2026-01-14T09:05:47.6911263Z     (0): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:47.6911804Z     (1): ReLU()
2026-01-14T09:05:47.6912046Z   )
2026-01-14T09:05:47.6912256Z )
2026-01-14T09:05:47.6912384Z 
2026-01-14T09:05:47.6912388Z 
2026-01-14T09:05:47.6912393Z 
2026-01-14T09:05:47.6912509Z def forward(self, x):
2026-01-14T09:05:47.6913324Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:47.6915014Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:47.6916380Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:47.6917525Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.006232379004359245, -128, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:47.6919282Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.006232379004359245, -128, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:47.6920486Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:47.6920823Z     
2026-01-14T09:05:47.6921175Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.6921721Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:47.6922022Z           [0., 0., 0.],
2026-01-14T09:05:47.6922282Z           [0., 0., 0.]],
2026-01-14T09:05:47.6922461Z 
2026-01-14T09:05:47.6922560Z          [[0., 0., 0.],
2026-01-14T09:05:47.6922813Z           [0., 0., 0.],
2026-01-14T09:05:47.6923140Z           [0., 0., 0.]],
2026-01-14T09:05:47.6923312Z 
2026-01-14T09:05:47.6923412Z          [[0., 0., 0.],
2026-01-14T09:05:47.6923660Z           [0., 0., 0.],
2026-01-14T09:05:47.6923918Z           [0., 0., 0.]]]])
2026-01-14T09:05:47.6924198Z model pt2e: GraphModule(
2026-01-14T09:05:47.6924485Z   (conv): Module()
2026-01-14T09:05:47.6924852Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6926234Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:47.6928044Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:05:47.6928903Z   )
2026-01-14T09:05:47.6929242Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6930527Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.6932136Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:47.6932805Z   )
2026-01-14T09:05:47.6933027Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:47.6933432Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6934766Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.6936348Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:05:47.6937075Z   )
2026-01-14T09:05:47.6937286Z )
2026-01-14T09:05:47.6937404Z 
2026-01-14T09:05:47.6937409Z 
2026-01-14T09:05:47.6937414Z 
2026-01-14T09:05:47.6937517Z def forward(self, x):
2026-01-14T09:05:47.6937875Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:47.6950186Z     conv_weight = self.conv.weight
2026-01-14T09:05:47.6950803Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:47.6951530Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:47.6952081Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:47.6953064Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:47.6954193Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:05:47.6954925Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:47.6955428Z     
2026-01-14T09:05:47.6955784Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.6956249Z model fx: GraphModule(
2026-01-14T09:05:47.6956650Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6958041Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.6959440Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:47.6960105Z   )
2026-01-14T09:05:47.6960287Z   (conv): Conv2d(
2026-01-14T09:05:47.6960545Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:47.6960928Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6962013Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0014, 0.0015]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:05:47.6963536Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1913, -0.1469, -0.1921]), max_val=tensor([0.1740, 0.1746, 0.1810]))
2026-01-14T09:05:47.6964223Z     )
2026-01-14T09:05:47.6964400Z   )
2026-01-14T09:05:47.6964678Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:47.6965777Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0080]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:47.6967004Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9872972965240479, max_val=1.0470484495162964)
2026-01-14T09:05:47.6967550Z   )
2026-01-14T09:05:47.6967728Z )
2026-01-14T09:05:47.6967831Z 
2026-01-14T09:05:47.6967835Z 
2026-01-14T09:05:47.6967839Z 
2026-01-14T09:05:47.6967925Z def forward(self, x):
2026-01-14T09:05:47.6968287Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:47.6968848Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:47.6969416Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:47.6969867Z     return activation_post_process_1
2026-01-14T09:05:47.6970130Z     
2026-01-14T09:05:47.6970492Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:47.6970879Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:47.6971130Z           [0., 0., 0.],
2026-01-14T09:05:47.6971399Z           [0., 0., 0.]],
2026-01-14T09:05:47.6971556Z 
2026-01-14T09:05:47.6971700Z          [[0., 0., 0.],
2026-01-14T09:05:47.6971920Z           [0., 0., 0.],
2026-01-14T09:05:47.6972137Z           [0., 0., 0.]],
2026-01-14T09:05:47.6972279Z 
2026-01-14T09:05:47.6972366Z          [[0., 0., 0.],
2026-01-14T09:05:47.6972577Z           [0., 0., 0.],
2026-01-14T09:05:47.6972835Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:47.6973155Z converted model pt2e: GraphModule(
2026-01-14T09:05:47.6973444Z   (conv): Module()
2026-01-14T09:05:47.6973658Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:47.6973895Z )
2026-01-14T09:05:47.6973994Z 
2026-01-14T09:05:47.6973997Z 
2026-01-14T09:05:47.6974001Z 
2026-01-14T09:05:47.6974094Z def forward(self, x):
2026-01-14T09:05:47.6974386Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:47.6974739Z     _scale_0 = self._scale_0
2026-01-14T09:05:47.6974994Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:05:47.6975327Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:05:47.6976408Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:05:47.6977831Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:47.6979134Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:47.6980105Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:47.6981016Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel_default);  dequantize_per_tensor_default = dequantize_per_channel_default = None
2026-01-14T09:05:47.6982288Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007977825589478016, -4, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:05:47.6983720Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:49.3943427Z     return pytree.tree_unflatten((dequantize_per_tensor_default_1,), self._out_spec)
2026-01-14T09:05:49.3944005Z     
2026-01-14T09:05:49.3944387Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:49.3944882Z onverted model fx: GraphModule(
2026-01-14T09:05:49.3945427Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:49.3945977Z )
2026-01-14T09:05:49.3946110Z 
2026-01-14T09:05:49.3946116Z 
2026-01-14T09:05:49.3946120Z 
2026-01-14T09:05:49.3946229Z def forward(self, x):
2026-01-14T09:05:49.3947061Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:49.3948810Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:49.3950387Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:49.3951544Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007977825589478016, -4, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:49.3953437Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007977825589478016, -4, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:49.3954654Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:49.3955081Z     
2026-01-14T09:05:49.3955427Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:49.3955907Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:49.3956194Z           [0., 0., 0.],
2026-01-14T09:05:49.3956469Z           [0., 0., 0.]],
2026-01-14T09:05:49.3956643Z 
2026-01-14T09:05:49.3956738Z          [[0., 0., 0.],
2026-01-14T09:05:49.3956998Z           [0., 0., 0.],
2026-01-14T09:05:49.3957248Z           [0., 0., 0.]],
2026-01-14T09:05:49.3957430Z 
2026-01-14T09:05:49.3957523Z          [[0., 0., 0.],
2026-01-14T09:05:49.3957785Z           [0., 0., 0.],
2026-01-14T09:05:49.3958049Z           [0., 0., 0.]]]])
2026-01-14T09:05:49.3958345Z model pt2e: GraphModule(
2026-01-14T09:05:49.3958631Z   (conv): Module()
2026-01-14T09:05:49.3959011Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3960319Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:49.3961906Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:05:49.3962604Z   )
2026-01-14T09:05:49.3962938Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3964243Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:49.3965775Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:49.3966459Z   )
2026-01-14T09:05:49.3966757Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:49.3967168Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3968453Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:49.3970057Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:05:49.3970738Z   )
2026-01-14T09:05:49.3970945Z )
2026-01-14T09:05:49.3971061Z 
2026-01-14T09:05:49.3971066Z 
2026-01-14T09:05:49.3971071Z 
2026-01-14T09:05:49.3971179Z def forward(self, x):
2026-01-14T09:05:49.3971634Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:49.3972067Z     conv_weight = self.conv.weight
2026-01-14T09:05:49.3972647Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:05:49.3973378Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:05:49.3973899Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:49.3974883Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1);  activation_post_process_0 = activation_post_process_1 = None
2026-01-14T09:05:49.3976010Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:05:49.3976730Z     return pytree.tree_unflatten((activation_post_process_2,), self._out_spec)
2026-01-14T09:05:49.3977236Z     
2026-01-14T09:05:49.3977580Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:49.3978051Z model fx: GraphModule(
2026-01-14T09:05:49.3978439Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3979804Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:49.3981354Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:05:49.3982070Z   )
2026-01-14T09:05:49.3982289Z   (conv): Conv2d(
2026-01-14T09:05:49.3982584Z     3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False
2026-01-14T09:05:49.3983050Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3984338Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:05:49.3985905Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.19212539494037628, max_val=0.18097467720508575)
2026-01-14T09:05:49.3986609Z     )
2026-01-14T09:05:49.3986812Z   )
2026-01-14T09:05:49.3987155Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:05:49.3988458Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0079]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:05:49.3989996Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9800506234169006, max_val=1.0470484495162964)
2026-01-14T09:05:49.3990676Z   )
2026-01-14T09:05:49.3990873Z )
2026-01-14T09:05:49.3990994Z 
2026-01-14T09:05:49.3990999Z 
2026-01-14T09:05:49.3991004Z 
2026-01-14T09:05:49.3991107Z def forward(self, x):
2026-01-14T09:05:49.3991538Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:05:49.3992232Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:05:49.3992945Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:05:49.3993542Z     return activation_post_process_1
2026-01-14T09:05:49.3993874Z     
2026-01-14T09:05:49.3994215Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:49.3994686Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:05:49.3994971Z           [0., 0., 0.],
2026-01-14T09:05:49.3995281Z           [0., 0., 0.]],
2026-01-14T09:05:49.3995452Z 
2026-01-14T09:05:49.3995550Z          [[0., 0., 0.],
2026-01-14T09:05:49.3995801Z           [0., 0., 0.],
2026-01-14T09:05:49.3996057Z           [0., 0., 0.]],
2026-01-14T09:05:49.3996227Z 
2026-01-14T09:05:49.3996320Z          [[0., 0., 0.],
2026-01-14T09:05:49.3996576Z           [0., 0., 0.],
2026-01-14T09:05:49.3996866Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:05:49.3997257Z converted model pt2e: GraphModule(
2026-01-14T09:05:49.3997577Z   (conv): Module()
2026-01-14T09:05:49.3997840Z   (_guards_fn): GuardsFn()
2026-01-14T09:05:49.3998113Z )
2026-01-14T09:05:49.3998238Z 
2026-01-14T09:05:49.3998243Z 
2026-01-14T09:05:49.3998250Z 
2026-01-14T09:05:49.3998352Z def forward(self, x):
2026-01-14T09:05:49.3998703Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:05:49.3999177Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:05:49.4000474Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0015127983642742038, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:49.4001994Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:05:49.4003305Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:49.4004372Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:05:49.4005226Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_1, dequantize_per_tensor_default);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:05:49.4006523Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.007949408143758774, -5, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:05:49.4007908Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:05:49.4008978Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:05:49.4009407Z     
2026-01-14T09:05:49.4009687Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:05:49.4010082Z onverted model fx: GraphModule(
2026-01-14T09:05:49.4010518Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1), bias=False)
2026-01-14T09:05:49.4010952Z )
2026-01-14T09:05:49.4011052Z 
2026-01-14T09:05:49.4011056Z 
2026-01-14T09:05:49.4011065Z 
2026-01-14T09:05:49.4011148Z def forward(self, x):
2026-01-14T09:05:49.4011842Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:05:49.4013160Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:05:49.4014237Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:05:49.4015140Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.007949408143758774, -5, -128, 127, torch.int8);  conv = None
2026-01-14T09:05:49.4016607Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.007949408143758774, -5, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:05:49.4017562Z     return dequantize_per_tensor_default_1
2026-01-14T09:05:49.4017835Z     
2026-01-14T09:07:15.4756398Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:15.4759747Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:15.4760044Z           [0., 0., 0.],
2026-01-14T09:07:15.4760628Z           [0., 0., 0.]],
2026-01-14T09:07:15.4760821Z 
2026-01-14T09:07:15.4760914Z          [[0., 0., 0.],
2026-01-14T09:07:15.4761131Z           [0., 0., 0.],
2026-01-14T09:07:15.4761342Z           [0., 0., 0.]],
2026-01-14T09:07:15.4761483Z 
2026-01-14T09:07:15.4761561Z          [[0., 0., 0.],
2026-01-14T09:07:15.4761771Z           [0., 0., 0.],
2026-01-14T09:07:15.4761980Z           [0., 0., 0.]]]])
2026-01-14T09:07:15.4762452Z [32mPASSED[0m
2026-01-14T09:07:15.4763112Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn [32mPASSED[0m
2026-01-14T09:07:15.4764177Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_transpose_bn_relu [32mPASSED[0m
2026-01-14T09:07:15.4765156Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_inplace_add_relu model pt2e: GraphModule(
2026-01-14T09:07:15.4765778Z   (conv): Module()
2026-01-14T09:07:15.4766085Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4767139Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:15.4768819Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:07:15.4769417Z   )
2026-01-14T09:07:15.4769704Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4770716Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4772178Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:15.4772713Z   )
2026-01-14T09:07:15.4772898Z   (_guards_fn): GuardsFn()
2026-01-14T09:07:15.4773233Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4774249Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4775465Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:15.4775998Z   )
2026-01-14T09:07:15.4776277Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4777299Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4778451Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:15.4778942Z   )
2026-01-14T09:07:15.4779104Z )
2026-01-14T09:07:15.4779206Z 
2026-01-14T09:07:15.4779211Z 
2026-01-14T09:07:15.4779215Z 
2026-01-14T09:07:15.4779302Z def forward(self, x):
2026-01-14T09:07:15.4779592Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:15.4779939Z     conv_weight = self.conv.weight
2026-01-14T09:07:15.4780521Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:07:15.4781007Z     conv_bias = self.conv.bias
2026-01-14T09:07:15.4781350Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:07:15.4781771Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:07:15.4782530Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:07:15.4783442Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:07:15.4784284Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:07:15.4785041Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:15.4785527Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:07:15.4786100Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:07:15.4786498Z     
2026-01-14T09:07:15.4786781Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:15.4787160Z model fx: GraphModule(
2026-01-14T09:07:15.4787476Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4788501Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4789699Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:15.4790233Z   )
2026-01-14T09:07:15.4790411Z   (conv): Conv2d(
2026-01-14T09:07:15.4790628Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:07:15.4791018Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4792034Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:07:15.4793362Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.2877]), max_val=tensor([-0.2877]))
2026-01-14T09:07:15.4793951Z     )
2026-01-14T09:07:15.4794121Z   )
2026-01-14T09:07:15.4794398Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4795421Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4796627Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:15.4797189Z   )
2026-01-14T09:07:15.4797383Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:15.4797720Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:15.4798748Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:15.4799905Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:15.4800385Z   )
2026-01-14T09:07:15.4800549Z )
2026-01-14T09:07:15.4800643Z 
2026-01-14T09:07:15.4800647Z 
2026-01-14T09:07:15.4800652Z 
2026-01-14T09:07:15.4800734Z def forward(self, x):
2026-01-14T09:07:15.4801087Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:15.4801527Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:07:15.4801968Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:07:15.4802743Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:07:15.4803331Z     relu = self.relu(add);  add = None
2026-01-14T09:07:15.4803755Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:07:15.4804239Z     return activation_post_process_2
2026-01-14T09:07:15.4804493Z     
2026-01-14T09:07:15.4804778Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:15.4805185Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:15.4805437Z           [0., 0., 0.],
2026-01-14T09:07:15.4805678Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:07:15.4805992Z converted model pt2e: GraphModule(
2026-01-14T09:07:15.4806249Z   (conv): Module()
2026-01-14T09:07:15.4806465Z   (_guards_fn): GuardsFn()
2026-01-14T09:07:15.4806685Z )
2026-01-14T09:07:15.4806787Z 
2026-01-14T09:07:15.4806793Z 
2026-01-14T09:07:15.4806798Z 
2026-01-14T09:07:15.4806882Z def forward(self, x):
2026-01-14T09:07:15.4807170Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:15.4807503Z     _scale_0 = self._scale_0
2026-01-14T09:07:15.4807763Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:07:15.4808089Z     quantize_per_channel_default = self._frozen_param0
2026-01-14T09:07:15.4809165Z     dequantize_per_channel_default = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel_default, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel_default = _scale_0 = _zero_point_0 = None
2026-01-14T09:07:15.4810189Z     conv_bias = self.conv.bias
2026-01-14T09:07:15.4810805Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:07:15.4812086Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:07:15.4813482Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:15.4815426Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:07:15.4816370Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_3, dequantize_per_channel_default, conv_bias);  dequantize_per_tensor_default_3 = dequantize_per_channel_default = conv_bias = None
2026-01-14T09:07:15.4817704Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:07:15.4819084Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:15.4820498Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_1, dequantize_per_tensor_default_4);  dequantize_per_tensor_default_1 = dequantize_per_tensor_default_4 = None
2026-01-14T09:07:15.4821345Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:15.4822146Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:07:17.2385057Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:17.2386284Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:07:17.2386720Z     
2026-01-14T09:07:17.2387025Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:17.2387420Z onverted model fx: GraphModule(
2026-01-14T09:07:17.2387958Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:07:17.2388382Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:17.2388629Z )
2026-01-14T09:07:17.2388730Z 
2026-01-14T09:07:17.2388735Z 
2026-01-14T09:07:17.2388739Z 
2026-01-14T09:07:17.2388913Z def forward(self, x):
2026-01-14T09:07:17.2389557Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:07:17.2390876Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:17.2391822Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:07:17.2392595Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:07:17.2393975Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:07:17.2395274Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:07:17.2395960Z     relu = self.relu(add);  add = None
2026-01-14T09:07:17.2396697Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:07:17.2398159Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:07:17.2399124Z     return dequantize_per_tensor_default_2
2026-01-14T09:07:17.2399406Z     
2026-01-14T09:07:17.2399699Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:17.2400089Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:17.2400412Z           [0., 0., 0.],
2026-01-14T09:07:17.2400637Z           [0., 0., 0.]]]])
2026-01-14T09:07:17.2400875Z model pt2e: GraphModule(
2026-01-14T09:07:17.2401115Z   (conv): Module()
2026-01-14T09:07:17.2401418Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2402465Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:07:17.2403744Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:07:17.2404293Z   )
2026-01-14T09:07:17.2404581Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2405650Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2406856Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:17.2407401Z   )
2026-01-14T09:07:17.2407588Z   (_guards_fn): GuardsFn()
2026-01-14T09:07:17.2407930Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2408943Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2410154Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:17.2410698Z   )
2026-01-14T09:07:17.2411021Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2412147Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2413345Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:17.2413836Z   )
2026-01-14T09:07:17.2414010Z )
2026-01-14T09:07:17.2414109Z 
2026-01-14T09:07:17.2414114Z 
2026-01-14T09:07:17.2414118Z 
2026-01-14T09:07:17.2414205Z def forward(self, x):
2026-01-14T09:07:17.2414499Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:17.2414845Z     conv_weight = self.conv.weight
2026-01-14T09:07:17.2415322Z     activation_post_process_1 = self.activation_post_process_1(conv_weight);  conv_weight = None
2026-01-14T09:07:17.2415812Z     conv_bias = self.conv.bias
2026-01-14T09:07:17.2416168Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:07:17.2416599Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:07:17.2417357Z     conv2d = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, conv_bias);  activation_post_process_1 = conv_bias = None
2026-01-14T09:07:17.2418220Z     activation_post_process_2 = self.activation_post_process_2(conv2d);  conv2d = None
2026-01-14T09:07:17.2419070Z     add_ = torch.ops.aten.add_.Tensor(activation_post_process_2, activation_post_process_0);  activation_post_process_2 = activation_post_process_0 = None
2026-01-14T09:07:17.2419836Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:07:17.2420331Z     activation_post_process_3 = self.activation_post_process_3(relu_);  relu_ = None
2026-01-14T09:07:17.2420948Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:07:17.2421355Z     
2026-01-14T09:07:17.2421642Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:17.2422027Z model fx: GraphModule(
2026-01-14T09:07:17.2422392Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2423422Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0126]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2424634Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7008640766143799, max_val=1.5035617351531982)
2026-01-14T09:07:17.2425173Z   )
2026-01-14T09:07:17.2425358Z   (conv): Conv2d(
2026-01-14T09:07:17.2425585Z     1, 1, kernel_size=(1, 1), stride=(1, 1)
2026-01-14T09:07:17.2425939Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2426953Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0011]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:07:17.2428205Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28767645359039307, max_val=-0.28767645359039307)
2026-01-14T09:07:17.2428758Z     )
2026-01-14T09:07:17.2428952Z   )
2026-01-14T09:07:17.2429232Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2430264Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0036]), zero_point=tensor([43], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2431474Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6198297739028931, max_val=0.30200809240341187)
2026-01-14T09:07:17.2440794Z   )
2026-01-14T09:07:17.2441033Z   (relu): ReLU(inplace=True)
2026-01-14T09:07:17.2441459Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:07:17.2442517Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0035]), zero_point=tensor([-128], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:07:17.2443793Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.8897914886474609)
2026-01-14T09:07:17.2444284Z   )
2026-01-14T09:07:17.2444459Z )
2026-01-14T09:07:17.2444557Z 
2026-01-14T09:07:17.2444562Z 
2026-01-14T09:07:17.2444566Z 
2026-01-14T09:07:17.2444663Z def forward(self, x):
2026-01-14T09:07:17.2445026Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:07:17.2445472Z     conv = self.conv(activation_post_process_0)
2026-01-14T09:07:17.2445915Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:07:17.2446649Z     add = activation_post_process_1 + activation_post_process_0;  activation_post_process_1 = activation_post_process_0 = None
2026-01-14T09:07:17.2447239Z     relu = self.relu(add);  add = None
2026-01-14T09:07:17.2447659Z     activation_post_process_2 = self.activation_post_process_2(relu);  relu = None
2026-01-14T09:07:17.2448094Z     return activation_post_process_2
2026-01-14T09:07:17.2448357Z     
2026-01-14T09:07:17.2448632Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:07:17.2449281Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:07:17.2449534Z           [0., 0., 0.],
2026-01-14T09:07:17.2449781Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:07:17.2450098Z converted model pt2e: GraphModule(
2026-01-14T09:07:17.2450364Z   (conv): Module()
2026-01-14T09:07:17.2450578Z   (_guards_fn): GuardsFn()
2026-01-14T09:07:17.2450794Z )
2026-01-14T09:07:17.2450898Z 
2026-01-14T09:07:17.2450902Z 
2026-01-14T09:07:17.2450906Z 
2026-01-14T09:07:17.2451073Z def forward(self, x):
2026-01-14T09:07:17.2451428Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:07:17.2451808Z     quantize_per_tensor_default = self._frozen_param0
2026-01-14T09:07:17.2452768Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.002265168819576502, 0, -127, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:07:17.2453740Z     conv_bias = self.conv.bias
2026-01-14T09:07:17.2454373Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:07:17.2455525Z     dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8)
2026-01-14T09:08:03.8457584Z     dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:03.8458617Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:03.8459566Z     conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default, conv_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default = conv_bias = None
2026-01-14T09:08:03.8460941Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d, 0.003615050343796611, 43, -128, 127, torch.int8);  conv2d = None
2026-01-14T09:08:03.8462346Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:03.8463779Z     add_ = torch.ops.aten.add_.Tensor(dequantize_per_tensor_default_2, dequantize_per_tensor_default_5);  dequantize_per_tensor_default_2 = dequantize_per_tensor_default_5 = None
2026-01-14T09:08:03.8464824Z     relu_ = torch.ops.aten.relu_.default(add_);  add_ = None
2026-01-14T09:08:03.8465631Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.003489378374069929, -128, -128, 127, torch.int8);  relu_ = None
2026-01-14T09:08:03.8467033Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:08:03.8468207Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:08:03.8468636Z     
2026-01-14T09:08:03.8468934Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:03.8469325Z onverted model fx: GraphModule(
2026-01-14T09:08:03.8469749Z   (conv): QuantizedConv2d(Reference)(1, 1, kernel_size=(1, 1), stride=(1, 1))
2026-01-14T09:08:03.8470181Z   (relu): ReLU(inplace=True)
2026-01-14T09:08:03.8470417Z )
2026-01-14T09:08:03.8470526Z 
2026-01-14T09:08:03.8470534Z 
2026-01-14T09:08:03.8470538Z 
2026-01-14T09:08:03.8470628Z def forward(self, x):
2026-01-14T09:08:03.8471278Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.01256637554615736, 7, -128, 127, torch.int8);  x = None
2026-01-14T09:08:03.8472590Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.01256637554615736, 7, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:03.8473535Z     conv = self.conv(dequantize_per_tensor_default)
2026-01-14T09:08:03.8474305Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.003615050343796611, 43, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:03.8475759Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.003615050343796611, 43, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:03.8477067Z     add = dequantize_per_tensor_default_1 + dequantize_per_tensor_default;  dequantize_per_tensor_default_1 = dequantize_per_tensor_default = None
2026-01-14T09:08:03.8477821Z     relu = self.relu(add);  add = None
2026-01-14T09:08:03.8478560Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.003489378374069929, -128, -128, 127, torch.int8);  relu = None
2026-01-14T09:08:03.8479945Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.003489378374069929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:03.8480897Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:03.8481185Z     
2026-01-14T09:08:03.8481473Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:03.8481871Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:03.8482115Z           [0., 0., 0.],
2026-01-14T09:08:03.8482339Z           [0., 0., 0.]]]])
2026-01-14T09:08:03.8482800Z [32mPASSED[0m
2026-01-14T09:08:03.8483523Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype [32mPASSED[0m
2026-01-14T09:08:03.8484626Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_preserve_source_fn_stack [32mPASSED[0m
2026-01-14T09:08:03.8485648Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec [32mPASSED[0m
2026-01-14T09:08:03.8486629Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_update_shared_qspec model pt2e: GraphModule(
2026-01-14T09:08:03.8487268Z   (conv): Module()
2026-01-14T09:08:03.8487472Z   (bn): Module()
2026-01-14T09:08:03.8487779Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:03.8488854Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:03.8490068Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:03.8490638Z   )
2026-01-14T09:08:03.8490828Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:03.8491173Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:03.8492347Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:03.8493782Z     (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:08:03.8494466Z   )
2026-01-14T09:08:03.8494756Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:03.8495788Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:03.8496995Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:03.8497535Z   )
2026-01-14T09:08:03.8497818Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:03.8498843Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:03.8500099Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:03.8500632Z   )
2026-01-14T09:08:03.8500807Z )
2026-01-14T09:08:03.8500903Z 
2026-01-14T09:08:03.8500908Z 
2026-01-14T09:08:03.8500911Z 
2026-01-14T09:08:03.8500993Z def forward(self, x):
2026-01-14T09:08:03.8501331Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:03.8501691Z     conv_weight = self.conv.weight
2026-01-14T09:08:03.8501966Z     conv_bias = self.conv.bias
2026-01-14T09:08:03.8502227Z     bn_weight = self.bn.weight
2026-01-14T09:08:03.8502484Z     bn_bias = self.bn.bias
2026-01-14T09:08:03.8502747Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:08:03.8503049Z     bn_running_var = self.bn.running_var
2026-01-14T09:08:03.8503390Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:08:03.8503807Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:08:03.8504238Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:03.8504789Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:08:03.8505342Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:08:03.8505747Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:08:03.8506170Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:08:03.8506636Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:08:03.8507157Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:08:03.8507745Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:08:03.8508393Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:08:03.8509438Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:08:03.8510436Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:08:03.8511005Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:08:03.8511627Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:08:03.8512261Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:08:03.8513221Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:08:03.8514253Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:08:03.8515029Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:08:03.8515786Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:08:03.8516384Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:03.8516827Z     
2026-01-14T09:08:03.8517115Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:03.8517486Z model fx: GraphModule(
2026-01-14T09:08:03.8517815Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5758304Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:23.5759610Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:23.5760150Z   )
2026-01-14T09:08:23.5760346Z   (conv): ConvBn2d(
2026-01-14T09:08:23.5760751Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:08:23.5761218Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:08:23.5761729Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5762908Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015, 0.0015, 0.0014]), zero_point=tensor([0, 0, 0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False
2026-01-14T09:08:23.5764375Z       (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([-0.1872, -0.1882, -0.1827]), max_val=tensor([0.1805, 0.1400, 0.1829]))
2026-01-14T09:08:23.5765068Z     )
2026-01-14T09:08:23.5765254Z   )
2026-01-14T09:08:23.5765547Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5766586Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:23.5767809Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:23.5768348Z   )
2026-01-14T09:08:23.5768579Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:23.5768988Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5770028Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0149]), zero_point=tensor([-46], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:23.5771304Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2267813682556152, max_val=2.578756093978882)
2026-01-14T09:08:23.5771836Z   )
2026-01-14T09:08:23.5772012Z )
2026-01-14T09:08:23.5772113Z 
2026-01-14T09:08:23.5772117Z 
2026-01-14T09:08:23.5772124Z 
2026-01-14T09:08:23.5772218Z def forward(self, x):
2026-01-14T09:08:23.5772669Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:23.5773233Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:08:23.5773801Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:23.5774492Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:08:23.5775122Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:08:23.5775603Z     return activation_post_process_2
2026-01-14T09:08:23.5775869Z     
2026-01-14T09:08:23.5776155Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:23.5776541Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:23.5776778Z           [0., 0., 0.],
2026-01-14T09:08:23.5776994Z           [0., 0., 0.]],
2026-01-14T09:08:23.5777139Z 
2026-01-14T09:08:23.5777219Z          [[0., 0., 0.],
2026-01-14T09:08:23.5777442Z           [0., 0., 0.],
2026-01-14T09:08:23.5777649Z           [0., 0., 0.]],
2026-01-14T09:08:23.5777797Z 
2026-01-14T09:08:23.5777874Z          [[0., 0., 0.],
2026-01-14T09:08:23.5778086Z           [0., 0., 0.],
2026-01-14T09:08:23.5778338Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:23.5778662Z converted model pt2e: GraphModule(
2026-01-14T09:08:23.5778922Z   (conv): Module()
2026-01-14T09:08:23.5779130Z   (bn): Module()
2026-01-14T09:08:23.5779335Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:23.5779559Z )
2026-01-14T09:08:23.5779657Z 
2026-01-14T09:08:23.5779661Z 
2026-01-14T09:08:23.5779665Z 
2026-01-14T09:08:23.5779765Z def forward(self, x):
2026-01-14T09:08:23.5780060Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:23.5780408Z     conv_bias = self.conv.bias
2026-01-14T09:08:23.5782681Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:08:23.5783998Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:23.5785012Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:23.5785357Z     _scale_0 = self._scale_0
2026-01-14T09:08:23.5785617Z     _zero_point_0 = self._zero_point_0
2026-01-14T09:08:23.5785927Z     quantize_per_channel = self._frozen_param0
2026-01-14T09:08:23.5786884Z     dequantize_per_channel = torch.ops.quantized_decomposed.dequantize_per_channel.default(quantize_per_channel, _scale_0, _zero_point_0, 0, -127, 127, torch.int8);  quantize_per_channel = _scale_0 = _zero_point_0 = None
2026-01-14T09:08:23.5788351Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_channel, conv_bias);  dequantize_per_tensor_default = dequantize_per_channel = conv_bias = None
2026-01-14T09:08:23.5789654Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014923675917088985, -46, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:08:23.5791110Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:23.5792366Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_1, -1.0, 1.0);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:23.5793470Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:23.5794867Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:23.5796000Z     return pytree.tree_unflatten((dequantize_per_tensor_default_2,), self._out_spec)
2026-01-14T09:08:23.5796431Z     
2026-01-14T09:08:23.5796718Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:23.5797111Z onverted model fx: GraphModule(
2026-01-14T09:08:23.5797541Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:08:23.5797991Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:23.5798281Z )
2026-01-14T09:08:23.5798384Z 
2026-01-14T09:08:23.5798388Z 
2026-01-14T09:08:23.5798392Z 
2026-01-14T09:08:23.5798478Z def forward(self, x):
2026-01-14T09:08:23.5799129Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:23.5800451Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:23.5801527Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:08:23.5802438Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014923675917088985, -46, -128, 127, torch.int8);  conv = None
2026-01-14T09:08:23.5803807Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:08:23.5804954Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:08:23.5805980Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014923675917088985, -46, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:23.5807391Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014923675917088985, -46, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:23.5808379Z     return dequantize_per_tensor_default_2
2026-01-14T09:08:23.5808653Z     
2026-01-14T09:08:23.5808947Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:23.5809327Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:23.5809571Z           [0., 0., 0.],
2026-01-14T09:08:23.5809788Z           [0., 0., 0.]],
2026-01-14T09:08:23.5809931Z 
2026-01-14T09:08:23.5810008Z          [[0., 0., 0.],
2026-01-14T09:08:23.5810225Z           [0., 0., 0.],
2026-01-14T09:08:23.5810433Z           [0., 0., 0.]],
2026-01-14T09:08:23.5810574Z 
2026-01-14T09:08:23.5810658Z          [[0., 0., 0.],
2026-01-14T09:08:23.5810867Z           [0., 0., 0.],
2026-01-14T09:08:23.5811083Z           [0., 0., 0.]]]])
2026-01-14T09:08:23.5811387Z model pt2e: GraphModule(
2026-01-14T09:08:23.5811627Z   (conv): Module()
2026-01-14T09:08:23.5811832Z   (bn): Module()
2026-01-14T09:08:23.5812139Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5813173Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:23.5814383Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:23.5814920Z   )
2026-01-14T09:08:23.5815111Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:23.5815454Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5816494Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.int8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:23.5817763Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:23.5818319Z   )
2026-01-14T09:08:23.5818601Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:23.5819632Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:23.5820931Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:23.5821459Z   )
2026-01-14T09:08:44.2667899Z   (activation_post_process_3): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:44.2670885Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.int8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:44.2672542Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:44.2673239Z   )
2026-01-14T09:08:44.2673447Z )
2026-01-14T09:08:44.2673573Z 
2026-01-14T09:08:44.2673578Z 
2026-01-14T09:08:44.2673596Z 
2026-01-14T09:08:44.2673701Z def forward(self, x):
2026-01-14T09:08:44.2674059Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:44.2674499Z     conv_weight = self.conv.weight
2026-01-14T09:08:44.2674841Z     conv_bias = self.conv.bias
2026-01-14T09:08:44.2675156Z     bn_weight = self.bn.weight
2026-01-14T09:08:44.2675476Z     bn_bias = self.bn.bias
2026-01-14T09:08:44.2675790Z     bn_running_mean = self.bn.running_mean
2026-01-14T09:08:44.2676166Z     bn_running_var = self.bn.running_var
2026-01-14T09:08:44.2676577Z     bn_num_batches_tracked = self.bn.num_batches_tracked
2026-01-14T09:08:44.2677314Z     activation_post_process_0 = self.activation_post_process_0(x)
2026-01-14T09:08:44.2677853Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:44.2678533Z     add_ = torch.ops.aten.add_.Tensor(bn_num_batches_tracked, 1);  bn_num_batches_tracked = add_ = None
2026-01-14T09:08:44.2679332Z     add = torch.ops.aten.add.Tensor(bn_running_var, 1e-05)
2026-01-14T09:08:44.2679831Z     sqrt = torch.ops.aten.sqrt.default(add);  add = None
2026-01-14T09:08:44.2680358Z     div = torch.ops.aten.div.Tensor(bn_weight, sqrt);  sqrt = None
2026-01-14T09:08:44.2680921Z     reshape = torch.ops.aten.reshape.default(div, [-1, 1, 1, 1])
2026-01-14T09:08:44.2681578Z     mul = torch.ops.aten.mul.Tensor(conv_weight, reshape);  conv_weight = reshape = None
2026-01-14T09:08:44.2682317Z     activation_post_process_1 = self.activation_post_process_1(mul);  mul = None
2026-01-14T09:08:44.2683140Z     zeros_like = torch.ops.aten.zeros_like.default(conv_bias, dtype = torch.float32, pin_memory = False)
2026-01-14T09:08:44.2684482Z     conv2d_1 = torch.ops.aten.conv2d.default(activation_post_process_0, activation_post_process_1, zeros_like);  activation_post_process_0 = activation_post_process_1 = zeros_like = None
2026-01-14T09:08:44.2685696Z     reshape_1 = torch.ops.aten.reshape.default(div, [1, -1, 1, 1]);  div = None
2026-01-14T09:08:44.2686412Z     div_1 = torch.ops.aten.div.Tensor(conv2d_1, reshape_1);  conv2d_1 = reshape_1 = None
2026-01-14T09:08:44.2687183Z     reshape_2 = torch.ops.aten.reshape.default(conv_bias, [1, -1, 1, 1]);  conv_bias = None
2026-01-14T09:08:44.2687927Z     add_1 = torch.ops.aten.add.Tensor(div_1, reshape_2);  div_1 = reshape_2 = None
2026-01-14T09:08:44.2689161Z     batch_norm_1 = torch.ops.aten.batch_norm.default(add_1, bn_weight, bn_bias, bn_running_mean, bn_running_var, True, 0.1, 1e-05, True);  add_1 = bn_weight = bn_bias = bn_running_mean = bn_running_var = None
2026-01-14T09:08:44.2690478Z     activation_post_process_2 = self.activation_post_process_2(batch_norm_1);  batch_norm_1 = None
2026-01-14T09:08:44.2691675Z     hardtanh = torch.ops.aten.hardtanh.default(activation_post_process_2, -1.0, 1.0);  activation_post_process_2 = None
2026-01-14T09:08:44.2692636Z     activation_post_process_3 = self.activation_post_process_3(hardtanh);  hardtanh = None
2026-01-14T09:08:44.2693388Z     return pytree.tree_unflatten((activation_post_process_3,), self._out_spec)
2026-01-14T09:08:44.2693984Z     
2026-01-14T09:08:44.2694334Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:44.2694809Z model fx: GraphModule(
2026-01-14T09:08:44.2695206Z   (activation_post_process_0): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:44.2696522Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0183]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:44.2698068Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.526270866394043, max_val=2.143237352371216)
2026-01-14T09:08:44.2698743Z   )
2026-01-14T09:08:44.2698973Z   (conv): ConvBn2d(
2026-01-14T09:08:44.2699250Z     3, 3, kernel_size=(3, 3), stride=(1, 1)
2026-01-14T09:08:44.2699785Z     (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
2026-01-14T09:08:44.2700400Z     (weight_fake_quant): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:44.2701684Z       fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0015]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-127, quant_max=127, qscheme=torch.per_tensor_symmetric, reduce_range=False
2026-01-14T09:08:44.2703261Z       (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.18815943598747253, max_val=0.1829397827386856)
2026-01-14T09:08:44.2703949Z     )
2026-01-14T09:08:44.2704167Z   )
2026-01-14T09:08:44.2704499Z   (activation_post_process_1): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:44.2705864Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:44.2707406Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:44.2708129Z   )
2026-01-14T09:08:44.2708399Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:44.2708895Z   (activation_post_process_2): FusedMovingAvgObsFakeQuantize(
2026-01-14T09:08:44.2710203Z     fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0150]), zero_point=tensor([-45], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False
2026-01-14T09:08:44.2711747Z     (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.235624074935913, max_val=2.578756093978882)
2026-01-14T09:08:44.2712426Z   )
2026-01-14T09:08:44.2712637Z )
2026-01-14T09:08:44.2712756Z 
2026-01-14T09:08:44.2712761Z 
2026-01-14T09:08:44.2712769Z 
2026-01-14T09:08:44.2712876Z def forward(self, x):
2026-01-14T09:08:44.2713329Z     activation_post_process_0 = self.activation_post_process_0(x);  x = None
2026-01-14T09:08:44.2714024Z     conv = self.conv(activation_post_process_0);  activation_post_process_0 = None
2026-01-14T09:08:44.2714747Z     activation_post_process_1 = self.activation_post_process_1(conv);  conv = None
2026-01-14T09:08:44.2715507Z     hardtanh = self.hardtanh(activation_post_process_1);  activation_post_process_1 = None
2026-01-14T09:08:44.2716300Z     activation_post_process_2 = self.activation_post_process_2(hardtanh);  hardtanh = None
2026-01-14T09:08:44.2716897Z     return activation_post_process_2
2026-01-14T09:08:44.2717218Z     
2026-01-14T09:08:44.2717571Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:44.2718047Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:08:44.2718349Z           [0., 0., 0.],
2026-01-14T09:08:44.2718611Z           [0., 0., 0.]],
2026-01-14T09:08:44.2718848Z 
2026-01-14T09:08:44.2718946Z          [[0., 0., 0.],
2026-01-14T09:08:44.2719210Z           [0., 0., 0.],
2026-01-14T09:08:44.2719471Z           [0., 0., 0.]],
2026-01-14T09:08:44.2719668Z 
2026-01-14T09:08:44.2719776Z          [[0., 0., 0.],
2026-01-14T09:08:44.2720102Z           [0., 0., 0.],
2026-01-14T09:08:44.2720415Z           [0., 0., 0.]]]], grad_fn=<SubBackward0>)
2026-01-14T09:08:44.2720821Z converted model pt2e: GraphModule(
2026-01-14T09:08:44.2721096Z   (conv): Module()
2026-01-14T09:08:44.2721298Z   (bn): Module()
2026-01-14T09:08:44.2721509Z   (_guards_fn): GuardsFn()
2026-01-14T09:08:44.2721734Z )
2026-01-14T09:08:44.2721830Z 
2026-01-14T09:08:44.2721834Z 
2026-01-14T09:08:44.2721838Z 
2026-01-14T09:08:44.2721920Z def forward(self, x):
2026-01-14T09:08:44.2722207Z     x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)
2026-01-14T09:08:44.2722548Z     conv_bias = self.conv.bias
2026-01-14T09:08:44.2723182Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8)
2026-01-14T09:08:44.2724467Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:08:44.2725436Z     _guards_fn = self._guards_fn(x);  x = _guards_fn = None
2026-01-14T09:08:44.2725809Z     quantize_per_tensor = self._frozen_param0
2026-01-14T09:08:44.2726637Z     dequantize_per_tensor = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0014815704198554158, 0, -127, 127, torch.int8);  quantize_per_tensor = None
2026-01-14T09:08:44.2727982Z     conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor, conv_bias);  dequantize_per_tensor_default = dequantize_per_tensor = conv_bias = None
2026-01-14T09:08:44.2729318Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.014958353713154793, -45, -128, 127, torch.int8);  conv2d_2 = None
2026-01-14T09:08:44.2730711Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:08:44.2732070Z     hardtanh = torch.ops.aten.hardtanh.default(dequantize_per_tensor_default_2, -1.0, 1.0);  dequantize_per_tensor_default_2 = None
2026-01-14T09:08:44.2733167Z     quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:08:44.2734562Z     dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None
2026-01-14T09:08:44.2735686Z     return pytree.tree_unflatten((dequantize_per_tensor_default_3,), self._out_spec)
2026-01-14T09:08:44.2736105Z     
2026-01-14T09:08:44.2736392Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:08:44.2736784Z onverted model fx: GraphModule(
2026-01-14T09:08:44.2737166Z   (conv): QuantizedConv2d(Reference)(3, 3, kernel_size=(3, 3), stride=(1, 1))
2026-01-14T09:08:44.2737613Z   (hardtanh): Hardtanh(min_val=-1.0, max_val=1.0)
2026-01-14T09:08:44.2737903Z )
2026-01-14T09:08:44.2738004Z 
2026-01-14T09:08:44.2738008Z 
2026-01-14T09:08:44.2738012Z 
2026-01-14T09:08:44.2738096Z def forward(self, x):
2026-01-14T09:08:44.2738734Z     quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.018311796709895134, 10, -128, 127, torch.int8);  x = None
2026-01-14T09:08:44.2740054Z     dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.018311796709895134, 10, -128, 127, torch.int8);  quantize_per_tensor_default = None
2026-01-14T09:09:12.4487079Z     conv = self.conv(dequantize_per_tensor_default);  dequantize_per_tensor_default = None
2026-01-14T09:09:12.4489639Z     quantize_per_tensor_default_1 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv, 0.014958353713154793, -45, -128, 127, torch.int8);  conv = None
2026-01-14T09:09:12.4491356Z     dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_1, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_1 = None
2026-01-14T09:09:12.4492574Z     hardtanh = self.hardtanh(dequantize_per_tensor_default_1);  dequantize_per_tensor_default_1 = None
2026-01-14T09:09:12.4493559Z     quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(hardtanh, 0.014958353713154793, -45, -128, 127, torch.int8);  hardtanh = None
2026-01-14T09:09:12.4503009Z     dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.014958353713154793, -45, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None
2026-01-14T09:09:12.4503965Z     return dequantize_per_tensor_default_2
2026-01-14T09:09:12.4504260Z     
2026-01-14T09:09:12.4504548Z # To see more debug info, please use `graph_module.print_readable()`
2026-01-14T09:09:12.4504933Z diff: tensor([[[[0., 0., 0.],
2026-01-14T09:09:12.4505179Z           [0., 0., 0.],
2026-01-14T09:09:12.4505386Z           [0., 0., 0.]],
2026-01-14T09:09:12.4505528Z 
2026-01-14T09:09:12.4505614Z          [[0., 0., 0.],
2026-01-14T09:09:12.4505819Z           [0., 0., 0.],
2026-01-14T09:09:12.4506030Z           [0., 0., 0.]],
2026-01-14T09:09:12.4506172Z 
2026-01-14T09:09:12.4506247Z          [[0., 0., 0.],
2026-01-14T09:09:12.4506456Z           [0., 0., 0.],
2026-01-14T09:09:12.4506669Z           [0., 0., 0.]]]])
2026-01-14T09:09:12.4507105Z [32mPASSED[0m
2026-01-14T09:09:12.4507879Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_mobilenet_v2 [33mSKIPPED[0m
2026-01-14T09:09:12.4508834Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQATModels::test_qat_resnet18 [33mSKIPPED[0m
2026-01-14T09:09:12.4509864Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizeMixQATAndPTQ::test_mixing_qat_ptq [33mSKIPPED[0m
2026-01-14T09:09:12.4510739Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add [32mPASSED[0m
2026-01-14T09:09:12.4511573Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_add_relu [32mPASSED[0m
2026-01-14T09:09:12.4512411Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_conv2d [32mPASSED[0m
2026-01-14T09:09:12.4513277Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_dynamic_linear [32mPASSED[0m
2026-01-14T09:09:12.4514162Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_maxpool2d [32mPASSED[0m
2026-01-14T09:09:12.4514991Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq [32mPASSED[0m
2026-01-14T09:09:12.4515858Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_qdq_per_channel [32mPASSED[0m
2026-01-14T09:09:12.4516766Z test/quantization/pt2e/test_representation.py::TestPT2ERepresentation::test_static_linear [32mPASSED[0m
2026-01-14T09:09:12.4518141Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4519923Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4521761Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4523513Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4525336Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4527107Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4528877Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4530641Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4532482Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4534233Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4536044Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4537792Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4539589Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4541353Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4543124Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4544871Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4546632Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4548390Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4550327Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4552157Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4553922Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4555750Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4557510Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:12.4559269Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:12.4561019Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:18.7854492Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:18.7857084Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:18.7859374Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:18.7861748Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:18.7864020Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:18.7866281Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:18.7868536Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:18.7870699Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7872144Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:18.7872659Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7874148Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7875525Z graph_break []
2026-01-14T09:09:18.7875808Z [32mPASSED[0m
2026-01-14T09:09:18.7877133Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7878497Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7879144Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7880355Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7881448Z graph_break []
2026-01-14T09:09:18.7881732Z [32mPASSED[0m
2026-01-14T09:09:18.7883002Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7884349Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7884859Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7886682Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7888380Z graph_break []
2026-01-14T09:09:18.7888671Z [32mPASSED[0m
2026-01-14T09:09:18.7889866Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7891357Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7891875Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7893072Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7894225Z graph_break []
2026-01-14T09:09:18.7894513Z [32mPASSED[0m
2026-01-14T09:09:18.7895730Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7897095Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:18.7897593Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7898802Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7899882Z graph_break []
2026-01-14T09:09:18.7900171Z [32mPASSED[0m
2026-01-14T09:09:18.7901373Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7902730Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7903237Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7904426Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7905516Z graph_break []
2026-01-14T09:09:18.7905796Z [32mPASSED[0m
2026-01-14T09:09:18.7907060Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7908416Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:18.7908917Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7910202Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7911292Z graph_break []
2026-01-14T09:09:18.7911577Z [32mPASSED[0m
2026-01-14T09:09:18.7912787Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7914123Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7914627Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7915819Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7916918Z graph_break []
2026-01-14T09:09:18.7917199Z [32mPASSED[0m
2026-01-14T09:09:18.7918387Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7919730Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:18.7920227Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7921769Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7923186Z graph_break []
2026-01-14T09:09:18.7923464Z [32mPASSED[0m
2026-01-14T09:09:18.7924657Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7925993Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:18.7926496Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:18.7927702Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:18.7928779Z graph_break []
2026-01-14T09:09:18.7929063Z [32mPASSED[0m
2026-01-14T09:09:18.7930249Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:18.7931650Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:18.7932152Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.6972744Z inductor [('pattern_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_nodes', 4), ('qlinear_binary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.6974545Z graph_break []
2026-01-14T09:09:28.6975037Z [32mPASSED[0m
2026-01-14T09:09:28.6976517Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.6977880Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.6978379Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.6979694Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.6980780Z graph_break []
2026-01-14T09:09:28.6981062Z [32mPASSED[0m
2026-01-14T09:09:28.6982275Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.6983618Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:28.6984128Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.6985324Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.6986415Z graph_break []
2026-01-14T09:09:28.6986704Z [32mPASSED[0m
2026-01-14T09:09:28.6987897Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.6989243Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.6989741Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.6991044Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.6992136Z graph_break []
2026-01-14T09:09:28.6992413Z [32mPASSED[0m
2026-01-14T09:09:28.6993708Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.6995054Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:28.6995561Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.6996753Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.6997833Z graph_break []
2026-01-14T09:09:28.6998120Z [32mPASSED[0m
2026-01-14T09:09:28.6999311Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7000650Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.7001158Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7002353Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7003436Z graph_break []
2026-01-14T09:09:28.7003712Z [32mPASSED[0m
2026-01-14T09:09:28.7004918Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7006319Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:28.7006817Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7008303Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7009714Z graph_break []
2026-01-14T09:09:28.7009995Z [32mPASSED[0m
2026-01-14T09:09:28.7011195Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7012633Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.7013136Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7014335Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7015425Z graph_break []
2026-01-14T09:09:28.7015710Z [32mPASSED[0m
2026-01-14T09:09:28.7016899Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7018236Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:28.7018727Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7020264Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7021639Z graph_break []
2026-01-14T09:09:28.7021915Z [32mPASSED[0m
2026-01-14T09:09:28.7023104Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7024482Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.7024986Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7026186Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7027260Z graph_break []
2026-01-14T09:09:28.7027542Z [32mPASSED[0m
2026-01-14T09:09:28.7028737Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7030081Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:28.7030591Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7031801Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7032876Z graph_break []
2026-01-14T09:09:28.7033160Z [32mPASSED[0m
2026-01-14T09:09:28.7034351Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7035746Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.7036295Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7037485Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7038572Z graph_break []
2026-01-14T09:09:28.7038896Z [32mPASSED[0m
2026-01-14T09:09:28.7040094Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7041425Z stats [('calls_captured', 4), ('unique_graphs', 1)]
2026-01-14T09:09:28.7041922Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:28.7043128Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:28.7044205Z graph_break []
2026-01-14T09:09:28.7044485Z [32mPASSED[0m
2026-01-14T09:09:28.7045684Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:28.7047014Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:28.7047513Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5429922Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5431700Z graph_break []
2026-01-14T09:09:34.5432421Z [32mPASSED[0m
2026-01-14T09:09:34.5434644Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5436509Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:34.5437018Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5438180Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5439236Z graph_break []
2026-01-14T09:09:34.5439474Z [32mPASSED[0m
2026-01-14T09:09:34.5440412Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5441453Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:34.5441864Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5442801Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5443640Z graph_break []
2026-01-14T09:09:34.5443876Z [32mPASSED[0m
2026-01-14T09:09:34.5444802Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5445828Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:34.5446239Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5447515Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5448581Z graph_break []
2026-01-14T09:09:34.5448820Z [32mPASSED[0m
2026-01-14T09:09:34.5450016Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5451137Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:34.5451617Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5452561Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5453405Z graph_break []
2026-01-14T09:09:34.5453643Z [32mPASSED[0m
2026-01-14T09:09:34.5454574Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5455609Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:34.5456015Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5456947Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5457777Z graph_break []
2026-01-14T09:09:34.5458011Z [32mPASSED[0m
2026-01-14T09:09:34.5459010Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5460047Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:34.5460450Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5461438Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5462283Z graph_break []
2026-01-14T09:09:34.5462513Z [32mPASSED[0m
2026-01-14T09:09:34.5463437Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5464467Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:34.5464870Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5465804Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5466637Z graph_break []
2026-01-14T09:09:34.5466875Z [32mPASSED[0m
2026-01-14T09:09:34.5467791Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_False_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:34.5468825Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:34.5469232Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:34.5470160Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:34.5471000Z graph_break []
2026-01-14T09:09:34.5471293Z [32mPASSED[0m
2026-01-14T09:09:34.5472333Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5474140Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5475886Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5477645Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5479421Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5481183Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5482947Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5484751Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5486562Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5488348Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5490096Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:34.5491897Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:34.5493645Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4756428Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4758866Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4761143Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4765424Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4767731Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4770081Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4772476Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4774754Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4777008Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4779272Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4781532Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4783892Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4786156Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4788525Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4790765Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4793017Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4795274Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4797530Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False [32mPASSED[0m
2026-01-14T09:09:40.4799760Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_bfloat16_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True [32mPASSED[0m
2026-01-14T09:09:40.4801964Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4803345Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:40.4803855Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4805349Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4806762Z graph_break []
2026-01-14T09:09:40.4807051Z [32mPASSED[0m
2026-01-14T09:09:40.4808263Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4809601Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:40.4810110Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4811383Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4812479Z graph_break []
2026-01-14T09:09:40.4812765Z [32mPASSED[0m
2026-01-14T09:09:40.4813961Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4815300Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:40.4815795Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4817377Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4818752Z graph_break []
2026-01-14T09:09:40.4819079Z [32mPASSED[0m
2026-01-14T09:09:40.4820278Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4821604Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:40.4822106Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4823317Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4824402Z graph_break []
2026-01-14T09:09:40.4824686Z [32mPASSED[0m
2026-01-14T09:09:40.4825888Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4827233Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:40.4827737Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4828929Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4830009Z graph_break []
2026-01-14T09:09:40.4830282Z [32mPASSED[0m
2026-01-14T09:09:40.4831487Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:40.4832880Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:40.4833377Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:40.4834582Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:40.4835707Z graph_break []
2026-01-14T09:09:40.4835990Z [32mPASSED[0m
2026-01-14T09:09:40.4837186Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6855145Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:51.6855731Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6856957Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6858060Z graph_break []
2026-01-14T09:09:51.6858534Z [32mPASSED[0m
2026-01-14T09:09:51.6859765Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6861139Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:51.6861637Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6862836Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6864169Z graph_break []
2026-01-14T09:09:51.6864469Z [32mPASSED[0m
2026-01-14T09:09:51.6865675Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6867123Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:51.6867630Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6869108Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6870477Z graph_break []
2026-01-14T09:09:51.6870761Z [32mPASSED[0m
2026-01-14T09:09:51.6871954Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6873294Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6873794Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6874993Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6876084Z graph_break []
2026-01-14T09:09:51.6876363Z [32mPASSED[0m
2026-01-14T09:09:51.6877572Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6878905Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:51.6879403Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6881043Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6882493Z graph_break []
2026-01-14T09:09:51.6882781Z [32mPASSED[0m
2026-01-14T09:09:51.6883965Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6885294Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6885797Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6886994Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6888105Z graph_break []
2026-01-14T09:09:51.6888381Z [32mPASSED[0m
2026-01-14T09:09:51.6898559Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6899936Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:51.6900435Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6901643Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6902732Z graph_break []
2026-01-14T09:09:51.6903041Z [32mPASSED[0m
2026-01-14T09:09:51.6904328Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6905709Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6906214Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6907421Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6908499Z graph_break []
2026-01-14T09:09:51.6908783Z [32mPASSED[0m
2026-01-14T09:09:51.6909972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6911310Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:09:51.6911807Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6913007Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6914096Z graph_break []
2026-01-14T09:09:51.6914369Z [32mPASSED[0m
2026-01-14T09:09:51.6915558Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_False_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6916881Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6917382Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6918643Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6919725Z graph_break []
2026-01-14T09:09:51.6920011Z [32mPASSED[0m
2026-01-14T09:09:51.6921203Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6922795Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:51.6923299Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6924780Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6926151Z graph_break []
2026-01-14T09:09:51.6926430Z [32mPASSED[0m
2026-01-14T09:09:51.6927624Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6928956Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6929454Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6930657Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6931811Z graph_break []
2026-01-14T09:09:51.6932098Z [32mPASSED[0m
2026-01-14T09:09:51.6933341Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6934680Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:09:51.6935182Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:09:51.6936703Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:09:51.6938072Z graph_break []
2026-01-14T09:09:51.6938356Z [32mPASSED[0m
2026-01-14T09:09:51.6939533Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:09:51.6940910Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:09:51.6941407Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0011774Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0012918Z graph_break []
2026-01-14T09:10:09.0013409Z [32mPASSED[0m
2026-01-14T09:10:09.0014724Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0016102Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:10:09.0016609Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0017826Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0021016Z graph_break []
2026-01-14T09:10:09.0021326Z [32mPASSED[0m
2026-01-14T09:10:09.0022537Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0023989Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:10:09.0024495Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0025702Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0026782Z graph_break []
2026-01-14T09:10:09.0027069Z [32mPASSED[0m
2026-01-14T09:10:09.0028268Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0029605Z stats [('calls_captured', 5), ('unique_graphs', 1)]
2026-01-14T09:10:09.0030106Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0031314Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0032404Z graph_break []
2026-01-14T09:10:09.0032683Z [32mPASSED[0m
2026-01-14T09:10:09.0033874Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_False_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0035203Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:10:09.0035819Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0037029Z inductor [('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_nodes', 4), ('qlinear_weight_prepack_matcher_count', 1), ('pattern_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0038207Z graph_break []
2026-01-14T09:10:09.0038501Z [32mPASSED[0m
2026-01-14T09:10:09.0039691Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0041037Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:10:09.0041546Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0043036Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0044411Z graph_break []
2026-01-14T09:10:09.0044693Z [32mPASSED[0m
2026-01-14T09:10:09.0045888Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0047222Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:10:09.0047720Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0048928Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0050301Z graph_break []
2026-01-14T09:10:09.0050601Z [32mPASSED[0m
2026-01-14T09:10:09.0051972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0053310Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:10:09.0053819Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0055374Z inductor [('pattern_matcher_nodes', 6), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0056751Z graph_break []
2026-01-14T09:10:09.0057047Z [32mPASSED[0m
2026-01-14T09:10:09.0058227Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_1_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0059558Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:10:09.0060056Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0061266Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0062363Z graph_break []
2026-01-14T09:10:09.0062640Z [32mPASSED[0m
2026-01-14T09:10:09.0063927Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0065059Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:10:09.0065468Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0066490Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0067335Z graph_break []
2026-01-14T09:10:09.0067635Z [32mPASSED[0m
2026-01-14T09:10:09.0068559Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_False_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0069586Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:10:09.0069994Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0070926Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0071767Z graph_break []
2026-01-14T09:10:09.0072001Z [32mPASSED[0m
2026-01-14T09:10:09.0072922Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0073953Z stats [('calls_captured', 6), ('unique_graphs', 1)]
2026-01-14T09:10:09.0074353Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0075285Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0076121Z graph_break []
2026-01-14T09:10:09.0076348Z [32mPASSED[0m
2026-01-14T09:10:09.0077265Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_da8w8_sym_act_sym_wgt_with_int_mm_has_bias_True_float32_dynamic_True_reshape_a_True_M_32_inplace_add_True_expand_a_scale_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0078343Z stats [('calls_captured', 8), ('unique_graphs', 1)]
2026-01-14T09:10:09.0078752Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0079687Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:10:09.0080566Z graph_break []
2026-01-14T09:10:09.0080804Z [32mPASSED[0m
2026-01-14T09:10:09.0081420Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:10:09.0082107Z inline_call []
2026-01-14T09:10:09.0082314Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:09.0082663Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:09.0083869Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:10:09.0084932Z graph_break []
2026-01-14T09:10:09.0085165Z [32mPASSED[0m
2026-01-14T09:10:33.6992295Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_input_dim_exceeds_2 stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:10:33.6994426Z inline_call []
2026-01-14T09:10:33.6995049Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.6995463Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.6996919Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:10:33.6998564Z graph_break []
2026-01-14T09:10:33.6999059Z [32mPASSED[0m
2026-01-14T09:10:33.6999711Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_dynamic_qlinear_qat_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:10:33.7000567Z inline_call []
2026-01-14T09:10:33.7000774Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7001135Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.7002294Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:10:33.7003351Z graph_break []
2026-01-14T09:10:33.7003592Z [32mPASSED[0m
2026-01-14T09:10:33.7004318Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:10:33.7005507Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_False_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:10:33.7006677Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_False [33mSKIPPED[0m
2026-01-14T09:10:33.7007843Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_add_cpu_use_relu_True_mixed_bf16_True [33mSKIPPED[0m
2026-01-14T09:10:33.7008831Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7009423Z inline_call []
2026-01-14T09:10:33.7009684Z stats [('calls_captured', 32), ('unique_graphs', 2)]
2026-01-14T09:10:33.7010094Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:10:33.7012128Z inductor [('pattern_matcher_nodes', 24), ('qlinear_weight_prepack_matcher_nodes', 16), ('pattern_matcher_count', 10), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:10:33.7013573Z graph_break []
2026-01-14T09:10:33.7013932Z [32mPASSED[0m
2026-01-14T09:10:33.7014720Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7015473Z inline_call []
2026-01-14T09:10:33.7015725Z stats [('calls_captured', 25), ('unique_graphs', 1)]
2026-01-14T09:10:33.7016137Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.7018284Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:10:33.7020337Z graph_break []
2026-01-14T09:10:33.7020593Z [32mPASSED[0m
2026-01-14T09:10:33.7021271Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7022012Z inline_call []
2026-01-14T09:10:33.7022258Z stats [('calls_captured', 25), ('unique_graphs', 1)]
2026-01-14T09:10:33.7022671Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.7024910Z inductor [('pattern_matcher_nodes', 33), ('qlinear_weight_prepack_matcher_nodes', 18), ('pattern_matcher_count', 15), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('dequant_promotion_matcher_nodes', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:10:33.7026980Z graph_break []
2026-01-14T09:10:33.7027208Z [32mPASSED[0m
2026-01-14T09:10:33.7027898Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:10:33.7029093Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:10:33.7030151Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7030767Z inline_call []
2026-01-14T09:10:33.7031016Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:10:33.7031429Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.7032812Z inductor [('pattern_matcher_nodes', 31), ('qlinear_unary_matcher_nodes', 21), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:10:33.7034117Z graph_break []
2026-01-14T09:10:33.7034352Z [32mPASSED[0m
2026-01-14T09:10:33.7034972Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:10:33.7035947Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7036595Z inline_call []
2026-01-14T09:10:33.7036900Z stats [('calls_captured', 32), ('unique_graphs', 2)]
2026-01-14T09:10:33.7037306Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:10:33.7038777Z inductor [('pattern_matcher_nodes', 40), ('qlinear_weight_prepack_matcher_nodes', 24), ('pattern_matcher_count', 18), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:10:33.7040239Z graph_break []
2026-01-14T09:10:33.7040472Z [32mPASSED[0m
2026-01-14T09:10:33.7041137Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_input_dim_exceeds_2_and_not_contiguous frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7041862Z inline_call []
2026-01-14T09:10:33.7042113Z stats [('calls_captured', 36), ('unique_graphs', 2)]
2026-01-14T09:10:33.7042536Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:10:33.7043990Z inductor [('pattern_matcher_nodes', 40), ('qlinear_weight_prepack_matcher_nodes', 24), ('pattern_matcher_count', 18), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_matcher_nodes', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('extern_calls', 4), ('qlinear_unary_matcher_count', 2), ('fxgraph_cache_miss', 1), ('fxgraph_cache_hit', 1)]
2026-01-14T09:10:33.7045370Z graph_break []
2026-01-14T09:10:33.7045604Z [32mPASSED[0m
2026-01-14T09:10:33.7046204Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:10:33.7047256Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:10:33.7048499Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:10:33.7054000Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_mul_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7054714Z inline_call []
2026-01-14T09:10:33.7054956Z stats [('calls_captured', 9), ('unique_graphs', 1)]
2026-01-14T09:10:33.7055363Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:10:33.7056501Z inductor [('pattern_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_miss', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:10:33.7057550Z graph_break []
2026-01-14T09:10:33.7057802Z [32mPASSED[0m
2026-01-14T09:10:33.7058359Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_cpu frames [('total', 1), ('ok', 1)]
2026-01-14T09:10:33.7058971Z inline_call []
2026-01-14T09:10:33.7059222Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:10:33.7059634Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5678707Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:13:45.5680483Z graph_break []
2026-01-14T09:13:45.5681033Z [32mPASSED[0m
2026-01-14T09:13:45.5681839Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_input_dim_exceeds_2 frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5682758Z inline_call []
2026-01-14T09:13:45.5683076Z stats [('calls_captured', 18), ('unique_graphs', 1)]
2026-01-14T09:13:45.5683587Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5685783Z inductor [('pattern_matcher_nodes', 23), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_miss', 1)]
2026-01-14T09:13:45.5687583Z graph_break []
2026-01-14T09:13:45.5687872Z [32mPASSED[0m
2026-01-14T09:13:45.5688657Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:13:45.5690042Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_fp8_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:13:45.5691596Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_dynamic_fp16 stats [('calls_captured', 20), ('unique_graphs', 16)]
2026-01-14T09:13:45.5692481Z inline_call []
2026-01-14T09:13:45.5692736Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5693162Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:13:45.5694367Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:13:45.5695467Z graph_break []
2026-01-14T09:13:45.5695745Z [32mPASSED[0m
2026-01-14T09:13:45.5696561Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_linear_relu_dynamic_fp16 stats [('calls_captured', 24), ('unique_graphs', 16)]
2026-01-14T09:13:45.5697464Z inline_call []
2026-01-14T09:13:45.5697720Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5698145Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:13:45.5699473Z inductor [('pattern_matcher_nodes', 17), ('qlinear_weight_prepack_matcher_nodes', 14), ('pattern_matcher_count', 5), ('extern_calls', 4), ('qlinear_weight_prepack_matcher_count', 2), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:13:45.5700565Z graph_break []
2026-01-14T09:13:45.5700841Z [32mPASSED[0m
2026-01-14T09:13:45.5701704Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d stats [('calls_captured', 1958), ('unique_graphs', 224)]
2026-01-14T09:13:45.5702568Z inline_call []
2026-01-14T09:13:45.5702817Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5703239Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5704962Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:13:45.5706574Z graph_break []
2026-01-14T09:13:45.5706859Z [32mPASSED[0m
2026-01-14T09:13:45.5707641Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add stats [('calls_captured', 1967), ('unique_graphs', 224)]
2026-01-14T09:13:45.5708510Z inline_call []
2026-01-14T09:13:45.5708758Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5709189Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5711895Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:13:45.5714493Z graph_break []
2026-01-14T09:13:45.5714821Z [32mPASSED[0m
2026-01-14T09:13:45.5715634Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_add_relu stats [('calls_captured', 1969), ('unique_graphs', 224)]
2026-01-14T09:13:45.5716525Z inline_call []
2026-01-14T09:13:45.5716779Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5717241Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5719936Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv2d_binary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('extern_calls', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:13:45.5722507Z graph_break []
2026-01-14T09:13:45.5722784Z [32mPASSED[0m
2026-01-14T09:13:45.5723599Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardswish stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:45.5724508Z inline_call []
2026-01-14T09:13:45.5724756Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5725181Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5726938Z inductor [('pattern_matcher_nodes', 24), ('qconv_unary_matcher_nodes', 14), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:45.5728461Z graph_break []
2026-01-14T09:13:45.5728701Z [32mPASSED[0m
2026-01-14T09:13:45.5729408Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_hardtanh stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:45.5730119Z inline_call []
2026-01-14T09:13:45.5730327Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5730722Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5732154Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:45.5733390Z graph_break []
2026-01-14T09:13:45.5733632Z [32mPASSED[0m
2026-01-14T09:13:45.5734247Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:45.5734933Z inline_call []
2026-01-14T09:13:45.5735137Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5735482Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5736818Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:45.5738046Z graph_break []
2026-01-14T09:13:45.5738279Z [32mPASSED[0m
2026-01-14T09:13:45.5738898Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_relu6 stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:45.5739584Z inline_call []
2026-01-14T09:13:45.5739786Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5740135Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5741530Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:45.5742806Z graph_break []
2026-01-14T09:13:45.5743039Z [32mPASSED[0m
2026-01-14T09:13:45.5743659Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qat_qconv2d_silu stats [('calls_captured', 1968), ('unique_graphs', 224)]
2026-01-14T09:13:45.5744341Z inline_call []
2026-01-14T09:13:45.5744550Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5744888Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:13:45.5746224Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:13:45.5747450Z graph_break []
2026-01-14T09:13:45.5747685Z [32mPASSED[0m
2026-01-14T09:13:45.5748254Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qcat stats [('calls_captured', 26), ('unique_graphs', 8)]
2026-01-14T09:13:45.5748874Z inline_call []
2026-01-14T09:13:45.5749488Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:13:45.5749845Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1676849Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 7), ('qconv_unary_matcher_nodes', 4), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:14:35.1678793Z graph_break []
2026-01-14T09:14:35.1688107Z [32mPASSED[0m
2026-01-14T09:14:35.1688932Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv1d_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:14:35.1689948Z inline_call []
2026-01-14T09:14:35.1690210Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1690653Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1692554Z inductor [('pattern_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:14:35.1694174Z graph_break []
2026-01-14T09:14:35.1694473Z [32mPASSED[0m
2026-01-14T09:14:35.1695237Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_2 stats [('calls_captured', 13), ('unique_graphs', 8)]
2026-01-14T09:14:35.1696086Z inline_call []
2026-01-14T09:14:35.1696347Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1696770Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1698230Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:14:35.1699560Z graph_break []
2026-01-14T09:14:35.1699853Z [32mPASSED[0m
2026-01-14T09:14:35.1700620Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3 stats [('calls_captured', 29), ('unique_graphs', 8)]
2026-01-14T09:14:35.1701460Z inline_call []
2026-01-14T09:14:35.1701722Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1702152Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1705216Z inductor [('pattern_matcher_nodes', 18), ('pattern_matcher_count', 8), ('qconv_weight_prepack_matcher_nodes', 7), ('qcat_matcher_nodes', 4), ('extern_calls', 4), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_nodes', 2), ('qconv2d_binary_matcher_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv_unary_matcher_count', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:14:35.1708118Z graph_break []
2026-01-14T09:14:35.1708408Z [32mPASSED[0m
2026-01-14T09:14:35.1709262Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_broadcast_shapes_cpu stats [('calls_captured', 15), ('unique_graphs', 8)]
2026-01-14T09:14:35.1710212Z inline_call []
2026-01-14T09:14:35.1710464Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1710896Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1712330Z inductor [('pattern_matcher_nodes', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 2), ('qconv_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:14:35.1713661Z graph_break []
2026-01-14T09:14:35.1713947Z [32mPASSED[0m
2026-01-14T09:14:35.1714533Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_cpu inline_call []
2026-01-14T09:14:35.1715279Z stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:14:35.1715674Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1716108Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1717967Z inductor [('pattern_matcher_nodes', 16), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv2d_binary_matcher_nodes', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:14:35.1719687Z graph_break []
2026-01-14T09:14:35.1719973Z [32mPASSED[0m
2026-01-14T09:14:35.1720715Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1721958Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:14:35.1723232Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:14:35.1724332Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_cpu inline_call []
2026-01-14T09:14:35.1725107Z stats [('calls_captured', 28), ('unique_graphs', 8)]
2026-01-14T09:14:35.1725507Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1725935Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1727731Z inductor [('pattern_matcher_nodes', 18), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv2d_binary_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv2d_binary_matcher_count', 2), ('qconv2d_binary_lower_count', 2), ('qconv2d_binary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:14:35.1729533Z graph_break []
2026-01-14T09:14:35.1729788Z [32mPASSED[0m
2026-01-14T09:14:35.1730391Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1731451Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:14:35.1732485Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_relu_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:14:35.1733545Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_cpu stats [('calls_captured', 21), ('unique_graphs', 8)]
2026-01-14T09:14:35.1734205Z inline_call []
2026-01-14T09:14:35.1734421Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1734774Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1736179Z inductor [('pattern_matcher_nodes', 19), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('qconv_unary_lower_count', 3), ('qconv_unary_lower_nodes', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:14:35.1737428Z graph_break []
2026-01-14T09:14:35.1737672Z [32mPASSED[0m
2026-01-14T09:14:35.1738337Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_dequant_promotion_cpu stats [('calls_captured', 24), ('unique_graphs', 8)]
2026-01-14T09:14:35.1739072Z inline_call []
2026-01-14T09:14:35.1739281Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1739639Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1741726Z inductor [('pattern_matcher_nodes', 22), ('qconv_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qconv_unary_matcher_nodes', 4), ('qconv_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qconv_unary_matcher_count', 2), ('qconv2d_binary_matcher_nodes', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qconv2d_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv2d_binary_lower_count', 1), ('qconv2d_binary_lower_nodes', 1)]
2026-01-14T09:14:35.1743712Z graph_break []
2026-01-14T09:14:35.1743951Z [32mPASSED[0m
2026-01-14T09:14:35.1744560Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1745507Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_fp8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:14:35.1746509Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:14:35.1747245Z inline_call []
2026-01-14T09:14:35.1747464Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1747810Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:14:35.1749481Z inductor [('pattern_matcher_nodes', 23), ('qconv_unary_matcher_nodes', 13), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:14:35.1750735Z graph_break []
2026-01-14T09:14:35.1750981Z [32mPASSED[0m
2026-01-14T09:14:35.1751601Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1752639Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1753719Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardswish_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:14:35.1754771Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:14:35.1755461Z inline_call []
2026-01-14T09:14:35.1755673Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:14:35.1756015Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2777218Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:16:31.2778926Z graph_break []
2026-01-14T09:16:31.2779421Z [32mPASSED[0m
2026-01-14T09:16:31.2780216Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2781668Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2783022Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_hardtanh_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2784317Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_int8_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:16:31.2785578Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:16:31.2786441Z inline_call []
2026-01-14T09:16:31.2786700Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2787120Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2788858Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:16:31.2790482Z graph_break []
2026-01-14T09:16:31.2790763Z [32mPASSED[0m
2026-01-14T09:16:31.2791507Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu6_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2792887Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:16:31.2793753Z inline_call []
2026-01-14T09:16:31.2794013Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2794434Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2796168Z inductor [('pattern_matcher_nodes', 15), ('qconv_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qconv_unary_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:16:31.2797901Z graph_break []
2026-01-14T09:16:31.2798185Z [32mPASSED[0m
2026-01-14T09:16:31.2798915Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2800235Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_relu_int8_mixed_bf16_xpu [33mSKIPPED[0m
2026-01-14T09:16:31.2801532Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:16:31.2802385Z inline_call []
2026-01-14T09:16:31.2802644Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2803067Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2804803Z inductor [('pattern_matcher_nodes', 17), ('qconv_weight_prepack_matcher_nodes', 8), ('qconv_unary_matcher_nodes', 7), ('pattern_matcher_count', 6), ('qconv_weight_prepack_matcher_count', 2), ('qconv_unary_matcher_count', 2), ('qconv_unary_lower_count', 2), ('qconv_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:16:31.2806414Z graph_break []
2026-01-14T09:16:31.2806686Z [32mPASSED[0m
2026-01-14T09:16:31.2807424Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2808675Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_fp8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2810044Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_silu_int8_mixed_bf16_cpu [33mSKIPPED[0m
2026-01-14T09:16:31.2811481Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_with_concat_cpu stats [('calls_captured', 32), ('unique_graphs', 8)]
2026-01-14T09:16:31.2812433Z inline_call []
2026-01-14T09:16:31.2812688Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2813108Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2815429Z inductor [('pattern_matcher_nodes', 30), ('pattern_matcher_count', 14), ('qconv_weight_prepack_matcher_nodes', 13), ('qconv_unary_matcher_nodes', 6), ('extern_calls', 6), ('qcat_matcher_nodes', 5), ('qconv_weight_prepack_matcher_count', 4), ('qconv_unary_lower_count', 4), ('qconv_unary_lower_nodes', 4), ('qconv_unary_matcher_count', 3), ('dequant_promotion_matcher_count', 2), ('dequant_promotion_matcher_nodes', 2), ('fxgraph_cache_bypass', 1), ('qcat_matcher_count', 1)]
2026-01-14T09:16:31.2817624Z graph_break []
2026-01-14T09:16:31.2817907Z [32mPASSED[0m
2026-01-14T09:16:31.2818642Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qflatten stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:16:31.2819500Z inline_call []
2026-01-14T09:16:31.2819775Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2820201Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:16:31.2822192Z inductor [('pattern_matcher_nodes', 12), ('pattern_matcher_count', 5), ('qconv_weight_prepack_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qreshape_matcher_count', 1), ('extern_calls', 1)]
2026-01-14T09:16:31.2824083Z graph_break []
2026-01-14T09:16:31.2824427Z [32mPASSED[0m
2026-01-14T09:16:31.2825241Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_False inline_call []
2026-01-14T09:16:31.2826208Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:16:31.2826683Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2827030Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:16:31.2829064Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:16:31.2831038Z graph_break []
2026-01-14T09:16:31.2831276Z [32mPASSED[0m
2026-01-14T09:16:31.2831909Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_False_is_dynamic_True inline_call []
2026-01-14T09:16:31.2832655Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:16:31.2832987Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2833325Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:16:31.2835349Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:16:31.2837318Z graph_break []
2026-01-14T09:16:31.2837554Z [32mPASSED[0m
2026-01-14T09:16:31.2838182Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_False inline_call []
2026-01-14T09:16:31.2838937Z stats [('calls_captured', 56), ('unique_graphs', 16)]
2026-01-14T09:16:31.2839303Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2839652Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:16:31.2841676Z inductor [('pattern_matcher_nodes', 102), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 10), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:16:31.2843592Z graph_break []
2026-01-14T09:16:31.2843820Z [32mPASSED[0m
2026-01-14T09:16:31.2844447Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_False_is_qat_True_is_dynamic_True inline_call []
2026-01-14T09:16:31.2845198Z stats [('calls_captured', 60), ('unique_graphs', 16)]
2026-01-14T09:16:31.2845525Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:16:31.2845864Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:18:34.0099557Z inductor [('pattern_matcher_nodes', 101), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 9), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:18:34.0102162Z graph_break []
2026-01-14T09:18:34.0102650Z [32mPASSED[0m
2026-01-14T09:18:34.0103638Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_False inline_call []
2026-01-14T09:18:34.0104624Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:18:34.0105035Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0105461Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:18:34.0108169Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:18:34.0110683Z graph_break []
2026-01-14T09:18:34.0110966Z [32mPASSED[0m
2026-01-14T09:18:34.0111772Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_False_is_dynamic_True inline_call []
2026-01-14T09:18:34.0112726Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:18:34.0113134Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0113550Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:18:34.0116320Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:18:34.0118843Z graph_break []
2026-01-14T09:18:34.0119217Z [32mPASSED[0m
2026-01-14T09:18:34.0120018Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_False inline_call []
2026-01-14T09:18:34.0120973Z stats [('calls_captured', 64), ('unique_graphs', 16)]
2026-01-14T09:18:34.0121370Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0121795Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:18:34.0124427Z inductor [('pattern_matcher_nodes', 106), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 14), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:18:34.0126943Z graph_break []
2026-01-14T09:18:34.0127225Z [32mPASSED[0m
2026-01-14T09:18:34.0128011Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_cpu_use_relu_True_is_qat_True_is_dynamic_True inline_call []
2026-01-14T09:18:34.0128963Z stats [('calls_captured', 68), ('unique_graphs', 16)]
2026-01-14T09:18:34.0129363Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0129789Z aot_autograd [('total', 2), ('autograd_cache_bypass', 2), ('ok', 2)]
2026-01-14T09:18:34.0132616Z inductor [('pattern_matcher_nodes', 105), ('pattern_matcher_count', 48), ('qlinear_weight_prepack_matcher_nodes', 48), ('qlinear_binary_matcher_nodes', 13), ('dequant_promotion_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_count', 8), ('extern_calls', 8), ('removed_pointless_view_pair', 4), ('dequant_promotion_matcher_count', 4), ('qlinear_binary_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('qlinear_binary_lower_count', 4), ('qlinear_binary_lower_nodes', 4), ('fxgraph_cache_bypass', 2)]
2026-01-14T09:18:34.0135176Z graph_break []
2026-01-14T09:18:34.0135458Z [32mPASSED[0m
2026-01-14T09:18:34.0136494Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:18:34.0138220Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:18:34.0139938Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:18:34.0141643Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_False_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:18:34.0143335Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:18:34.0145032Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_False_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:18:34.0146717Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_False [33mSKIPPED[0m
2026-01-14T09:18:34.0148405Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_add_int8_mixed_bf16_use_relu_True_is_qat_True_is_dynamic_True [33mSKIPPED[0m
2026-01-14T09:18:34.0150037Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_cpu stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:18:34.0150694Z inline_call []
2026-01-14T09:18:34.0150906Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0151254Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:34.0152709Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:18:34.0153998Z graph_break []
2026-01-14T09:18:34.0154244Z [32mPASSED[0m
2026-01-14T09:18:34.0154910Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:18:34.0155628Z inline_call []
2026-01-14T09:18:34.0155847Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0156199Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:34.0158318Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:18:34.0160346Z graph_break []
2026-01-14T09:18:34.0160580Z [32mPASSED[0m
2026-01-14T09:18:34.0161383Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_cpu_input_dim_exceeds_2 stats [('calls_captured', 22), ('unique_graphs', 8)]
2026-01-14T09:18:34.0162181Z inline_call []
2026-01-14T09:18:34.0162386Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0162732Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:18:34.0164925Z inductor [('pattern_matcher_nodes', 33), ('qlinear_weight_prepack_matcher_nodes', 18), ('pattern_matcher_count', 15), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('dequant_promotion_matcher_nodes', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:18:34.0166951Z graph_break []
2026-01-14T09:18:34.0167215Z [32mPASSED[0m
2026-01-14T09:18:34.0167923Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_dynamic_cpu stats [('calls_captured', 27), ('unique_graphs', 8)]
2026-01-14T09:18:34.0168676Z inline_call []
2026-01-14T09:18:34.0168882Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:18:34.0169222Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3597376Z inductor [('pattern_matcher_nodes', 18), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_count', 3), ('extern_calls', 3), ('qlinear_binary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('dequant_promotion_matcher_count', 1), ('dequant_promotion_matcher_nodes', 1), ('qlinear_binary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_binary_lower_count', 1), ('qlinear_binary_lower_nodes', 1)]
2026-01-14T09:19:05.3599824Z graph_break []
2026-01-14T09:19:05.3600323Z [32mPASSED[0m
2026-01-14T09:19:05.3601437Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:19:05.3602950Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_dequant_promotion_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:19:05.3604410Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:19:05.3605366Z inline_call []
2026-01-14T09:19:05.3605627Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3606050Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3607860Z inductor [('pattern_matcher_nodes', 31), ('qlinear_unary_matcher_nodes', 21), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:05.3609550Z graph_break []
2026-01-14T09:19:05.3609835Z [32mPASSED[0m
2026-01-14T09:19:05.3610585Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_gelu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:19:05.3612036Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2 stats [('calls_captured', 16), ('unique_graphs', 8)]
2026-01-14T09:19:05.3612951Z inline_call []
2026-01-14T09:19:05.3613202Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3613629Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3615546Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:05.3617233Z graph_break []
2026-01-14T09:19:05.3617528Z [32mPASSED[0m
2026-01-14T09:19:05.3618443Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_input_dim_exceeds_2_and_not_contiguous stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:19:05.3619544Z inline_call []
2026-01-14T09:19:05.3619803Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3620227Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3622013Z inductor [('pattern_matcher_nodes', 20), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 9), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_nodes', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:05.3623669Z graph_break []
2026-01-14T09:19:05.3623952Z [32mPASSED[0m
2026-01-14T09:19:05.3624668Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:19:05.3625951Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:19:05.3627443Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mixed_bf16_input_dim_exceeds_2_and_not_contiguous [33mSKIPPED[0m
2026-01-14T09:19:05.3628848Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_mul_cpu stats [('calls_captured', 17), ('unique_graphs', 8)]
2026-01-14T09:19:05.3629700Z inline_call []
2026-01-14T09:19:05.3629948Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3630376Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3632278Z inductor [('pattern_matcher_nodes', 7), ('qlinear_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qlinear_unary_matcher_nodes', 2), ('qlinear_weight_prepack_matcher_count', 1), ('qlinear_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:19:05.3633948Z graph_break []
2026-01-14T09:19:05.3634239Z [32mPASSED[0m
2026-01-14T09:19:05.3635006Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_cpu stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:19:05.3635913Z inline_call []
2026-01-14T09:19:05.3636173Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3636596Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3638394Z inductor [('pattern_matcher_nodes', 15), ('qlinear_weight_prepack_matcher_nodes', 8), ('pattern_matcher_count', 6), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:05.3640059Z graph_break []
2026-01-14T09:19:05.3640343Z [32mPASSED[0m
2026-01-14T09:19:05.3641184Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_input_dim_exceeds_2 stats [('calls_captured', 20), ('unique_graphs', 8)]
2026-01-14T09:19:05.3642124Z inline_call []
2026-01-14T09:19:05.3642383Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3642806Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3644609Z inductor [('pattern_matcher_nodes', 23), ('qlinear_weight_prepack_matcher_nodes', 12), ('pattern_matcher_count', 10), ('qlinear_unary_matcher_nodes', 5), ('qlinear_weight_prepack_matcher_count', 2), ('qlinear_unary_matcher_count', 2), ('qlinear_unary_lower_count', 2), ('qlinear_unary_lower_nodes', 2), ('extern_calls', 2), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:05.3646298Z graph_break []
2026-01-14T09:19:05.3646576Z [32mPASSED[0m
2026-01-14T09:19:05.3647390Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16 [33mSKIPPED[0m
2026-01-14T09:19:05.3648728Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qlinear_relu_mixed_bf16_input_dim_exceeds_2 [33mSKIPPED[0m
2026-01-14T09:19:05.3650353Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qmaxpool2d stats [('calls_captured', 19), ('unique_graphs', 8)]
2026-01-14T09:19:05.3651187Z inline_call []
2026-01-14T09:19:05.3651536Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3651961Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3653966Z inductor [('pattern_matcher_nodes', 12), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 4), ('qmaxpool2d_matcher_nodes', 4), ('qconv_unary_matcher_nodes', 3), ('extern_calls', 3), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1)]
2026-01-14T09:19:05.3655855Z graph_break []
2026-01-14T09:19:05.3656145Z [32mPASSED[0m
2026-01-14T09:19:05.3657247Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:19:05.3659110Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:19:05.3660944Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:19:05.3662778Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:19:05.3664629Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3665774Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:19:05.3666285Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3667473Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:05.3668626Z graph_break []
2026-01-14T09:19:05.3668913Z [32mPASSED[0m
2026-01-14T09:19:05.3669903Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:05.3671050Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:19:05.3671556Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:05.3673046Z inductor [('pattern_matcher_nodes', 10), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 4), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:19:05.3674415Z graph_break []
2026-01-14T09:19:05.3674689Z [32mPASSED[0m
2026-01-14T09:19:47.9945936Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9947876Z stats [('calls_captured', 7), ('unique_graphs', 1)]
2026-01-14T09:19:47.9948421Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9950261Z inductor [('pattern_matcher_nodes', 8), ('qlinear_weight_prepack_matcher_nodes', 6), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9951389Z graph_break []
2026-01-14T09:19:47.9951865Z [32mPASSED[0m
2026-01-14T09:19:47.9952896Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_False_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9954176Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:19:47.9954697Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9955904Z inductor [('pattern_matcher_nodes', 9), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 3), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9957004Z graph_break []
2026-01-14T09:19:47.9957298Z [32mPASSED[0m
2026-01-14T09:19:47.9958395Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_False [32mPASSED[0m
2026-01-14T09:19:47.9960262Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_False_dynamic_True [32mPASSED[0m
2026-01-14T09:19:47.9962106Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_False [32mPASSED[0m
2026-01-14T09:19:47.9963952Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_bfloat16_per_channel_quant_True_dynamic_True [32mPASSED[0m
2026-01-14T09:19:47.9965712Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9966863Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:19:47.9967379Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9968883Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9970166Z graph_break []
2026-01-14T09:19:47.9970553Z [32mPASSED[0m
2026-01-14T09:19:47.9971654Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_False_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9972811Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:19:47.9973329Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9974983Z inductor [('pattern_matcher_nodes', 13), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 6), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9976525Z graph_break []
2026-01-14T09:19:47.9976809Z [32mPASSED[0m
2026-01-14T09:19:47.9977808Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_False frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9978967Z stats [('calls_captured', 10), ('unique_graphs', 1)]
2026-01-14T09:19:47.9979476Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9980849Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9982092Z graph_break []
2026-01-14T09:19:47.9982379Z [32mPASSED[0m
2026-01-14T09:19:47.9983435Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_smooth_quant_with_int_mm_has_bias_True_float32_per_channel_quant_True_dynamic_True frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9984578Z stats [('calls_captured', 14), ('unique_graphs', 1)]
2026-01-14T09:19:47.9985134Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9986503Z inductor [('pattern_matcher_nodes', 12), ('qlinear_weight_prepack_matcher_nodes', 7), ('pattern_matcher_count', 5), ('removed_pointless_view_pair', 1), ('qlinear_weight_prepack_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('extern_calls', 1)]
2026-01-14T09:19:47.9987758Z graph_break []
2026-01-14T09:19:47.9988049Z [32mPASSED[0m
2026-01-14T09:19:47.9988796Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_q_attention_block frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9989642Z inline_call []
2026-01-14T09:19:47.9989952Z stats [('calls_captured', 50), ('unique_graphs', 1)]
2026-01-14T09:19:47.9990468Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:47.9992407Z inductor [('pattern_matcher_nodes', 74), ('pattern_matcher_count', 26), ('qlinear_weight_prepack_matcher_nodes', 24), ('extern_calls', 6), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('dequant_promotion_matcher_nodes', 2), ('fuse_attention', 1), ('dequant_promotion_matcher_count', 1), ('fxgraph_cache_miss', 1)]
2026-01-14T09:19:47.9994242Z graph_break []
2026-01-14T09:19:47.9994535Z [32mPASSED[0m
2026-01-14T09:19:47.9995184Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_fp8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:19:47.9996252Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag [33mSKIPPED[0m
2026-01-14T09:19:47.9997388Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_int8_scaled_embedding_bag_with_output_quant [33mSKIPPED[0m
2026-01-14T09:19:47.9998448Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block inline_call []
2026-01-14T09:19:47.9999087Z stats [('calls_captured', 52), ('unique_graphs', 8)]
2026-01-14T09:19:47.9999414Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:47.9999810Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:48.0001309Z inductor [('pattern_matcher_nodes', 74), ('pattern_matcher_count', 26), ('qlinear_weight_prepack_matcher_nodes', 24), ('extern_calls', 6), ('qlinear_weight_prepack_matcher_count', 4), ('qlinear_unary_lower_count', 4), ('qlinear_unary_lower_nodes', 4), ('dequant_promotion_matcher_nodes', 2), ('fuse_attention', 1), ('dequant_promotion_matcher_count', 1), ('fxgraph_cache_bypass', 1)]
2026-01-14T09:19:48.0002715Z graph_break []
2026-01-14T09:19:48.0002954Z [32mPASSED[0m
2026-01-14T09:19:48.0003603Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qat_bn_conv2d stats [('calls_captured', 1960), ('unique_graphs', 224)]
2026-01-14T09:19:48.0004314Z inline_call []
2026-01-14T09:19:48.0004523Z frames [('total', 1), ('ok', 1)]
2026-01-14T09:19:48.0004876Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:48.0006217Z inductor [('pattern_matcher_nodes', 7), ('qconv_weight_prepack_matcher_nodes', 4), ('pattern_matcher_count', 3), ('qconv_unary_matcher_nodes', 2), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('extern_calls', 1)]
2026-01-14T09:19:48.0007452Z graph_break []
2026-01-14T09:19:48.0007689Z [32mPASSED[0m
2026-01-14T09:19:48.0008405Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu stats [('calls_captured', 30), ('unique_graphs', 8)]
2026-01-14T09:19:48.0009195Z inline_call []
2026-01-14T09:19:48.0009546Z aot_autograd [('total', 1), ('autograd_cache_bypass', 1), ('ok', 1)]
2026-01-14T09:19:48.0011882Z inductor [('pattern_matcher_nodes', 21), ('pattern_matcher_count', 8), ('qlinear_weight_prepack_matcher_nodes', 4), ('qconv_weight_prepack_matcher_nodes', 4), ('qmaxpool2d_matcher_nodes', 4), ('extern_calls', 4), ('qconv_unary_matcher_nodes', 3), ('qreshape_matcher_nodes', 3), ('qlinear_weight_prepack_matcher_count', 1), ('qconv_weight_prepack_matcher_count', 1), ('qconv_unary_matcher_count', 1), ('fxgraph_cache_bypass', 1), ('qconv_unary_lower_count', 1), ('qconv_unary_lower_nodes', 1), ('qmaxpool2d_matcher_count', 1), ('qreshape_matcher_count', 1), ('qlinear_unary_lower_count', 1), ('qlinear_unary_lower_nodes', 1)]
2026-01-14T09:19:48.0014112Z graph_break []
2026-01-14T09:19:48.0014352Z [32mPASSED[0m
2026-01-14T09:19:48.0015029Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_adaptive_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:19:48.0016116Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_annotate_mul_tensor [32mPASSED[0m
2026-01-14T09:19:48.0017139Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_attention_block [32mPASSED[0m
2026-01-14T09:19:48.0018167Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_avg_pool2d_recipe [32mPASSED[0m
2026-01-14T09:25:33.8773394Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe [32mPASSED[0m
2026-01-14T09:25:33.8777523Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_same_inputs [32mPASSED[0m
2026-01-14T09:25:33.8779571Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_cat_recipe_single_input [32mPASSED[0m
2026-01-14T09:25:33.8781336Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d [32mPASSED[0m
2026-01-14T09:25:33.8782658Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary [32mPASSED[0m
2026-01-14T09:25:33.8783672Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:25:33.8784713Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:25:33.8785914Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_serials_binary_unary [32mPASSED[0m
2026-01-14T09:25:33.8786962Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_conv2d_unary [32mPASSED[0m
2026-01-14T09:25:33.8787993Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:25:33.8789064Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe [32mPASSED[0m
2026-01-14T09:25:33.8790125Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_linear_recipe [32mPASSED[0m
2026-01-14T09:25:33.8791251Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:25:33.8792306Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe [32mPASSED[0m
2026-01-14T09:25:33.8793321Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_flatten_recipe2 [32mPASSED[0m
2026-01-14T09:25:33.8794305Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear [32mPASSED[0m
2026-01-14T09:25:33.8795279Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary [32mPASSED[0m
2026-01-14T09:25:33.8796422Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary2 [32mPASSED[0m
2026-01-14T09:25:33.8797476Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic [32mPASSED[0m
2026-01-14T09:25:33.8798553Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_dynamic_qat [32mPASSED[0m
2026-01-14T09:25:33.8799742Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_qat [32mPASSED[0m
2026-01-14T09:25:33.8800784Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary [32mPASSED[0m
2026-01-14T09:25:33.8801870Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic [32mPASSED[0m
2026-01-14T09:25:33.8803027Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:25:33.8804155Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_qat [32mPASSED[0m
2026-01-14T09:25:33.8805256Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_binary_unary_serials [32mPASSED[0m
2026-01-14T09:25:33.8806341Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_dynamic_fp16 [32mPASSED[0m
2026-01-14T09:25:33.8807355Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary [32mPASSED[0m
2026-01-14T09:25:33.8808385Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic [32mPASSED[0m
2026-01-14T09:25:33.8809460Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_dynamic_qat [32mPASSED[0m
2026-01-14T09:25:33.8810520Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_linear_unary_qat [32mPASSED[0m
2026-01-14T09:25:33.8811685Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_lowering_to_x86 [33mSKIPPED[0m
2026-01-14T09:25:33.8812709Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_maxpool2d_recipe [32mPASSED[0m
2026-01-14T09:25:33.8813715Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d [32mPASSED[0m
2026-01-14T09:25:33.8814767Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary [32mPASSED[0m
2026-01-14T09:25:33.8815793Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary2 [32mPASSED[0m
2026-01-14T09:25:33.8816860Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_binary_unary [32mPASSED[0m
2026-01-14T09:25:33.8817907Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_conv2d_unary [32mPASSED[0m
2026-01-14T09:25:33.8818971Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_qat_dynamic_quant_linear [32mPASSED[0m
2026-01-14T09:25:33.8820118Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case1 [32mPASSED[0m
2026-01-14T09:25:33.8821313Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_case2 [32mPASSED[0m
2026-01-14T09:25:33.8822562Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs [32mPASSED[0m
2026-01-14T09:25:33.8823746Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig [32mPASSED[0m
2026-01-14T09:25:33.8824948Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_for_dynamic_quant [32mPASSED[0m
2026-01-14T09:25:33.8826184Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_qconfig_with_underscores [32mPASSED[0m
2026-01-14T09:25:33.8827368Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_with_mixed_configs [32mPASSED[0m
2026-01-14T09:25:33.8828464Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:25:33.8829499Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_bmm_weight_in_bkn_layout [33mSKIPPED[0m
2026-01-14T09:25:33.8830599Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.8831698Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.8832801Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:33.8833895Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.8834992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.8836087Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_cat_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:33.8837149Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-1 [33mSKIPPED[0m
2026-01-14T09:25:33.8838157Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_chunk_dim_-2 [33mSKIPPED[0m
2026-01-14T09:25:33.8839255Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_create_tensor_out_of_inference_mode [33mSKIPPED[0m
2026-01-14T09:25:33.8840471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_expected_gpu_kernel_fbgemm [33mSKIPPED[0m
2026-01-14T09:25:33.8841765Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.8843232Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.8844647Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.8846059Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_False_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.9071144Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.9072577Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_False_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.9073982Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.9075374Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_no_input_copy_compile_True_inference_mode_True_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.9076661Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.9077949Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.9079135Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:33.9080387Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_bfloat16_sizes3 [33mSKIPPED[0m
2026-01-14T09:25:33.9081561Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:33.9082739Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:33.9083918Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:33.9085086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_skip_quant_float32_sizes3 [33mSKIPPED[0m
2026-01-14T09:25:33.9086671Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9088607Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9090509Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9092558Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9094468Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9096441Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9098340Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9100253Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9102155Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9104055Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9106032Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9107932Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9109871Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9111830Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9113727Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9115614Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9117512Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9119413Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9121314Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9123251Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9125151Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9127099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9129000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9130895Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9132846Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9134739Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9136682Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9342827Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9344834Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9346720Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9348619Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9350754Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_bfloat16_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9352652Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9354560Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9356544Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9358444Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9360396Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9362300Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9364208Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9366097Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9368001Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9369891Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9371936Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9373823Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9375780Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9377666Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9379567Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9381450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_False_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9383345Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9385234Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9387169Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9389054Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9391026Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9392928Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9394815Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9396689Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_False_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9398574Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9400497Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9402370Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9404285Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes0_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9406164Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9408050Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_False_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9598673Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_False [33mSKIPPED[0m
2026-01-14T09:25:33.9600661Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_conv_variants_float32_compile_True_inference_mode_True_sizes1_is_input_channels_last_True_is_weight_channels_last_True [33mSKIPPED[0m
2026-01-14T09:25:33.9602572Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9604505Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9607956Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9609976Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9611989Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9613951Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9615903Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9617861Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9619802Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9621874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9623820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9625820Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9627759Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9629697Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9631626Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9633565Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9635516Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9637526Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9639475Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9641471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9643424Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9645364Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9647310Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9649439Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9651526Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9653472Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9655461Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9657388Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9659337Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9661290Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9663244Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9665187Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9856222Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9858213Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9860226Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9862216Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9864151Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9866070Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9867992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9869913Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9871908Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9873848Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9875858Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9877808Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9879743Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9881676Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9883620Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9885554Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9887524Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9889450Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9891520Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9893435Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9895369Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9897315Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9899253Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9901321Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9903260Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9905232Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9907169Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9917407Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9919461Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9921458Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9923378Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9925316Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:33.9927333Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:33.9929295Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0112527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0116151Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0119718Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0122281Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0124227Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0126280Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0128268Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0130319Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0132389Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0134381Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0136372Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0138385Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0140403Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0142469Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0144482Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0146538Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0148536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0150766Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0152812Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0154801Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0156854Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0158848Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0160925Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0162954Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0164965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0166967Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0168974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0170965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0173072Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0175068Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0177116Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0179096Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0181129Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0183116Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0368397Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0370552Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0372667Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0374740Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0376760Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0378765Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0380770Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0382817Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0384819Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0386874Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0388860Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0390926Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0392951Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0394947Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0396950Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0398959Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0400994Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0403085Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0405084Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0407128Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0409112Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0411104Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0413162Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0415144Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0417147Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0419199Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0421263Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0423315Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0425319Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0427325Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0429323Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0431335Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0433379Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0435359Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0621541Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0623569Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0625586Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0627581Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0629607Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0631655Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0633745Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0635753Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0637813Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0639796Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_bfloat16_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0641774Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0643726Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0645665Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0647671Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0649805Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0651974Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0653934Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0655894Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0657851Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0659795Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0661803Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0663750Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0665768Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0667705Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0669706Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0671648Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0673591Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0675550Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0677511Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0679527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0681478Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0683471Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0685413Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0687367Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0879622Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0881592Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0883534Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0885576Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0887542Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0889600Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0891612Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0893584Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0895544Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0897495Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0899451Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0901470Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0903467Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0905407Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0907346Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0909278Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0911282Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0913245Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0915200Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0917195Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0919152Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0921196Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0923136Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0925081Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0927028Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0928960Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0930979Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0933004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0934990Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0936937Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0938891Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0940864Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0942828Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.0944770Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.0946761Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1130377Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1132500Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1134461Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1136408Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1138337Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1140292Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1142251Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1144268Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1146233Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1148243Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1150357Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1152303Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1154237Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_dynamic_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1156203Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1158174Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1160229Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1162273Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1164313Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1166309Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1168308Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1170296Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1172356Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1174415Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1176409Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1178452Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1180433Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1182416Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1184392Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1186374Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1188361Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1190434Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1192480Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1194520Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1196503Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1382559Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1384599Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1386596Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1388682Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1390681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1392725Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1394721Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1396710Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1398709Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1400719Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1402723Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1404783Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1406773Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1408824Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1410812Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_False_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1412869Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1414849Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1416835Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1418811Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1420879Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1422924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1424969Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1426962Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1428967Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1430965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1432959Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1434958Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1436995Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1438973Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1441004Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1442992Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1444979Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1446984Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1449236Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1643810Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1645841Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1647888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1650042Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1652107Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1654086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1656073Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1658054Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1660094Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_AUTO_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1662086Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1664143Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1666134Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1668131Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_FBGEMM_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1670120Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1672162Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes0_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1674153Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_False [33mSKIPPED[0m
2026-01-14T09:25:34.1676939Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_linear_variants_float32_mode_weight-only_compile_True_granularity2_kernel_preference_KernelPreference_TORCH_sizes1_bias_True [33mSKIPPED[0m
2026-01-14T09:25:34.1678980Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1680888Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1682811Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1684732Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1686635Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1688546Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1690455Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1692464Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1694379Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1696337Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1698239Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1700145Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1702108Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1704000Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1705937Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1707851Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1709797Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1711690Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1894924Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1896846Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1898737Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1900625Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1902527Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1904518Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1906434Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1908420Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1910360Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1912362Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1914307Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1916249Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1918240Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1920174Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1922227Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1924170Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1926111Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1928048Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1929980Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1932036Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1934014Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1935952Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1937929Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1939860Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1941839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1943745Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1945681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1947617Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1949782Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1951764Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_bfloat16_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1953743Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1955618Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1957509Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.1959406Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.1961352Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2154311Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2156332Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2158220Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2160165Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2162051Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2163947Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2165834Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2167710Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2169584Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2171631Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2173579Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2175480Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2177365Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2179252Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2181181Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2183068Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2184965Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2186897Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2188790Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_dynamic_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2190745Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2192718Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2194660Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2196611Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2198550Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2200534Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2202518Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2204484Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2206418Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2208374Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2210315Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2212368Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_False_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2214289Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2216200Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2218167Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2220100Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2520595Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2522603Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity0_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2524514Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2526441Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_AUTO_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2528363Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2530396Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_FBGEMM_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2532464Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2534459Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_fp8_matmul_lora_variants_float32_mode_weight-only_compile_True_granularity1_kernel_preference_KernelPreference_TORCH_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2535986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_has_compatible_shallow_copy_type [33mSKIPPED[0m
2026-01-14T09:25:34.2537069Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_index_select [33mSKIPPED[0m
2026-01-14T09:25:34.2538301Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2539697Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2541099Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2542499Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_kernel_preference_numerical_equivalence_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2543729Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:25:34.2544836Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_per_row_config_before_dim [33mSKIPPED[0m
2026-01-14T09:25:34.2545986Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config0 [33mSKIPPED[0m
2026-01-14T09:25:34.2547036Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config1 [33mSKIPPED[0m
2026-01-14T09:25:34.2548092Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_pin_memory_config2 [33mSKIPPED[0m
2026-01-14T09:25:34.2549536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2550912Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2552279Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2553640Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2555013Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2556378Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity0_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2557735Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2559171Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_0_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2560536Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2561897Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_1_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2563324Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape0 [33mSKIPPED[0m
2026-01-14T09:25:34.2564681Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_3d_operation_granularity1_slice_dim_2_tensor_shape1 [33mSKIPPED[0m
2026-01-14T09:25:34.2565989Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity0 [33mSKIPPED[0m
2026-01-14T09:25:34.2567246Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_and_copy_similar_to_vllm_granularity1 [33mSKIPPED[0m
2026-01-14T09:25:34.2568383Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity0 [33mSKIPPED[0m
2026-01-14T09:25:34.2569445Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_granularity1 [33mSKIPPED[0m
2026-01-14T09:25:34.2570588Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity0 [33mSKIPPED[0m
2026-01-14T09:25:34.2571839Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_slice_preserves_aliasing_granularity1 [33mSKIPPED[0m
2026-01-14T09:25:34.2573015Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2574156Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2575359Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity0_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:34.2576498Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2577714Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2578845Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_device_granularity1_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:34.2579920Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_to_dtype_layout [33mSKIPPED[0m
2026-01-14T09:25:34.2580931Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_transpose [33mSKIPPED[0m
2026-01-14T09:25:34.2581982Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_conv2d_weight [33mSKIPPED[0m
2026-01-14T09:25:34.2583143Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2584375Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity0_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:34.2585600Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:34.2586819Z test/quantization/quantize_/workflows/float8/test_float8_tensor.py::TestFloat8Tensor::test_unsqueeze_operation_granularity1_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:36.6728070Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:25:36.6729688Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:25:36.6731209Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:25:36.6732730Z test/quantization/quantize_/workflows/float8/test_sparse_2x4_cutlass_float8_tensor.py::TestSparse2x4Float8Tensor::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:25:36.6734031Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6735212Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_bmm_bmm_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6736407Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_from_int4_tensor [33mSKIPPED[0m
2026-01-14T09:25:36.6737586Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6738764Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_linear_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6739962Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6741171Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6742378Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6743675Z test/quantization/quantize_/workflows/int4/test_int4_preshuffled_tensor.py::TestInt4PreshuffledTensor::test_to_device_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6744782Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_activation_prescaling [33mSKIPPED[0m
2026-01-14T09:25:36.6745744Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_bmm [33mSKIPPED[0m
2026-01-14T09:25:36.6746722Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:36.6747647Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:36.6748567Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_cat_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:36.6749701Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_linear [33mSKIPPED[0m
2026-01-14T09:25:36.6750678Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_moe_weight_reshape_ops [33mSKIPPED[0m
2026-01-14T09:25:36.6751686Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice [33mSKIPPED[0m
2026-01-14T09:25:36.6752680Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_and_copy_similar_to_vllm [33mSKIPPED[0m
2026-01-14T09:25:36.6753754Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_slice_preserves_aliasing [33mSKIPPED[0m
2026-01-14T09:25:36.6754755Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes0 [33mSKIPPED[0m
2026-01-14T09:25:36.6755729Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes1 [33mSKIPPED[0m
2026-01-14T09:25:36.6756766Z test/quantization/quantize_/workflows/int4/test_int4_tensor.py::TestInt4Tensor::test_to_device_sizes2 [33mSKIPPED[0m
2026-01-14T09:25:36.6757960Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6759330Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_activation_prescaling_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6760721Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_cant_initialize_in_cpu [33mSKIPPED[0m
2026-01-14T09:25:36.6762099Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_128 [33mSKIPPED[0m
2026-01-14T09:25:36.6763516Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_32 [33mSKIPPED[0m
2026-01-14T09:25:36.6764916Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_different_group_sizes_group_size_64 [33mSKIPPED[0m
2026-01-14T09:25:36.6766236Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_error_conditions [33mSKIPPED[0m
2026-01-14T09:25:36.6767511Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6768802Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes0_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6770095Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6771438Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes1_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6772793Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6774089Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_linear_sizes2_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6775478Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_mm_int4wo_device_cuda_bfloat16 [33mSKIPPED[0m
2026-01-14T09:25:36.6776806Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6778084Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_module_path_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6779437Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6780872Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_and_copy_similar_to_vllm_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6782255Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6783480Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6784790Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config0 [33mSKIPPED[0m
2026-01-14T09:25:36.6786221Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_slice_preserves_aliasing_config1 [33mSKIPPED[0m
2026-01-14T09:25:36.6787499Z test/quantization/quantize_/workflows/int4/test_int4_tile_packed_to_4d_tensor.py::TestInt4TilePackedTo4dTensor::test_to_device [33mSKIPPED[0m
2026-01-14T09:25:36.6788640Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_available_gpu_kernels [32mPASSED[0m
2026-01-14T09:25:36.6789692Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config0 [32mPASSED[0m
2026-01-14T09:25:36.6790780Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config1 [32mPASSED[0m
2026-01-14T09:25:36.6791925Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config2 [32mPASSED[0m
2026-01-14T09:25:36.6793006Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_creation_and_attributes_config3 [32mPASSED[0m
2026-01-14T09:25:36.6794093Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config0 [32mPASSED[0m
2026-01-14T09:25:36.6795182Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config1 [32mPASSED[0m
2026-01-14T09:26:39.2903181Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config2 [32mPASSED[0m
2026-01-14T09:26:39.2906451Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_dequantization_accuracy_config3 [32mPASSED[0m
2026-01-14T09:26:39.2907843Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config0 [32mPASSED[0m
2026-01-14T09:26:39.2909128Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config1 [32mPASSED[0m
2026-01-14T09:26:39.2910785Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config2 [32mPASSED[0m
2026-01-14T09:26:39.2912061Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_index_select_config3 [32mPASSED[0m
2026-01-14T09:26:39.2913558Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2915345Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2917020Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2918694Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2920359Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2922025Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2923702Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2925358Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2927022Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2928810Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2930469Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2932346Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2934001Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2935657Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2937313Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2938967Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_bfloat16_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2940622Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2942283Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config0_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2943931Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2945583Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config1_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2947346Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2949409Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config2_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2951103Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2952853Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_False_config3_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2954505Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2956153Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config0_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2957796Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2959438Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config1_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2961083Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2962718Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config2_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2964363Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes0 [32mPASSED[0m
2026-01-14T09:26:39.2966098Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_int8_linear_variants_float32_compile_True_config3_sizes1 [32mPASSED[0m
2026-01-14T09:26:39.2967525Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config0 [32mPASSED[0m
2026-01-14T09:26:39.2968831Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config1 [32mPASSED[0m
2026-01-14T09:26:39.2970072Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config2 [32mPASSED[0m
2026-01-14T09:26:39.2971383Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_pin_memory_config3 [32mPASSED[0m
2026-01-14T09:26:39.2972690Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2974022Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_cuda_float16 [32mPASSED[0m
2026-01-14T09:26:39.2975402Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2976795Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config0_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:26:39.2978167Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2979502Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_cuda_float16 [32mPASSED[0m
2026-01-14T09:26:39.2980856Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2982247Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config1_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:26:39.2983695Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2985024Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_cuda_float16 [32mPASSED[0m
2026-01-14T09:26:39.2986302Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2987442Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config2_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:26:39.2988508Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_bfloat16 [32mPASSED[0m
2026-01-14T09:26:39.2989558Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_cuda_float16 [32mPASSED[0m
2026-01-14T09:26:43.0041919Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_bfloat16 [32mPASSED[0m
2026-01-14T09:26:43.0043067Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8Tensor::test_slice_config3_device_cpu_float16 [32mPASSED[0m
2026-01-14T09:26:43.0044315Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:26:43.0045691Z test/quantization/quantize_/workflows/int8/test_int8_tensor.py::TestInt8StaticQuant::test_static_activation_per_row_int8_weight_granularity1_bfloat16 [32mPASSED[0m
2026-01-14T09:26:43.0047913Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0051510Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0054532Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0057459Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0060378Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0063328Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0066358Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0069289Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0072370Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0075413Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0078399Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0081380Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0084301Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0087320Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0090303Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0094060Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0097981Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0101749Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0105531Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0109283Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0239869Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0243175Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0247010Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0250677Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0253679Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0256596Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0259579Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0262698Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0265736Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0268674Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0271585Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0274509Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0277549Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0280640Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0283618Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0286546Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0289467Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0292548Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0295526Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0298616Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0301594Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0304528Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0402263Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0405210Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0408259Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0411395Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0414408Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0417472Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0420526Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0423714Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0426811Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0429785Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0432794Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0435752Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0438755Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0441733Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0444687Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0447646Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0450970Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0454162Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0457242Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0460206Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0463169Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0466232Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0563860Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0567021Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0570037Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0573068Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0576108Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0579076Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0582240Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0585328Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0588346Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0591378Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0594417Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0597426Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0600444Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0603526Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0606582Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0609548Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0612645Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0615610Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0618629Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0621748Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0624763Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0627787Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0733828Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0736799Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0739911Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0742991Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0746099Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0749307Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0752272Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0755318Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0758340Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0761481Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0764460Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0767343Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0770219Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0773248Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0776180Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0779137Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0782005Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0784887Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0787861Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0790857Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0793826Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0796697Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0894400Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0897429Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0900360Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0903414Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0906338Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0909224Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0912184Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0915063Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0918110Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0921093Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0924025Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0926968Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0929893Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0932847Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0935815Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0938812Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0941735Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0944666Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0947535Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0950702Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.0953641Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.0956631Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1051037Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1056438Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1059373Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1062252Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1065184Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1068299Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1071231Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1074179Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1077109Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1079991Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1082925Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1085956Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.bfloat16, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1088958Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1091997Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1094916Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1097890Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1100852Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1103777Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1106793Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1109713Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1112679Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1115763Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1204595Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1207723Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1210639Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1213625Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1216653Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1219691Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1224477Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1227450Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1230350Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1233260Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1236304Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1239386Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1242357Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1245271Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1248187Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1251511Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1254541Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1257578Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1260539Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1263455Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1266427Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1269342Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1364998Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1368054Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1371046Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1374118Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1377087Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1380066Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1383039Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1386113Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1389108Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1392101Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1395080Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1397993Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1410155Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1413602Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1416701Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1419756Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1422805Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1425904Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_KLEIDIAI: 'opaque_torchao_kleidiai'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1428927Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1431924Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1434863Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1437904Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1523774Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1526809Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1529864Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1532962Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1535975Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1539096Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1542097Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1545120Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1548073Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1551976Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1555362Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1558460Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1561759Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1564722Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1567750Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1570691Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1573760Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1576917Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1579911Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1582948Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1585885Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1588818Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1683038Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1686147Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1689216Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1692266Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1695210Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1698147Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1701212Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1704333Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1707339Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1710288Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1713224Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1716267Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1719316Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1722388Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1725386Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1728331Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1731377Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1734324Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1737370Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1740437Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_LOWBIT: 'opaque_torchao_lowbit'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1743398Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1746360Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1840830Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1843801Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int1, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1846710Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1850772Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1853705Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1856667Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1859640Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1862617Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int2, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1865525Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1868397Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1871316Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1874221Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1877192Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1880168Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int3, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1883090Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1886008Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1888859Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1891795Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1894718Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1897703Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int4, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.1900663Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.1903525Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2003673Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2006613Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2009533Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2012563Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int5, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2015565Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2018492Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2021353Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2024203Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2027179Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2030205Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int6, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2033170Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2036048Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2038897Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2041754Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2044708Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2047683Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int7, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2050874Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2053801Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.ASYMMETRIC: 3>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2056718Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2059644Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC: 1>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2062562Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerAxis(axis=0)} [33mSKIPPED[0m
2026-01-14T09:26:43.2065621Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_accuracy_{'model_dtype': torch.float32, 'packing_format': <IntxPackingFormat.UNPACKED_TO_INT8: 'unpacked_to_int8'>, 'weight_dtype': torch.int8, 'weight_mapping_type': <MappingType.SYMMETRIC_NO_CLIPPING_ERR: 2>, 'weight_granularity': PerGroup(group_size=128)} [33mSKIPPED[0m
2026-01-14T09:26:43.2067635Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_export_compile_aoti [33mSKIPPED[0m
2026-01-14T09:26:51.1744110Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_ATEN_KLEIDIAI: 'opaque_aten_kleidiai'>} [33mSKIPPED[0m
2026-01-14T09:26:51.1746466Z test/quantization/quantize_/workflows/intx/test_intx_opaque_tensor.py::TestIntxOpaqueTensor::test_serialization_{'packing_format': <IntxPackingFormat.OPAQUE_TORCHAO_AUTO: 'opaque_torchao_auto'>} [33mSKIPPED[0m
2026-01-14T09:26:51.1748373Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_conv2d [32mPASSED[0m
2026-01-14T09:26:51.1750082Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_embedding [32mPASSED[0m
2026-01-14T09:26:51.1751784Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:26:51.1754036Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_int8_dyn_act_intx_weight_config_with_unwrap [32mPASSED[0m
2026-01-14T09:26:51.1755876Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_export_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:26:51.1759350Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:26:51.1761091Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_hqq_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:26:51.1762661Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_linear [32mPASSED[0m
2026-01-14T09:26:51.1765139Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1768594Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1771994Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1775387Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1778748Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1782015Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1785308Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1788577Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1791856Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1795190Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1798562Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1801819Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1805063Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1808327Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1811689Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1814970Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1818290Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.1821545Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.1824806Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.1828158Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4382065Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4385434Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4388830Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4392119Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4395397Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4398673Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4402051Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int1, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4405354Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4408772Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4412193Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4415500Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4418851Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4422207Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4425523Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4428874Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4432187Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4435477Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4438778Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4442173Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4445507Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4448789Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4452345Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.4455641Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.4458930Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.4462325Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7043585Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7047323Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7050813Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7054218Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7057497Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7060908Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7064287Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7067564Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7070828Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int2, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7074124Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7077431Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7080880Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7084235Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7087531Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7090838Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7094247Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7097588Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7100893Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7104239Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7107532Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7110812Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7114100Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.7117434Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.7120771Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.7124104Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9655225Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9658589Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9661923Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9665441Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9668741Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9672150Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9675428Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9678676Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9681912Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9685285Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9688556Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int3, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9692035Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9695329Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9698597Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9701871Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9705213Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9708613Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9711926Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9715220Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9718584Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9721884Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9725226Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:51.9728530Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:51.9731904Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:51.9735178Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2266262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2269763Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2273095Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2277047Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2280365Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2283694Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2287013Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2290345Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2293812Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2297153Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2300464Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2303764Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2307020Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int4, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2310503Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2313854Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2317313Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2320660Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2323979Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2327311Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2330741Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2334115Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2337538Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.2340896Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.2344262Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.2347595Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4872203Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4875625Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4879008Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4882313Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4885627Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4888987Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4892469Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4895768Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4899149Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4902466Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4905788Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4909083Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4912451Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4915871Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4919245Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int5, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4922626Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4925949Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4929286Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4932781Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4936136Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4939502Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4942918Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.4946282Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.4950086Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.4953414Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7470879Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7474261Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7477598Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7480933Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7484225Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7487668Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7491066Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7494448Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7497752Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7501086Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7504530Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7507850Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7511210Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7514524Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7517830Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7521134Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7524549Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int6, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7527907Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7531474Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7534844Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7538186Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7541524Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:52.7544903Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:52.7548236Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:52.7551812Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0137458Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0140863Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0144188Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0147643Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0151176Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0154572Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0157873Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0161256Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0164590Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0167983Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0171414Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0174757Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0178121Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0181467Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0184779Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0188195Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0191560Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0194926Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0198233Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int7, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0201576Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0204989Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0208365Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.0211831Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.0215171Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.0218583Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2587455Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2590930Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2594193Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 128, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2605504Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2608077Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2610630Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2613280Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2615898Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2618494Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2621107Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2623657Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2626189Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 32, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2628799Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2631402Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2633956Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.bfloat16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2636541Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2639090Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2641635Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float16, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2644196Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.bfloat16} [32mPASSED[0m
2026-01-14T09:26:53.2646785Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float16} [32mPASSED[0m
2026-01-14T09:26:53.2649634Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_qat_int8_dyn_act_intx_weight_config_{'weight_dtype': torch.int8, 'group_size': 64, 'mapping_type': <MappingType.SYMMETRIC: 1>, 'scale_dtype': torch.float32, 'model_dtype': torch.float32} [32mPASSED[0m
2026-01-14T09:26:53.2651747Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_int8_dyn_act_intx_weight_config [32mPASSED[0m
2026-01-14T09:26:53.2653206Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_serialization_intx_weight_only_config [32mPASSED[0m
2026-01-14T09:26:53.2654493Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice [32mPASSED[0m
2026-01-14T09:26:53.2655694Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_slice_and_copy_ [32mPASSED[0m
2026-01-14T09:26:53.2656898Z test/quantization/quantize_/workflows/intx/test_intx_unpacked_to_int8_tensor.py::TestIntxUnpackedToInt8Tensor::test_to_dtype [32mPASSED[0m
2026-01-14T09:26:53.2657960Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_False [33mSKIPPED[0m
2026-01-14T09:26:53.2658947Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_2_bias_True [33mSKIPPED[0m
2026-01-14T09:26:53.2659859Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_False [33mSKIPPED[0m
2026-01-14T09:26:53.2660792Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_concat_linear_cpu_x_dim_3_bias_True [33mSKIPPED[0m
2026-01-14T09:26:53.2661860Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3479090Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3480309Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3481375Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3482434Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3483499Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3484561Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3485792Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3487158Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3488519Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3489875Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3491325Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3492763Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3494115Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3495523Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3496846Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_bfloat16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3498182Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3499569Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3500899Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3502225Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3503544Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3504879Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3506195Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3507511Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3508841Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3510245Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3511593Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3512926Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3514299Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3515627Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3516941Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3518262Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float16_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3519592Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3520923Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3522256Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3523584Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3524899Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3526284Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3527602Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3528969Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_2_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3530378Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3531775Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3533111Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3534435Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_False_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3535764Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3537103Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_160_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3538470Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_False [33mSKIPPED[0m
2026-01-14T09:26:53.3539785Z test/quantization/test_da8w4_cpu.py::TestDa8w4Cpu::test_8da4w_cpu_float32_x_dim_3_bias_True_bs_1_sym_quant_a_True [33mSKIPPED[0m
2026-01-14T09:26:53.3540940Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_add_tensors [32mPASSED[0m
2026-01-14T09:26:53.3541992Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_inplace_operation [32mPASSED[0m
2026-01-14T09:26:53.3543034Z test/quantization/test_gptq.py::TestMultiTensorFlow::test_multitensor_pad_unpad [32mPASSED[0m
2026-01-14T09:26:53.3544173Z test/quantization/test_gptq.py::TestMultiTensorInputRecorder::test_multitensor_input_recorder [32mPASSED[0m
2026-01-14T09:26:53.3545254Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_calc_success [32mPASSED[0m
2026-01-14T09:26:53.3546241Z test/quantization/test_observer.py::TestQuantFlow::test_block_size_row_errors [32mPASSED[0m
2026-01-14T09:26:53.3547251Z test/quantization/test_observer.py::TestQuantFlow::test_fixed_qparams_observer [32mPASSED[0m
2026-01-14T09:26:53.3548251Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_channel_affine [32mPASSED[0m
2026-01-14T09:26:53.3549449Z test/quantization/test_observer.py::TestQuantFlow::test_min_max_per_tensor_affine [32mPASSED[0m
2026-01-14T09:26:53.3550411Z test/quantization/test_observer.py::TestQuantFlow::test_mse_observer [32mPASSED[0m
2026-01-14T09:26:53.3551512Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_False [32mPASSED[0m
2026-01-14T09:26:53.3552774Z test/quantization/test_observer.py::TestLinearObserver::test_linear_observer_tensor_observe_weight_True [32mPASSED[0m
2026-01-14T09:26:53.3553829Z test/quantization/test_qat.py::TestQAT::test_composable_qat_quantizer [32mPASSED[0m
2026-01-14T09:26:53.3554710Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dtype [32mPASSED[0m
2026-01-14T09:26:53.3555715Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_dynamic_and_range_learning [32mPASSED[0m
2026-01-14T09:26:53.3556683Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_eps [32mPASSED[0m
2026-01-14T09:26:53.3557588Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity [32mPASSED[0m
2026-01-14T09:26:53.3558590Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_granularity_error_cases [32mPASSED[0m
2026-01-14T09:26:53.3559677Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_mapping_type [32mPASSED[0m
2026-01-14T09:27:07.6519543Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_config_torch_intx [32mPASSED[0m
2026-01-14T09:27:07.6520325Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_channel_group [32mPASSED[0m
2026-01-14T09:27:07.6521463Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token [32mPASSED[0m
2026-01-14T09:27:07.6522309Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6523138Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:27:07.6523976Z test/quantization/test_qat.py::TestQAT::test_fake_quantize_per_token_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:27:07.6524750Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_embedding_4w [32mPASSED[0m
2026-01-14T09:27:07.6525465Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_4w [32mPASSED[0m
2026-01-14T09:27:07.6526181Z test/quantization/test_qat.py::TestQAT::test_fake_quantized_linear_8da4w [32mPASSED[0m
2026-01-14T09:27:07.6526987Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:27:07.6527874Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:27:07.6528627Z test/quantization/test_qat.py::TestQAT::test_fake_quantizer_repr [32mPASSED[0m
2026-01-14T09:27:07.6529371Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_int4_preshuffled_primitives [33mSKIPPED[0m
2026-01-14T09:27:07.6530114Z test/quantization/test_qat.py::TestQAT::test_fbgemm_fp8_primitives [33mSKIPPED[0m
2026-01-14T09:27:07.6530846Z test/quantization/test_qat.py::TestQAT::test_fbgemm_int4_weight_only_primitives [33mSKIPPED[0m
2026-01-14T09:27:07.6531661Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_config [32mPASSED[0m
2026-01-14T09:27:07.6532390Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity0 [32mPASSED[0m
2026-01-14T09:27:07.6534905Z test/quantization/test_qat.py::TestQAT::test_float8_fake_quantize_granularity1 [32mPASSED[0m
2026-01-14T09:27:07.6535624Z test/quantization/test_qat.py::TestQAT::test_infer_fp8_int4_config [32mPASSED[0m
2026-01-14T09:27:07.6536314Z test/quantization/test_qat.py::TestQAT::test_infer_int4_weight_only_config [32mPASSED[0m
2026-01-14T09:27:07.6537095Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:27:07.6537857Z test/quantization/test_qat.py::TestQAT::test_nvfp4_fake_quanitzed_linear_mixed_precision [33mSKIPPED[0m
2026-01-14T09:27:07.6538599Z test/quantization/test_qat.py::TestQAT::test_qat_4w_embedding [32mPASSED[0m
2026-01-14T09:27:07.6539296Z test/quantization/test_qat.py::TestQAT::test_qat_4w_linear tensor(5.9366e-05, device='cuda:0', dtype=torch.bfloat16,
2026-01-14T09:27:07.6539857Z        grad_fn=<AbsBackward0>)
2026-01-14T09:27:07.6540151Z [32mPASSED[0m
2026-01-14T09:27:07.6540640Z test/quantization/test_qat.py::TestQAT::test_qat_4w_primitives tensor(0.0005, device='cuda:0', dtype=torch.bfloat16)
2026-01-14T09:27:07.6541221Z [32mPASSED[0m
2026-01-14T09:27:07.6541783Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer tensor(0.0038, device='cuda:0', dtype=torch.bfloat16, grad_fn=<AbsBackward0>)
2026-01-14T09:27:07.6542457Z [32mPASSED[0m
2026-01-14T09:27:07.6542914Z test/quantization/test_qat.py::TestQAT::test_qat_4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:27:07.6543564Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_eps [32mPASSED[0m
2026-01-14T09:27:07.6544182Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_linear [32mPASSED[0m
2026-01-14T09:27:07.6544883Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6545664Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float16 [32mPASSED[0m
2026-01-14T09:27:07.6546528Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_prepare_vs_convert_float32 [32mPASSED[0m
2026-01-14T09:27:07.6547240Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:27:07.6547964Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant [32mPASSED[0m
2026-01-14T09:27:07.6548837Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_disable_fake_quant_backward [32mPASSED[0m
2026-01-14T09:27:07.6549882Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_gradients [32mPASSED[0m
2026-01-14T09:27:07.6550610Z test/quantization/test_qat.py::TestQAT::test_qat_8da4w_quantizer_meta_weights [32mPASSED[0m
2026-01-14T09:27:07.6551350Z test/quantization/test_qat.py::TestQAT::test_qat_api_convert_no_quantization [32mPASSED[0m
2026-01-14T09:27:07.6552043Z test/quantization/test_qat.py::TestQAT::test_qat_api_deprecation [32mPASSED[0m
2026-01-14T09:27:07.6552674Z test/quantization/test_qat.py::TestQAT::test_qat_config_init [32mPASSED[0m
2026-01-14T09:27:07.6553316Z test/quantization/test_qat.py::TestQAT::test_qat_fp8a4w_quantizer [32mPASSED[0m
2026-01-14T09:27:07.6553947Z test/quantization/test_qat.py::TestQAT::test_qat_linear_bias [32mPASSED[0m
2026-01-14T09:27:07.6554691Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:27:07.6555549Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_training_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:27:07.6556360Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:27:07.6557138Z test/quantization/test_qat.py::TestQAT::test_qat_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:27:07.6557831Z test/quantization/test_qat.py::TestQAT::test_qat_prototype_bc [32mPASSED[0m
2026-01-14T09:27:07.6558544Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_False [32mPASSED[0m
2026-01-14T09:27:07.6559393Z test/quantization/test_qat.py::TestQAT::test_qat_range_learning_is_symmetric_True [32mPASSED[0m
2026-01-14T09:27:07.6560091Z test/quantization/test_qat.py::TestQAT::test_quantize_api_e2e [32mPASSED[0m
2026-01-14T09:27:07.6560732Z test/quantization/test_qat.py::TestQAT::test_quantize_api_errors [32mPASSED[0m
2026-01-14T09:27:07.6561440Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity0 [33mSKIPPED[0m
2026-01-14T09:27:07.6562265Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_fp8_granularity1 [33mSKIPPED[0m
2026-01-14T09:27:07.6562971Z test/quantization/test_qat.py::TestQAT::test_quantize_api_fp8_int4 [33mSKIPPED[0m
2026-01-14T09:27:07.6563838Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:27:07.6564909Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_1_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:27:07.6565973Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PLAIN [33mSKIPPED[0m
2026-01-14T09:27:07.6567041Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int4_version_2_packing_format_Int4PackingFormat_PRESHUFFLED [33mSKIPPED[0m
2026-01-14T09:27:07.6567904Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_int4 [32mPASSED[0m
2026-01-14T09:27:07.6568732Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity0_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6569671Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity1_float32 [32mPASSED[0m
2026-01-14T09:27:07.6570604Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity2_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6571609Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int2_weight_granularity3_float32 [32mPASSED[0m
2026-01-14T09:27:07.6572636Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity4_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6573575Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity5_float32 [32mPASSED[0m
2026-01-14T09:27:07.6574573Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity6_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6575504Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int3_weight_granularity7_float32 [32mPASSED[0m
2026-01-14T09:27:07.6576441Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity10_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6577380Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity11_float32 [32mPASSED[0m
2026-01-14T09:27:07.6578306Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity8_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6579245Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int4_weight_granularity9_float32 [32mPASSED[0m
2026-01-14T09:27:07.6580180Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity12_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6581125Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity13_float32 [32mPASSED[0m
2026-01-14T09:27:07.6582122Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity14_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6583052Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int5_weight_granularity15_float32 [32mPASSED[0m
2026-01-14T09:27:07.6583992Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity16_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6584943Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity17_float32 [32mPASSED[0m
2026-01-14T09:27:07.6585937Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity18_bfloat16 [32mPASSED[0m
2026-01-14T09:27:07.6586886Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int6_weight_granularity19_float32 [32mPASSED[0m
2026-01-14T09:27:08.2762610Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity20_bfloat16 [32mPASSED[0m
2026-01-14T09:27:08.2763735Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity21_float32 [32mPASSED[0m
2026-01-14T09:27:08.2764697Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity22_bfloat16 [32mPASSED[0m
2026-01-14T09:27:08.2765659Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int7_weight_granularity23_float32 [32mPASSED[0m
2026-01-14T09:27:08.2766622Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity24_bfloat16 [32mPASSED[0m
2026-01-14T09:27:08.2767581Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity25_float32 [32mPASSED[0m
2026-01-14T09:27:08.2768528Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity26_bfloat16 [32mPASSED[0m
2026-01-14T09:27:08.2769494Z test/quantization/test_qat.py::TestQAT::test_quantize_api_int8_intx_int8_weight_granularity27_float32 [32mPASSED[0m
2026-01-14T09:27:08.2770486Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity0_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2771627Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity1_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2772691Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity2_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2773782Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity3_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2774813Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity4_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2775845Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity5_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2776930Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity6_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2777951Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int2_granularity7_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2778973Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity10_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2779994Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity11_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2781033Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity12_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2782065Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity13_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2783099Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity14_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2784175Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity15_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2785497Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity8_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2786813Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int3_granularity9_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2788107Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity16_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2789536Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity17_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2790839Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity18_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2792170Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity19_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2793509Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity20_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2794813Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity21_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2796099Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity22_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2797387Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int4_granularity23_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2798670Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity24_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2799972Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity25_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2801269Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity26_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2802599Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity27_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2803890Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity28_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2805226Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity29_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2806526Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity30_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2807812Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int5_granularity31_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2809138Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity32_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2810446Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity33_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2811838Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity34_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2813120Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity35_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2814422Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity36_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2815726Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity37_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2817020Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity38_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2818317Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int6_granularity39_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2819612Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity40_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2820919Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity41_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2822205Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity42_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2823553Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity43_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2824865Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity44_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2826169Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity45_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2827525Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity46_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2828823Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int7_granularity47_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2830116Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity48_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2831435Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity49_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2832777Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity50_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2834071Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity51_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2835379Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity52_bfloat16_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2836676Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity53_bfloat16_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2837969Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity54_float32_module_type_linear [32mPASSED[0m
2026-01-14T09:27:08.2839251Z test/quantization/test_qat.py::TestQAT::test_quantize_api_intx_int8_granularity55_float32_module_type_embedding [32mPASSED[0m
2026-01-14T09:27:08.2840499Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_False [33mSKIPPED[0m
2026-01-14T09:27:23.0143162Z test/quantization/test_qat.py::TestQAT::test_quantize_api_nvfp4_use_per_tensor_scale_True [33mSKIPPED[0m
2026-01-14T09:27:23.0144560Z test/quantization/test_qat.py::TestQAT::test_quantize_api_prepare [32mPASSED[0m
2026-01-14T09:27:23.0145581Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls0 [32mPASSED[0m
2026-01-14T09:27:23.0146750Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls1 [32mPASSED[0m
2026-01-14T09:27:23.0147911Z test/quantization/test_qat.py::TestQAT::test_range_learning_convert_pass_qparams_base_config_cls2 [32mPASSED[0m
2026-01-14T09:27:23.0148895Z test/quantization/test_qat.py::TestQAT::test_replace_linear_8da4w [32mPASSED[0m
2026-01-14T09:27:23.0149978Z test/quantization/test_qat.py::TestQAT::test_replace_linear_int4 [32mPASSED[0m
2026-01-14T09:27:23.0150856Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer [32mPASSED[0m
2026-01-14T09:27:23.0151836Z test/quantization/test_quant_api.py::TestQuantFlow::test_8da4w_quantizer_linear_bias [32mPASSED[0m
2026-01-14T09:27:23.0152826Z test/quantization/test_quant_api.py::TestQuantFlow::test_config_deprecation [32mPASSED[0m
2026-01-14T09:27:23.0153819Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_singleline [32mPASSED[0m
2026-01-14T09:27:23.0154982Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_eager_mode_impl [33mSKIPPED[0m
2026-01-14T09:27:23.0156206Z test/quantization/test_quant_api.py::TestQuantFlow::test_dynamic_quant_gpu_unified_api_unified_impl [33mSKIPPED[0m
2026-01-14T09:27:23.0157298Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4_wo_quant_save_load [33mSKIPPED[0m
2026-01-14T09:27:23.0158400Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0159686Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0160851Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0162026Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_bfloat16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0163332Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0164490Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0165650Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0166798Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float16_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0167956Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0169102Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_2_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0170268Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_False [32mPASSED[0m
2026-01-14T09:27:23.0171525Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cpu_float32_x_dim_3_use_hqq_True [32mPASSED[0m
2026-01-14T09:27:23.0172605Z test/quantization/test_quant_api.py::TestQuantFlow::test_int4wo_cuda_serialization [32mPASSED[0m
2026-01-14T09:27:23.0173609Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8_wo_quant_save_load [32mPASSED[0m
2026-01-14T09:27:23.0174641Z test/quantization/test_quant_api.py::TestQuantFlow::test_int8wo_quantized_model_to_device [32mPASSED[0m
2026-01-14T09:27:23.0175819Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_default [32mPASSED[0m
2026-01-14T09:27:23.0176919Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_embedding_linear [32mPASSED[0m
2026-01-14T09:27:23.0178018Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_module_name [32mPASSED[0m
2026-01-14T09:27:23.0179174Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_basic [32mPASSED[0m
2026-01-14T09:27:23.0180281Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_fullmatch [32mPASSED[0m
2026-01-14T09:27:23.0181411Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence [32mPASSED[0m
2026-01-14T09:27:23.0182509Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_regex_precedence2 [32mPASSED[0m
2026-01-14T09:27:23.0183359Z test/quantization/test_quant_api.py::TestQuantFlow::test_module_fqn_to_config_skip [32mPASSED[0m
2026-01-14T09:27:23.0184168Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_model_streaming [32mPASSED[0m
2026-01-14T09:27:23.0185056Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type0 [32mPASSED[0m
2026-01-14T09:27:23.0186028Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_8da4w_mapping_type1 [32mPASSED[0m
2026-01-14T09:27:23.0186950Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load [32mPASSED[0m
2026-01-14T09:27:23.0187888Z test/quantization/test_quant_api.py::TestQuantFlow::test_quantized_tensor_subclass_save_load_map_location [32mPASSED[0m
2026-01-14T09:27:23.0188797Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config0 [32mPASSED[0m
2026-01-14T09:27:23.0189632Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config1 [32mPASSED[0m
2026-01-14T09:27:23.0190465Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config2 [32mPASSED[0m
2026-01-14T09:27:23.0191378Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config3 [32mPASSED[0m
2026-01-14T09:27:23.0192208Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config4 [32mPASSED[0m
2026-01-14T09:27:23.0193041Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config5 [32mPASSED[0m
2026-01-14T09:27:23.0193915Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config6 [32mPASSED[0m
2026-01-14T09:27:23.0194755Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config7 [32mPASSED[0m
2026-01-14T09:27:23.0195588Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config8 [32mPASSED[0m
2026-01-14T09:27:23.0196415Z test/quantization/test_quant_api.py::TestQuantFlow::test_workflow_e2e_numerics_config9 [32mPASSED[0m
2026-01-14T09:27:23.0197288Z test/quantization/test_quant_api.py::TestFqnToConfig::test_filter_fn_and_fqn_to_config_error [33mSKIPPED[0m
2026-01-14T09:27:23.0198272Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_module_config_and_fqn_config_both_specified [33mSKIPPED[0m
2026-01-14T09:27:23.0199252Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module [33mSKIPPED[0m
2026-01-14T09:27:23.0200218Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_module_swap [33mSKIPPED[0m
2026-01-14T09:27:23.0201186Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_config_quantized_nested_module_param [33mSKIPPED[0m
2026-01-14T09:27:23.0202076Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_custom [33mSKIPPED[0m
2026-01-14T09:27:23.0202904Z test/quantization/test_quant_api.py::TestFqnToConfig::test_fqn_to_config_repr_linear [33mSKIPPED[0m
2026-01-14T09:27:23.0203812Z test/quantization/test_quant_api.py::TestFqnToConfig::test_non_fqn_config_filter_fn_none [33mSKIPPED[0m
2026-01-14T09:27:23.0204763Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_module_over_param_regex [33mSKIPPED[0m
2026-01-14T09:27:23.0205845Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_default [33mSKIPPED[0m
2026-01-14T09:27:23.0206821Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module [33mSKIPPED[0m
2026-01-14T09:27:23.0207803Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_over_module_regex [33mSKIPPED[0m
2026-01-14T09:27:23.0208825Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_default [33mSKIPPED[0m
2026-01-14T09:27:23.0209877Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_fqn_precedence_param_regex_over_module_regex [33mSKIPPED[0m
2026-01-14T09:27:23.0210891Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param [33mSKIPPED[0m
2026-01-14T09:27:23.0211972Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_model_same_module_different_param_regex [33mSKIPPED[0m
2026-01-14T09:27:23.0212886Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_exact [33mSKIPPED[0m
2026-01-14T09:27:23.0213720Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantize_param_fqn_regex [33mSKIPPED[0m
2026-01-14T09:27:23.0214602Z test/quantization/test_quant_api.py::TestFqnToConfig::test_quantized_model_streaming_fqn_config [33mSKIPPED[0m
2026-01-14T09:27:23.0215479Z test/quantization/test_quant_api.py::TestFqnToConfig::test_top_level_param [33mSKIPPED[0m
2026-01-14T09:27:23.0216401Z test/quantization/test_quant_api.py::TestFqnToConfig::test_unsupported_param_config_raises_not_implemented_error [33mSKIPPED[0m
2026-01-14T09:27:23.0217539Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_and_quantize_scale_only_sinq [32mPASSED[0m
2026-01-14T09:27:42.9406389Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym [32mPASSED[0m
2026-01-14T09:27:42.9408323Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_group_sym_no_clipping_err [32mPASSED[0m
2026-01-14T09:27:42.9410553Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym [32mPASSED[0m
2026-01-14T09:27:42.9411704Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_asym_eps [32mPASSED[0m
2026-01-14T09:27:42.9413006Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_tensor_sym [32mPASSED[0m
2026-01-14T09:27:42.9414305Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_choose_qparams_token_asym [32mPASSED[0m
2026-01-14T09:27:42.9415602Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine [32mPASSED[0m
2026-01-14T09:27:42.9416780Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_fake_quantize_affine_cachemask [32mPASSED[0m
2026-01-14T09:27:42.9418041Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_blockwise_scaling [32mPASSED[0m
2026-01-14T09:27:42.9419308Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_float8_rowwise_scaling_3d_weight_axis_1 [32mPASSED[0m
2026-01-14T09:27:42.9420556Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric [32mPASSED[0m
2026-01-14T09:27:42.9421838Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_group_qparams_symmetric_memory [32mPASSED[0m
2026-01-14T09:27:42.9423065Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_get_groupwise_affine_qparams [32mPASSED[0m
2026-01-14T09:27:42.9424597Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_dequantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:27:42.9426027Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_groupwise_affine_quantize_tensor_from_qparams [32mPASSED[0m
2026-01-14T09:27:42.9427532Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_maybe_expand_scale_to_tensor_shape [32mPASSED[0m
2026-01-14T09:27:42.9428823Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max [32mPASSED[0m
2026-01-14T09:27:42.9430158Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_dtype [32mPASSED[0m
2026-01-14T09:27:42.9431565Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_activation_per_token_abs_max_zero_input [32mPASSED[0m
2026-01-14T09:27:42.9432905Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym [32mPASSED[0m
2026-01-14T09:27:42.9434167Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d [32mPASSED[0m
2026-01-14T09:27:42.9435568Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_channel_asym_4d_multi_dim_reduction [32mPASSED[0m
2026-01-14T09:27:42.9436924Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_group_sym [32mPASSED[0m
2026-01-14T09:27:42.9438156Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_quantize_dequantize_tensor_asym [32mPASSED[0m
2026-01-14T09:27:42.9439258Z test/quantization/test_quant_primitives.py::TestQuantPrimitives::test_raises [32mPASSED[0m
2026-01-14T09:27:42.9440205Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity [33mSKIPPED[0m
2026-01-14T09:27:42.9441164Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_identity_scaled [33mSKIPPED[0m
2026-01-14T09:27:42.9442117Z test/sparsity/test_activation24.py::test_sparse24_sm90_sparsify_srelu [33mSKIPPED[0m
2026-01-14T09:27:42.9443167Z test/sparsity/test_activation24.py::test_srelu_fp8_semi_sparse_activation_linear [33mSKIPPED[0m
2026-01-14T09:27:42.9444141Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_eye [33mSKIPPED[0m
2026-01-14T09:27:42.9445140Z test/sparsity/test_activation24.py::test_sparse24_fp8_sm90_cutlass_gemm_random_tensor [33mSKIPPED[0m
2026-01-14T09:27:42.9455360Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification [33mSKIPPED[0m
2026-01-14T09:27:42.9456944Z test/sparsity/test_fast_sparse_training.py::TestRuntimeSemiStructuredSparsity::test_runtime_weight_sparsification_compile [33mSKIPPED[0m
2026-01-14T09:27:42.9458135Z test/sparsity/test_sparse_api.py::TestSemiStructuredSparse::test_sparse [33mSKIPPED[0m
2026-01-14T09:27:42.9459181Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:27:42.9460305Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_compile_True [33mSKIPPED[0m
2026-01-14T09:27:42.9461449Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_clone [33mSKIPPED[0m
2026-01-14T09:27:42.9462604Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_fp8_cutlass_sparse_lowering_op_to [33mSKIPPED[0m
2026-01-14T09:27:42.9463722Z test/sparsity/test_sparse_api.py::TestQuantSemiSparse::test_quant_semi_sparse_compile_False [33mSKIPPED[0m
2026-01-14T09:27:42.9464866Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1 [32mPASSED[0m
2026-01-14T09:27:42.9466044Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024 [32mPASSED[0m
2026-01-14T09:27:42.9467214Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1 [32mPASSED[0m
2026-01-14T09:27:42.9468507Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_True_input_shape_1024 [32mPASSED[0m
2026-01-14T09:27:42.9469691Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False [32mPASSED[0m
2026-01-14T09:27:42.9470837Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_True [32mPASSED[0m
2026-01-14T09:27:42.9471780Z test/sparsity/test_supermask.py::TestSupermask::test_from_linear [32mPASSED[0m
2026-01-14T09:27:42.9472772Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_2 [32mPASSED[0m
2026-01-14T09:27:42.9473904Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_4 [32mPASSED[0m
2026-01-14T09:27:42.9475025Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_25_blocksize_8 [32mPASSED[0m
2026-01-14T09:27:42.9476150Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_2 [32mPASSED[0m
2026-01-14T09:27:42.9477260Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_4 [32mPASSED[0m
2026-01-14T09:27:42.9478376Z test/sparsity/test_supermask.py::TestSupermask::test_supermask_sparsity_level_0_5_blocksize_8 [32mPASSED[0m
2026-01-14T09:27:42.9479379Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4 [32mPASSED[0m
2026-01-14T09:27:42.9480335Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:27:42.9481235Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare [32mPASSED[0m
2026-01-14T09:27:42.9482044Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask [32mPASSED[0m
2026-01-14T09:27:42.9482968Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured [32mPASSED[0m
2026-01-14T09:27:42.9484053Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config [32mPASSED[0m
2026-01-14T09:27:42.9485240Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_False [32mPASSED[0m
2026-01-14T09:27:42.9486341Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cpu_compile_True [32mPASSED[0m
2026-01-14T09:27:42.9487430Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_False [32mPASSED[0m
2026-01-14T09:27:42.9488598Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_device_cuda_compile_True [32mPASSED[0m
2026-01-14T09:27:42.9489982Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_False [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9491413Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9491945Z [32mPASSED[0m
2026-01-14T09:27:42.9492694Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cpu_compile_True [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9493679Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9494171Z [32mPASSED[0m
2026-01-14T09:27:42.9494921Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_False [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9495920Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9496384Z [32mPASSED[0m
2026-01-14T09:27:42.9497135Z test/test_low_bit_optim.py::TestQuantize::test_bf16_stochastic_round_dtensor_device_cuda_compile_True [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9498179Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2026-01-14T09:27:42.9498648Z [32mPASSED[0m
2026-01-14T09:27:42.9499190Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:34:30.9988670Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:34:30.9991716Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:34:30.9992621Z test/test_low_bit_optim.py::TestQuantize::test_quantize_4bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:34:30.9993494Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cpu [32mPASSED[0m
2026-01-14T09:34:30.9994337Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_compile_device_cuda [32mPASSED[0m
2026-01-14T09:34:30.9995211Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:34:30.9996090Z test/test_low_bit_optim.py::TestQuantize::test_quantize_8bit_with_qmap_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:34:30.9996940Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_Adam4bit [33mSKIPPED[0m
2026-01-14T09:34:30.9997768Z test/test_low_bit_optim.py::TestOptim::test_optim_4bit_correctness_optim_name_AdamW4bit [33mSKIPPED[0m
2026-01-14T09:34:30.9998588Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_Adam8bit [33mSKIPPED[0m
2026-01-14T09:34:30.9999409Z test/test_low_bit_optim.py::TestOptim::test_optim_8bit_correctness_optim_name_AdamW8bit [33mSKIPPED[0m
2026-01-14T09:34:31.0000255Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0001189Z test/test_low_bit_optim.py::TestOptim::test_optim_bf16_stochastic_round_correctness_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0002269Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_1 [32mPASSED[0m
2026-01-14T09:34:31.0003238Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_False_grad_accum_2 [32mPASSED[0m
2026-01-14T09:34:31.0004211Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_correctness_offload_grad_True_grad_accum_1 [32mPASSED[0m
2026-01-14T09:34:31.0005132Z test/test_low_bit_optim.py::TestOptim::test_optim_cpu_offload_save_load [32mPASSED[0m
2026-01-14T09:34:31.0005940Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0006857Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0007765Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0008680Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0009584Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0010532Z test/test_low_bit_optim.py::TestOptim::test_optim_default_dtype_bf16_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0011542Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0012411Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0013280Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0014139Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0015138Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0016017Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0016881Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0017793Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_Adam8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0018675Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0019544Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0020415Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0021283Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0022155Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0023041Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0023921Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0024789Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW4bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0025666Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0026543Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_bfloat16_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0027422Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0028353Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamW8bit_float32_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0029221Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0030111Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_bfloat16_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0031027Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0031899Z test/test_low_bit_optim.py::TestOptim::test_optim_smoke_optim_name_AdamWFp8_float32_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0032747Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0033563Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam4bit_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0034400Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0035219Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_Adam8bit_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0036031Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0036844Z test/test_low_bit_optim.py::TestOptim::test_param_groups_optim_name_AdamFp8_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0037650Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0038456Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0039264Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0040074Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass0_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0041095Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0042096Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape0_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0043033Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0043880Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass1_shape1_device_cuda [32mPASSED[0m
2026-01-14T09:34:31.0044692Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0045505Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape0_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0046306Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cpu [32mPASSED[0m
2026-01-14T09:34:31.0047124Z test/test_low_bit_optim.py::TestOptim::test_subclass_slice_subclass2_shape1_device_cuda [33mSKIPPED[0m
2026-01-14T09:34:31.0048126Z test/test_low_bit_optim.py::TestFSDP2::test_fsdp2 I0114 09:32:53.848000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 54251
2026-01-14T09:34:31.0049392Z I0114 09:32:53.849000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 54252
2026-01-14T09:34:31.0049987Z dist init r=1, world=2
2026-01-14T09:34:31.0050214Z dist init r=0, world=2
2026-01-14T09:34:31.0051444Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T09:34:31.0052606Z   warnings.warn(  # warn only once
2026-01-14T09:34:31.0053582Z /opt/conda/envs/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4876: UserWarning: barrier(): using the device under current context. You can specify `device_id` in `init_process_group` to mute this warning.
2026-01-14T09:34:31.0054585Z   warnings.warn(  # warn only once
2026-01-14T09:34:31.0054963Z [32mPASSED[0m
2026-01-14T09:34:42.7555590Z test/test_low_bit_optim.py::TestFSDP2::test_uneven_shard I0114 09:34:30.997000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 0 with pid 56470
2026-01-14T09:34:42.7557076Z I0114 09:34:30.999000 1007 site-packages/torch/testing/_internal/common_distributed.py:741] Started process 1 with pid 56471
2026-01-14T09:34:42.7557969Z dist init r=1, world=2
2026-01-14T09:34:42.7558212Z dist init r=0, world=2
2026-01-14T09:34:42.7558650Z [32mPASSED[0m
2026-01-14T09:34:42.7559188Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_0_cpu [32mPASSED[0m
2026-01-14T09:34:42.7559991Z test/test_model_architecture.py::TestModels::test_ln_linear_activation_model_1_cuda [32mPASSED[0m
2026-01-14T09:34:42.7560750Z test/test_model_architecture.py::TestModels::test_toy_linear_model_0_cpu [32mPASSED[0m
2026-01-14T09:34:42.7561466Z test/test_model_architecture.py::TestModels::test_toy_linear_model_1_cuda [32mPASSED[0m
2026-01-14T09:34:42.7562180Z test/test_model_architecture.py::TestModels::test_transformer_block_0_cpu [32mPASSED[0m
2026-01-14T09:34:42.7562914Z test/test_model_architecture.py::TestModels::test_transformer_block_1_cuda [32mPASSED[0m
2026-01-14T09:34:42.7563965Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7565274Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7566582Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7568005Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7569304Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7570689Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7572102Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7573430Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7574717Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7576007Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7577284Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7578762Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7580175Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7581476Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7583044Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7584441Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7585882Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7587354Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7588677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7590095Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7591468Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7592843Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7594227Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7595606Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7597072Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7598461Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7599836Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7601287Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7602658Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7604028Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7605467Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7606775Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7608189Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7609613Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7610986Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7612366Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7613837Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7615191Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7616629Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7617937Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7619331Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7620772Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7780972Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7782684Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7784552Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7786100Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7787831Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7789317Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7790833Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7792501Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7794035Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7795568Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7797152Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7798695Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7800233Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7801925Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7803556Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7805162Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7806800Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7808314Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7809875Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7811565Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7813110Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7814757Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7816276Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7817927Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7819527Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7821240Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7822695Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7824285Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7825583Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7827111Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7828660Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7830223Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7831800Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7833296Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7834955Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7836542Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7839949Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7841445Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7843074Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7844579Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7846089Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7847764Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7849547Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7851029Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7852535Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.7853992Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.7855653Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.7857094Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8015268Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8017017Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8018324Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8019746Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8021131Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8022557Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_float8_e4m3fn_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8024249Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8025861Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8027490Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8029072Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8030472Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8032055Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8033529Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8034935Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8036549Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8038012Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8039677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8041239Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8042639Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8044214Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8045705Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8047257Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8048726Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8050527Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8052212Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8053691Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8055099Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8056728Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8058324Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8059840Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8061452Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8062908Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8064428Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8065907Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8067375Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8068892Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8070363Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8071863Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8073498Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8074967Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8076496Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8087542Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8088923Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8090296Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8091761Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8093208Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8094573Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8095963Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8097196Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8098542Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8249326Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8250643Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8252032Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8253252Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_120_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8254472Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8255677Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8256898Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8258124Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8259324Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8260542Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8261840Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8263045Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8264335Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8265564Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8266774Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8268001Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8269226Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8270435Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8271659Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8273004Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8274274Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8275550Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8276965Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8278216Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8279496Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8280706Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8281919Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8283148Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_16_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8284361Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8285578Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8286783Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8288000Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8289259Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8290467Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8291846Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8293054Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8294268Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8295768Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8297004Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8298354Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_18_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8299585Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8300780Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8301998Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8303292Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8304497Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8305759Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_100_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8306978Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8308174Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_float32 [33mSKIPPED[0m
2026-01-14T09:34:42.8309401Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_32_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:42.8310619Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_bfloat16 [33mSKIPPED[0m
2026-01-14T09:34:42.8311824Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_float32 [33mSKIPPED[0m
2026-01-14T09:34:45.9641182Z test/test_ops.py::TestOps::test_quantized_scaled_dot_product_op_uint8_batch_size_56_n_head_2_q_seq_len_89_kv_seq_len_253_head_dim_64_mask_dtype0 [33mSKIPPED[0m
2026-01-14T09:34:45.9643621Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9644678Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9645683Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9646562Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9647428Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9648348Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9649411Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9650277Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9651147Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9652096Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9652963Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9653814Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9654659Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9655508Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9656356Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_correctness[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9657168Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9657944Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9658717Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9659571Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9660356Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9661136Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x11008-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9661987Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9662759Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9663532Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_11008x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9664304Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9665092Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9665865Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_4096x14336-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9666644Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_2] [32mPASSED[0m
2026-01-14T09:34:45.9667417Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_4] [32mPASSED[0m
2026-01-14T09:34:45.9668197Z test/test_ops.py::test_unpack_tensor_core_tiled_layout_op[shape_14336x4096-tiles_8] [32mPASSED[0m
2026-01-14T09:34:45.9669072Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:45.9670009Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:45.9671041Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:45.9672001Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:45.9672967Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:45.9673977Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:45.9674928Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:45.9675883Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:45.9676824Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:45.9677766Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:45.9678748Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:45.9679689Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:45.9680654Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:34:45.9681616Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:34:45.9682567Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:34:45.9683542Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:34:45.9684546Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:34:45.9685556Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:34:45.9686527Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:34:45.9687526Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:34:45.9688496Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:34:45.9689450Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:34:45.9690424Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:34:45.9691443Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:34:45.9692406Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:45.9693366Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:45.9694316Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:45.9695267Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:45.9696211Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:45.9697146Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:45.9698142Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:45.9699096Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:45.9700074Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:45.9701029Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:45.9701973Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:45.9702926Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:45.9703871Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:34:45.9704817Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:34:45.9705781Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:34:45.9706736Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4343987Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4345235Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4346217Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4347180Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4348273Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:34:50.4349428Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:34:50.4350384Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:34:50.4351423Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:34:50.4352376Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:50.4353317Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:50.4354279Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:50.4355280Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4356232Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4357179Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4358122Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4359076Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4360013Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:50.4361037Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:50.4362003Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:50.4362947Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_quant_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:50.4363987Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:50.4364954Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:50.4365941Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:50.4366924Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4367906Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4368883Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4369872Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4370850Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4371910Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:50.4372877Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:50.4373856Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:50.4374909Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:50.4375883Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:34:50.4376870Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:34:50.4377905Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:34:50.4378908Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4379893Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4380880Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4381864Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4382860Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4383857Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:34:50.4384836Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:34:50.4385882Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:34:50.4386919Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:34:50.4387916Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:50.4388902Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:50.4389923Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:50.4390933Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4391930Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4392910Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4393911Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4394906Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4395898Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:50.4396888Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:50.4397875Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:50.4398868Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:50.4399852Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:34:50.4400893Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:34:50.4401881Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:34:50.4402864Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:34:50.4403898Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:34:50.4404898Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:34:50.4405889Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:34:50.4406893Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:34:50.4407884Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.6993714Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.6995042Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.6996159Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.6997416Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.6998593Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7000759Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7001957Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7003399Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7004408Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7005717Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7006783Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7008069Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7009101Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7010366Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7011480Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_correctness_unpack_and_dequant[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7012355Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.7013095Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7013851Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7014796Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7015687Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7016589Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7017598Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7018359Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7019524Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7020354Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7021175Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7022142Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7022902Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.7023836Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7024729Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7025518Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7026561Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7027321Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7028217Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7029165Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7030022Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7031079Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7031859Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7032988Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 11008)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7033846Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.7034696Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7035670Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7036448Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7037409Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7038279Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7039073Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7040071Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7040840Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7041745Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7042663Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7043452Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(11008, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7044460Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.7045307Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7046254Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7047156Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7048030Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7049327Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7050122Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7051129Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7052064Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7052915Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7053871Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7054642Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(4096, 14336)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7055596Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-32] [32mPASSED[0m
2026-01-14T09:34:55.7056499Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-64] [32mPASSED[0m
2026-01-14T09:34:55.7057321Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-128] [32mPASSED[0m
2026-01-14T09:34:55.7058293Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-2-256] [32mPASSED[0m
2026-01-14T09:34:55.7059188Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-32] [32mPASSED[0m
2026-01-14T09:34:55.7060237Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-64] [32mPASSED[0m
2026-01-14T09:34:55.7061050Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-128] [32mPASSED[0m
2026-01-14T09:34:55.7062029Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-4-256] [32mPASSED[0m
2026-01-14T09:34:55.7062970Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-32] [32mPASSED[0m
2026-01-14T09:34:55.7063717Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-64] [32mPASSED[0m
2026-01-14T09:34:55.7064472Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-128] [32mPASSED[0m
2026-01-14T09:34:55.7065238Z test/test_ops.py::test_dequantize_tensor_core_tiled_layout_op[(14336, 4096)-8-256] [32mPASSED[0m
2026-01-14T09:34:55.7066114Z test/test_ops.py::test_swizzle_mm [33mSKIPPED[0m (ROCm not available)
2026-01-14T09:34:55.7066909Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7067607Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7068577Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7402008Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7403050Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7403852Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7404568Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7405262Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7406051Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7406888Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7407608Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7408409Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7409231Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7409937Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7410746Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7411579Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7412306Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7413131Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7413852Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7414577Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7415384Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7416128Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7416901Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7417681Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7418384Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7419272Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7419997Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7420710Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7421586Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7422297Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7423001Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7423781Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7424493Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7425217Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7426015Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7426776Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7427480Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7428192Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7428915Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7429641Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7430377Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7431108Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7431836Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7432622Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7433360Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7434102Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7434976Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7435723Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7436436Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7437212Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7437924Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7438632Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7439428Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7440149Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7440864Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7441640Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7442342Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7443054Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7443840Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7444627Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7445348Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7446141Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7446975Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7447702Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7448521Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7449496Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7450223Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7451054Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7451862Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7452625Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7453418Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7454163Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7454945Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7455675Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7456388Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7457200Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7458032Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7458766Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7459562Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7460282Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7461075Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7461884Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7462593Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7463308Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7464130Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7464845Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7465584Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7466406Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7478257Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7479214Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7480211Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7480983Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7813097Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7814340Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7815111Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7815926Z test/test_ops.py::test_scaled_embedding_bag_int8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7816649Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7817335Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7818038Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7818744Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7819446Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7820149Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7820837Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7821523Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7822216Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7822932Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7823636Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7824331Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7825034Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7825734Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7826532Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7827267Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7827983Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7828708Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7829479Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7830197Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7830923Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7831652Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7832384Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7833105Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[1-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7833812Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7834490Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7835187Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7835896Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7836591Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7837291Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7837976Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7838715Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7839417Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7840117Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7840880Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7841576Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7842284Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7842981Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7843698Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7844425Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7845144Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7845861Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7846569Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7847286Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7848009Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7848729Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7849690Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7850410Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[2-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7851120Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7851984Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7852674Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7853379Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7854131Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7854828Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7855510Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7856192Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7856886Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7857585Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7858287Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7858978Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7859682Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7860383Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7861083Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7861806Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7862514Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7863310Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7864028Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7864729Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7865504Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7866220Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7866942Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7867656Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[3-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7868361Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7869055Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7869754Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7870456Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7871155Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7871861Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7872560Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7873246Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7873945Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7874640Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7875343Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7876096Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-2-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.7876792Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.7877497Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8140280Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.8141377Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8142115Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.8142836Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-128-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8143555Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.8144277Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-1-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8144997Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.8145732Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-128-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8146456Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int64] [33mSKIPPED[0m
2026-01-14T09:34:55.8147186Z test/test_ops.py::test_scaled_embedding_bag_fp8_cpu[10-1024-512-torch.int32] [33mSKIPPED[0m
2026-01-14T09:34:55.8148022Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8148956Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8150175Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8151124Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8152055Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8153042Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8153967Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8154904Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8155826Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8156745Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8157680Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8158611Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8159549Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8160476Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8161417Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8162374Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8163312Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8164343Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8165279Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8166231Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8167530Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8168475Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8169425Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8170376Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8171576Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8172605Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8173767Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8174813Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8175955Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8176895Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8178033Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8179068Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8180187Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8181213Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8182360Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8183325Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8184434Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8185417Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8186542Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8187544Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8188619Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8189644Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8190694Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8191758Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8192781Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8193849Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8194925Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8196037Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8197107Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8198182Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8199193Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8200283Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8201246Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8202366Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8203300Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8204471Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8205412Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8206552Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8207497Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8208721Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8209680Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8210820Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8457504Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8458741Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8459699Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8460629Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8461580Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8462529Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8463475Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8464418Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8465366Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8466325Z test/test_ops.py::test_float8_linear_cpu[w_granularity0-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8467266Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8468196Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8469250Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8470199Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8471136Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8472128Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8473057Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8473997Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8474934Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8475865Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8476792Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8477732Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8478669Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8479603Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8480552Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8481580Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8482531Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8483464Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8484556Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8485516Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8486504Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8487443Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8488382Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8489339Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8490274Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8491202Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8492231Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8493161Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8494088Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8495009Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8495986Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8496927Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8497855Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8498809Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8499727Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8500657Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8501586Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8502532Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8503467Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8504416Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8505345Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8506272Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8507212Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8508151Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8509142Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8510063Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8511072Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8512021Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8512949Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8513865Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8514796Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8515740Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8516675Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8517592Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8518528Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8519460Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8520385Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8521303Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8522227Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8523214Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8775636Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8777855Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8778808Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8779766Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8780698Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8781647Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8782587Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8783546Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8784499Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8785422Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8786364Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8787315Z test/test_ops.py::test_float8_linear_cpu[w_granularity1-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8788336Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8789267Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8790196Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8791198Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8792137Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8793050Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8793987Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8794925Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8795857Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8796780Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8797707Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8798646Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8799576Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8800505Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8801455Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8802468Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8803414Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8804342Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8805330Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8806291Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8807233Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8808172Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8809110Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8810070Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity0-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8811010Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8812022Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8812955Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8813892Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8814879Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8815808Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8816736Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8817720Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8818651Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8819565Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8820505Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8821441Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8822388Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8823326Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8824273Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8825235Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8826172Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8827096Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8828041Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8829039Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8829982Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8830910Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8831894Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8832848Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity1-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8833777Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8834697Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8835629Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8836622Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8837552Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8838470Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8839398Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8840336Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.8841271Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.8842246Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9062504Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9063877Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-True-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9064835Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9065769Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9066722Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9067696Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype0-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9068645Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9069588Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9070537Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9071498Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype1-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9072451Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9073384Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-1-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9074333Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape0] [33mSKIPPED[0m
2026-01-14T09:34:55.9075293Z test/test_ops.py::test_float8_linear_cpu[w_granularity2-x_granularity2-False-out_dtype2-160-shape1] [33mSKIPPED[0m
2026-01-14T09:34:55.9076383Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9077451Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9078553Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9079592Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9080626Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9081673Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9082713Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9083742Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9084773Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9085819Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9086863Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9087925Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9089080Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9090152Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9091250Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9092411Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9093478Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9094538Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9095593Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9096661Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9097709Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9098768Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9099821Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9100869Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9101926Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9103032Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9104090Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9105145Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9106236Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9107290Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9108349Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9109399Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9110454Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9111515Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9112578Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9113639Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9114828Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9115974Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9117036Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9118085Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9119187Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9120235Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9121284Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9122344Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9123400Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9124463Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9125508Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9126566Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9127621Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9339901Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9341389Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9342455Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9352000Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9353182Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9354227Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9355287Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9356343Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9357405Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9358468Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9359515Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9360562Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9361613Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9362741Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9363800Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9364852Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9365979Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9367041Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9368093Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9369148Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9370208Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9371270Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9372412Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9373458Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9374505Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9375552Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9376597Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9377719Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9378764Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9379862Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9380908Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9381954Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9383011Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9384062Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9385108Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9386155Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9387198Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9388247Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9389292Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9390384Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9391432Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9392509Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9393556Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9394606Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9395641Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9396688Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9397737Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9398778Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9399830Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9400865Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9401914Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9402985Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9404094Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9405166Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9406233Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9407329Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9408388Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9409444Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9410512Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9411675Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9412745Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9615484Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9616969Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9618045Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9619238Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9620327Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9621468Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9622550Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9623621Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9624707Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9625787Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9626912Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9627983Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9629066Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9630133Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9631212Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9632285Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9633436Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9634520Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9635648Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9636726Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9637802Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9638876Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9639965Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9641032Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9642111Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9643191Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9644266Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9645345Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9646467Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9647547Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9648695Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9649950Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9651024Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9652174Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s4s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9653218Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9654258Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9655286Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9656322Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9657348Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9658364Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9659400Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9660506Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9661538Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9662569Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9663662Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9664707Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9665757Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9666811Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9667859Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9668915Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9669957Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9671009Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9672049Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9673165Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9674220Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9675260Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9676371Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9677411Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9678460Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype24-8-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9679506Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype25-8-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9680548Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype26-8-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9892814Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype27-8-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9894369Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype28-8-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9895682Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype29-8-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9896790Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype30-8-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9897839Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype31-8-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9898988Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype32-8-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9900043Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype33-8-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9901081Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype34-8-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9902196Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype35-8-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9903248Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype36-16-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9904302Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype37-16-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9905361Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype38-16-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9906419Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype39-16-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9907472Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype40-16-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9908533Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype41-16-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9909584Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype42-16-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9910638Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype43-16-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9911763Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype44-16-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9912819Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype45-16-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9913875Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype46-16-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9914996Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype47-16-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9916049Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype48-32-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9917165Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype49-32-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9918218Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype50-32-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9919275Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype51-32-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9920330Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype52-32-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9921384Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype53-32-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9922442Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype54-32-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9923497Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype55-32-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9924557Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype56-32-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9925623Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype57-32-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9926726Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype58-32-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9927776Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype59-32-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9928880Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype60-64-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9929930Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype61-64-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9930993Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype62-64-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9932135Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype63-64-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9933190Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype64-64-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9934246Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype65-64-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9935306Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype66-64-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9936360Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype67-64-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9937424Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype68-64-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9938479Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype69-64-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9939587Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype70-64-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9940638Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype71-64-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9941729Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9942783Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9943828Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9944875Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9945926Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9946977Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9948028Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9949259Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9950317Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9951363Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9952409Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9953534Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9954577Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9955622Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:34:55.9956776Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:34:55.9957811Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0167895Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0169285Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0170337Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0171448Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0172504Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0173549Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0174601Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0175789Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0176859Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype96-8-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0177978Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype97-8-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0179033Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype98-8-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0180081Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype99-8-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0181144Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype100-8-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0182216Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype101-8-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0183289Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype102-8-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0184356Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype103-8-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0185429Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype104-8-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0186486Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype105-8-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0187559Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype106-8-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0188624Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype107-8-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0189763Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype108-16-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0190842Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype109-16-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0191909Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype110-16-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0193041Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype111-16-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0194102Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype112-16-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0195182Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype113-16-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0196266Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype114-16-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0197327Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype115-16-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0198401Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype116-16-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0199470Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype117-16-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0200533Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype118-16-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0201605Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype119-16-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0202726Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype120-32-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0203800Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype121-32-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0204908Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype122-32-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0205972Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype123-32-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0207099Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype124-32-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0208166Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype125-32-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0209232Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype126-32-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0210311Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype127-32-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0211445Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype128-32-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0212523Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype129-32-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0213594Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype130-32-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0214667Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype131-32-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0215741Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype132-64-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0216869Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype133-64-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0217941Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype134-64-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0219011Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype135-64-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0220123Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype136-64-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0221193Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype137-64-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0222262Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype138-64-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0223329Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype139-64-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0224404Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype140-64-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0225470Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype141-64-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0226546Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype142-64-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0227613Z test/test_ops_rowwise_scaled_linear_cutlass.py::test_rowwise_scaled_linear_cutlass_s8s4[dtype143-64-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0228792Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype0-Xq_Wq_dtypes0-1-size_mnk0-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0230193Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype1-Xq_Wq_dtypes1-1-size_mnk1-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0231457Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype2-Xq_Wq_dtypes2-1-size_mnk2-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0232754Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype3-Xq_Wq_dtypes3-1-size_mnk3-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0396645Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype4-Xq_Wq_dtypes4-1-size_mnk4-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0398120Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype5-Xq_Wq_dtypes5-1-size_mnk5-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0399388Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype6-Xq_Wq_dtypes6-1-size_mnk6-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0400656Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype7-Xq_Wq_dtypes7-1-size_mnk7-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0401919Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype8-Xq_Wq_dtypes8-1-size_mnk8-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0403177Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype9-Xq_Wq_dtypes9-1-size_mnk9-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0404454Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype10-Xq_Wq_dtypes10-1-size_mnk10-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0405746Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype11-Xq_Wq_dtypes11-1-size_mnk11-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0407139Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype12-Xq_Wq_dtypes12-4-size_mnk12-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0408428Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype13-Xq_Wq_dtypes13-4-size_mnk13-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0409778Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype14-Xq_Wq_dtypes14-4-size_mnk14-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0411054Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype15-Xq_Wq_dtypes15-4-size_mnk15-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0412435Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype16-Xq_Wq_dtypes16-4-size_mnk16-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0413712Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype17-Xq_Wq_dtypes17-4-size_mnk17-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0414994Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype18-Xq_Wq_dtypes18-4-size_mnk18-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0416279Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype19-Xq_Wq_dtypes19-4-size_mnk19-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0417558Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype20-Xq_Wq_dtypes20-4-size_mnk20-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0418840Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype21-Xq_Wq_dtypes21-4-size_mnk21-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0420199Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype22-Xq_Wq_dtypes22-4-size_mnk22-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0421487Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype23-Xq_Wq_dtypes23-4-size_mnk23-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0422771Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype24-Xq_Wq_dtypes24-1-size_mnk24-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0424113Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype25-Xq_Wq_dtypes25-1-size_mnk25-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0425388Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype26-Xq_Wq_dtypes26-1-size_mnk26-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0426677Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype27-Xq_Wq_dtypes27-1-size_mnk27-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0427964Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype28-Xq_Wq_dtypes28-1-size_mnk28-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0429241Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype29-Xq_Wq_dtypes29-1-size_mnk29-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0430523Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype30-Xq_Wq_dtypes30-1-size_mnk30-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0431796Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype31-Xq_Wq_dtypes31-1-size_mnk31-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0433079Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype32-Xq_Wq_dtypes32-1-size_mnk32-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0434359Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype33-Xq_Wq_dtypes33-1-size_mnk33-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0435682Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype34-Xq_Wq_dtypes34-1-size_mnk34-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0436966Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype35-Xq_Wq_dtypes35-1-size_mnk35-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0438312Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype36-Xq_Wq_dtypes36-4-size_mnk36-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0439583Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype37-Xq_Wq_dtypes37-4-size_mnk37-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0440864Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype38-Xq_Wq_dtypes38-4-size_mnk38-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0442148Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype39-Xq_Wq_dtypes39-4-size_mnk39-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0443421Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype40-Xq_Wq_dtypes40-4-size_mnk40-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0444704Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype41-Xq_Wq_dtypes41-4-size_mnk41-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0445975Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype42-Xq_Wq_dtypes42-4-size_mnk42-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0447250Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype43-Xq_Wq_dtypes43-4-size_mnk43-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0448579Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype44-Xq_Wq_dtypes44-4-size_mnk44-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0450103Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype45-Xq_Wq_dtypes45-4-size_mnk45-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0451511Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype46-Xq_Wq_dtypes46-4-size_mnk46-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0452795Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype47-Xq_Wq_dtypes47-4-size_mnk47-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0454073Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype48-Xq_Wq_dtypes48-1-size_mnk48-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0455356Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype49-Xq_Wq_dtypes49-1-size_mnk49-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0456639Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype50-Xq_Wq_dtypes50-1-size_mnk50-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0457915Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype51-Xq_Wq_dtypes51-1-size_mnk51-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0459203Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype52-Xq_Wq_dtypes52-1-size_mnk52-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0460485Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype53-Xq_Wq_dtypes53-1-size_mnk53-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0626826Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype54-Xq_Wq_dtypes54-1-size_mnk54-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0628254Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype55-Xq_Wq_dtypes55-1-size_mnk55-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0629546Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype56-Xq_Wq_dtypes56-1-size_mnk56-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0630884Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype57-Xq_Wq_dtypes57-1-size_mnk57-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0632170Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype58-Xq_Wq_dtypes58-1-size_mnk58-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0633459Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype59-Xq_Wq_dtypes59-1-size_mnk59-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0634740Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype60-Xq_Wq_dtypes60-4-size_mnk60-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0636032Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype61-Xq_Wq_dtypes61-4-size_mnk61-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0637312Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype62-Xq_Wq_dtypes62-4-size_mnk62-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0638598Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype63-Xq_Wq_dtypes63-4-size_mnk63-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0639886Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype64-Xq_Wq_dtypes64-4-size_mnk64-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0641238Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype65-Xq_Wq_dtypes65-4-size_mnk65-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0642528Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype66-Xq_Wq_dtypes66-4-size_mnk66-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0643810Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype67-Xq_Wq_dtypes67-4-size_mnk67-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0645152Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype68-Xq_Wq_dtypes68-4-size_mnk68-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0646479Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype69-Xq_Wq_dtypes69-4-size_mnk69-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0647756Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype70-Xq_Wq_dtypes70-4-size_mnk70-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0649204Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype71-Xq_Wq_dtypes71-4-size_mnk71-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0650497Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype72-Xq_Wq_dtypes72-1-size_mnk72-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0651830Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype73-Xq_Wq_dtypes73-1-size_mnk73-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0653115Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype74-Xq_Wq_dtypes74-1-size_mnk74-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0654399Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype75-Xq_Wq_dtypes75-1-size_mnk75-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0655680Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype76-Xq_Wq_dtypes76-1-size_mnk76-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0657037Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype77-Xq_Wq_dtypes77-1-size_mnk77-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0658321Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype78-Xq_Wq_dtypes78-1-size_mnk78-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0659658Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype79-Xq_Wq_dtypes79-1-size_mnk79-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0660945Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype80-Xq_Wq_dtypes80-1-size_mnk80-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0662228Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype81-Xq_Wq_dtypes81-1-size_mnk81-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0663510Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype82-Xq_Wq_dtypes82-1-size_mnk82-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0664788Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype83-Xq_Wq_dtypes83-1-size_mnk83-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0666080Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype84-Xq_Wq_dtypes84-4-size_mnk84-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0667355Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype85-Xq_Wq_dtypes85-4-size_mnk85-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0668636Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype86-Xq_Wq_dtypes86-4-size_mnk86-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0669982Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype87-Xq_Wq_dtypes87-4-size_mnk87-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0671263Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype88-Xq_Wq_dtypes88-4-size_mnk88-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0672605Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype89-Xq_Wq_dtypes89-4-size_mnk89-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0673881Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype90-Xq_Wq_dtypes90-4-size_mnk90-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0675161Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype91-Xq_Wq_dtypes91-4-size_mnk91-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0676482Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype92-Xq_Wq_dtypes92-4-size_mnk92-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0677761Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype93-Xq_Wq_dtypes93-4-size_mnk93-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0679051Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype94-Xq_Wq_dtypes94-4-size_mnk94-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0680340Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype95-Xq_Wq_dtypes95-4-size_mnk95-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0681620Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype96-Xq_Wq_dtypes96-1-size_mnk96-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0682906Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype97-Xq_Wq_dtypes97-1-size_mnk97-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0684234Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype98-Xq_Wq_dtypes98-1-size_mnk98-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0685526Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype99-Xq_Wq_dtypes99-1-size_mnk99-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0686833Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype100-Xq_Wq_dtypes100-1-size_mnk100-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0688191Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype101-Xq_Wq_dtypes101-1-size_mnk101-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0689511Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype102-Xq_Wq_dtypes102-1-size_mnk102-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0690826Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype103-Xq_Wq_dtypes103-1-size_mnk103-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0852880Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype104-Xq_Wq_dtypes104-1-size_mnk104-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0854403Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype105-Xq_Wq_dtypes105-1-size_mnk105-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0855730Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype106-Xq_Wq_dtypes106-1-size_mnk106-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0857042Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype107-Xq_Wq_dtypes107-1-size_mnk107-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0858474Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype108-Xq_Wq_dtypes108-4-size_mnk108-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0859803Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype109-Xq_Wq_dtypes109-4-size_mnk109-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0861188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype110-Xq_Wq_dtypes110-4-size_mnk110-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0862514Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype111-Xq_Wq_dtypes111-4-size_mnk111-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0863842Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype112-Xq_Wq_dtypes112-4-size_mnk112-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0865158Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype113-Xq_Wq_dtypes113-4-size_mnk113-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0866488Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype114-Xq_Wq_dtypes114-4-size_mnk114-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0867816Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype115-Xq_Wq_dtypes115-4-size_mnk115-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0869140Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype116-Xq_Wq_dtypes116-4-size_mnk116-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0870459Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype117-Xq_Wq_dtypes117-4-size_mnk117-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0871780Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype118-Xq_Wq_dtypes118-4-size_mnk118-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0873188Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype119-Xq_Wq_dtypes119-4-size_mnk119-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0874510Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype120-Xq_Wq_dtypes120-1-size_mnk120-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0875825Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype121-Xq_Wq_dtypes121-1-size_mnk121-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0877201Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype122-Xq_Wq_dtypes122-1-size_mnk122-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0878530Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype123-Xq_Wq_dtypes123-1-size_mnk123-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0879845Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype124-Xq_Wq_dtypes124-1-size_mnk124-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0881167Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype125-Xq_Wq_dtypes125-1-size_mnk125-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0882490Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype126-Xq_Wq_dtypes126-1-size_mnk126-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0883805Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype127-Xq_Wq_dtypes127-1-size_mnk127-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0885124Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype128-Xq_Wq_dtypes128-1-size_mnk128-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0886487Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype129-Xq_Wq_dtypes129-1-size_mnk129-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0887816Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype130-Xq_Wq_dtypes130-1-size_mnk130-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0889132Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype131-Xq_Wq_dtypes131-1-size_mnk131-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0890504Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype132-Xq_Wq_dtypes132-4-size_mnk132-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0891886Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype133-Xq_Wq_dtypes133-4-size_mnk133-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0893207Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype134-Xq_Wq_dtypes134-4-size_mnk134-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0894523Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype135-Xq_Wq_dtypes135-4-size_mnk135-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0895841Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype136-Xq_Wq_dtypes136-4-size_mnk136-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0897170Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype137-Xq_Wq_dtypes137-4-size_mnk137-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0898488Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype138-Xq_Wq_dtypes138-4-size_mnk138-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0899814Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype139-Xq_Wq_dtypes139-4-size_mnk139-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0901132Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype140-Xq_Wq_dtypes140-4-size_mnk140-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0902497Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype141-Xq_Wq_dtypes141-4-size_mnk141-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0903817Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype142-Xq_Wq_dtypes142-4-size_mnk142-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0905181Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype143-Xq_Wq_dtypes143-4-size_mnk143-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0906494Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype144-Xq_Wq_dtypes144-1-size_mnk144-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0914821Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype145-Xq_Wq_dtypes145-1-size_mnk145-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0916246Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype146-Xq_Wq_dtypes146-1-size_mnk146-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0917567Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype147-Xq_Wq_dtypes147-1-size_mnk147-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0918885Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype148-Xq_Wq_dtypes148-1-size_mnk148-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0920195Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype149-Xq_Wq_dtypes149-1-size_mnk149-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0921507Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype150-Xq_Wq_dtypes150-1-size_mnk150-False] [33mSKIPPED[0m
2026-01-14T09:34:56.0922899Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype151-Xq_Wq_dtypes151-1-size_mnk151-True] [33mSKIPPED[0m
2026-01-14T09:34:56.0924221Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype152-Xq_Wq_dtypes152-1-size_mnk152-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1284924Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype153-Xq_Wq_dtypes153-1-size_mnk153-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1286548Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype154-Xq_Wq_dtypes154-1-size_mnk154-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1288075Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype155-Xq_Wq_dtypes155-1-size_mnk155-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1289663Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype156-Xq_Wq_dtypes156-4-size_mnk156-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1291421Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype157-Xq_Wq_dtypes157-4-size_mnk157-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1293065Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype158-Xq_Wq_dtypes158-4-size_mnk158-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1294583Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype159-Xq_Wq_dtypes159-4-size_mnk159-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1296281Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype160-Xq_Wq_dtypes160-4-size_mnk160-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1297953Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype161-Xq_Wq_dtypes161-4-size_mnk161-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1300015Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype162-Xq_Wq_dtypes162-4-size_mnk162-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1301723Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype163-Xq_Wq_dtypes163-4-size_mnk163-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1304012Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype164-Xq_Wq_dtypes164-4-size_mnk164-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1305947Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype165-Xq_Wq_dtypes165-4-size_mnk165-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1307712Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype166-Xq_Wq_dtypes166-4-size_mnk166-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1309500Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype167-Xq_Wq_dtypes167-4-size_mnk167-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1311103Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype168-Xq_Wq_dtypes168-1-size_mnk168-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1312471Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype169-Xq_Wq_dtypes169-1-size_mnk169-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1313816Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype170-Xq_Wq_dtypes170-1-size_mnk170-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1315152Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype171-Xq_Wq_dtypes171-1-size_mnk171-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1316629Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype172-Xq_Wq_dtypes172-1-size_mnk172-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1317993Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype173-Xq_Wq_dtypes173-1-size_mnk173-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1319409Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype174-Xq_Wq_dtypes174-1-size_mnk174-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1320758Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype175-Xq_Wq_dtypes175-1-size_mnk175-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1322099Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype176-Xq_Wq_dtypes176-1-size_mnk176-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1323447Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype177-Xq_Wq_dtypes177-1-size_mnk177-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1324794Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype178-Xq_Wq_dtypes178-1-size_mnk178-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1326140Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype179-Xq_Wq_dtypes179-1-size_mnk179-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1327486Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype180-Xq_Wq_dtypes180-4-size_mnk180-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1328826Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype181-Xq_Wq_dtypes181-4-size_mnk181-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1330165Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype182-Xq_Wq_dtypes182-4-size_mnk182-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1331692Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype183-Xq_Wq_dtypes183-4-size_mnk183-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1333017Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype184-Xq_Wq_dtypes184-4-size_mnk184-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1334367Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype185-Xq_Wq_dtypes185-4-size_mnk185-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1335679Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype186-Xq_Wq_dtypes186-4-size_mnk186-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1337048Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype187-Xq_Wq_dtypes187-4-size_mnk187-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1338362Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype188-Xq_Wq_dtypes188-4-size_mnk188-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1339676Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype189-Xq_Wq_dtypes189-4-size_mnk189-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1340989Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype190-Xq_Wq_dtypes190-4-size_mnk190-False] [33mSKIPPED[0m
2026-01-14T09:34:56.1342302Z test/test_ops_rowwise_scaled_linear_sparse_cutlass.py::test_rowwise_scaled_linear_sparse_cutlass_f8f8[dtype191-Xq_Wq_dtypes191-4-size_mnk191-True] [33mSKIPPED[0m
2026-01-14T09:34:56.1343264Z test/test_utils.py::TestTorchVersion::test_torch_version_at_least [32mPASSED[0m
2026-01-14T09:34:56.1343911Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls [32mPASSED[0m
2026-01-14T09:34:56.1344684Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_attr [32mPASSED[0m
2026-01-14T09:34:56.1345484Z test/test_utils.py::TestTorchAOBaseTensor::test_default_impls_with_optional_data [32mPASSED[0m
2026-01-14T09:34:56.1346330Z test/test_utils.py::TestTorchAOBaseTensor::test_implements_and_torch_function_together [32mPASSED[0m
2026-01-14T09:34:56.1347137Z test/test_utils.py::TestTorchAOBaseTensor::test_print_arg_types [32mPASSED[0m
2026-01-14T09:34:56.1347484Z 
2026-01-14T09:34:56.1347734Z [33m=============================== warnings summary ===============================[0m
2026-01-14T09:34:56.1348296Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1
2026-01-14T09:34:56.1350450Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:1: DeprecationWarning: Importing from torchao.dtypes.uintx.dyn_int8_act_int4_wei_cpu_layout is deprecated. Please use 'from torchao.prototype.dtypes import Int8DynamicActInt4WeightCPULayout' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1352322Z     from .dyn_int8_act_int4_wei_cpu_layout import (
2026-01-14T09:34:56.1352562Z 
2026-01-14T09:34:56.1352828Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22
2026-01-14T09:34:56.1354630Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/__init__.py:22: DeprecationWarning: Importing from torchao.dtypes.uintx.uintx_layout is deprecated. Please use 'from torchao.prototype.dtypes import UintxLayout, UintxTensor' instead. This import path will be removed in a future release of torchao. See https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1356245Z     from .uintx_layout import (
2026-01-14T09:34:56.1356425Z 
2026-01-14T09:34:56.1356721Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23
2026-01-14T09:34:56.1358580Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:23: DeprecationWarning: Importing BlockSparseLayout from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import BlockSparseLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:34:56.1360325Z     from .uintx.block_sparse_layout import BlockSparseLayout
2026-01-14T09:34:56.1360593Z 
2026-01-14T09:34:56.1360837Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24
2026-01-14T09:34:56.1362572Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/__init__.py:24: DeprecationWarning: Importing from torchao.dtypes is deprecated. Please use 'from torchao.prototype.dtypes import CutlassInt4PackedLayout' instead. This import path will be removed in a future torchao release. Please check issue: https://github.com/pytorch/ao/issues/2752 for more details. 
2026-01-14T09:34:56.1364258Z     from .uintx.cutlass_int4_packed_layout import CutlassInt4PackedLayout
2026-01-14T09:34:56.1364582Z 
2026-01-14T09:34:56.1364955Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: 2 warnings
2026-01-14T09:34:56.1365543Z test/core/test_config.py: 2 warnings
2026-01-14T09:34:56.1365834Z test/dtypes/test_uintx.py: 84 warnings
2026-01-14T09:34:56.1366139Z test/hqq/test_hqq_affine.py: 6 warnings
2026-01-14T09:34:56.1367304Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:539: UserWarning: `UIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1368420Z     warnings.warn(
2026-01-14T09:34:56.1368551Z 
2026-01-14T09:34:56.1368884Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:34:56.1369709Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209
2026-01-14T09:34:56.1370372Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config7]
2026-01-14T09:34:56.1370974Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_print_quantized_module
2026-01-14T09:34:56.1371733Z test/dtypes/test_affine_quantized.py::TestAffineQuantized::test_weights_only
2026-01-14T09:34:56.1372431Z test/dtypes/test_affine_quantized.py::TestAffineQuantizedBasic::test_flatten_unflatten_device_cuda_bfloat16
2026-01-14T09:34:56.1373891Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:209: UserWarning: `Int4DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1375080Z     warnings.warn(
2026-01-14T09:34:56.1375214Z 
2026-01-14T09:34:56.1375593Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: 3 warnings
2026-01-14T09:34:56.1376173Z test/core/test_config.py: 2 warnings
2026-01-14T09:34:56.1376494Z test/dtypes/test_affine_quantized.py: 4 warnings
2026-01-14T09:34:56.1376894Z test/integration/test_integration.py: 6 warnings
2026-01-14T09:34:56.1377236Z test/quantization/test_qat.py: 6 warnings
2026-01-14T09:34:56.1377558Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:34:56.1378781Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:101: UserWarning: `Int8DynamicActivationInt4WeightConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1379984Z     warnings.warn(
2026-01-14T09:34:56.1380115Z 
2026-01-14T09:34:56.1380444Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:34:56.1381219Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272
2026-01-14T09:34:56.1381955Z test/core/test_config.py::test_reconstructable_dict_file_round_trip[config14]
2026-01-14T09:34:56.1383272Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:272: UserWarning: `GemliteUIntXWeightOnlyConfig` will be deleted in a future release of torchao. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1384472Z     warnings.warn(
2026-01-14T09:34:56.1384600Z 
2026-01-14T09:34:56.1384927Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: 1 warning
2026-01-14T09:34:56.1385468Z test/core/test_config.py: 1 warning
2026-01-14T09:34:56.1385760Z test/prototype/test_parq.py: 25 warnings
2026-01-14T09:34:56.1386095Z test/quantization/test_quant_api.py: 2 warnings
2026-01-14T09:34:56.1387349Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:1900: UserWarning: Config Deprecation: _default is deprecated and will no longer be supported in a future release. Please see https://github.com/pytorch/ao/issues/3229 for more details.
2026-01-14T09:34:56.1388503Z     warnings.warn(
2026-01-14T09:34:56.1388637Z 
2026-01-14T09:34:56.1388765Z test/prototype/mx_formats/test_mx_tensor.py:531
2026-01-14T09:34:56.1389897Z   /pytorch/ao/test/prototype/mx_formats/test_mx_tensor.py:531: PytestUnknownMarkWarning: Unknown pytest.mark.skipIf - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
2026-01-14T09:34:56.1391074Z     @pytest.mark.skipIf(not is_sm_at_least_90(), "Need sm90+")
2026-01-14T09:34:56.1391342Z 
2026-01-14T09:34:56.1391670Z ../../opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360
2026-01-14T09:34:56.1393382Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/quantization/quant_api.py:360: UserWarning: `Float8StaticActivationFloat8WeightConfig` version 1 will be deleted in a future release of torchao. Please migrate to version 2 by setting version=2. Please see https://github.com/pytorch/ao/issues/2752 for more details.
2026-01-14T09:34:56.1394799Z     warnings.warn(
2026-01-14T09:34:56.1394927Z 
2026-01-14T09:34:56.1395059Z test/dtypes/test_affine_quantized.py: 7 warnings
2026-01-14T09:34:56.1395459Z test/integration/test_integration.py: 52 warnings
2026-01-14T09:34:56.1395818Z test/quantization/test_quant_api.py: 8 warnings
2026-01-14T09:34:56.1397135Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:963: UserWarning: Config Deprecation: version 1 of Int8WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2752 for more details
2026-01-14T09:34:56.1398417Z     warnings.warn(
2026-01-14T09:34:56.1398545Z 
2026-01-14T09:34:56.1398683Z test/dtypes/test_affine_quantized.py: 10 warnings
2026-01-14T09:34:56.1399016Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:34:56.1399340Z test/integration/test_integration.py: 18 warnings
2026-01-14T09:34:56.1399691Z test/quantization/test_quant_api.py: 17 warnings
2026-01-14T09:34:56.1401011Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/quant_api.py:827: UserWarning: Config Deprecation: version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please use version 2, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:34:56.1402297Z     warnings.warn(
2026-01-14T09:34:56.1402428Z 
2026-01-14T09:34:56.1402554Z test/dtypes/test_affine_quantized.py: 9 warnings
2026-01-14T09:34:56.1402891Z test/hqq/test_hqq_affine.py: 1 warning
2026-01-14T09:34:56.1403210Z test/integration/test_integration.py: 52 warnings
2026-01-14T09:34:56.1403566Z test/quantization/test_quant_api.py: 5 warnings
2026-01-14T09:34:56.1406065Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/tensor_core_tiled_layout.py:241: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:34:56.1407653Z     warnings.warn(
2026-01-14T09:34:56.1407788Z 
2026-01-14T09:34:56.1407911Z test/dtypes/test_affine_quantized.py: 1 warning
2026-01-14T09:34:56.1408307Z test/integration/test_integration.py: 18 warnings
2026-01-14T09:34:56.1408663Z test/quantization/test_quant_api.py: 30 warnings
2026-01-14T09:34:56.1410235Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/dtypes/uintx/int4_cpu_layout.py:82: UserWarning: Models quantized with version 1 of Int4WeightOnlyConfig is deprecated and will no longer be supported in a future release, please upgrade torchao and quantize again, or download a newer torchao checkpoint, see https://github.com/pytorch/ao/issues/2948 for more details
2026-01-14T09:34:56.1411969Z     warnings.warn(
2026-01-14T09:34:56.1412106Z 
2026-01-14T09:34:56.1412289Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:34:56.1412733Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:34:56.1413174Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:34:56.1414515Z   /pytorch/ao/test/dtypes/test_nf4.py:224: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:34:56.1415922Z     torch.testing.assert_allclose(input_tensor, nf4_to_dtype, atol=0.13, rtol=0.13)
2026-01-14T09:34:56.1416284Z 
2026-01-14T09:34:56.1416459Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_bfloat16
2026-01-14T09:34:56.1416902Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float16
2026-01-14T09:34:56.1417400Z test/dtypes/test_nf4.py::TestNF4Linear::test_to_copy_float32
2026-01-14T09:34:56.1418728Z   /pytorch/ao/test/dtypes/test_nf4.py:230: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:34:56.1420032Z     torch.testing.assert_allclose(
2026-01-14T09:34:56.1420223Z 
2026-01-14T09:34:56.1420323Z test/float8/test_base.py: 36 warnings
2026-01-14T09:34:56.1421506Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/float8/float8_linear.py:261: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
2026-01-14T09:34:56.1422727Z     autocast_dtype = torch.get_autocast_gpu_dtype()
2026-01-14T09:34:56.1422966Z 
2026-01-14T09:34:56.1423159Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_0_cuda
2026-01-14T09:34:56.1423634Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_mm_1_cuda
2026-01-14T09:34:56.1425003Z   /pytorch/ao/test/kernel/test_autotuner.py:50: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:34:56.1426324Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:34:56.1426559Z 
2026-01-14T09:34:56.1426771Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_0_cuda
2026-01-14T09:34:56.1427296Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_1_cpu
2026-01-14T09:34:56.1427804Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_2_cuda
2026-01-14T09:34:56.1428324Z test/kernel/test_autotuner.py::TestQuantFlow::test_int_scaled_mm_3_cpu
2026-01-14T09:34:56.1429763Z   /pytorch/ao/test/kernel/test_autotuner.py:96: FutureWarning: `torch.testing.assert_allclose()` is deprecated since 1.12 and will be removed in a future release. Please use `torch.testing.assert_close()` instead. You can find detailed upgrade instructions in https://github.com/pytorch/pytorch/issues/61844.
2026-01-14T09:34:56.1431080Z     torch.testing.assert_allclose(out32_1, out32_2)
2026-01-14T09:34:56.1431363Z 
2026-01-14T09:34:56.1431664Z test/prototype/test_codebook_quant.py::TestCodebookQuantization::test_choose_qparams_codebook
2026-01-14T09:34:56.1432990Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/testing/_internal/common_utils.py:904: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1517.)
2026-01-14T09:34:56.1434093Z     return callable(*args, **kwargs)
2026-01-14T09:34:56.1434286Z 
2026-01-14T09:34:56.1434509Z test/prototype/test_parametrization.py::TestFakeSparsity::test_jit_trace
2026-01-14T09:34:56.1436144Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/sparsifier/utils.py:134: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
2026-01-14T09:34:56.1437649Z     assert self.mask.shape == x.shape
2026-01-14T09:34:56.1437848Z 
2026-01-14T09:34:56.1438059Z test/prototype/test_scheduler.py::TestScheduler::test_lambda_scheduler
2026-01-14T09:34:56.1438561Z test/prototype/test_scheduler.py::TestCubicScheduler::test_step
2026-01-14T09:34:56.1439849Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/scheduler/base_scheduler.py:133: UserWarning: Detected call of `scheduler.step()` before `sparsifier.step()`. You have to make sure you run the sparsifier.step() BEFORE any calls to the scheduler.step().
2026-01-14T09:34:56.1441077Z     warnings.warn(
2026-01-14T09:34:56.1441209Z 
2026-01-14T09:34:56.1441534Z test/prototype/test_structured_sparsifier.py::TestBaseStructuredSparsifier::test_complex_conv2d
2026-01-14T09:34:56.1442713Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/prototype/sparsity/pruner/prune_functions.py:347: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
2026-01-14T09:34:56.1444078Z   Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)
2026-01-14T09:34:56.1444757Z     flattened_pruned_biases = torch.tensor(
2026-01-14T09:34:56.1444964Z 
2026-01-14T09:34:56.1445229Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_conv_relu
2026-01-14T09:34:56.1446595Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:42: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:34:56.1447894Z     m, guards = torchdynamo.export(  # noqa: F841©
2026-01-14T09:34:56.1448126Z 
2026-01-14T09:34:56.1448369Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_conv_bn_relu
2026-01-14T09:34:56.1449872Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:86: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:34:56.1451110Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:34:56.1451380Z 
2026-01-14T09:34:56.1451696Z test/quantization/pt2e/test_graph_utils.py::TestGraphUtils::test_customized_equivalet_types_dict
2026-01-14T09:34:56.1453193Z   /pytorch/ao/test/quantization/pt2e/test_graph_utils.py:118: FutureWarning: export(f, *args, **kwargs) is deprecated, use export(f)(*args, **kwargs) instead.  If you don't migrate, we may break your export call in the future if your user defined kwargs conflict with future kwargs added to export(f).
2026-01-14T09:34:56.1454430Z     m, guards = torchdynamo.export(  # noqa: F841
2026-01-14T09:34:56.1454660Z 
2026-01-14T09:34:56.1454827Z test/quantization/pt2e/test_quantize_pt2e.py: 18 warnings
2026-01-14T09:34:56.1455323Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 88 warnings
2026-01-14T09:34:56.1455761Z test/quantization/pt2e/test_representation.py: 8 warnings
2026-01-14T09:34:56.1456512Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/_xnnpack_quantizer.py:289: UserWarning: XNNPACKQuantizer is deprecated!
2026-01-14T09:34:56.1457281Z     warnings.warn(f"{self.__class__.__name__} is deprecated!")
2026-01-14T09:34:56.1457550Z 
2026-01-14T09:34:56.1457890Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_conv_linear_quantization
2026-01-14T09:34:56.1458603Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_embedding_quantizer
2026-01-14T09:34:56.1459599Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/testing/pt2e/utils.py:108: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:34:56.1460402Z   For migrations of users: 
2026-01-14T09:34:56.1461144Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:34:56.1462581Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:34:56.1463825Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:34:56.1464503Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:34:56.1464940Z     m_fx = prepare_fx(
2026-01-14T09:34:56.1465091Z 
2026-01-14T09:34:56.1465362Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_model_is_exported
2026-01-14T09:34:56.1466715Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/fx/_symbolic_trace.py:941: UserWarning: Was not able to add assertion to guarantee correct input x to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.
2026-01-14T09:34:56.1467961Z     warnings.warn(
2026-01-14T09:34:56.1468092Z 
2026-01-14T09:34:56.1468335Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:34:56.1469029Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_fold_bn_erases_bn_node
2026-01-14T09:34:56.1469830Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_fold_bn_erases_bn_node
2026-01-14T09:34:56.1470914Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/utils.py:145: UserWarning: must run observer before calling calculate_qparams. Returning default values.
2026-01-14T09:34:56.1471735Z     warnings.warn(
2026-01-14T09:34:56.1471865Z 
2026-01-14T09:34:56.1472101Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_reentrant
2026-01-14T09:34:56.1473216Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:1360: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point 
2026-01-14T09:34:56.1474173Z     warnings.warn(
2026-01-14T09:34:56.1474301Z 
2026-01-14T09:34:56.1474536Z test/quantization/pt2e/test_quantize_pt2e.py::TestQuantizePT2E::test_save_load
2026-01-14T09:34:56.1476833Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/export/pt2_archive/_package.py:682: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1581.)
2026-01-14T09:34:56.1478948Z     tensor = torch.frombuffer(
2026-01-14T09:34:56.1479166Z 
2026-01-14T09:34:56.1479554Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:34:56.1480444Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:34:56.1481351Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn1d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:34:56.1482231Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_bias_derived_qspec
2026-01-14T09:34:56.1483120Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_conv_bn_per_channel_weight_bias
2026-01-14T09:34:56.1484018Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_per_channel_weight_custom_dtype
2026-01-14T09:34:56.1484842Z test/quantization/pt2e/test_quantize_pt2e_qat.py::TestQuantizePT2EQAT_ConvBn2d::test_qat_shared_qspec
2026-01-14T09:34:56.1486153Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/observer.py:263: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.
2026-01-14T09:34:56.1487214Z     warnings.warn(
2026-01-14T09:34:56.1487349Z 
2026-01-14T09:34:56.1487523Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T09:34:56.1488371Z   /pytorch/ao/test/quantization/pt2e/test_quantize_pt2e_qat.py:169: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:34:56.1489091Z   For migrations of users: 
2026-01-14T09:34:56.1489837Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:34:56.1491358Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:34:56.1492608Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:34:56.1493287Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:34:56.1493658Z     model_fx = prepare_qat_fx(
2026-01-14T09:34:56.1493833Z 
2026-01-14T09:34:56.1494007Z test/quantization/pt2e/test_quantize_pt2e_qat.py: 48 warnings
2026-01-14T09:34:56.1494914Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/ao/quantization/fx/prepare.py:464: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:34:56.1495736Z   For migrations of users: 
2026-01-14T09:34:56.1496478Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:34:56.1497921Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:34:56.1499168Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:34:56.1499842Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:34:56.1500355Z     convert(root, mapping=module_to_qat_module, inplace=True, remove_qconfig=False)
2026-01-14T09:34:56.1500705Z 
2026-01-14T09:34:56.1501038Z test/quantization/pt2e/test_x86inductor_fusion.py::TestPatternMatcher::test_qconv2d_add_3
2026-01-14T09:34:56.1501796Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_filter_conv2d_recipe
2026-01-14T09:34:56.1506449Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:1325: UserWarning: The input of maxpool2d is not quantized, skip annotate maxpool2d with config QuantizationConfig(input_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), output_activation=QuantizationSpec(dtype=torch.uint8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.HistogramObserver'>, eps=0.000244140625){}, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, ch_axis=None, is_dynamic=False), weight=QuantizationSpec(dtype=torch.int8, observer_or_fake_quant_ctr=functools.partial(<class 'torchao.quantization.pt2e.observer.PerChannelMinMaxObserver'>, eps=0.000244140625){}, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, ch_axis=0, is_dynamic=False), bias=None, is_qat=False).
2026-01-14T09:34:56.1511113Z     warnings.warn(
2026-01-14T09:34:56.1511246Z 
2026-01-14T09:34:56.1511581Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T09:34:56.1512352Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_q_attention_block
2026-01-14T09:34:56.1513196Z test/quantization/pt2e/test_x86inductor_fusion.py::TestDynamicPatternMatcher::test_qconv2d_maxpool2d_linear_dynamic_cpu
2026-01-14T09:34:56.1514783Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torch/_inductor/mkldnn_lowerings.py:736: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
2026-01-14T09:34:56.1516097Z     torch.tensor(w_zp_tensor, dtype=torch.int32), name=w_zp.get_name()
2026-01-14T09:34:56.1516392Z 
2026-01-14T09:34:56.1516918Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:34:56.1518196Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:484: UserWarning: Mixed dynamic and static quantization config is not supported.
2026-01-14T09:34:56.1519073Z     warnings.warn(
2026-01-14T09:34:56.1519202Z 
2026-01-14T09:34:56.1519680Z test/quantization/pt2e/test_x86inductor_quantizer.py::TestQuantizePT2EX86Inductor::test_set_module_name_and_module_type_with_mixed_configs
2026-01-14T09:34:56.1521007Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/pt2e/quantizer/x86_inductor_quantizer.py:383: UserWarning: Skip the quantization config for <class 'torch.nn.modules.linear.Linear'>.
2026-01-14T09:34:56.1521930Z     warnings.warn(
2026-01-14T09:34:56.1522062Z 
2026-01-14T09:34:56.1522266Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:34:56.1523421Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'IntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:34:56.1524440Z   
2026-01-14T09:34:56.1524757Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:34:56.1525239Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:34:56.1525589Z       # train (not shown)
2026-01-14T09:34:56.1525906Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:34:56.1526238Z   
2026-01-14T09:34:56.1526540Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:34:56.1526912Z   
2026-01-14T09:34:56.1527345Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:34:56.1527944Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:34:56.1528340Z       qat_config = QATConfig(
2026-01-14T09:34:56.1528612Z           activation_config=activation_config,
2026-01-14T09:34:56.1528963Z           weight_config=weight_config,
2026-01-14T09:34:56.1529242Z           step="prepare",
2026-01-14T09:34:56.1529461Z       )
2026-01-14T09:34:56.1529656Z       quantize_(model, qat_config)
2026-01-14T09:34:56.1529901Z   
2026-01-14T09:34:56.1530202Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:34:56.1530584Z           
2026-01-14T09:34:56.1530776Z     warnings.warn(
2026-01-14T09:34:56.1530904Z 
2026-01-14T09:34:56.1531109Z test/quantization/test_qat.py::TestQAT::test_legacy_quantize_api_e2e
2026-01-14T09:34:56.1532340Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/quantization/qat/utils.py:84: UserWarning: 'FromIntXQuantizationAwareTrainingConfig' is deprecated and will be removed in a future release. Please use the following API instead:
2026-01-14T09:34:56.1533388Z   
2026-01-14T09:34:56.1533699Z       base_config = Int8DynamicActivationInt4WeightConfig(group_size=32)
2026-01-14T09:34:56.1534188Z       quantize_(model, QATConfig(base_config, step="prepare"))
2026-01-14T09:34:56.1534530Z       # train (not shown)
2026-01-14T09:34:56.1534841Z       quantize_(model, QATConfig(base_config, step="convert"))
2026-01-14T09:34:56.1535169Z   
2026-01-14T09:34:56.1535465Z   Alternatively, if you prefer to pass in fake quantization configs:
2026-01-14T09:34:56.1535831Z   
2026-01-14T09:34:56.1536213Z       activation_config = IntxFakeQuantizeConfig(torch.int8, "per_token", is_symmetric=False)
2026-01-14T09:34:56.1536810Z       weight_config = IntxFakeQuantizeConfig(torch.int4, group_size=32)
2026-01-14T09:34:56.1537255Z       qat_config = QATConfig(
2026-01-14T09:34:56.1537537Z           activation_config=activation_config,
2026-01-14T09:34:56.1537843Z           weight_config=weight_config,
2026-01-14T09:34:56.1538117Z           step="prepare",
2026-01-14T09:34:56.1538335Z       )
2026-01-14T09:34:56.1538575Z       quantize_(model, qat_config)
2026-01-14T09:34:56.1538820Z   
2026-01-14T09:34:56.1539127Z   Please see https://github.com/pytorch/ao/issues/2630 for more details.
2026-01-14T09:34:56.1539512Z           
2026-01-14T09:34:56.1539694Z     warnings.warn(
2026-01-14T09:34:56.1539823Z 
2026-01-14T09:34:56.1540140Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:34:56.1541866Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/blocksparse.py:198: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)
2026-01-14T09:34:56.1543409Z     bsr_tensor = dense_tensor.to_sparse_bsr(blocksize)
2026-01-14T09:34:56.1543649Z 
2026-01-14T09:34:56.1543962Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:35:32.1593397Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1595467Z     warn_once(
2026-01-14T09:35:32.1595712Z 
2026-01-14T09:35:32.1596359Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1
2026-01-14T09:35:32.1599790Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1602336Z     warn_once(
2026-01-14T09:35:32.1602580Z 
2026-01-14T09:35:32.1603264Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:35:32.1605368Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=2048 K=1024 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1606652Z     warn_once(
2026-01-14T09:35:32.1606774Z 
2026-01-14T09:35:32.1607098Z test/sparsity/test_sparse_api.py::TestBlockSparseWeight::test_sparse_compile_False_input_shape_1024
2026-01-14T09:35:32.1608631Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=1024 K=2048 N=1024 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.float16 out_dtype=torch.float16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1609910Z     warn_once(
2026-01-14T09:35:32.1610038Z 
2026-01-14T09:35:32.1610316Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:35:32.1611865Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=256 K=128 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1613124Z     warn_once(
2026-01-14T09:35:32.1613255Z 
2026-01-14T09:35:32.1613526Z test/sparsity/test_sparse_api.py::TestQuantBlockSparseWeight::test_sparse_compile_False
2026-01-14T09:35:32.1617626Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/kernel/bsr_triton_ops.py:240: UserWarning: bsr_dense_addmm uses non-optimal triton kernel parameters for M=128 K=256 N=256 Ms=64, Ks=64 beta=0 alpha=1 dtype=torch.int8 out_dtype=torch.bfloat16. To find optimal triton kernel parameters, run with BSR_AUTOTUNE=1
2026-01-14T09:35:32.1618993Z     warn_once(
2026-01-14T09:35:32.1619124Z 
2026-01-14T09:35:32.1619348Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T09:35:32.1620310Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:46: UserWarning: WandaSparsifier got semi_structured_bock_size=4, sparsity_level fixed to 50% (2:4) sparsity
2026-01-14T09:35:32.1621147Z     warnings.warn(
2026-01-14T09:35:32.1621281Z 
2026-01-14T09:35:32.1621506Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_2x4
2026-01-14T09:35:32.1622070Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_one_layer_mlp_unstructured
2026-01-14T09:35:32.1622613Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_prepare
2026-01-14T09:35:32.1623100Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_squash_mask
2026-01-14T09:35:32.1623653Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured
2026-01-14T09:35:32.1624312Z test/sparsity/test_wanda.py::TestWandaSparsifier::test_two_layer_mlp_unstructured_custom_config
2026-01-14T09:35:32.1625308Z   /opt/conda/envs/venv/lib/python3.10/site-packages/torchao/sparsity/wanda.py:75: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. 
2026-01-14T09:35:32.1626095Z   For migrations of users: 
2026-01-14T09:35:32.1626832Z   1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead 
2026-01-14T09:35:32.1628271Z   2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) 
2026-01-14T09:35:32.1629590Z   3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) 
2026-01-14T09:35:32.1630273Z   see https://github.com/pytorch/ao/issues/2259 for more details
2026-01-14T09:35:32.1630709Z     torch.ao.quantization.prepare(model, inplace=True)
2026-01-14T09:35:32.1631002Z 
2026-01-14T09:35:32.1631216Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-01-14T09:35:32.1632225Z [33m======== [32m2542 passed[0m, [33m[1m6428 skipped[0m, [33m[1m694 warnings[0m[33m in 3764.96s (1:02:44)[0m[33m =========[0m
2026-01-14T09:35:32.1700673Z ##[group]Run pmeier/pytest-results-action@a2c1430e2bddadbad9f49a6f9b879f062c6b19b1
2026-01-14T09:35:32.1701143Z with:
2026-01-14T09:35:32.1701429Z   path: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:32.1701806Z   fail-on-empty: false
2026-01-14T09:35:32.1702085Z env:
2026-01-14T09:35:32.1702337Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:32.1702665Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:32.1702904Z   PR_NUMBER: 3500
2026-01-14T09:35:32.1704436Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:32.1706157Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:32.1706704Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:32.1707226Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:32.1707593Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:32.1707876Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:32.1708213Z ##[endgroup]
2026-01-14T09:35:32.2319859Z Prepare all required actions
2026-01-14T09:35:32.2359815Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:35:32.2360179Z with:
2026-01-14T09:35:32.2360573Z   directory: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:35:32.2361052Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:35:32.2361451Z env:
2026-01-14T09:35:32.2361705Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:32.2362038Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:32.2362296Z   PR_NUMBER: 3500
2026-01-14T09:35:32.2363804Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:32.2365660Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:32.2366210Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:32.2366745Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:32.2367126Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:32.2367423Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:32.2367766Z ##[endgroup]
2026-01-14T09:35:32.2389922Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:35:32.2390604Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:35:32.2404745Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:35:32.2405103Z env:
2026-01-14T09:35:32.2405352Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:32.2405702Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:32.2405958Z   PR_NUMBER: 3500
2026-01-14T09:35:32.2407459Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:32.2409251Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:32.2409810Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:32.2410336Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:32.2410714Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:32.2411010Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:32.2411612Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:35:32.2412087Z   DIRECTORY: /home/ec2-user/actions-runner/_work/ao/ao/
2026-01-14T09:35:32.2412424Z ##[endgroup]
2026-01-14T09:35:32.2667031Z Unable to find image '308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest' locally
2026-01-14T09:35:32.4740477Z latest: Pulling from tool/alpine
2026-01-14T09:35:32.4741112Z 540db60ca938: Pulling fs layer
2026-01-14T09:35:32.5796143Z 540db60ca938: Verifying Checksum
2026-01-14T09:35:32.5796632Z 540db60ca938: Download complete
2026-01-14T09:35:32.6900837Z 540db60ca938: Pull complete
2026-01-14T09:35:32.6969357Z Digest: sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:35:32.6995256Z Status: Downloaded newer image for 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:35:33.7070401Z Prepare all required actions
2026-01-14T09:35:33.7100959Z ##[group]Run ./test-infra/.github/actions/chown-directory
2026-01-14T09:35:33.7101295Z with:
2026-01-14T09:35:33.7101549Z   directory: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:35:33.7102005Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:35:33.7102389Z env:
2026-01-14T09:35:33.7102634Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:33.7103144Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:33.7103387Z   PR_NUMBER: 3500
2026-01-14T09:35:33.7104880Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:33.7106579Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:33.7107131Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:33.7107650Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:33.7108022Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:33.7108322Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:33.7108651Z ##[endgroup]
2026-01-14T09:35:33.7132275Z ##[group]Run docker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .
2026-01-14T09:35:33.7132967Z [36;1mdocker run --rm -v "${DIRECTORY}":/v -w /v "${ALPINE_IMAGE}" chown -R "$(id -u):$(id -g)" .[0m
2026-01-14T09:35:33.7148223Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:35:33.7148582Z env:
2026-01-14T09:35:33.7148833Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:33.7149345Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:33.7149597Z   PR_NUMBER: 3500
2026-01-14T09:35:33.7151102Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:33.7152794Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:33.7153470Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:33.7153994Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:33.7154376Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:33.7154675Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:33.7155145Z   ALPINE_IMAGE: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine
2026-01-14T09:35:33.7155615Z   DIRECTORY: /home/ec2-user/actions-runner/_work/_temp
2026-01-14T09:35:33.7155946Z ##[endgroup]
2026-01-14T09:35:34.9999515Z ##[group]Run # Only do these steps if we actually want to upload an artifact
2026-01-14T09:35:35.0000092Z [36;1m# Only do these steps if we actually want to upload an artifact[0m
2026-01-14T09:35:35.0000547Z [36;1mif [[ -n "${UPLOAD_ARTIFACT_NAME}" ]]; then[0m
2026-01-14T09:35:35.0001071Z [36;1m  # If the default execution path is followed then we should get a wheel in the dist/ folder[0m
2026-01-14T09:35:35.0001698Z [36;1m  # attempt to just grab whatever is in there and scoop it all up[0m
2026-01-14T09:35:35.0002201Z [36;1m  if find "dist/" -name "*.whl" >/dev/null 2>/dev/null; then[0m
2026-01-14T09:35:35.0002628Z [36;1m    mv -v dist/*.whl "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:35:35.0002968Z [36;1m  fi[0m
2026-01-14T09:35:35.0003237Z [36;1m  if [[ -d "artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:35:35.0003688Z [36;1m    mv -v artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:35:35.0004067Z [36;1m  fi[0m
2026-01-14T09:35:35.0004395Z [36;1m  if [[ -d "${RUNNER_TEMP}/artifacts-to-be-uploaded" ]]; then[0m
2026-01-14T09:35:35.0004928Z [36;1m    mv -v "${RUNNER_TEMP}"/artifacts-to-be-uploaded/* "${RUNNER_ARTIFACT_DIR}/"[0m
2026-01-14T09:35:35.0005383Z [36;1m  fi[0m
2026-01-14T09:35:35.0005592Z [36;1mfi[0m
2026-01-14T09:35:35.0005786Z [36;1m[0m
2026-01-14T09:35:35.0006105Z [36;1mupload_docs=0[0m
2026-01-14T09:35:35.0006495Z [36;1m# Check if there are files in the documentation folder to upload, note that[0m
2026-01-14T09:35:35.0006954Z [36;1m# empty folders do not count[0m
2026-01-14T09:35:35.0007378Z [36;1mif find "${RUNNER_DOCS_DIR}" -mindepth 1 -maxdepth 1 -type f | read -r; then[0m
2026-01-14T09:35:35.0007974Z [36;1m  # TODO: Add a check here to test if on ec2 because if we're not on ec2 then this[0m
2026-01-14T09:35:35.0008476Z [36;1m  # upload will probably not work correctly[0m
2026-01-14T09:35:35.0008802Z [36;1m  upload_docs=1[0m
2026-01-14T09:35:35.0009048Z [36;1mfi[0m
2026-01-14T09:35:35.0009345Z [36;1mecho "upload-docs=${upload_docs}" >> "${GITHUB_OUTPUT}"[0m
2026-01-14T09:35:35.0020343Z shell: /usr/bin/bash -e {0}
2026-01-14T09:35:35.0020609Z env:
2026-01-14T09:35:35.0020949Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:35.0021322Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:35.0021562Z   PR_NUMBER: 3500
2026-01-14T09:35:35.0023089Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:35.0024793Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:35.0025346Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:35.0025879Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:35.0026260Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:35.0026559Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:35.0026916Z   UPLOAD_ARTIFACT_NAME: 
2026-01-14T09:35:35.0027158Z ##[endgroup]
2026-01-14T09:35:35.0151036Z Prepare all required actions
2026-01-14T09:35:35.0189967Z ##[group]Run ./test-infra/.github/actions/teardown-linux
2026-01-14T09:35:35.0190311Z with:
2026-01-14T09:35:35.0190588Z env:
2026-01-14T09:35:35.0190829Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:35.0191155Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:35.0191397Z   PR_NUMBER: 3500
2026-01-14T09:35:35.0192895Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:35.0194567Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:35.0195152Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:35.0195672Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:35.0196051Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:35.0196342Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:35.0196680Z ##[endgroup]
2026-01-14T09:35:35.0220955Z ##[group]Run set -eou pipefail
2026-01-14T09:35:35.0221245Z [36;1mset -eou pipefail[0m
2026-01-14T09:35:35.0221498Z [36;1m[0m
2026-01-14T09:35:35.0221845Z [36;1mecho "Holding runner for 2 hours until all ssh sessions have logged out"[0m
2026-01-14T09:35:35.0222298Z [36;1mfor _ in $(seq 1440); do[0m
2026-01-14T09:35:35.0222618Z [36;1m    # Break if no ssh session exists anymore[0m
2026-01-14T09:35:35.0222948Z [36;1m    if [ "$(who)" = "" ]; then[0m
2026-01-14T09:35:35.0223234Z [36;1m      break[0m
2026-01-14T09:35:35.0223449Z [36;1m    fi[0m
2026-01-14T09:35:35.0223666Z [36;1m    echo "."[0m
2026-01-14T09:35:35.0223894Z [36;1m    sleep 5[0m
2026-01-14T09:35:35.0224126Z [36;1mdone[0m
2026-01-14T09:35:35.0232494Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:35:35.0232960Z env:
2026-01-14T09:35:35.0233205Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:35.0233552Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:35.0233797Z   PR_NUMBER: 3500
2026-01-14T09:35:35.0235306Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:35.0236994Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:35.0237557Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:35.0238090Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:35.0238468Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:35.0238773Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:35.0239114Z ##[endgroup]
2026-01-14T09:35:35.0269971Z Holding runner for 2 hours until all ssh sessions have logged out
2026-01-14T09:35:35.0366180Z ##[group]Run # ignore expansion of "docker ps -q" since it could be empty
2026-01-14T09:35:35.0366714Z [36;1m# ignore expansion of "docker ps -q" since it could be empty[0m
2026-01-14T09:35:35.0367129Z [36;1m# shellcheck disable=SC2046[0m
2026-01-14T09:35:35.0367442Z [36;1mdocker stop $(docker ps -q) || true[0m
2026-01-14T09:35:35.0367778Z [36;1m# Prune all of the docker images[0m
2026-01-14T09:35:35.0368097Z [36;1mdocker system prune -af[0m
2026-01-14T09:35:35.0377492Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:35:35.0377849Z env:
2026-01-14T09:35:35.0378096Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:35.0378650Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:35.0378906Z   PR_NUMBER: 3500
2026-01-14T09:35:35.0380423Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:35.0382205Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:35.0382763Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:35.0383302Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:35.0383677Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:35.0383992Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:35.0384341Z ##[endgroup]
2026-01-14T09:35:36.2139871Z 451254f3fa53
2026-01-14T09:35:44.1427441Z Deleted Containers:
2026-01-14T09:35:44.1427837Z 451254f3fa5348b7469a76b736b562f41522bc2bbdcbaf083564ac4d246c8605
2026-01-14T09:35:44.1428158Z 
2026-01-14T09:35:52.4897986Z Deleted Images:
2026-01-14T09:35:52.4898424Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine:latest
2026-01-14T09:35:52.4899798Z untagged: 308535385114.dkr.ecr.us-east-1.amazonaws.com/tool/alpine@sha256:def822f9851ca422481ec6fee59a9966f12b351c62ccb9aca841526ffaa9f748
2026-01-14T09:35:52.4900704Z deleted: sha256:6dbb9cc54074106d46d4ccb330f2a40a682d49dda5f4844962b7dce9fe44aaec
2026-01-14T09:35:52.4901338Z deleted: sha256:b2d5eeeaba3a22b9b8aa97261957974a6bd65274ebd43e1d81d0a7b8b752b116
2026-01-14T09:35:52.4902020Z untagged: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:52.4902593Z untagged: pytorch/almalinux-builder@sha256:38e012b20747e9f72b4c4dc2ffb4134a450ad6e57e64886e7daf42b9a8ffa9f2
2026-01-14T09:35:52.4903544Z deleted: sha256:bb1a1950b861327b13d8893bffd39e26f8e80f9318971babe6b3f9bab8d65d21
2026-01-14T09:35:52.4904386Z deleted: sha256:a54dbc7bc094481efb3d7798f26feac4f04f2c7d3b16372162cacf83ed2388ce
2026-01-14T09:35:52.4905385Z deleted: sha256:645a24a13a583a58c04ea348b38daba4a40b2bbe09eb2012e9d33e823ff99c8e
2026-01-14T09:35:52.4905984Z deleted: sha256:74c5765839aa7e92b734630a11e6a02dc4f9932142efb4becedf62941283e0cd
2026-01-14T09:35:52.4906558Z deleted: sha256:7a626ac79b7f4d3436fb97d7a7ca125845805c133303239c31f4eed62b556453
2026-01-14T09:35:52.4907150Z deleted: sha256:31c03ed8c3f72312100269f048fea1b331a93b53b496ce34be4bac621109f901
2026-01-14T09:35:52.4907744Z deleted: sha256:c32b905bbd58816c78ef90a77285dd4d9b1cdafdbaa7332cd398891b30feee8e
2026-01-14T09:35:52.4908341Z deleted: sha256:4dc58665c3bd3ca188c201fdcfdeb41b0118191cd6843ddeda62495ba0c15986
2026-01-14T09:35:52.4908946Z deleted: sha256:dad808738bccf06931c05520f69d148be75a61afd28065e9aee100d5af6133bd
2026-01-14T09:35:52.4909526Z deleted: sha256:6e036a485561034f6c52610c6a2c7f11e64060ce9e2f10b3d4064a87d091745a
2026-01-14T09:35:52.4910122Z deleted: sha256:ef2ba6b1ca100c37739c13afedd9c52143448d948239c375f611f5bbe19f175d
2026-01-14T09:35:52.4910725Z deleted: sha256:37d850998e8d82d40ffce6b7020d480daecaa091b6fbac01c04a0da1f90f7e8f
2026-01-14T09:35:52.4911327Z deleted: sha256:16a70495db3a28a89c3250c0824d0e3e08c22dced61a31110ef1c7f8c5b127cd
2026-01-14T09:35:52.4911909Z deleted: sha256:b7982627380d2b6bc6a223770c8c18cb45dcc8229c32e1160fcb416a32fc969a
2026-01-14T09:35:52.4912482Z deleted: sha256:a4d99473e3f02923cf34c61996bf5a25863e8ee02801d6634174d671e0ac7367
2026-01-14T09:35:52.4913066Z deleted: sha256:2c683ce33d69b13bbcfe1f405137ff2aea4213c8228876ff55a791116cdcf2e2
2026-01-14T09:35:52.4913653Z deleted: sha256:ffaa389b629375310a946fd02f2f26fcf3678b2c23d94f4aab82a0fc46214892
2026-01-14T09:35:52.4914255Z deleted: sha256:e7ce15ca67e07966f2da85c8d2242c7535a7c9ab1f63b2069834ffba95a5978c
2026-01-14T09:35:52.4914854Z deleted: sha256:63b0fcbf70a9ee9ece0aeb6610359975830e1646da68f5f7722c2e64426bd4c7
2026-01-14T09:35:52.4915687Z deleted: sha256:5c48134bdee035683ad0d4846f19aa135bd7b8735e8c0b6420d13e5779f720e4
2026-01-14T09:35:52.4916292Z deleted: sha256:badca1798f4ace2b0179b607780a5cce32170bedeb23d076335fc973ec72f34c
2026-01-14T09:35:52.4916899Z deleted: sha256:ae88b0e9396996f876f32bf01d80534d3cf5c06c395eba64f7dd66dda56fa55f
2026-01-14T09:35:52.4917604Z deleted: sha256:b52e19c766f22b187f4fcd4e90cfb1e4e3c547dfe7484bf5423db65775cf352f
2026-01-14T09:35:52.4918203Z deleted: sha256:1d80070b73e86e9afa159ca72ee6fc6bcf7f387d21c1d6dcd065fa877e678592
2026-01-14T09:35:52.4918803Z deleted: sha256:ff4f19608a1944c0c2807cd533515673285a9632dc74bf020e83e18630d1ae35
2026-01-14T09:35:52.4919294Z untagged: public.ecr.aws/docker/library/python:3.13
2026-01-14T09:35:52.4919930Z untagged: public.ecr.aws/docker/library/python@sha256:02865b3929f3910fc2d6ebbf745bf00504d316478dacaea7d9e230e134411bcb
2026-01-14T09:35:52.4920686Z deleted: sha256:6b1b86f270ccdb848adf78330c7a27041a2f8e971cfd9c808e1ad503d236f9ae
2026-01-14T09:35:52.4921281Z deleted: sha256:ab3ff5992dd09a2d006ef37d701d92e11590962848a698a0824ab2129505b946
2026-01-14T09:35:52.4921874Z deleted: sha256:c839d2b1d0949c101d8e022855435eedb0179697af77be6012f911dfcb69742c
2026-01-14T09:35:52.4922470Z deleted: sha256:b3fb8a2c0606137f473565b54a51bb1e18dfca24cbc417e0f7a0b3d68395d9ea
2026-01-14T09:35:52.4923054Z deleted: sha256:a643465a85469890e6e498fe0d0ac4e6a251e77c92a179ac27085d4ffeb4c8da
2026-01-14T09:35:52.4923644Z deleted: sha256:09db7ba2ba0ebb76125f8bf37573369eb90202594586d30c6f9c202d968f4d00
2026-01-14T09:35:52.4924406Z deleted: sha256:ba4e59af8cdbb2e2cd899773f1cdbcb3027d48d9be333f5a823d9cccfd5c4a15
2026-01-14T09:35:52.4925248Z deleted: sha256:da7213941eca995ecec09e85fe1affcac44194792b48cbacdd3c0d9038bbaf9e
2026-01-14T09:35:52.4925644Z 
2026-01-14T09:35:52.4925757Z Total reclaimed space: 30.92GB
2026-01-14T09:35:52.4997324Z ##[group]Run set +e
2026-01-14T09:35:52.4997599Z [36;1mset +e[0m
2026-01-14T09:35:52.4997835Z [36;1mif [[ "${NO_SUDO}" == "false" ]]; then[0m
2026-01-14T09:35:52.4998220Z [36;1m  sudo rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:35:52.4998561Z [36;1melse[0m
2026-01-14T09:35:52.4998822Z [36;1m  rm -rf "${GITHUB_WORKSPACE:?}/${REPOSITORY:?}"[0m
2026-01-14T09:35:52.4999276Z [36;1mfi[0m
2026-01-14T09:35:52.4999480Z [36;1mset -e[0m
2026-01-14T09:35:52.5009413Z shell: /usr/bin/bash -e {0}
2026-01-14T09:35:52.5009655Z env:
2026-01-14T09:35:52.5009910Z   DOCKER_IMAGE: pytorch/almalinux-builder:cuda12.6
2026-01-14T09:35:52.5010240Z   REPOSITORY: pytorch/ao
2026-01-14T09:35:52.5010486Z   PR_NUMBER: 3500
2026-01-14T09:35:52.5012218Z   SCRIPT: conda create -n venv python=3.10 libgcc-ng=11.2.0 libstdcxx-ng=11.2.0 -y
conda activate venv
python -m pip install --upgrade pip
pip install torch==2.9.1
sed -i '' dev-requirements.txt
pip install -r dev-requirements.txt
pip install . --no-build-isolation
export CONDA=$(dirname $(dirname $(which conda)))
export LD_LIBRARY_PATH=$CONDA/lib/:$LD_LIBRARY_PATH
pytest test --verbose -s

2026-01-14T09:35:52.5027415Z   RUNNER_ARTIFACT_DIR: /home/ec2-user/actions-runner/_work/_temp/artifacts
2026-01-14T09:35:52.5027998Z   RUNNER_TEST_RESULTS_DIR: /home/ec2-user/actions-runner/_work/_temp/test-results
2026-01-14T09:35:52.5028527Z   RUNNER_DOCS_DIR: /home/ec2-user/actions-runner/_work/_temp/docs
2026-01-14T09:35:52.5028895Z   HAS_NVIDIA_GPU: true
2026-01-14T09:35:52.5029192Z   GPU_FLAG: --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all
2026-01-14T09:35:52.5029533Z   NO_SUDO: false
2026-01-14T09:35:52.5029732Z ##[endgroup]
2026-01-14T09:35:53.0375171Z Post job cleanup.
2026-01-14T09:35:53.1471213Z Post job cleanup.
2026-01-14T09:35:53.2457897Z [command]/usr/bin/git version
2026-01-14T09:35:53.2508985Z git version 2.50.1
2026-01-14T09:35:53.2555367Z Temporarily overriding HOME='/home/ec2-user/actions-runner/_work/_temp/3d2453fd-0e69-4d3c-846b-c27488604f80' before making global git config changes
2026-01-14T09:35:53.2556398Z Adding repository directory to the temporary git global config as a safe directory
2026-01-14T09:35:53.2560793Z [command]/usr/bin/git config --global --add safe.directory /home/ec2-user/actions-runner/_work/ao/ao/test-infra
2026-01-14T09:35:53.2604710Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-01-14T09:35:53.2645129Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-01-14T09:35:53.3067320Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-01-14T09:35:53.3096501Z http.https://github.com/.extraheader
2026-01-14T09:35:53.3108782Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-01-14T09:35:53.3146561Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-01-14T09:35:53.3659066Z A job completed hook has been configured by the self-hosted runner administrator
2026-01-14T09:35:53.3692267Z ##[group]Run '/home/ec2-user/runner-scripts/after_job.sh'
2026-01-14T09:35:53.3700529Z shell: /usr/bin/bash --noprofile --norc -e -o pipefail {0}
2026-01-14T09:35:53.3700906Z ##[endgroup]
2026-01-14T09:35:53.3827135Z [!ALERT!] Swap in detected! [!ALERT!]
2026-01-14T09:36:04.8862492Z [!ALERT!] Swap out detected [!ALERT!]
2026-01-14T09:36:23.5972823Z Cleaning up orphan processes